# Source: oecd governing with AI.pdf

**Type:** pdf

---

OECD

# Governing with Artificial Intelligence

The State of Play and Way Forward in Core Government Functions

---

# Governing with Artificial Intelligence

THE STATE OF PLAY AND WAY FORWARD IN CORE GOVERNMENT FUNCTIONS

OECD
BETTER POLICIES FOR BETTER LIVES

---

This work was approved and declassified by the Public Governance Committee on 05/09/2025.

This document, as well as any data and map included herein, are without prejudice to the status of or sovereignty over any territory, to the delimitation of international frontiers and boundaries and to the name of any territory, city or area.

The statistical data for Israel are supplied by and under the responsibility of the relevant Israeli authorities. The use of such data by the OECD is without prejudice to the status of the Golan Heights, East Jerusalem and Israeli settlements in the West Bank under the terms of international law.

Note by the Republic of Türkiye
The information in this document with reference to “Cyprus” relates to the southern part of the Island. There is no single authority representing both Turkish and Greek Cypriot people on the Island. Türkiye recognises the Turkish Republic of Northern Cyprus (TRNC). Until a lasting and equitable solution is found within the context of the United Nations, Türkiye shall preserve its position concerning the “Cyprus issue”.

Note by all the European Union Member States of the OECD and the European Union
The Republic of Cyprus is recognised by all members of the United Nations with the exception of Türkiye. The information in this document relates to the area under the effective control of the Government of the Republic of Cyprus.

Please cite this publication as:
OECD (2025), Governing with Artificial Intelligence: The State of Play and Way Forward in Core Government Functions, OECD Publishing, Paris, https://doi.org/10.1787/795de142-en.

ISBN 978-92-64-81828-6 (print)
ISBN 978-92-64-68405-8 (PDF)
ISBN 978-92-64-43767-8 (HTML)

Photo credits: Cover © cofotoisme/Getty Images.

Corrigenda to OECD publications may be found at: https://www.oecd.org/en/publications/support/corrigenda.html.

© OECD 2025

CC BY

Attribution 4.0 International (CC BY 4.0)
This work is made available under the Creative Commons Attribution 4.0 International licence. By using this work, you accept to be bound by the terms of this licence (https://creativecommons.org/licenses/by/4.0/).

**Attribution** - you must cite the work.

**Translations** - you must cite the original work, identify changes to the original and add the following text: In the event of any discrepancy between the original work and the translation, only the text of the original work should be considered valid.

**Adaptations** - you must cite the original work and add the following text: This is an adaptation of an original work by the OECD. The opinions expressed and arguments employed in this adaptation should not be reported as representing the official views of the OECD or of its Member countries.

**Third-party material** - the licence does not apply to third-party material in the work. If using such material, you are responsible for obtaining permission from the third party and for any claims of infringement.

You must not use the OECD logo, visual identity or cover image without express permission or suggest the OECD endorses your use of the work.

Any dispute arising under this licence shall be settled by arbitration in accordance with the Permanent Court of Arbitration (PCA) Arbitration Rules 2012. The seat of arbitration shall be Paris (France). The number of arbitrators shall be one.

---

| 3
# Foreword

In recent years, governments worldwide have made significant strides in the digitalisation of the public
sector, accelerated by the challenges posed by the COVID-19 pandemic. Despite these advancements,
many obstacles remain. Today, the focus is on harnessing digital technologies to better meet the needs of
citizens — creating efficiencies to deliver more value for taxpayers' money; providing tailored, accessible
and inclusive public services; and improving communication and engagement with citizens.

The importance of these efforts cannot be overstated. Enhanced government efficiency and effectiveness
are crucial, but the trust citizens place in their governments is equally important. Trust in government is a
key factor in the success of digital initiatives. Conversely, while OECD data from 2023 shows that only
39% of people have moderately high or greater trust in national government, reliable, responsive and fair
public services can enhance trust in government.

Artificial intelligence (Al) is becoming a significant component of the digital government journey, offering
substantial benefits in various areas such as automation, anomaly detection and improved decision
making. For example, Al-powered chatbots are being used to answer citizen queries and assist with form
filling. In disaster management, Al is helping to anticipate natural disasters and speed up response efforts.
In tax administration, Al is being used for fraud detection. Overall, the use of Al in government can improve
government productivity, responsiveness and accountability.

However, Al adoption in government trails behind that of the private sector. Governments face unique
contexts and challenges that hinder the rapid uptake of Al, including skills shortages, outdated legacy
systems, data availability and a financially constrained environment, as well as higher requirements
regarding privacy, transparency and representation of various groups.

In this fast-paced digital landscape, learning from experience is the best way to make progress. While Al
maturity is not yet prevalent in governments, there are many examples of Al applications from which
lessons can be drawn. The OECD is committed to supporting governments on their Al journey by facilitating
the sharing of experiences and insights. This report, built on the analysis of dozens of governance
approaches and 200 Al use cases, extensive research and discussions with governments serves as a
foundation for an ongoing workstream on "Governing with Al" (https://oecd.ai/gov). It aims to provide
governments with the necessary elements for effective Al use and to identify areas where Al is having an
impact and where gaps remain. Future efforts will build on the growing evidence base of policies and use
cases, seeking to further assist governments putting in place the enablers, guardrails and engagement
mechanisms needed for a strategic and trustworthy approach to Al.

The OECD acknowledges the efforts of many countries in accelerating the adoption of Al in government
beyond the data and insights analysed for this report. Their examples have been instrumental in shaping
our understanding of Al's role in transforming government.

This report is part of the OECD Horizontal Project on Thriving with Al: Empowering Economies and
Societies.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

4|

# Acknowledgements

This report was prepared by the OECD Public Governance Directorate (GOV), under the leadership of Elsa Pilichowski, Director, and Gillian Dorner, Deputy Director. It was developed as a joint effort across GOV, coordinated by the Innovative, Digital and Open Government Division (INDIGO) under the direction of Carlos Santiso, Head of Division, and supervision of Marco Daglio, acting Head of the Digital Government Unit (DGU). Jamie Berryhill, Barbara Ubaldi and Ricardo Zapata managed the project. Simone Maria Parazzoli and Paula Ayala, consultants, provided analytical and drafting support throughout the report.

Chapters 1-3 were drafted by Jamie Berryhill and Ricardo Zapata. Chapter 4 was drafted by Jamie Berryhill, Emma Cantera, Cecilia Emilsson, Felipe González, Julian Olsen, Seong Ju Park, María Pascual-Dapena, Arturo Rivera, Alex Seeman, Barbara Ubaldi and Ricardo Zapata (INDIGO); Daniel Gerson of the Public Management and Budgeting Division (PMB); Erika Bozzay, Simon Cox and András Hlács of the Infrastructure and Public Procurement Division (IPP); and Paula Ayala and Hana Murr, consultants.

Chapter 5 was a collaborative effort, with sections authored by:

*   **Tax administration**: Paul Marsh and Sofie Stenbøg of the Centre for Tax Policy and Administration (CTP) Tax Administration and VAT Division (TAV).
*   **Public financial management**: Delphine Moretti (GOV/PMB) and Nicolas Botton, consultant.
*   **Regulatory design and delivery**: Anna Pietikäinen, Giuseppa Ottimofiore, Becky King, James Drummond, Margarita Escobar, Carola Bertone, Alexander Roberts, Martha Baxter and Shemsije Jashari of GOV's Regulatory Policy Division (REG); and, Ekaterina Zakharyan and Vincent Van Langen, consultants.
*   **Civil service reform**: Daniel Gerson, Donal Mulligan, Alana Baker, Francois Villeneuve and Natalia Nolan-Flecha (GOV/PMB).
*   **Public procurement**: Erika Bozzay, Andras Hlacs, Simon Cox, Kenza Khachani (GOV/IPP) and Matthieu Cahen (GOV/DO).
*   **Fighting corruption and promoting public integrity**: Maria Eugenia Heyaca and Helene Wells of GOV's Anti-corruption and Integrity in Government Division (ACIG).
*   **Policy evaluation**: Stéphane Jacobzone, Silvia Picalarga (GOV/PMB) and Guste Papaurelyte, consultant.
*   **Civic participation and open government**: David Goessmann, Giulia Cibrario and Mauricio Mejía Galvan (GOV/INDIGO).
*   **Public service design and delivery**: Piret Tõnurist and Angela Hanson (GOV/INDIGO). Contributions were also made by Oscar Huerta of the OECD Centre for Entrepreneurship, SMEs, Regions and Cities (CFE) and Ailbhe Brioscu, Valerie Frey and Anne Lauringson of the OECD Directorate for Employment, Labour and Social Affairs (ELS).
*   **Law enforcement and disaster risk management**: Jack Radisch and Nestor Alfonzo Santamaria (GOV/IPP).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 5

*   **Justice administration and access to justice**: Tatyana Teplova, Maaike de Langen and Mariane Piccinini Barbieri of GOV's Global Partnerships, Inclusion and Justice Division (GPIJ) and Paola Gálvez Callirgos, consultant. Contributions were also made by Celine Cojocar (GOV/GPIJ), Aitor Cubo, Fabiola Solino Díaz and Alejandro Fernández Muñoz (Spain); and Tomislav Boršić (Croatia).

In addition the these contributors, other OECD colleagues reviewed the report and provided valuable comments, including, Mia Drazilova, Marianna Karttunen, Haris Khan, Cameron Knott, Bruno Monteiro and Chiara Varazzani (GOV/INDIGO); Celine Caira, Julia Carro, Gallia Daor, Christy Dentler, Sergi Gálvez Duran, Limor Shmerling Magazanik, Tana McCauley, Karine Perset, Lucia Russo and Kasumi Sugimoto of the Directorate for Science, Technology and Innovation (STI); Stefano Marta of CFE; and Theodora Xenogiani and Angelica Salvi Del Pero (ELS).

The report benefited significantly from the expertise of the OECD Working Party of Senior Digital Government Officials (E-Leaders), chaired by Frank Leyman (Belgium). It also benefited from reviews and feedback provided by the delegates of the Public Governance Committee (PGC), the Regional Development Policy Committee (RDPC) and the Digital Policy Committee (DPC) and its project the Global Partnership on Artificial Intelligence (GPAI). The team also thanks Cindy Garcia and Deborah Fernandez for administrative support; Sara Sreberny-Mohammadi, Justin Kavanaugh and Thibaut Gigou for communications support; and Andrea Uhrhammer, Rebecca Bonthius and Jeff Israely for editorial support.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

6|

# Table of contents

Foreword 3
Acknowledgements 4
Executive summary 9
Acronyms and abbreviations 12

**1 How artificial intelligence is accelerating the digital government journey 15**
The digital government journey 17
Understanding Al's transformative potential 19
Using Al in government, a unique context 22
Key opportunity areas and benefits for Al in government 22
To seize the benefits of Al, its risks need to be managed 32
Realising a positive future for Al in government 44
References 45
Notes 56

**2 Trends and early lessons from the use of Al across functions of government 59**
OECD analysis of 200 use cases across 11 government functions 60
Al is a priority, but efforts are not systemic 61
General trends in government Al use cases 62
Use cases could pose risks if not implemented in a trustworthy manner 74
References 77
Notes 79

**3 Implementation challenges that hinder the strategic use of Al in government 81**
Most government Al efforts exist in exploratory or pilot phases, with limited scaling and documentation 82
Common challenges shared across core government functions 85
Challenges that are somewhat less common or vary among government functions 91
References 98
Notes 103

**4 Enablers, guardrails and engagement for unlocking trustworthy Al 105**
Policy action to unlock Al's potential 106
Strengthening enablers to facilitate the adoption of trustworthy Al 108
Establishing guardrails to guide strategic and responsible Al 133

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 7

Engagement to shape strategic and responsible Al 143
A framework for trustworthy Al in government 147
Future OECD work on these issues 148
References 148
Notes 159

**5 Deep dive: The current status and future potential of Al in government 167**
Al in tax administration 169
Current state of play 169
Managing risks and challenges 173
Untapped potential and way forward 175
Al in public financial management 176
Current state of play 176
Managing risks and challenges 179
Untapped potential and way forward 182
Al in regulatory design and delivery 185
Al in civil service reform 196
Al in public procurement 204
Al in fighting corruption and promoting public integrity 213
Al in policy evaluation 221
Current state of play 221
Al in civic participation and open government 228
Al in public service design and delivery 238
Al in law enforcement and disaster risk management 254
Al in justice administration and access to justice 265
References 278
Notes 301

## FIGURES

Figure 1.1. OECD 2023 Digital Government Index, composite results by country 18
Figure 1.2. Venture capital investments in Al have grown over the years 21
Figure 1.3. Al at each stage of the policy cycle 24
Figure 1.4. More than half (59%) of open-source Al training datasets are in English 41
Figure 1.5. Al incidents have generally trended upwards since late 2022 43
Figure 2.1. Use cases are most present in public service, civic participation and justice functions 63
Figure 2.2. EU and LAC follow a similar trend with the Al use cases sample collected for this report 64
Figure 2.3. Al use cases per core function and government activity 65
Figure 2.4. Public services and engagement represent an important share of use cases under government processes in the EU and LAC 66
Figure 2.5. Potential benefits of Al use cases across functions of government 67
Figure 2.6. Specific benefits of Al use cases 68
Figure 2.7. The potential for operational risks is the most represented across government functions 75
Figure 3.1. Most European Union (EU) Al use cases are in pilot or development phases 84
Figure 4.1. OECD Open, Useful and Re-usable data (OURdata) Index, 2023 117
Figure 4.2. Data governance in the public sector 118
Figure 4.3. Considering the level of Al literacy needed for different user groups in the workforce 124
Figure 4.4. OECD GovTech Policy Framework 133
Figure 4.5. Key steps to understand the users and their needs in government Al developments 146
Figure 4.6. OECD Framework for Trustworthy Artificial Intelligence in Government 147
Figure 5.1. Al deployments across OECD Members who use Al in tax administration 169
Figure 5.2. Objectives for FMIS upgrades in OECD countries, 2022 182
Figure 5.3. Potential use of Al and data analytics throughout the public procurement cycle 204

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

8|

## TABLES

| Table Number | Title | Page |
| :--- | :--- | :--- |
| Table 1.1. | Understanding the use of Al in government | 23 |
| Table 2.1. | Functions of government analysed for *Governing with AI* | 61 |
| Table 2.2. | OECD AI Principles | 61 |
| Table 2.3. | Examples of Al for automated, streamlined and tailored processes and services | 69 |
| Table 2.4. | Examples of Al for better decision-making, sense-making and forecasting | 70 |
| Table 2.5. | Examples of Al for enhanced accountability and anomaly detection | 71 |
| Table 2.6. | Examples of Al unlocking opportunities for external stakeholders through Al as a good for all | 72 |
| Table 3.1. | Costs for 1 million tokens on common Generative Al models (USD) | 94 |
| Table 4.1. | Policy questions and measures underpinning the Framework for Trustworthy Al in Government | 148 |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

9

# Executive summary

Artificial intelligence (AI) is one of the most transformative forces of the 21st century, and it is becoming an integral part of digital government worldwide. Governments' use of Al can facilitate automated and tailored internal processes and public services, foster better decision making and forecasting, improve fraud detection and improve public servants' job quality and learning - all with tangible impacts. For example, The Alan Turing Institute estimates that the Al could automate 84% of repetitive public service transactions in the United Kingdom, saving the equivalent of 1 200 person-years of work annually. Despite its promise, government Al use trails the private sector.

## Key findings: How Al can serve citizens

The OECD has conducted in-depth research of Al in 11 core functions of government across 200 use cases. The results suggest that Al is most prevalent in terms of total use cases in public service and justice functions and civic participation, with relatively less use seen in policy evaluation, tax administration and civil service reform. In between are public procurement, financial management, fighting corruption and promoting public integrity, and regulatory design and delivery. Possible explanations for this distribution include that some functions encompass a wider variety of uses (public services) while others are more narrow (civil service reform, tax administration). Also, some face more regulatory constraints (e.g. tax administration, given rules on using tax data), while some face fewer implementation challenges and can mature faster (civic participation). In some functions, such as justice administration, public demands and growing transactions backlogs may precipitate Al adoption as an opportunity to tackle urgent challenges.

Al's use is more prevalent in internal operations and public service delivery, but less prominent in government oversight. Less use is also seen in policymaking, consistent with previous OECD analysis. Use cases often rely on classic rules-based approaches or established machine learning (ML) techniques, with generative Al (GenAI), including large language models (LLMs), being less common. In terms of benefits, the largest share of cases seeks to promote automated, streamlined and tailored processes and services; followed by better decision making and forecasting; and enhanced accountability and anomaly detection. A few cases seek to unlock new opportunities for external stakeholders (e.g. citizens, businesses) through access to government-provided Al systems, but further efforts may be warranted.

## Risks for Al use in government

There is no such thing as risk-free Al adoption. Unlocking Al's benefits requires mitigating its risks. Biased algorithms can result in adverse outcomes; Al misuse can infringe on or prevent the free exercise of human rights; insufficient transparency, explainability and public understanding of Al can erode accountability and cause public resistance; and the over-reliance on Al can widen digital divides and allow systemic errors to propagate, weakening citizen trust in government. Such risks may be amplified in countries lacking mechanisms to guarantee the exercise, protection and promotion of human rights, or result from Al misuse

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

10 |

by individual public servants. Public service workforce displacement could also occur if governments seek to replace rather than augment civil servants' capabilities.

Governments' failure to leverage Al also represents risk, resulting in missed opportunities to yield benefits and widening the gap between public and private sector capacities. They will need to adopt Al if they want to meet increasing citizen demands and strengthen trust in government. Ignoring Al transformation or waiting for all unknowns to be resolved relegates government to being a technology-taker rather and an option-shaper, incurring significant costs and disadvantages. If governments do not bolster internal Al capacities soon, they may struggle to ever catch up.

## Governments also face Al implementation challenges

Challenges in scaling up successful Al applications means government Al initiatives often remain in pilot phases. Skills gaps and difficulties in obtaining and sharing quality data are encountered across government functions. Moreover, although strategies for Al in government are common, a lack of concrete guidance hinders their transformation into practice. These factors compound risk aversion, hindering governments' ability to innovate with Al. Furthermore, insufficient monitoring and evaluation mechanisms restrict their ability to gauge progress, detect risks and demonstrate return on investment. Financial costs are also a common challenge.

Some challenges are more prevalent in some functions than others. For instance, tax administration faces complex laws and rules around tax processes and data, whereas public procurement struggles with a lack of established rules around Al. Finally, the use of Al in functions such as public financial management is constrained by outdated legacy technology infrastructure unsuitable for Al development or use.

## How governments can ensure their use of Al is trustworthy

To reap the benefits of Al in government while mitigating its risks and overcoming implementation challenges, governments need to put in place:

*   **Enablers** to facilitate trustworthy adoption, including governance, data, digital infrastructure, skills, financial investments, agile procurement processes and capacities to partner with non-governmental actors.
*   **Guardrails** to guide the use of Al, including rules and policies, guidance and frameworks, transparency and accountability mechanisms that span the Al system lifecycle, and oversight and advisory bodies to guide and evaluate efforts.
*   **Engagement approaches** to shape user-centred and responsive approaches, including mechanisms to engage with key stakeholders, including the public, civil society and businesses.

## More action is needed to invest in and adopt trustworthy Al in government, but existing approaches provide lessons and inspiration

To the extent possible, the OECD encourages governments to prioritise high-benefit, low-risk applications of Al, especially when building an initial level of maturity. Most, however, lack the processes for holistic measurement of potential or realised results — spending efficiency, service quality, potential harms — that would allow them to make these determinations. Addressing this should be a priority for governments, ensuring Al implementations are transparent, fair and secure.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 11

Many government Al efforts are in their infancy, but some are yielding valuable lessons. The OECD is committed to expanding an evidence base of what works through data collection and analysis, with a focus on how governments can leverage trustworthy Al to deliver public value.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

12 |

# Acronyms and abbreviations

| Acronym | Definition |
| :--- | :--- |
| **AGI** | Artificial general intelligence |
| **Al** | Artificial intelligence |
| **ΑΙΑ** | Algorithmic impact assessment |
| **AIG** | Anticipatory Innovation Governance |
| **AIM** | OECD Al Incidents Monitor |
| **API** | Application programming interface |
| **APS** | Australian Public Service |
| **ATI** | Access to information |
| **AU** | African Union |
| **BLOOM** | BigScience Large Open-science Open-access Multilingual Language Model |
| **CIAO** | Chief Artificial Intelligence Officer |
| **CoE** | Council of Europe |
| **COMPAS** | Correctional Offender Management Profiling for Alternative Sanctions (United States) |
| **CSO** | Civil society organisation |
| **DGI** | OECD Digital Government Index |
| **DPI** | Digital public infrastructure |
| **DSIT** | Department for Science, Innovation and Technology (United Kingdom) |
| **E-Leaders** | OECD Working Party on Senior Digital Government Officials |
| **EC** | European Commission |
| **EU** | European Union |
| **FMIS** | Financial management information system |
| **FTE** | Full-time equivalent |
| **GDP** | Gross Domestic Product |
| **GDPR** | General Data Protection Regulation (European Union) |
| **GenAl** | Generative artificial intelligence |
| **GPAI** | Global Partnership on Artificial Intelligence (GPAI) |
| **HR** | Human resource |
| **HRM** | Human resource management |
| **i.Al** | Incubator for Al (United Kingdom) |
| **IAPR** | Independent Authority for Public Revenue (Greece) |
| **ITTI** | Inventory of Tax Technology Initiatives (OECD) |
| **JRC** | Joint Research Centre (European Commission) |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 13

| Acronym | Definition |
| :--- | :--- |
| **LLM** | Large language model |
| **ML** | Machine learning |
| **NER** | OECD Network of Economic Regulators |
| **NIST** | National Institute of Standards and Technology (United States) |
| **NLP** | Natural Language Processing |
| **OCR** | Optical character recognition |
| **OECD** | Organisation for Economic Co-operation and Development |
| **OGD** | Open government data |
| **OMB** | Office of Management and Budget (United States) |
| **PAC** | Public Accounts Committee (Parliament of the United Kingdom) |
| **Palkeet** | Government Shared Services Centre for Finance and Human Resources (Finland) |
| **PET** | Privacy-enhancing technology |
| **PFM** | Public financial management |
| **PPP** | Public-private partnership |
| **R&D** | Research and development |
| **RaC** | Rules as code |
| **RAG** | Retrieval-augmented generation |
| **RCT** | Randomised control trial |
| **RIA** | Regulatory impact assessment |
| **ROI** | Return on investment |
| **RPA** | Robotic process automation |
| **SAI** | Supreme Audit Institution |
| **TCU** | Federal Court of Accounts (Brazil) |
| **SDG** | Sustainable Development Goal |
| **UN** | United Nations |

Note: Terms are generally only included if the abbreviation or acronym is mentioned outside of context of where it is originally defined. Abbreviations for country names are not included.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 15

# 1 How artificial intelligence is accelerating the digital government journey

This chapter explains how artificial intelligence (Al) can accelerate the digital government journey. It situates government as a developer and user of Al, going beyond traditional investor and regulator roles. The chapter groups opportunities – productivity (efficiency and effectiveness), responsiveness and accountability – across the policy cycle, and stresses prerequisites in data and information management. It also outlines government-specific risks and risks of inaction, within emerging regulatory approaches, and closes with a vision for trustworthy Al in government.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

16 |

# Key messages

*   Artificial intelligence (AI) has the potential to reshape industries, economies, governments and societies. Yet, its progress in the government has been limited.
*   Al can help governments in three key opportunity areas: productivity, responsiveness and accountability.
*   At each stage of the policy cycle, Al can bring highly complementary benefits:
    *   automating mundane and repetitive tasks
    *   improving productivity in analytical or creative tasks
    *   tailoring services to address personalised citizen needs
    *   tailoring approaches to strengthen the civil service
    *   enhancing decision-making and sense-making of the present
    *   better forecasting of the future
    *   improving information management and accessibility
    *   detecting improper transactions and assessing integrity risks
    *   enabling non-governmental actors to understand and engage with government and promote accountability
    *   unlocking opportunities for external stakeholders through Al as a good for all.
*   These benefits are not mutually exclusive and can be categorised into four broad areas:
    *   automated, streamlined and tailored processes and services
    *   better decision-making, sense-making and forecasting
    *   enhanced accountability and anomaly detection
    *   unlocking opportunities for external stakeholders.
*   Governments should manage the risks of Al that are specific to government use, which are: ethical risks, operational risks, exclusion risks, public resistance risks and risks of inaction.
*   A vision of a future where governments successfully develop and adopt trustworthy Al for systematic transformation of government processes and services is beginning to emerge.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 17

# The digital government journey

Digital government is essential to transforming processes and services in ways that improve the public sector's responsiveness and reliability and bring governments closer to their people. Since the adoption of the OECD Recommendation on Digital Government Strategies (2014[1]), the OECD has been promoting digital government in OECD member countries and beyond, supporting them in their efforts to achieve government digital maturity. Digitally mature governments recognise that technology is a strategic driver not only to improve efficiency, but also to make policies more effective and governments more open, accountable, innovative, participatory and trustworthy.

The COVID-19 pandemic underscored the importance of digital technologies and data in building economic and social resilience through strategic, agile and innovative government approaches. While the pandemic and the multidimensional crisis it provoked disrupted governments, it also offered an opportunity to revisit strategic approaches on the use of digital tools and data to improve the delivery of public services. Faced with no alternative, governments compressed years' worth of technological advancements into weeks and months. Deploying technology solutions at scale enabled governments to continue operating in times of crisis, and secured the timely provision of services to citizens and businesses (OECD, 2020[2]; [3]). Where digital technologies or data were not used strategically or effectively, the crisis highlighted gaps and exacerbated challenges, which governments are working to address to this day.

Today, governments worldwide are facing decreasing levels of public trust (OECD, 2024[4]), while simultaneously experiencing growing and rapidly accelerating changes brought about by the digital age. In this time of fast-paced disruption — rapid technological evolution, changing societal needs, unexpected crises — it is crucial governments be capable and equipped to use digital technologies and data to increase productivity and resilience in their public administrations, and enhance the quality of public services.

## Institutionalising digital government, with varying maturity levels

To unlock the potential of digital government, establishing the right institutional arrangements, coordination mechanisms and policy instruments is critical to sustaining the needed long-term transformations and overcoming changing political priorities. The OECD (2020[3]) Digital Government Policy Framework establishes six dimensions critical for establishing a digital government:

1. **Digital by design**: designing policies to enable the public sector to use digital tools and data in a coherent way when formulating policies or transforming public services.
2. **Data-driven**: developing the governance and enablers needed for data access, sharing and re-use across the public sector.
3. **Government as a platform**: deploying common building blocks such as guidelines, tools, data, digital identity and software to advance a coherent transformation of government processes and services across the public sector.
4. **Open by default**: openness beyond the release of open data, including efforts to encourage the use of technologies and data to communicate and engage with different actors.
5. **User-driven**: placing user needs at the core of the design and delivery of public policies and services, including through engagement with users and measurement of metrics to assess impact and satisfaction.
6. **Proactiveness**: anticipating the needs of users and service providers to deliver government services proactively.

The OECD Digital Government Index (DGI) benchmarks governments' maturity across these dimensions (Figure 1.1). In this figure, it is clear that some countries are further progressed in their journey towards

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

18 |

digital government maturity than others, and the broad array of OECD analysis on digital government illuminates that each country faces its own challenges in achieving maturity.¹

# Figure 1.1. OECD 2023 Digital Government Index, composite results by country

## Chart Data Extraction

The chart is a stacked bar chart showing the composite results for the OECD 2023 Digital Government Index by country. The index is composed of six dimensions.

**Legend/Categories:**
*   Digital by Design
*   Data-driven public sector
*   Government as a Platform
*   Open by Default
*   User-Driven
*   Proactiveness

**Y-Axis Scale:**
0.0, 0.2, 0.4, 0.6, 0.8, 1.0

**Data Points by Country (Composite Score and Component Scores, approximated from chart):**

| Country | Digital by Design | Data-driven public sector | Government as a Platform | Open by Default | User-Driven | Proactiveness | Total Composite Score (Approx.) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Korea | 0.16 | 0.16 | 0.16 | 0.14 | 0.15 | 0.14 | 0.91 |
| Denmark | 0.17 | 0.15 | 0.16 | 0.13 | 0.15 | 0.12 | 0.88 |
| United Kingdom | 0.15 | 0.14 | 0.15 | 0.12 | 0.14 | 0.13 | 0.83 |
| Norway | 0.15 | 0.14 | 0.15 | 0.12 | 0.14 | 0.11 | 0.81 |
| Australia | 0.13 | 0.13 | 0.14 | 0.12 | 0.13 | 0.12 | 0.77 |
| Estonia | 0.16 | 0.13 | 0.15 | 0.11 | 0.12 | 0.10 | 0.77 |
| Colombia | 0.13 | 0.13 | 0.12 | 0.13 | 0.13 | 0.11 | 0.75 |
| Ireland | 0.13 | 0.12 | 0.13 | 0.11 | 0.13 | 0.12 | 0.74 |
| France | 0.13 | 0.12 | 0.13 | 0.11 | 0.13 | 0.11 | 0.73 |
| Canada | 0.12 | 0.12 | 0.13 | 0.11 | 0.13 | 0.11 | 0.72 |
| Portugal | 0.12 | 0.12 | 0.12 | 0.12 | 0.12 | 0.11 | 0.71 |
| Finland | 0.13 | 0.12 | 0.12 | 0.11 | 0.12 | 0.10 | 0.70 |
| Iceland | 0.12 | 0.11 | 0.12 | 0.11 | 0.12 | 0.11 | 0.69 |
| Lithuania | 0.13 | 0.12 | 0.11 | 0.10 | 0.12 | 0.10 | 0.68 |
| OECD | 0.11 | 0.11 | 0.11 | 0.11 | 0.12 | 0.11 | 0.67 |
| Spain | 0.11 | 0.11 | 0.11 | 0.11 | 0.11 | 0.11 | 0.66 |
| Latvia | 0.12 | 0.11 | 0.11 | 0.10 | 0.11 | 0.10 | 0.65 |
| Czechia | 0.11 | 0.11 | 0.11 | 0.10 | 0.11 | 0.10 | 0.64 |
| Turkiye | 0.11 | 0.11 | 0.11 | 0.10 | 0.10 | 0.10 | 0.63 |
| Italy | 0.11 | 0.10 | 0.11 | 0.10 | 0.10 | 0.10 | 0.62 |
| Poland | 0.11 | 0.10 | 0.11 | 0.10 | 0.10 | 0.09 | 0.61 |
| Luxembourg | 0.10 | 0.10 | 0.10 | 0.10 | 0.10 | 0.10 | 0.60 |
| Netherlands | 0.10 | 0.10 | 0.10 | 0.09 | 0.10 | 0.10 | 0.59 |
| Austria | 0.10 | 0.10 | 0.10 | 0.09 | 0.10 | 0.09 | 0.58 |
| Belgium | 0.10 | 0.10 | 0.09 | 0.09 | 0.10 | 0.09 | 0.57 |
| Mexico | 0.10 | 0.10 | 0.09 | 0.09 | 0.09 | 0.09 | 0.56 |
| Sweden | 0.10 | 0.09 | 0.09 | 0.09 | 0.09 | 0.09 | 0.55 |
| New Zealand | 0.09 | 0.09 | 0.09 | 0.09 | 0.09 | 0.09 | 0.54 |
| Slovenia | 0.09 | 0.09 | 0.09 | 0.08 | 0.09 | 0.09 | 0.53 |
| Israel | 0.09 | 0.09 | 0.08 | 0.08 | 0.09 | 0.09 | 0.52 |
| Hungary | 0.09 | 0.08 | 0.08 | 0.08 | 0.09 | 0.09 | 0.51 |
| Japan | 0.08 | 0.08 | 0.08 | 0.08 | 0.09 | 0.09 | 0.50 |
| Chile | 0.08 | 0.08 | 0.08 | 0.08 | 0.08 | 0.08 | 0.48 |
| Costa Rica | 0.07 | 0.07 | 0.07 | 0.06 | 0.07 | 0.06 | 0.40 |
| Peru | 0.07 | 0.07 | 0.06 | 0.06 | 0.06 | 0.06 | 0.38 |
| Brazil | 0.06 | 0.06 | 0.06 | 0.06 | 0.06 | 0.06 | 0.36 |
| Argentina | 0.06 | 0.06 | 0.06 | 0.05 | 0.06 | 0.05 | 0.34 |
| Croatia | 0.06 | 0.05 | 0.05 | 0.05 | 0.06 | 0.05 | 0.32 |
| Romania | 0.05 | 0.05 | 0.05 | 0.04 | 0.05 | 0.04 | 0.28 |

Note: Data for Germany, Greece, Slovakia, Switzerland and the United States (US) are not included.
Source: (OECD, 2024[5]).

# Al's growing role in digital government

The OECD defines an Al system as:

> “a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.” – see OECD *Explanatory Memorandum* for further clarification (2024[6]; [7]).

Global Al discussions mainly focus on governments as Al regulators or investors, but significant opportunities exist for government as an Al developer and user. Not only do governments set national priorities, investments and regulations for Al, but they increasingly use it to design and implement policies and services. Although hype around Al has increased in recent years, governments are not new to using Al; there are thousands of government Al projects underway around the world.²

Since 2019, the OECD has been working to better understand Al’s uses and implications in the unique context of government. This includes developing foundational pieces on the technical underpinnings of Al and its use and implications by and for government (2019[8]; [9]); targeted analysis on specific countries (2022[10]; 2024[11]; [12]); surfacing government innovation trends, which often involve Al;³ and establishing a preliminary framework for Al in government (2024[13]). The OECD has also collected details on hundreds of initiatives for Al in government.⁴

The 2023 DGI highlights while some governments have been deploying a wide range of initiatives to enhance their capacity to use Al, implementation is still a challenge for most. At the time of the DGI’s publishing, 70% of countries had used Al to improve internal governmental processes, while only 33% had used Al to enhance policy design and implementation. Although use is increasing, Al use in government has not yet made a transformative impact. The forthcoming 2025 DGI will include updated figures and more in-depth comparative analysis. It will also incorporate complementary qualitative evidence to further

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 19
inform how governments can implement the right enablers, safeguards, risk mitigation and engagement mechanisms to adopt trustworthy Al while monitoring for adverse effects.

# Understanding Al's transformative potential
Al is one of the most transformative forces of the 21st century. It is reshaping industries, economies, governments and societies at an unprecedented pace. If governments and other Al actors are successful in seizing Al's benefits while mitigating its risks, Al experts and researchers envision a future in which Al contributes to scientific and medical breakthroughs, such as discovering new cancer treatments; catalyses productivity growth from a 1-7% rise in global gross domestic product (GDP) by 2033 to a 10-fold increase in the decades to come; eliminates poverty and reduces inequality; and helps address weather-related impacts and natural disasters (OECD, 2024[14]).

While Al has gained intense worldwide attention in recent years, Al research and development has been going on for over 70 years. Before taking a deeper look at Al use in government, it is useful to understand some of the background on Al and why it has recently become a topic of household discussion, as discussed in Box 1.1.

---
**Box 1.1. The evolution of Al**

The Al landscape has evolved significantly since the 1950s when British mathematician Alan Turing first posed the question of whether machines can think. For decades, **“rules-based” or “symbolic" Al systems** dominated research, using a series of “If-then” (If a condition, then an action) statements that, when taken together, would give the appearance of intelligent action. Such systems are limited and require significant human knowledge to programme the rules. They are still in use today, such as in robotic process automation (RPA) software bots that automate human-programmed tasks. Due to their limitations, some argue that rules-based systems and RPA should not be considered Al at all.

The 21st century saw breakthroughs in the branch of Al called **machine learning (ML)** that improved the ability of machines to make predictions from historical data. ML focuses on the development of systems that can learn and adapt without following explicit instructions imitating the way humans learn, gradually improving its accuracy, by using algorithms and statistical models to analyse and draw inferences from patterns in data. The “learning” process using machine-learning techniques is known as "training".

The application of ML techniques, the availability of large datasets, and faster and more powerful computing hardware have converged, dramatically increasing the capabilities, impact and availability of Al models and systems. Inspired by the human brain, **neural networks** are made up of layers of "neurons”, known as “nodes”, that process inputs with weights and biases to give specific outputs. A subset of algorithms in the area of neural networks — called deep neural networks (in the field of study and set of techniques called **deep learning**) - allows machine-based systems to "learn" from examples to make predictions or "inferences” based on the large amount of data processed during their training phase. Because of their complexity, it can be difficult to understand how they work or produce a given output.

**Recent conceptual breakthroughs**

In 2017, Google researchers introduced a type of neural network architecture called **"transformers"**, which learn to detect how data elements — such as the words in this sentence — influence and depend on each other. Unlike previous neural networks, transformers can process inputs from a sequence, such as words of text, in parallel. This unleashed major progress by enabling Al developers to design
---

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

20 |
larger-scale language models with more parameters and greater efficiency. This contributed greatly to advances in **generative Al (GenAl)**, including **large language models (LLMs)**, that can generate novel content and enable consumer-facing applications like advanced chatbots at people's fingertips.

For many, Al became "real" in 2022, the year that OpenAl's ChatGPT (Chat Generative Pre-Trained Transformer) became the fastest-growing consumer application in history. Transformers also contributed to the advent of **foundation models**, which are trained on large amounts of data that can be adapted (i.e. fine-tuned) and built upon to conduct a wide range of downstream tasks. Although transformers are often discussed, other approaches exist, especially for non-text (e.g. images, video, audio) generation, such as generative adversarial network (GANs) and diffusion models.

## Most Al today is "narrow”, but some argue more "general" forms of Al are emerging
Most Al today can be considered **“narrow"** (designed to perform a specific task), but some experts argue that foundation models are an early form of more “general” Al. This includes progress towards the hypothetical advent of **artificial general intelligence (AGI)** — a controversial concept that can be described as machines with human-level or greater intelligence across a broad spectrum of contexts. There is substantial debate and uncertainty among experts about when or if AGI might be developed, and what potential opportunities and challenges it may bring.

While some experts believe AGI will be developed at some point, emerging early forms of **"agentic" Al systems** — which can operate in a somewhat autonomous manner without the constant need for human guidance — hint at the potential for future systems that can handle more general tasks with minimal human input. For instance, LLM-based "agents” have already been developed to autonomously search the internet and interpret what they find on behalf of the user. Such systems are very early, comprising many limitations and risks, but further advancements may yield opportunities across sectors.

As Al systems become increasingly capable, many argue that humans should not defer decisions to machines but rather work in tandem, or in **machine-human collaboration**, using Al to assist decision-making.

Note: The OECD primer *Hello World: Artificial intelligence and its use in the public sector* (Berryhill et al., 2019[8]) provides details on the technical underpinnings and potential implications of Al.
Source: (OECD, 2024[15]), (OECD, 2024[14]), (OECD.AI, 2023[16]), (Lorenz, Perset and Berryhill, 2023[17]), (Berryhill et al., 2019[8]) (Cognitus, 2024[18]), (Purdy, 2024[19]), (NIST, 2025[20]), (Horvitz, 2014[21]), (Brizuela et al., 2025[22]), https://playbooks.aip.gov.sg/agentic-ai-primer.

---

# Despite the hype, Al progress is limited
Data from the OECD.AI Policy Observatory demonstrates the boom in interest in Al in recent years. For example, Figure 1.2 shows significant growth in venture capital investments in Al over time. While interest is high, advisory firm Gartner's latest “hype cycle” puts GenAl just beyond its "peak of inflated expectations", and starting a descent into the “trough of disillusionment”, “as business focus continues to shift from excitement around foundation models to use cases that drive ROI” (Gartner, 2024[23]). Still, it expects GenAl and some other forms of Al, such as Al supercomputing and the use of Al to support and enforce Al governance policies, trust, risk and security, to reach fuller productivity in just two to five years.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 21
# Figure 1.2. Venture capital investments in Al have grown over the years
Venture global capital investments in Al in USD millions by country from 2012 onwards

## Chart Data
- **Y-axis (USD millions):** 4 770.5, 50 000.0, 100 000.0, 150 000.0, 225 918.6
- **X-axis (Year):** 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024

### Data Points (Approximate values in USD millions):
- **2012:** 4,770.5
- **2013:** 10,000
- **2014:** 20,000
- **2015:** 35,000
- **2016:** 50,000
- **2017:** 75,000
- **2018:** 100,000
- **2019:** 95,000
- **2020:** 115,000
- **2021:** 225,918.6
- **2022:** 120,000
- **2023:** 110,000
- **2024:** 140,000

Note: A methodological note with more information can be found at https://oecd.ai/p/methodology. The surge in investments in 2021 was in part due to an increase in "healthcare, drugs and biotechnology" Al investments during the COVID-19 pandemic. A significant spike that year was also seen in "Mobility and autonomous vehicles".
Source: OECD.AI (2025), visualisations powered by JSI using data from Preqin, last updated 3 June 2025 accessed on 16 June 2025, www.oecd.ai.

Although some Al experts predict significant economic gains from Al, OECD (2024[24]) research indicates more tepid growth, estimating annual productivity growth due to Al ranging between 0.25-0.6 percentage points over the next 10 years in the most Al-ready countries. Research shows Al improves individual worker productivity (OECD, 2023[25]; Bengio et al., 2025[26]), but evidence connecting this to broader organisational and economic gains is weak. This is, in part, because some tasks cannot yet be conducted by Al and not all organisations or workers are ready to adopt it. Some evidence suggests firms adopting Al are more productive and grow faster than those that do not (Calvino and Fontanelli, 2023[27]; Hampole et al., 2025[28]), but this should not be interpreted as causality. For now, limitations persist. According to US Census Bureau statistics, only 5-6% of US businesses use Al to produce goods and services and only 7% plan to adopt Al in the coming months (Williams, 2025[29]). In a more global survey, only an estimated 26% of companies have the capabilities needed to derive real value from Al, and only 4% have succeeded in generating significant value (BCG, 2024[30]).5

Beyond economic gains, Al's transformative potential to achieve positive societal outcomes is beginning to show signs of promise. However, its full impact has yet to be realised. For instance, Al in science has contributed to real progress in robotics, nuclear fusion, drug discovery, antibody generation and protein folding (OECD, 2023[31]). Despite these early successes, many uses remain localised or experimental, and systemic change on a global scale is still forthcoming. Al's contribution to science is just beginning, and in some areas, the technology may have achieved less than anticipated. For example, some found Al contributed little to research during the COVID-19 pandemic (OECD, 2023[31]). So far, Al has mostly contributed to breakthroughs in a narrow set of natural and physical sciences. Similar transformations in other disciplines, such as social sciences, have progressed less despite high expectations (Manning, Zhu and Horton, 2024[32]). As such, while Al's societal benefits are emerging, the full scope of its transformative potential is still unfolding.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

22 |
# Using Al in government, a unique context
In addition to governing Al for society by setting the conditions and regulations for its trustworthy use, governments are striving to integrate the technology to better govern with Al. Similar to the private sector, the use of Al in government promises tremendous benefits while posing a number of risks and challenges. In fact, a Deloitte survey (2024[33]) of 2 770 senior leaders across 14 countries found public sector leaders were twice as likely as industry leaders to foresee Al-driven transformation in their organisations in the near term, but they felt more cautious and were less optimistic that it would result in productivity gains. Yet the subject has only recently become a focus of mainstream public management literature and many governments (Mergel et al., 2023[34]; Mellouli, Janssen and Ojo, 2024[35]). This is due to a combination of factors, including recent technological breakthroughs resulting in Al applications that are more practical and effective for government use (see Box 1.1); government access to vast amount of data that can be used as inputs for Al systems; and ongoing fiscal pressures that make Al attractive as a way to streamline operations and reduce costs. As a result, government use of Al trails that of the private sector.

While some lessons learned and success factors can be derived from industry efforts (Santos et al., 2024[36]), the purpose of and context within government are unique and present a number of specific opportunities and challenges. In addition, the field of Al is complex, progressing rapidly and has a steep learning curve for public servants and policymakers. If successful, however, the application of Al in government promises to significantly impact the wider economy and society by enhancing the quality and outcomes of public services, policies and government operations (Berglind, Fadia and Isherwood, 2022[37]).

Governments have huge influence over and impact in people's lives, bringing with it a duty of care for the public good — one that goes above that of companies (OECD, 2023[38]; Santiso, 2023[39]). Thus, they have a special responsibility to deploy Al in a way that minimises harm and prioritises the well-being of individuals and communities. This is especially the case when deploying Al in sensitive policy domains such as law enforcement, immigration control, welfare benefits and fraud prevention (OECD, 2024[13]).

Governments also operate with a unique mandate: they serve the public interest and are funded by public resources. As such, their actions — particularly those involving data and digital technologies — need to be guided by principles that uphold democratic values, individual rights and the rule of law. Unlike private entities, which may prioritise efficiency or profit, governments are expected to act transparently and with due regard for the public good to a greater extent than companies.

# Key opportunity areas and benefits for Al in government
Opportunities for governments as developers and users of Al include the potential to transform service delivery, policymaking, internal operations and oversight. This is a pivotal moment for governments worldwide. Grappling with the rapid advances in Al technologies, they are trying to seize the opportunities provided by Al to innovate and modernise public administration, while managing and mitigating the associated risks, discussed below, and implementation challenges, discussed in Chapter 3.

Embracing Al in government unlocks new possibilities. Through years of research on the topic and working with governments around the world, the OECD (2024[13]) has identified three concrete opportunity areas for government use of Al:

*   **Productivity** with more efficient internal operations and more effective policy design, decision-making and service delivery. For example, using predictive Al systems for more effective policy planning, automating processes for more accelerated service delivery, and boosting performance by allowing civil servants to focus less on mundane tasks and more on mission-critical activities.
*   **Responsiveness** of public policies and service through enhanced design and delivery approaches that better meet evolving needs of citizens and specific communities, as well as through improved

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 23
civic participation mechanisms. This includes offering more personalised public services more proactively.
*   **Accountability** by enhancing capacity for oversight and transparency, for instance through real-time monitoring. This shift may boost overall public satisfaction and enhance the perception of government as competent, fair and responsive, thereby strengthening public trust in government's capacity for innovation and transformation.

Table 1.1 illustrates how various Al tasks can feed into government activities, thus supporting these opportunity areas.

## Table 1.1. Understanding the use of Al in government
| Al tasks | Government activity | Opportunity area |
|---|---|---|
| - Recognition<br>- Event detection | Internal operations | Productivity (efficiency and effectiveness) |
| - Forecasting<br>- Personalisation | Policymaking | Responsiveness |
| - Interaction support<br>- Goal-driven optimisation<br>- Content generation | Service delivery | |
| - Reasoning with knowledge structures | Internal and external oversight | Accountability |

Note: The Al tasks column is adapted from the "Al System Tasks" of the OECD Framework for the Classification of Al Systems (2022[40]).
Source: (OECD, 2024[13]).

# Key benefits for Al in government
To guide investment decisions, it is crucial for public servants, especially decision-makers in leadership positions, to understand the benefits Al can offer. A study by the European Commission (EC) (2024[41]), which surveyed 576 public managers across seven countries, found that Al's perceived benefits significantly influence its adoption. Al has the potential to enhance decision-making at various stages of the policy cycle (Figure 1.3). The sections below outline key benefits of using Al in government. These benefits are not mutually exclusive and indeed are highly complementary with some overlap in four concepts: automated, streamlined and tailored processes and services; better decision-making, sense-making and forecasting; enhanced accountability and anomaly detection; and unlocking opportunities for external stakeholders through Al as a good for all. It is important to note, however, that the use of Al in government can also pose risks. Several of these risks can be the converse of or undermine the potential benefits. The next section provides a dedicated discussion on risks.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

24

# Figure 1.3. Al at each stage of the policy cycle

**Diagram Content:**

**Main Categories (colored squares):**
- **Green Square:** Automating, streamlining and tailoring processes and services
- **Red Square:** Enhanced accountability and anomaly detection
- **Yellow Square:** Better decision making, sense making and forecasting
- **Blue Square:** Unlocking opportunities for external stakeholders through AI as a good for all

**Policy Cycle Stages and Associated Actions:**

**POLICY CYCLE (Center of diagram)**

**1. OVERSIGHT AND EVALUATION (Top-left section of the cycle)**
- Improving information management and accessibility (throughout)
- Detecting improper transactions and assessing integrity risks

**2. AGENDA SETTING AND POLICY FORMULATION (Top-right section of the cycle)**
- Empowering citizens and stakeholders (throughout)
- Improving productivity in analytical or creative tasks (throughout)
- Better forecasting of the future
- Enhancing decision making and sense making of the present (throughout)
- Enabling non-governmental actors to understand and engage with government and promote accountability

**3. POLICY IMPLEMENTATION (Bottom section of the cycle)**
- Tailoring services to address personalised citizen needs
- Tailoring approaches to strengthen the civil service
- Automating mundane and repetitive tasks (throughout)

Source: (Pencheva, Esteve and Mikhaylov, 2018[42]), adapted to align with OECD terminology below.

# Automated, streamlined and tailored processes and services
Al-enabled automation can help in directly automating existing processes and services, or contribute to the full re-imagining of how governments work both in internal operations as well as in public-facing services. In leveraging vast data assets, governments can also use Al to develop tailored services precisely crafted for specific individuals and groups. These benefits not only make government more efficient, effective and response, but they also can improve job quality and well-being for public servants by enabling them to spend more time on more valuable and meaningful work. This has been shown to improve workers' well-being. Nearly two-thirds of workers surveyed by the OECD (2023[25]) reported that Al improved their enjoyment of work, with studies showing this can enhance workers' well-being (Brougham and Haar, 2017[43]; Xu, Xue and Zhao, 2023[44]). However, as discussed below, some Al uses can reduce job quality and potentially lead to public service workforce displacement.

## Automating mundane and repetitive tasks
Governments can use Al to the enhance efficiency of their internal operations and service delivery activities, reducing the time public officials invest in monotonous tasks (OECD, 2024[13]). Typically, these internal operations are repetitive and do not require extensive analytical thinking or human judgment. By automating these tasks, Al can streamline workflows, reduce errors, optimise resource allocation and free

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 25

up human resources for more complex, judgment-intensive activities. Ultimately, this leads to a more efficient delivery of higher quality public services (OECD/UNESCO, 2024[12]).

Repetitive and time-consuming tasks include:
*   **Data entry:** manually inputting data into various systems and databases.
*   **Payroll processing:** calculating and processing employee salaries and benefits.
*   **Basic customer inquiries:** addressing routine inquiries and providing information to the public.
*   **Information verification:** checking and verifying the authenticity of documents.
*   **Form processing:** handling and processing various application forms.
*   **Email and correspondence:** sorting, responding to and managing official emails and correspondence.

Governments can use of a variety of Al systems for these types of tasks, ranging from simplistic rules-based systems to more advanced ML systems, such as LLM-enabled chatbots. These systems have extensive capabilities ranging from handling simple and routine inquiries (both with citizens as well as with public servants) to generating entirely new tailored content and optimising resource allocation (Lorenz, Perset and Berryhill, 2023[17]; Sapci and Sapci, 2019[45]).

As an example, Argentina is automating repetitive tasks and expediting case processing in justice administration through its Al-driven Prometea system (see Chapter 5, Box 5.62). As discussed below, however, Al-enabled automation can pose risks – in areas such as justice administration – that governments need to consider. In the case of Prometea, for example, Argentina seeks to limit these risks through human control of how the Al system and its outputs are used (Corvalán and Le Fevre Cervini, 2020[46]).

## Improving productivity in analytical or creative tasks
Al further contributes to productivity through the discovery of new ideas and through new efficient and effective means of conducting work (Jones, 2022[47]). One of Al's most notable benefits is its ability to help government offices handle and manage the analysis and synthesis of extensive documentation (OECD/UNESCO, 2024[12]). While a variety of Al-enabled tools may be useful, LLMs in particular can serve as powerful assistants for government officials in this regard, aiding in tasks such as research, content summarisation and synthesis (Berglind, Fadia and Isherwood, 2022[37]). Research conducted with knowledge professionals in the private sector showed that Al use can improve the performance of individual and teams, and also break down functional siloes (Dell'Acqua et al., 2025[48]). Governments can use Al to reduce civil servants' workload and to improve access to information for both citizens and public servants.

Some relevant uses include:
*   **Processing and categorising textual information:** Al tools can quickly and accurately analyse extensive texts and unstructured documents, highlighting key points and summarising information. This enhances efficiency in departments dealing with vast amounts of information, such as legal affairs and administrative processes (OECD/UNESCO, 2024[12]). Consequently, workflows are sped up and the risk of human error is reduced, leading to more accurate and reliable outcomes in internal operations and in service delivery activities.
*   **Drafting documents and legal texts:** Al systems can generate preliminary drafts of various types of documents by using templates and existing legislation. This process helps ensure adherence to standards while saving time and resources. Additionally, Al can cross-reference new drafts with current laws, identifying potential conflicts and minimising human errors. For report drafting, Al tools can offer automatic suggestions for clearer and more concise structures. Furthermore, it can

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

26 |

*   improve communication of extensive reports by summarising them into shorter formats for dissemination to decision-makers or the public.
*   **Making sense of unstructured inputs:** Al can analyse and synthesise large amounts of information from participatory processes, public service feedback and consultations, turning them into actionable recommendations. It can identify recurring topics, cluster opinions, detect outliers, perform sentiment analysis and rank policy options based on preferences. This use can help identifying emerging issues, better considering stakeholder concerns and addressing potential policy impacts.

Studies show that generative Al systems reduce the time people spend conducting tasks while improving quality output. They also show that these tools have a greater impact on the productivity of lower-skilled workers, such as junior employees, allowing them to catch up with their more senior colleagues (Noy and Zhang, 2023[49]; Peng et al., 2023[50]). This can produce and equalising effect and drive productivity gains by helping workers conduct many tasks typically handled by subject matter experts (OECD, 2023[25]). However, some research also indicates that Al could contribute to further divides between higher-skilled and lower-skilled workers, and that while existing Al systems can increase worker productivity, they still cannot perform many tasks that humans can (The Economist, 2025[51]; Dell'Acqua et al., 2023[52]; Bengio et al., 2025[26]). More research is needed on this topic, including Al’s specific advantages and potential drawbacks for public servants.

As an example, the UK tax authority is using Al to draft job descriptions and to analyse and evaluate the qualifications of job applications to speed up hiring (Box 5.20). As discussed below, using Al can pose risks if not done in a trustworthy manner.

Al can also play a role as a catalyst for creativity and innovation among public servants and how they design and implement internal processes and public policies and services. Generative Al, for instance, can support the exploration of policy alternatives, scenario simulations, legislative drafting and service prototyping, fostering a more imaginative and experimental public administration. For example, the UK's Government Communication Service is developing an Al-powered conversational tool to generate draft texts, plans and strategic ideas, integrating communication guidelines and audience insights to ensure high-quality, compliant outputs (Box 5.39). Designed as a collaborative assistant, it boosts creativity, reduces routine workload, and is being gradually rolled out after successful piloting and iterative Al-driven refinement.

## Tailoring services to address personalised citizen needs
Al can help governments to better understand people's needs and behaviours, and facilitate the delivery of targeted and personalised information and services at an individual level (Huang and Rust, 2021[53]; Flavián and Casaló, 2021[54]; OECD, 2020[3]). This can include developing individualised citizen profiles, generating and delivering tailored information, and shaping service offerings based on unique needs (UN, 2022[55]). By improving responsiveness, such efforts can make services more efficient, effective and citizen-centred, resulting in higher satisfaction, better outcomes and a more agile and proactive approach to meeting public needs.

This enables a better response to the needs of user sub-groups, including vulnerable and disadvantaged groups, who may have specific and context-dependent needs (Giest, 2017[56]). The use of Al tools for personalisation has broadened into several public service sectors, frequently associated with life-event-based service delivery, such as services offered proactively for a child's birth, new educational pursuits or marriage (Kopponen et al., 2024[57]).

Governments can also tap into Al's capacity to analyse vast behavioural datasets for a deeper understanding of individual heterogeneity, incorporating cognitive and contextual factors — such as timing, location and personal preferences — into service design. This enables more adaptive and equitable

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 27

service interventions that align with citizens' unique circumstances while safeguarding autonomy and informed decision-making (Mills, Costa and Sunstein, 2023[58]).

In addition to enhancing services themselves, Al can help optimise communications on the availability and thus, the uptake of services. Using existing administrative data, Al can simplify processes by pre-filling (or eliminating) forms with known information and tailoring questions to the individual, reducing the time and effort required to complete bureaucratic tasks. This is already being done in a limited way with administrative data and (human) programmed algorithms in the area of social programmes (OECD, 2024[59]). This targeted approach can help ensure that citizens receive the information they need efficiently, and that interactions with public services are streamlined and user-friendly.

Examples of this benefit in action include a wide variety of chatbots and virtual assistants that can respond to unique queries from citizens with tailored information. For example, Singapore's tax authority offers a public-facing chatbot that can provide information and services tailored to individual needs (Box 5.4). As another example, social protection systems are using Al for proactive outreach to promote service uptake among those who quality (Box 5.49).

It is important to note, however, that such services often require a great deal of data collection and analysis to determine individual characteristics and needs. Governments should undertake such data collections and Al use in a trustworthy manner. Otherwise, as discussed below, these efforts run the risk of infringing upon the free exercise of human rights, such as through privacy infringements.

## Tailoring approaches to strengthen the civil service
Al can also strengthen the public service through more effective and inclusive hiring processes and personalised programmes for continuous development. With regards to human resource management (HRM), for instance, Al can help governments optimise hiring decisions by helping to find the best candidates for the job and improve inclusiveness by controlling for human biases.

Al can also empower public servants; it can contribute to learning development, enhance knowledge creation and optimise learning platforms for upskilling public servants. This includes crafting skills development strategies, designing and running tailored training courses and implementing tools to improve information access. By doing so, Al can help ensure that public servants are equipped with the latest knowledge and skills necessary to meet the evolving demands of their roles, fostering a more responsive public administration.

Some relevant Al applications include:
*   **Developing learning material for civil servants:** Al can create learning content (such as modules and course materials) from source documents and integrate diverse information into effective resources. It can also design, structure and deploy online learning courses. Al-driven tools can continually update and refine these resources as new information becomes available, enhancing the ongoing education and skill development of the government workforce.
*   **Personalising material and learning routes for civil servants:** Al can tailor educational content and learning pathways to meet the specific needs, preferences and progress of each civil servant, ensuring a more effective, engaging and adaptive learning experience. By equipping civil servants with the right skills more efficiently, this personalisation also enhances government responsiveness.
*   **Identifying and cataloguing learning resources:** Al tools can identify, describe and catalogue multiple learning resources, making them easily searchable and shareable, thereby simplifying resource discovery and identifying relevant content for learners. For example, integrating Al into digital platforms can enhance organisation, cataloguing and search functions.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

28 |

As an example, the Australian Public Service Commission (APSC) has run a six-week pilot project to see if Al can design, structure and deploy an online learning course on digital skills for leadership (see Box 5.22). For further relevant discussion on this topic, see Chapter 5, section on “Civil service reform”.

# Better decision-making, sense-making and forecasting
Al experts have identified better decision-making, sense-making and forecasting as the most important Al benefits overall, and they recommend stronger actions and further investments by governments in achieving these areas (OECD, 2024[14]). As discussed below, governments should pursue these benefits while being cautious to avoid over-reliance on Al, as flaws in systems can be difficult to identify, and overly deferring human judgement to machines could allow the systemic propagation of errors and cause real-world harm.

## Enhancing decision-making and sense-making of the present
By providing actionable, data-driven insights, Al can help governments improve the effectiveness and efficiency of targeting actions, allocate resources and identify policy problems and solutions. Governments can therefore respond more effectively to emerging issues, can ensure informed policy development, increase their overall responsiveness and accountability, and ultimately, promote societal well-being.

Some specific ways in which Al can be beneficial throughout the policy cycle (Figure 1.3) include:
*   **Agenda setting and policy formulation:** Al can play a pivotal role bringing issues to the attention of policymakers and in the agenda setting process by framing social problems in ways that make them more responsive to actual social needs. For example, Al enables governments to monitor and make sense of emerging topics in real time from vast and representative datasets, enhancing the accuracy and speed of agenda-setting (Valle-Cruz et al., 2020[60]; Kolkman, 2020[61]). By detecting potential challenges more accurately and quickly, Al facilitates faster policy responses before issues escalate (OECD/UNESCO, 2024[12]; Höchtl, Parycek and Schöllhammer, 2015[62]). Through policy formulation, Al can influence the decision-making process by bringing important data and information about issues to the forefront (Valle-Cruz et al., 2020[60]). Al-enabled analysis can provide insights that estimate not only the likely impacts of policies, but also identify the target populations and make economic and social diagnosis, helping policymakers make informed decisions (Wirjo et al., 2022[63]; Ubaldi et al., 2019[9]). Al can also assist in devising policy alternatives, providing more in-depth ex-ante policy evaluation (Desouza and Jacob, 2014[64]).
*   **Policy implementation.** As policies move to the implementation phase, Al-driven automation, rapid data processing and real-time analysis enhance the quality, speed and efficiency of policy implementation. Al analytics notably strengthen and expedite the acquisition of data and information, supporting continuous improvements. Real-time data analytics can facilitate large-scale enhancements, ultimately improving the delivery of services during policy implementation (Valle-Cruz et al., 2020[60]; OECD/UNESCO, 2024[12]).
*   **Oversight and evaluation.** Al can monitor policy interventions in real time, providing better insights into the policy process, facilitating timely and accurate data assessments of policy interventions and enabling quick policy adjustments when needed (OECD, 2019[65]; OECD/UNESCO, 2024[12]).

Accessible data and increased computing power are providing Al with a competitive advantage over humans when it comes to decision-making in some cases (Green, 2022[66]). For instance, LLMs can support individual reasoning, and evidence shows real-world benefits from Al-assisted decision-making (Brynjolfsson, Danielle and Raymond, 2023[67]). Al systems can enhance decision =-making by mitigating reasoning mistakes and cognitive errors, helping humans filter out “noise” — the unwanted variability in human decision-making — and irrelevant influences that can lead to inconsistent and inaccurate decisions

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 29
(Du, 2023[68]). 7 The potential for Al systems to make data-driven decisions is leading to its adoption across a range of sectors, including within the public sector. Al can identify and address elements that distort human judgment across various applications in government (Mills, Costa and Sunstein, 2023[58]).

Additionally, noise may obscure key insights into human behaviour, which Al can uncover and quantify, contributing to more precise policymaking (Aonghusa and Michie, 2020[69]). Algorithms can significantly reduce noise by ensuring consistency in outcomes regardless of contextual factors, such as mood or time of day. By uncovering previously undetected or obscured behavioural patterns, Al can allow policymakers to better understand systemic trends and decision-making inconsistencies (Ludwig and Mullainathan, 2022[70]). While eliminating noise does not address all mistakes or errors, it enhances reliability, reducing arbitrary disparities in decisions across government functions like justice administration and public service delivery (Sunstein, 2023[71]).

As Al becomes more embedded in public administration, understanding the psychological and cognitive processes that shape human interactions with these technologies is increasingly important. Behavioural public administration can provide further valuable insights into the challenges that may arise, offering strategies to mitigate them and improve governance and decision-making (Alon-Barkat and Busuioc, 2024[72]). An example of this is governments' use of Polis, an open-source civic engagement tool for understanding citizen views as well as areas of consensus and disagreement on public policy matters (Box 5.36). In the field of public financial management, Korea developed dBrain+, an information system that leverages Al to analyse real-time economic, fiscal and financial data to optimise risk assessment and decision-making in public finance (Box 5.8).

# Better forecasting of the future
Al systems can process large volumes of data from multiple sources, including unstructured data, and identify complex patterns and weak signals — early signs of potential emerging changes, threats and opportunities — that are not easily detectable with existing methods. This can enhance the accuracy and timeliness of predictions and can be highly beneficial to other strategic foresight activities (Fitkov-Norris and Kocheva, 2025[73]). Al predictive analytics and forecasting in government involves using algorithms to anticipate future trends and risks. It can be widely applied across various domains, such as forecasting macroeconomic and fiscal outcomes (e.g. "nowcasting” GDP, as discussed in Chapter 5, section on "Al in public financial management").

By providing accurate and timely forward-looking insights, Al enhances decision-making, resource allocation and the overall effectiveness of government operations. Some relevant Al applications include:
*   **Predicting future service needs:** Al has important potential in generating predictive analytics and forecasting, allowing public services to anticipate needs and be proactive. Al can help forecast future service needs, optimise resource allocation and enhance responsiveness across various policy domains by enabling the analysis of historical data and trends.
*   **Regulatory forecasting:** regulators can use Al to uncover emerging trends and shifts in various industries to proactively plan regulatory responses. By continuously monitoring and analysing data from multiple sources, such as market reports, social media and news articles, Al can identify new developments and technological advancements that may impact regulatory landscapes.
*   **Disaster risk management:** Al can also help forecast natural disasters by analysing historical data and current trends. For example, Al systems can analyse satellite imagery and other data to predict the likelihood of natural disasters like wildfires and earthquakes, allowing for proactive measures to minimise damage and enhance public safety (Sun, Bocchini and Davison, 2020[74]; Gupta and Roy, 2024[75]). Al systems can offer early warnings and useful information to help governments respond promptly to such events and mitigate their effects.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

30 |
*   **Anticipating corruption and fraud risks:** predictive Al systems are helping integrity actors to prioritise cases for further human examination. Although the transfer of these approaches from research to governments is still limited, it is growing steadily. For instance, Al systems can be used to prioritise risky cases and streamline auditing processes. They can also support anti-corruption policy targeting by providing early warning systems that predict public corruption based on data such as economic and political factors. Predictive techniques are also key to several Al-enabled government accountability and oversight activities, such as risk-based fraud detection, as further discussed below.

As an example of predicting future public service needs, Portugal's PrevOcupAl system aims to predict work-related illnesses and connected risks factors in the public administration to minimise disruptions (see discussion in Chapter 5, section on "Al in public service design and delivery").

# Improving information management and accessibility
Robust, quality data is an underlying pre-requisite for enjoying Al's benefits. Al can help to maximise the quality and utility of data, as well as the ability of humans and machines to process and analyse it (Jarrahi et al., 2023[76]). For instance, Al systems enable new forms of data collection, including automatically detecting and identifying items in images, audio recordings or video. The capabilities and prevalence of Al-enabled sensing devices have progressed rapidly, allowing automatic speech transcription, motion detection, live image recognition and a wide range of tasks that previously required human labour (Zhang, Wang and Lee, 2023[77]; OECD, 2023[31]). Al can also improve how information is stored, disseminated and applied. This is particularly visible with the integration of Al into knowledge management systems (Sanzogni, Guzman and Busch, 2017[78]).

Improving how information is managed internally within governments can also help governments provide open information and data to the public. The use of Al can help minimise errors in data management, such as by reducing manual effort, and when used in combination with Privacy-Enhancing Technologies (PETs), can help enhance the privacy and protection of sensitive personal data and information (OECD, 2025[79]). This, in turn, enables the wider publication and access to open data. For instance, in justice administration, an Al-powered anonymisation engine can automatically identify and protect personal data within court decisions (Box 5.64), preparing them for public release as part of an open data initiative. The OECD (2023[80]) is also exploring the use of PETs, which are digital solutions that allow information to be collected, processed, analysed and shared while protecting data confidentiality and privacy.9

Internal government virtual assistants for civil servants provide a good example, with France's Albert and the UK's Caddy providing a wealth of historical and cross-government information at public servants' fingertips to inform decisions and help respond to citizen inquiries (Box 5.46).

# Enhanced accountability and anomaly detection
One of the most longstanding uses of Al in government is to detect existing anomalies, such as fraud, or forecast future integrity risks, thus enhancing accountability and integrity in public programmes. Extra care in this use of Al should be taken to avoid possibly damaging outcomes in results.

## Detecting improper transactions and assessing integrity risks
Such activities are common in a variety of government functions, including public procurement, tax administration and public financial management. Fraud and improper payments in government programmes can be significant sources of financial leakage. For instance, in the United States alone, the federal government loses an estimated USD 233-521 billion annually to fraud (US GAO, 2024[81]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 31
ML algorithms are particularly effective at pattern recognition, as they enable the analysis of large datasets and detect data outliers, hidden relationships (e.g. indicating collusion) and other anomalies that require further human investigation. Without the capacity to analyse data at scale or the capability to identify hidden patterns, such irregularities may go otherwise unnoticed without Al. This use of Al can enhance the ability of government organisations to maintain integrity and accountability. For example, France's tax authority uses Al to analyse arial photography and identify undeclared properties (Box 5.1).

Governments can use Al to better identify, evaluate, predict and respond to potential integrity risks, enabling better management, mitigation and timely interventions. For example, in regulatory compliance, inspectors are increasingly using Al to assess the risk posed by private operators. This improves the targeting of inspections, protection of public interests and efficient use of resources (OECD, 2018[82]; 2021[83]). Al assists inspectors by detecting patterns indicative of potential non-compliance, allowing for more accurate risk assessment. This use of Al not only streamlines inspections but also enhances the overall effectiveness of regulatory frameworks by ensuring that resources are directed where they are most needed.

## Enabling non-governmental actors to understand and engage with government and promote accountability
Governments can use Al to be more transparent and to enable new forms and channels of interaction between citizens, civil society organisations (CSOs) and public institutions. In fact, Al experts suggest that empowering citizens, CSOs and social partners (e.g. trade unions) is one of the 10 most important benefits that Al can yield. This is underpinned by government transparency and use of Al (OECD, 2024[14]). They are:
*   offering Al-enabled tools leveraging open government data (OGD) directly to citizens to help them navigate and make sense of government processes and actions
*   enabling third-party oversight and scrutiny of government operations by CSOs and other non-governmental actors
*   providing engagement opportunities and channels where the public can provide feedback and raise potential issues about government performance and decisions.

If executed well, this use of Al has the potential to promote accountability and public integrity, strengthen policymaking and increase citizen trust in government. This benefit — including real-world examples and discussion on the steps governments need to take to achieve it — are discussed in-depth in Chapter 5 in the section on "Al in civic participation and open government".

# Unlocking opportunities for external stakeholders through Al as a good for all
A final benefit to the use of Al in government is unlocking new opportunities for external stakeholders, such as businesses and citizens, by providing them with access to government-developed Al systems. This benefit of Al may not be as directly observable in direct government activities as the other benefits. But it has the potential to improve public governance through increased trust in government, a more informed and skilled citizenry, or even economic growth. Countries have put in place OGD programmes not only to promote transparency and accountability, but also to promote entrepreneurship, economic growth and the creation of value that may not have necessarily been understood or foreseen in their onset (OECD, 2018[84]). For instance, Landsat satellite image data freely released by the US Geological Service since 2008 now results in over USD 25 billion annually in economic value (USGS, 2024[85]). When the OGD movement began in the late 2000s and early 2010s (Chignard, 2013[86]), it was not fully realised that the data made available would serve as vast resources for training Al systems a decade later.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

32 |
Al's nature is distinctly different from that of data in that it is not a natural byproduct of an array of existing functions and activities, and it cannot serve as a raw input for other processes. (For example, data has been compared to fuel, electricity or drinking water for Al). Yet governments' use of Al has the potential to generate public good by empowering stakeholders to enhance their capabilities and access to information to derive new value.

Unlike other applications — where Al facilitates interactions between government and citizens, or improves information provision and accessibility — certain specific uses of Al in public governance can augment the capabilities of these actors, enabling them to achieve their missions and objectives more effectively. For example, the government of India has made Al systems available to farmers to help them ensure crop health and mitigate pest-related challenges (Jeevanandam, 2024[87]). Another example is Germany's FAIR Forward - Artificial Intelligence for All development initiative, which supports open creation and responsible usage of Al systems on areas such as agriculture, climate protection and citizen participation (OECD, 2023[88]). Such approaches may be particularly useful in markets not yet served by, or with little appeal for, private sector solutions. Governments may have the resources to invest in under-explored fields and can take the first steps to build out new markets, taking risks where others may not be ready or willing to.

The potential for positive external opportunities would be amplified further if governments were to provide access to enablers for Al, such as digital infrastructure in the form of computing power (Ho, 2023[89]) (see Chapter 4, section on "Building out digital infrastructure"). In some cases, these enablers may already exist for government use, only requiring some adjustments and scaling to make them available to a broader audience. In other cases, enablers targeting external actors could be developed and supplied. This can democratise Al's potential value (OECD, 2024[14]).

Non-governmental entities can also participate in the creation and deployment of Al tools, playing leading roles in fostering technology-enabled participation (OECD, 2025[90]).

# To seize the benefits of Al, its risks need to be managed
The global adoption of Al in all sectors raises questions about trust, fairness, privacy, safety and accountability, among others. Considering these issues and managing Al's risks can have an impact on its adoption and the realisation of its benefits (Tse and Karimov, 2022[91]). Al poses hundreds of risks,10 and experts identify some of the most important for society as (OECD, 2024[15]; [14]; [92]; 2022[93]):
*   Possible adverse outcomes for some groups or individuals if Al systems are underpinned by inadequate or skewed data.
*   Al systems lacking sufficient transparency and explainability erode accountability.
*   Certain Al uses raise data protection, privacy and surveillance concerns.
*   Al can facilitate increasingly sophisticated cyber threats.
*   Minor to serious Al incidents and disasters could occur in critical systems.
*   Al could contribute to labour market disruptions.
*   Al computational power requires very significant energy use.

These are thorny issues that are being considered by governments, companies, CSOs and other relevant stakeholders. Efforts such as the adoption of the European Union (EU) Al Act (2024[94]) and a variety of national-level governance initiatives help to illustrate how governments are taking an active role in governing Al for society.11

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 33
# Risks specific to Al use in government
Perhaps all Al risks could implicate governments in some way, such as necessitating governance processes or mitigation measures. Yet a narrower subset of risks is most relevant for policymakers and public servants as they pursue the strategic and responsible use of Al in government. As mentioned above, governments have an outsize influence on people's lives, thus their use of Al can have a greater impact on the public in both positive and negative ways. Accountability expectations are, therefore, higher for government use of Al. This can be seen explicitly in the EU AI Act, which classifies many public sector Al use cases as "high-risk", and some as "unacceptable risk" and therefore banned in the EU (Box 1.2). The United States takes a different approach, considering some use cases as "high-impact", and thereby requiring certain risk management practices (Box 1.3). Korea's Basic Act on the Development of Al and the Establishment of Foundation for Trustworthiness (“Al Basic Act") (2024[95]), which will take effect in January 2026 and applies to organisations developing or using Al in the Korean market, similarly designates some uses as “high-impact”, thereby requiring enhanced measures for ensuring Al safety and reliability. The Al Basic Act also includes a separate designation for generative Al that includes specific transparency and disclosure requirements.

## Box 1.2. The EU AI Act's risk levels as related to Al in government
The European Union (EU) Al Act is a regulation on Al that entered into force in August 2024. The regulation establishes obligations for Al based on its potential risks and level of impact. The Act identifies four different levels of risks that are relevant for governments' use of Al.

*   **Unacceptable risk.** Al uses under this category are prohibited. Examples include predictive policing, real-time remote biometric identification (including facial recognition) in public spaces for law enforcement, social scoring and assessing the risk of an individual committing criminal offenses. Law enforcement and justice administration are among the functions of government most concerned by this category. However, some exceptions apply, such as use cases concerned with national security and those remaining subject to judicial oversight.
*   **High-risk.** Al uses under this category are allowed but regulated due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law. Due to its potential impact on these aspects, many government uses of Al might fall under this category. Examples include systems used to influence the outcome of elections and voter behaviour, automated processing of personal data to assess various aspects of a person's life, assessing eligibility for benefits and services, and safety components used in the management and operation of critical infrastructure. Obligations include establishing a risk management system, conducting data governance, setting up technical documentation to demonstrate compliance and mandatory fundamental rights impact assessment.
*   **Limited risk.** These uses might include systems intended to communicate with individuals, such as chatbots, as well as systems that generate content such as text and images. Transparency obligations require developers and deployers to ensure that end users are aware that they are interacting with Al.
*   **Minimal risk.** These systems are unregulated, but a code of conduct is suggested. Examples include video games and spam filters.

Source: (EU, 2024[94]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

34

# Box 1.3. The concept of "high-impact" Al in United States (US) policy

In the United States, the policy M-25-21 Accelerating Federal Use of Al through Innovation, Governance and Public Trust establishes a dualistic approach for Al use cases in government: either the Al use case is considered “high-impact", or it is not.

High-impact Al is Al with an output that serves as a principal basis for decisions or actions with legal, material, binding or significant effect on:

* an individual or entity's civil rights, civil liberties or privacy; access to education, housing, insurance, credit, employment, critical government resources or services; or other programmes
* human health and safety
* critical infrastructure or public safety
* strategic assets or resources, including high-value property and information marked as sensitive or classified by the federal government.

Federal agencies are responsible for conducting reviews on their Al use cases and determining the applicability of the high-impact definition. The policy provides examples of 15 categories of Al use cases that are presumed to be high-impact.

Agencies must implement minimum risk management practices for high-impact Al use cases. The minimum risk management practices include the following: conducting pre-deployment testing and an Al impact assessment; ongoing monitoring for performance and potential adverse impacts; ensuring adequate human training, assessment, human oversight, intervention and accountability; offering consistent remedies and appeals; and consulting and incorporating feedback from end users and the public. Agencies must have a plan to discontinue the use of any high-impact Al system that is not performing at an appropriate level in compliance with the policy, until actions are taken to achieve compliance.

Limited pilot programmes should follow minimum risk management practices where practicable. However, if the CAIO certifies and other criteria are met as detailed in the source document, pilot programmes are exempt from the minimum risk management practices. Agency CAIOs may also waive one or more minimum risk management practices under certain circumstances for a specific use case, though they must certify the ongoing validity of each determination and waiver annually, track them centrally and publicly release a summary of each.

Source: https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-Al-through-Innovation-Governance-and-Public-Trust.pdf.

As they seek to develop and use Al, governments face risks that include potential dangers and threats that could cause serious problems for individuals and society (Valle-Cruz, Garcia-Contreras and Gil-Garcia, 2023[96]), potentially undermining public trust, the legitimacy of government's Al use and even democratic values. To address these concerns, it is important to identify and manage these risks, consider how Al systems may impact citizens or marginalised populations differently, help ensure the equitable distribution of Al benefits and mitigate potential harm. The continuous consideration of potential risks is important because known risks can evolve and new risks can emerge, including ones previously considered to be outside the realm of possibility.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 35

This report identifies five general types of risks for the use of Al in government, as presented below. Beyond grappling with these risks, governments also face a number of implementation challenges when seeking to develop and use Al. These implementation challenges are discussed in Chapter 3.

*   **Ethical risks:** These include Al uses that undermine the free exercise of human rights and freedoms, including privacy, potentially infringing on human-centred values either deliberately or inadvertently. Al algorithms can introduce ethical risks from the digital realm to the physical world through biased algorithms and unethical behaviours like invasive surveillance. Key concerns include threats to trust, fairness, freedom, dignity, individual autonomy and labour rights.
*   **Operational risks:** These include technical and operational failures that might affect data privacy, the quality of Al outcomes and internal government operations due to cybers threats, unintended consequences, hallucinations, systematic errors and overreliance on Al systems.
*   **Exclusion risks:** These risks relate to gaps that arise when citizens without access to technology or digital literacy can be left behind and unable to benefit from Al advancements in public services.
*   **Public resistance risks:** These include public resistance to government use of Al. This can be driven by distrust in government Al systems or processes, or by the spread of false or misleading information about how Al is implemented in public administrations and its potential impacts.
*   **Risks of inaction:** Although often overlooked, this risk includes government delays in using Al to yield positive benefits. This can result in significant financial and non-financial costs – which could have otherwise been avoided with Al's successful adoption — and a widening gap between public sector and private sector capabilities.

# Ethical risks

## Inadequate or skewed data in Al systems

Al systems have the potential to perpetuate or generate adverse or harmful outcomes, stemming from incomplete or inadequate data, as well as how Al usage intersects with institutional and social practices that are human-centred or systemic in nature.

It is important to recognise that algorithms do not operate autonomously; they are shaped by human choices at every stage, from model selection and training data to fine-tuning and parameter adjustments. Since Al systems usually learn from human-generated data, they inevitably reflect existing social outlooks and behaviours. Moreover, in government, algorithms rarely make decisions independently — they typically serve as tools that inform and influence human decision-making rather than replace it. Even where policies aim for standardisation, successful implementation still heavily depends on local context and the "messy engagement of multiple players with diverse knowledge" (Davies, Nutley and Walter, 2008[97]). This interplay between Al and human judgment means that errors can persist not only in algorithmic outputs but also in how Al-generated recommendations are interpreted and applied. Understanding how decision-makers process and respond to Al-generated information and ensuring they have the skills to use Al in a trustworthy manner are therefore critical. On one side, cognitive subjectivity remains relevant in shaping human-Al interactions despite Al's perceived neutrality, while on the other, machines lack empathy. Therefore, it is important that public servants can use professional judgment and practical wisdom to ensure fairness by exercising judicious discretion.

Al systems are also highly sensitive to the quality of training data, making them susceptible to overfitting patterns,12 learning spurious correlations and amplifying errors or skew embedded in human-generated datasets. While Al can help eliminate noise, as discussed as a benefit above, its pattern-seeking nature can also exacerbate it, particularly when systemic inconsistencies exist in the training data. Without rigorous oversight and mitigation, Al risks reinforcing distortions rather than delivering objective, reliable decisions, highlighting the critical need for careful data curation and validation, system testing, anticipatory

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
36 |

and retrospective impact monitoring and assessment, and algorithmic transparency in Al-driven decision-making (Shane, 2019[98]).

Because of its potential to have systemic impacts, insufficient or skewed data and algorithms can also exacerbate other types of risks, such as those discussed below.

## Misuse or questionable use of Al, resulting in surveillance and privacy concerns

The misuse or questionable application of Al in government could result in harm to the free exercise of individual freedoms and rights. A prominent concern is the use of Al in delivering public security and safety services, where it enables efficient identification and tracking through biometric data and real-time monitoring. While these tools can be useful for law enforcement and crime prevention, they also raise concerns about data privacy, as well as surveillance and social control by public administrations. For instance, during the COVID-19 pandemic, Al was employed to track people's movements to ensure compliance with self-isolation mandates (Saheb, 2022[99]). Although this measure was intended to control the spread of the virus, it raised privacy concerns among the public (OECD, 2020[100]). Indeed, Al-driven surveillance in increasingly pervasive, with the Carnegie Endowment for International Peace (2022[101]) finding that 97 of 179 (54%) countries analysed are using Al technologies for public surveillance. 13 The index identified non-democratic states as a major driver of Al surveillance, including through selling products to other countries. Yet others, including liberal democracies, are also major users of Al surveillance (Saheb, 2022[99]). As seen in Box 1.2, the EU Al Act regulates when the use of Al for surveillance is admissible, and it identifies use cases that are an "unacceptable risk" and banned throughout the EU.

Similarly, personalised service delivery often requires algorithmic processing of data scattered across multiple public and sometimes private data sources (Nikiforova et al., 2023[102]). This raises privacy concerns and highlights the need for governments to pursue both efficient service delivery and the robust protection of individual privacy rights. For instance, to provide personalised social services, governments might aggregate data from healthcare records, educational achievements, employment history and even social media activity. While the goal is to offer tailored support and timely interventions, processing such vast amounts of personal information needs to be done carefully and deliberately, with controls in place to mitigate concerns of surveillance. Such guidance may be found in (OECD, 2017[103]) and (OECD, 1980[104]). Robust policies and infrastructure are needed to consider trade-offs between responsiveness, transparency and the protection of sensitive information (OECD, 2024[105]; [59]).

Another misuse case is social scoring in service delivery or policymaking, a practice where individuals are classified based on behaviour or personal traits. Al algorithms analyse data from sources like social media, financial transactions and public records to assign scores. These scores can impact access to services, loans and employment opportunities, leading to unfair treatment. Government use of such systems is banned in the EU as an unacceptable use (EU, 2024[94]).

In a recent survey of hundreds of experts across fields, 79% said that Al will have a negative impact on people's privacy by 2040, a concern shared by the general public (Rainie and Anderson, 2024[106]; Fazlioglu, 2024[107]). Governments will need to ensure their use of Al is trustworthy to allay these concerns as it related to Al in government.

The potential misuse of Al tools for citizen surveillance by authorities can lead to overreach and abuse of power. Continuous monitoring and data collection can create a climate of fear and mistrust, particularly among communities who may already feel disproportionately targeted by law enforcement (UN, 2024[108]). Governments can also use Al to strengthen political power, potentially facilitating wide-scale subjugation and authoritarianism (OECD, 2024[14]), especially by non-democratic governments or those that do not prioritise the protection of human rights. Some experts argue that Al could be — and in some instances already is being — used to track and monitor citizens and residents at scale, using algorithms and

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 37

behavioural analysis, identify and supress opposition, and perpetuate totalitarian regimes (OECD, 2022[109]; Tegmark, 2017[110]; Clarke and Whittlestone, 2022[111]; Byler, 2021 [112]).

Finally, algorithmic manipulation, where Al systems and their results are altered to produce specific outcomes, is another potential misuse and unethical behaviour in the governmental use of Al (Valle-Cruz, Garcia-Contreras and Gil-Garcia, 2023[96]). This manipulation can stem from individual public servants, decision-makers or Al system developers intentionally altering system results to benefit or harm certain groups or individuals or push a specific agenda. Al's inherent complexity can additionally make it challenging to trace and understand algorithms' inner workings.

## Lack of transparency and explainability

Systems based on deep learning are "black boxes”, meaning that it is difficult to describe how they produce a given output. Such outputs are indirectly generated from deep learning training as engineers continually tweak parameters until the model scores highly on training objectives (Clarke and Whittlestone, 2022[111]). Even scientists working on advanced deep learning models do not understand the inner workings of their systems, and they find it hard to trace back these outputs and test the reliability of these systems through traditional methods (OECD, 2022[109]).

This makes it hard to detect and mitigate harmful outcomes and produces challenges in determining accountability when issues arise. As Al systems become increasingly integrated into functions of government, black box systems could make it difficult to explain the rationale for Al-assisted decisions to citizens. It can also exacerbate other Al risks. For instance, it can be more difficult to identify algorithmic bias and its root causes in opaque systems. Public servants could also increasingly have a false sense of trust in seemingly efficient yet flawed Al systems because such flaws may be unobservable (contributing to automation bias, discussed below) (OECD, 2024[14]; Russell, 2019[113]). This can erode government accountability and disempower the public by limiting their ability to make informed decisions or potentially making them subject to opaque, flawed Al-driven decisions (Lima et al., 2022[114]).

# Operational risks

## "Automation bias" – overreliance on Al

Many people perceive Al systems and their decisions to be neutral and impartial, leading users to accept results without scrutiny. Studies on Al-assisted decision-making have identified a tendency to overweight algorithmic recommendations, often assuming their prediction to be more reliable than human judgment — even when the Al system itself has limitations (Alon-Barkat and Busuioc, 2024[72]). This “automation bias" (the propensity for people to trust Al outputs because they appear rational and neutral) can lead to the application of Al decision-making to a growing number of societal challenges (Horowitz, 2023[115]; Alon-Barkat and Busuioc, 2022 [116]) — perhaps to avoid difficult conversations and decisions about human approaches to these issues. Some experts assert that this habit is creating "blind faith" in technology, a problematic phenomenon that can reinforce existing systemic issues against certain groups or individuals and contribute to neglect of human suffering and erosion of empathy (Goldman, 2023[117]; Olson, 2023[118]).

So-called "automation bias” in government occurs when public organisations or civil servants rely too heavily on Al systems for decision-making or task execution. For example, if healthcare professionals rely too heavily on Al-automated suggestions without cross checking, they might miss critical information or make incorrect diagnoses. This excessive dependence can result in users failing to recognise mistakes, accepting incorrect Al outputs, and diminishing human oversight and judgment (Passi and Vorvoreanu, 2022[119]; Klingbeil, Grützner and Schrec, 2024[120]). Al could be systematically adopted without fully assessing accuracy and potential consequences, leading to reliance on Al systems and the propagation of compounding errors throughout entire systems (Valle-Cruz, Garcia-Contreras and Gil-Garcia, 2023[96]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
38 |

One contributor to such issues are hallucinations, which occur when generative Al systems make up facts in a credible way, often when a correct answer is not found in the training data. This can be harmful in contexts such as government decision-making, where they may lead to misguided decisions or actions (OECD, 2024[15]; Beltran, Ruiz Mondragon and Han, 2024[121]). For example, an Al system designed to answer queries from the public could provide erroneous details about public services or list services that do not exist. If not carefully mitigated, these unintended consequences and incorrect outputs can scale rapidly, affecting large populations or critical internal government decisions.

Al systems can also be prone to simple errors and malfunctions, which can lead to systematic deviations and imprecision in algorithmic outputs. If these systems are not carefully implemented or fail to be technically reliable, they risk diminishing public trust, including that of civil servants. Citizens may experience frequent frustrations due to incorrect processing of their requests or delays in service delivery. For example, automated systems that handle form submissions, customer service inquiries and payment requests need to operate with great accuracy; otherwise, mistakes or technical glitches can lead to a perception of incompetence and unreliability in public services. Technical problems or errors in chatbot interactions, such as incorrect responses, inability to understand queries or system outages, can further erode trust, making citizens feel that Al systems are unreliable and ineffective.

Risk aversion also plays a role in "automation bias". Civil servants may be afraid to take personal responsibility for decisions for fear of getting in trouble later. An example is when a human decides against the advice of an Al system and it turns out to be the wrong decision. In such cases, the civil servant will seem doubly responsible. As seen in Box 5.43, some government Al systems have even been designed to make public servants write justifications for review if they go against an Al system's advice, adding to the burden of their work and reinforcing incentives to follow what the system recommends.

Research also highlights the concept of selective adherence, where decision-makers are more likely to follow algorithmic recommendations when they align with their pre-existing beliefs or societal stereotypes (Alon-Barkat and Busuioc, 2022[116]). This can lead to distorted public decision-making, as civil servants may unconsciously use Al outputs to justify pre-existing biases rather than critically evaluating them.

Some research suggests that overreliance on Al may contribute to a decline in human cognitive abilities, reducing exploration, creativity and independent thought, as individuals become accustomed to Al-generated solutions. Studies suggest that frequent reliance on Al-driven decision support systems can lead to cognitive offloading, reducing individuals' engagement in critical thinking and independent problem-solving (Gerlich, 2025[122]). Al-driven decision-making also risks promoting behavioural homogenisation, as its outputs often reflect limited diversity of perspectives. This narrowing of perspectives could hinder adaptive thinking and reduce the capacity of societies and governments to navigate uncertainty and risk (Meng, 2024[123]). Although over-reliance on Al may pose risks, Al tools can also help human operators interpret and question complex Al decisions, discouraging overreliance (OECD, 2024[15]).

## Reduced job quality for public servants

While Al can enhance public servants' job quality and well-being, as discussed above, some uses can have the opposite effect. The use of algorithmic management tools is increasing significantly, reaching an adoption rate of 90% in US firms and 79% in the EU (Milanez, Lemmens and Ruggiu, 2025[124]). While public sector-specific studies have not been conducted, tangible concerns have been raised about existing negative impacts of Al and algorithmic tools on job quality, including work intensification, increased stress, perceived reduction in fairness and workplace surveillance (OECD, 2023[25]). For instance, Al could make jobs less fulfilling and more stressful by incentivising new types of surveillance in the workplace, or new forms of hyper-efficient yet exhausting "digital Taylorism", in which work is subject to increased surveillance and regulation, including through algorithmic management (UC Berkeley, 2021[125]; EC, 2025[126]).14 Further research has shown that such Al surveillance can harm mental health (APA, 2023[127]), and that Al task management can erode the autonomy and voice of workers, reducing human insights into how work is

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 39
managed (Gmyrek, Berg and Bescond, 2023[128]). However, if used well, such tools have also been shown to improve worker safety and well-being (e.g. by alerting workers about dangers and hazards, or identifying burnout) (EC, 2025[126]). Algorithmic management and its impacts are already being seen and studied with regard to their use in the private sector (OECD, 2023[25]). Research on algorithmic management in the public sector is scarce, although its use is expanding rapidly (EC, 2025[126]).

# Privacy and data governance tensions
Developing and deploying Al systems poses privacy and data governance challenges throughout the Al lifecycle (OECD, 2024[129]; forthcoming[130]). In the Al training stage, many developers depend on publicly accessible sources for building Al training datasets, which may purposefully or inadvertently include personal data or information subject to intellectual property rights. However, just because data is accessible on the Internet does not automatically mean that it is free to be collected and used to train Al models. Further, people may have shared their personal data consenting to another use or uses, which do not necessarily include training Al models (ICO, 2023[131]). The collection of personal data for training Al systems, like any data processing activity, is subject to the commonly recognised privacy principles set forth in the OECD Recommendation Concerning Guidelines Governing the Protection of Privacy and Transborder Flows of Personal Data (OECD Privacy Guidelines) (1980[104]). These principles require that personal data be obtained through lawful and fair means, with the knowledge of the data subject, and that any further uses of the data are not incompatible with the original purposes.

Another important aspect to consider is the capacity of Al models to memorise personal data within their parameters during the training stage. As a result, LLMs behind text-based generative Al tools pose a particular risk of unauthorised access and use of third-party personal data without the knowledge of the individuals concerned (Brown et al., 2022[132]). Some research also shows that generative Al models are able to infer personal attributes of the data subject from text with high accuracy, yet at a low cost (Staab et al., 2023[133]). This raises privacy concerns not only because these inferences can reveal personal information or personal characteristics, especially when such traits were not intended to be shared.

During the deployment stage, Al systems can also be in tension with individuals' rights to access, correct, and where necessary, delete their personal data (also known as the "Individual Participation Principle" in the OECD Privacy Guidelines). For example, fulfilling individuals' rights to have their data deleted or corrected can be technically complex and resource-intensive, as it might require identifying specific data points related to an individual within unstructured datasets or in some cases re-training the Al model. Additionally, research conducted prior to the widespread use of generative Al models suggests that, in certain cases, it is possible to reconstruct or deanonymize original training data by analysing the behaviour of a model that includes that data (Salem et al., 2018[134]). To address such tensions, promoting further international cooperation between data privacy and Al communities can contribute to harmonised data practices with Al development and use. For example, OECD's Expert Group on Al, Data, and Privacy15 is exploring policy responses on data governance and privacy in the context of Al, involving experts from multiple sectors and disciplines around the world.

# Cyber threats
Al systems incorporated into government processes can be vulnerable to cyber threats, which can lead to data breaches, privacy violations and loss of functionality. The extensive collection and analysis of personal data for Al applications can result in loss, alteration or unauthorised disclosure of this data, infringing on individual privacy rights (Beltran, Ruiz Mondragon and Han, 2024[121]). Unauthorised access and data breaches can compromise personal data and operational integrity, which could result in identity theft, financial fraud and other privacy violations, undermining public trust in government institutions and resulting in legal consequences. Additionally, malicious cyber actors could manipulate Al systems, altering their outputs and causing erroneous decisions or actions (Brundage et al., 2018[135]; Gopireddy, 2024[136]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

40 |
Cyber risks may originate from external bad actors, or from insider threats within government (Eshelby, 2025[137]). Overall, cybersecurity can be seen as a horizontal function of government in itself, and indeed represents one of the areas of greatest Al adoption in government for enhancing security of government IT systems (Mariani, Kishnani and Alibage, 2025[138]). However, this function is highly specialised and not included in the primary scope of this report, and it is not a topic of thorough analysis and discussion. However, the OECD has an ongoing workstream on digital security that has conducted relevant work.16

# Exclusion risks

## Exacerbating digital divides
The risk of omitting people when using Al in government is closely linked to digital divides (UN, 2024[108]), the gap between those who can access and use information and communication technologies and those who cannot. This is particularly evident in public service delivery and policymaking activities, especially in the use of Al for predictive analytics, forecasting and service personalisation.

Digital divides risks hindering access to the benefits and public value that Al offers. This is especially the case among populations lacking the necessary infrastructure and digital literacy to engage with Al-driven public services (OECD, 2024[14]; ITU, 2023[139]). Al in government can offer advantages — like tailored information, faster response times and enhanced service delivery — but may be inaccessible to those without internet access or digital skills. Governments' shift to digitalisation can intensify the barriers to digital government services among certain segments of the population. Research in Canada found that users in rural locations, women and girls and those in low-income households were negatively affected by the push towards digital-first services due to the COVID-19 pandemic (Singh and Chobotaru, 2022[140]). In Norway, the digitalisation and automation of the system for awarding child benefits made it possible for most recipients to receive the benefit automatically. At the same time, it resulted in the need for other recipients to apply manually, a burden that disproportionally affected low-income segments (Larsson, 2021[141]).

Data divides are another form of exclusion caused by Al that is linked to unrepresentative data, a consequence of existing digital divides. Individuals without internet access are often absent from the data used to develop algorithms. Because most data are predominantly collected through the internet and online interactions, the widespread use of Al may exclude these individuals, as algorithms used to inform policymaking lack representative data. These gaps make it difficult for governments to respond adequately to the needs of all citizens, resulting in insufficient or inadequate data sets in Al-driven decision-making processes and service delivery. For instance, data divides limit the potential for Al benefits, such as personalised Al services, leaving them only useful and accurate for data-rich populations (UNESCO, 2019[142]; Perry and Turner Lee, 2019[143]; Dieterle, Dede and Walker, 2022[144]).

Another form of digital divide involves underrepresentation of languages (Röttger et al., 2024[145]; Peixoto, Canuto and Jordan, 2024[146]). Training datasets tend to overrepresent widely used languages, as seen in Figure 1.4. This imbalance can lead to Al systems that fail to serve non-dominant language groups effectively. Language preservation efforts, such as Estonia's Donate a Speech, reduce the current limitations of speech technology, which favour the most widely recognised languages, and enhance service delivery (OECD, 2023[38]). Additional considerations and examples are discussed in Chapter 4, section on "Creating a strong data foundation".

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 41
# Figure 1.4. More than half (59%) of open-source Al training datasets are in English
## Percentage breakdown of languages for open-source Al training datasets on Hugging Face

### Chart Data
- **Language Categories (from largest to smallest slice):**
  - English
  - Other
  - Chinese
  - French
  - Russian
  - Japanese
  - Spanish
  - Korean
  - Vietnamese
  - German
  - Portuguese

Note: This chart represents the language distribution of all datasets. Multilingual and translation datasets on Hugging Face contain more than one language and are thus double counted. More methodological information available at: https://oecd.ai/huggingface.
Source: OECD.AI (2024), visualisations powered by JSI using data from Hugging Face. Last updated on 5 June 2025, (accessed 16 June 2025).

# Public service workforce displacement
The OECD (2023[25]) found that while Al is capable of automating non-routine tasks, its future impacts on labour are ambiguous; they depend on the balance between the displacement of human labour by Al, the increase in labour demand due to greater productivity brought about by Al and the creation of new jobs caused by Al adoption. Al can enhance government productivity by automating tasks, and it also has the potential to reduce the need for human labour, resulting in the need to re-skill public servants to take on more meaningful tasks (Peixoto, Canuto and Jordan, 2024[146]).

At the same time, Al deployment is driving a growing demand for Al-related skills across the economy, and the public sector is no exception. As Al-related roles increase, hiring and retention efforts for non-Al or traditional positions may decline, highlighting the need for a workforce skilled in Al and related technologies to meet evolving demands (Acemoglu et al., 2022[147]).

Al technologies impact a wide range of occupations and sectors, affecting workers of all skill levels and influencing labour markets (OECD, 2023[25]). While some government workers may adapt to Al and even see their work enhanced, others, such as older and low-skilled workers conducting tasks that are easy to automate, face significant risks. This suggests that Al's benefits are not evenly shared among public servants (Milanez, 2023[148]). For instance, Al-powered chatbots are now commonly used for service delivery and citizen-centred communication to answer basic questions and provide information, which reduces the demand for government human customer service representatives (Acemoglu, 2024[149]).

For many years, concerns about job automation focused on low-skilled labour, but high-cognitive tasks are increasingly being assisted by Al, which can impact civil servants such as policy analysts. Generative Al can produce meaningful text, conduct data analysis and even propose policy strategies to address complex

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

42 |
challenges. Many civil servants will need to be trained to collaborate effectively with Al and focus on higher level strategic thinking and decision-making.

# Public resistance risks

## Citizens may selectively accept Al-informed outputs, potentially contributing to errors
Understanding human-Al interactions is increasingly seen as a key challenge for public administration, with significant implications for trust and legitimacy. As governments integrate Al into decision-making, public acceptance of these systems becomes critical. Research suggests algorithmic decisions, despite their promise of neutrality, are not always perceived as fair or legitimate, particularly when they contradict individuals' expectations or lack transparency (Alon-Barkat and Busuioc, 2022[116]).

Citizens process algorithmic decisions through cognitive perceptions and prior beliefs; they often selectively accept Al-generated recommendations that align with their expectations while resisting those to the contrary (Alon-Barkat and Busuioc, 2022[116]). This selective adherence can reinforce errors in government decision-making, as individuals may be more likely to trust algorithmic predictions when they confirm pre-existing stereotypes or prior knowledge.

## Lack of public empowerment and understanding about how government uses Al
There is often a lack of knowledge and understanding among the public regarding Al in general, and more specifically, how governments use it (Arnesen et al., 2024[150]). This can lead to misconceptions and fears about its capabilities and whether governments are using it in a trustworthy manner. This could potentially result in outcomes such as rumours spread online about government's use of Al in policymaking or in delivering services such as loans, access to justice or social benefits. This can occur because Al's complexity is often misunderstood, leading to inaccurate assumptions about how decisions are made, the fairness of outcomes and the ability to hold these systems accountable; or because of the limited transparency on how public authorities are using Al. This limited transparency or gap in understanding makes the public more susceptible to scepticism regarding governments' actions and intentions, resulting in resistance to Al-driven solutions in public services (Valle-Cruz, Garcia-Contreras and Gil-Garcia, 2023[96]).

Al decisions can be perceived as overly rigid or unaccountable, particularly in the absence of human oversight or avenues for redress. Research suggests that when citizens feel disempowered in interactions with automated systems — such as being unable to challenge incorrect Al-based decisions — they experience higher psychological and compliance costs (Alon-Barkat and Busuioc, 2024[72]).

Conversely, higher levels of public empowerment and transparency on use, knowledge and understanding of Al are associated with greater trust in the government's ability to use Al responsibly (Lahusen, Maggetti and Slavkovik, 2024[151]; KPMG, 2025[152]; Alessandro et al., 2021[153]). A well informed citizenry is more likely to recognise the safeguards and ethical considerations implemented by the government, fostering confidence in its competence and integrity in deploying Al technologies.

## Al misuse and scandals can undermine trust and contribute to public resistance
The use of Al in government has resulted in several high-profile scandals and cases of real-world harm. This underscores the high reputational costs of Al misuse, with issues happening years ago still resident in public discourse. High-profile failure in one Al system can erode confidence in a broader array of government use cases (Longoni, Cian and Kyung, 2022[154]). Public backlash has even led to people withdrawing from data sharing or hindered the use of existing tools (Ada Lovelace Institute, 2025[155]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 43
Public backlash is particularly likely when Al errors result in visible harm, such as wrongful denial of benefits or unfair treatment based on skewed predictions. High-profile failures can reinforce public scepticism and fuel concerns Al-driven decisions may undermine procedural justice and democratic accountability (Alon-Barkat and Busuioc, 2022[116]). Data from the OECD Al Incidents Monitor (AIM) shows growth in Al incidents and hazards reported by reputable media sources in recent years (Figure 1.5).17 As of April 2025, 3 816 of the 14 981 incidents listed (25%) were related to "government, security and defence", illustrating that governments need to ensure they mitigate risks in order to secure citizen trust.

# Figure 1.5. Al incidents have generally trended upwards since late 2022

## OECD AI Incidents Monitor (AIM)
Automated monitor of incidents and hazards from public sources (Beta).
Patrick J McGovern FOUNDATION

[Search Bar: Enter a concept or a keyword and press enter. Use advanced options to further narrow the search.] [Button: Reset]

### Evolution of incidents and hazards
[Dropdown Menu: As percentage of total AI events]

#### Chart Data
**Y-Axis:** Number of incidents and hazards, ranging from 0 to 900 in increments of 100.
**X-Axis:** Months from Oct 2020 to Aug 2024.
**Legend:**
- Total Incidents & Hazards
- 6-month moving average

**Approximate Data Points for "Total Incidents & Hazards" line:**
- Oct 2020: ~20
- Dec 2020: ~40
- Feb 2021: ~50
- Apr 2021: ~60
- Jun 2021: ~50
- Aug 2021: ~40
- Oct 2021: ~80
- Dec 2021: ~100
- Feb 2022: ~120
- Apr 2022: ~150
- Jun 2022: ~180
- Aug 2022: ~300
- Oct 2022: ~450
- Dec 2022: ~500
- Feb 2023: ~750
- Apr 2023: ~400
- Jun 2023: ~600
- Aug 2023: ~800
- Oct 2023: ~550
- Dec 2023: ~700
- Feb 2024: ~500
- Apr 2024: ~650
- Jun 2024: ~750

Note: An overview of the methodology can be found at https://oecd.ai/incidents-methodology.
Source: OECD AI Incidents Monitor (AIM) – https://oecd.ai/incidents.

Citizens can also exhibit algorithmic aversion, often resisting algorithmic decision-making due to a preference for personal agency and control, even when Al systems outperform humans. This reluctance is reinforced by a greater tolerance for human errors compared to algorithmic mistakes; people tend to lose trust in Al after observing a single failure, whereas they are more forgiving of similar errors made by humans. Algorithmic aversion can be more common in some functions (e.g. public safety) than in others (e.g. general management), which can contribute to different challenges and differing levels of maturity across government functions (see Chapter 3) (Zehnle, Hildebrand and Valenzuela, 2025[156]). Providing users with insight into the reasoning behind an Al's recommendation or offering limited control to modify its output can significantly improve acceptance, increasing the likelihood of users adopting Al-driven advice (Sunstein, 2023[71]). Beyond contributing to public resistance risks, algorithmic aversion on the part of public servants can hinder governments ability to harness the benefits of Al, as discussed in Chapter 3.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# Page 1

44 |

# Risks of inaction
The most discussed risks of Al involve the implications of its deployment and adoption. However, a less discussed risk involves delays in leveraging Al to yield real-world positive benefits, including in government and public services. Stanford University's One Hundred Year Study on Artificial Intelligence (AI100) (2014[21]) noted that “numerous advances in Al can reduce costs, introduce new efficiencies and raise the quality of life... However, the methods have not come into wide use. The sluggish translation of these technologies into the world translates into unnecessary deaths and costs. There is an urgent need to better understand how we can more quickly translate valuable existing Al competencies and advances into real-world practice." While this study is over a decade old, the conclusion remains the same, especially in government. Beyond missed opportunities, the risk of inaction on Al serves to widen the gap between public sector and private sector capacity (Pahlka, 2024[157]). This not only means governments could fall behind on their ability to use Al but also in their ability to regulate the technology. Al experts suggest that one of the most critical Al risks is the inability of governance mechanisms and institutions to keep up with rapid Al evolutions (OECD, 2024[14]).

Some research highlights that negative hype and fear around Al can contribute to this risk (Laplante et al., 2020[158]). Such research notes that other limitations may include a lack of suitable data, confusion around privacy issues and complexities, and dealing with outdated legacy IT systems. Experts have also attributed the issue of "analysis paralysis" the fear of getting Al wrong as a possibility that could paralyse the implementation of even low-risk efforts, foregoing significant benefits (OECD.AI, 2023[159]). This has proven true in government; the latest cross-cutting OECD (2024[13]) work on Al in government found that governments need to better promote and enable the positive aspects of using Al, rather than focusing so disproportionately on the prevention of negative ones. This focus on risks might deter the deployment of high-benefit, low-risk uses of Al to improve public policies and services.

# Realising a positive future for Al in government
As discussed above, governments are seeking to use Al to increase productivity, with more efficient internal operations and more effective policies and services; responsiveness, through tailored approaches that meet the evolving needs of citizens and businesses; and accountability by enhancing their capacity for oversight. However, there is tremendous untapped potential for governments to use today's Al technologies and prepare to unlock the opportunities presented by tomorrow's Al. Even so, a vision of a future where governments successfully develop and adopt trustworthy Al is beginning to emerge.

> See Al not as an opportunity to automate the public sector but to reimagine it. We welcome a long-term vision for public service transformation where Al follows rather than leads, one that is grounded in public and professional legitimacy. Public sector leaders should see the rollout of Al as an opportunity to reimagine the state, rather than focusing solely on immediate efficiency gains or automating the status quo. Al should be viewed as a catalyst for fundamental service redesign, placing the citizen at the centre of public service delivery. – Ada Lovelace Institute (2025[155])

This vision shines through in Chapter 5's discussion of Al in core functions of government. By pursuing Al as part of their digital journeys, governments can transform, rather than just optimise, how they achieve their missions, deliver public value and promote societal well-being.

Future capabilities and uses of Al may present benefits and changes that are currently impossible or even inconceivable. This is also true of its potential risks. The contents of Chapter 5 represent what is currently known about Al in government, and by extension, what can be imagined about the future. Governments and the OECD need to remain vigilant in evaluating how evolving Al technologies and applications may affect public institutions, civil servants, and society at large ensuring continuous assessment and adaptation in service of the public good.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
# Page 2

| 45

Through analysis and synthesis of the government functions in Chapter 5 and other research, and for further discussion of Al in government, the OECD has conducted cross-cutting research into the current trends of Al use across government functions and has identified early lessons from these use cases. This research and its findings are discussed in the following chapter.

# References
Acemoglu, D. (2024), “The Simple Macroeconomics of Al”, NBER, Working Paper 32487, http://www.nber.org/papers/w32487.
[149]

Acemoglu, D. et al. (2022), “Artificial Intelligence and Jobs: Evidence from Online Vacancies", Journal of Labor Economics, Vol. 40/S1, pp. S293-S340, https://doi.org/10.1086/718327.
[147]

Ada Lovelace Institute (2025), Learn fast and build things: Lessons from six years of studying Al in the public sector, Ada Lovelace Institute, https://www.adalovelaceinstitute.org/policy-briefing/public-sector-ai/.
[155]

Alessandro, M. et al. (2021), “Transparency and Trust in Government. Evidence from a Survey Experiment", World Development, Vol. 138, p. 105223, https://doi.org/10.1016/j.worlddev.2020.105223.
[153]

Alon-Barkat, S. and M. Busuioc (2024), “Public administration meets artificial intelligence: Towards a meaningful behavioral research agenda on algorithmic decision-making in government”, Journal of Behavioral Public Administration, Vol. 7, https://doi.org/10.30636/jbpa.71.261.
[72]

Alon-Barkat, S. and M. Busuioc (2022), “Human-Al Interactions in Public Sector Decision Making: "Automation Bias" and "Selective Adherence" to Algorithmic Advice", Journal of Public Administration Research and Theory, Vol. 33/1, pp. 153-169, https://doi.org/10.1093/jopart/muac007.
[116]

Aonghusa, P. and S. Michie (2020), “Artificial intelligence and behavioral science through the looking glass: Challenges for real-world application.", Annals of Behavioural Medicine, pp. 942-947, https://doi.org/10.1093/abm/kaaa095.
[69]

APA (2023), Worries about artificial intelligence, surveillance at work may be connected to poor mental health, https://www.apa.org/news/press/releases/2023/09/artificial-intelligence-poor-mental-health.
[127]

Arnesen, S. et al. (2024), “Knowledge and support for Al in the public sector: a deliberative poll experiment", Al &amp; SOCIETY, https://doi.org/10.1007/s00146-024-02104-w.
[150]

Austin, T. et al. (2024), A snapshot of how public sector leaders feel about generative Al, https://www2.deloitte.com/us/en/insights/industry/public-sector/ai-adoption-in-public-sector.html.
[33]

BCG (2024), Where's the Value in Al?, https://www.bcg.com/publications/2024/wheres-value-in-ai.
[30]

Beltran, M., M. Ruiz Mondragon and S. Han (2024), “Comparative Analysis of Generative Al Risks in the Public Sector", Proceedings of the 25th Annual International Conference on Digital Government Research, pp. 610-617, https://doi.org/10.1145/3657054.3657125.
[121]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
# Page 3

46 |

Bengio, Y. et al. (2025), International Al Safety Report, DSIT 2025/001, 2025, https://www.gov.uk/government/publications/international-ai-safety-report-2025.
[26]

Berglind, N., A. Fadia and T. Isherwood (2022), The potential value of Al—and how governments could look to capture it, https://www.mckinsey.com/industries/public-sector/our-insights/the-potential-value-of-ai-and-how-governments-could-look-to-capture-it (accessed on July 2024).
[37]

Berryhill, J. et al. (2019), "Hello, World: Artificial intelligence and its use in the public sector", OECD Working Papers on Public Governance, No. 36, OECD Publishing, Paris, https://doi.org/10.1787/726fd39d-en.
[8]

Brizuela, A. et al. (2025), Analysis of the generative Al landscape in the European public sector, European Commission, https://op.europa.eu/s/z4XY.
[22]

Brougham, D. and J. Haar (2017), “Smart Technology, Artificial Intelligence, Robotics, and Algorithms (STARA): Employees' perceptions of our future workplace”, Journal of Management &amp; Organization, Vol. 24/2, pp. 239-257, https://doi.org/10.1017/jmo.2016.55.
[43]

Brown, H. et al. (2022), “What Does it Mean for a Language Model to Preserve Privacy?", 2022 ACM Conference on Fairness, Accountability, and Transparency, pp. 2280-2292, https://doi.org/10.1145/3531146.3534642.
[132]

Brundage, M. et al. (2018), The Malicious Use of Artificial Intelligence: Forecasting, Precention, and Mitigation, https://arxiv.org/abs/1802.07228.
[135]

Brynjolfsson, E., L. Danielle and L. Raymond (2023), Generative Al at Work, National Bureau of Economic Research, https://doi.org/10.3386/w31161.
[67]

Byler, D. (2021), In the Camps: China's High-Tech Penal Colony, Columbia Global Reports, https://www.jstor.org/stable/j.ctv2dzzqqm.
[112]

Calvino, F. and L. Fontanelli (2023), “A portrait of Al adopters across countries: Firm characteristics, assets' complementarities and productivity”, OECD Science, Technology and Industry Working Papers, No. 2023/02, OECD Publishing, Paris, https://doi.org/10.1787/0fb79bb9-en.
[27]

Chignard, S. (2013), A brief history of Open Data, https://www.paristechreview.com/2013/03/29/brief-history-open-data.
[86]

Clarke, S. and J. Whittlestone (2022), A Survey of the Potential Long-term Impacts of Al - How Al Could Lead to Long-term Changes in Science, Cooperation, Power, Epistemics and Values, https://dl.acm.org/doi/abs/10.1145/3514094.3534131.
[111]

Cognitus, A. (2024), 9 Agentic Al Examples: Real-World Use Cases and Applications, https://integrail.ai/blog/agentic-ai-examples.
[18]

Corvalán, J. and E. Le Fevre Cervini (2020), Prometea experience. Using Al to optimize public institutions, https://ceridap.eu/prometea-experience-using-ai-to-optimize-public-institutions.
[46]

DataHeroes (2023), Noise in Machine Learning, https://dataheroes.ai/glossary/noise-in-machine-learning.
[160]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
# Page 4

| 47

Davies, H., S. Nutley and I. Walter (2008), “Why 'knowledge transfer' is misconceived for applied social research”, Journal of Health Services Research &amp; Policy, Vol. 13/3, pp. 188-190, https://doi.org/10.1258/jhsrp.2008.008055.
[97]

Dell'Acqua, F. et al. (2025), The Cybernetic Teammate: A Field Experiment on Generative Al Reshaping Teamwork and Expertise, Elsevier BV, https://doi.org/10.2139/ssrn.5188231.
[48]

Dell'Acqua, F. et al. (2023), “Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of Al on Knowledge Worker Productivity and Quality”, SSRN Electronic Journal, https://doi.org/10.2139/ssrn.4573321.
[52]

Desouza, K. and B. Jacob (2014), “Big Data in the Public Sector: Lessons for Practitioners and Scholars", Administration &amp; Society, Vol. 49/7, pp. 1043-1064, https://doi.org/10.1177/0095399714555751.
[64]

Dieterle, E., C. Dede and M. Walker (2022), "The cyclical ethical effects of using artificial intelligence in education", Al &amp; SOCIETY, Vol. 39/2, pp. 633-643, https://doi.org/10.1007/s00146-022-01497-w.
[144]

Du, M. (2023), “Machine vs. human, who makes a better judgment on innovation? Take GPT-4 for example", Frontiers in Artificial Intelligence, Vol. 6, https://doi.org/10.3389/frai.2023.1206516.
[68]

EC (2025), Study exploring the context, challenges, opportunities, and trends in algorithmic management, European Commission, https://employment-social-affairs.ec.europa.eu/study-exploring-context-challenges-opportunities-and-trends-algorithmic-management en.
[126]

EC (2024), What factors influence perceived artificial intelligence adoption by public managers, https://publications.jrc.ec.europa.eu/repository/handle/JRC138684.
[41]

Eshelby, L. (2025), Addressing insider threats in the public sector, https://www.openaccessgovernment.org/addressing-insider-threats-in-the-public-sector/187801/.
[137]

EU (2024), Regulation (EU) 2024/1689 laying down harmonised rules on artificial, European Union, https://eur-lex.europa.eu/eli/reg/2024/1689/oj.
[94]

Fazlioglu, M. (2024), Consumer Perspectives of Privacy and Artificial Intelligence, https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/.
[107]

Feldstein, S. (2022), Al & Big Data Global Surveillance Index (2022 updated), https://doi.org/10.17632/gjhf5y4xjp.4.
[101]

Filippucci, F., P. Gal and M. Schief (2024), “Miracle or Myth? Assessing the macroeconomic productivity gains from Artificial Intelligence”, OECD Artificial Intelligence Papers, No. 29, OECD Publishing, Paris, https://doi.org/10.1787/b524a072-en.
[24]

Fitkov-Norris, E. and N. Kocheva (2025), “Leveraging Al for strategic foresight: Unveiling future horizons", in Improving and Enhancing Scenario Planning, Edward Elgar Publishing, https://doi.org/10.4337/9781035310586.00023.
[73]

Flavián, C. and L. Casaló (2021), “Artificial intelligence in services: current trends, benefits and challenges", The Service Industries Journal, Vol. 41/13-14, pp. 853–859, https://doi.org/10.1080/02642069.2021.1989177.
[54]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
# Page 5

48 |

Gartner (2024), Gartner 2024 Hype Cycle for Emerging Technologies Highlights Developer Productivity, Total Experience, Al and Security, https://www.gartner.com/en/newsroom/press-releases/2024-08-21-gartner-2024-hype-cycle-for-emerging-technologies-highlights-developer-productivity-total-experience-ai-and-security.
[23]

Gerlich, M. (2025), “Al Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking”, Societies, Vol. 15/1, p. 6, https://doi.org/10.3390/soc15010006.
[122]

Giest, S. (2017), "Big data for policymaking: fad or fasttrack?", Policy Sciences, Vol. 50/3, pp. 367-382, https://doi.org/10.1007/s11077-017-9293-1.
[56]

Gmyrek, P., J. Berg and D. Bescond (2023), Generative Al and Jobs: A global analysis of potential effects on job quantity and quality, ILO, https://doi.org/10.54394/FHEM8239.
[128]

Goldman, S. (2023), OpenAl has grand 'plans' for AGI. Here's another way to read its manifesto, https://venturebeat.com/ai/openai-has-grand-plans-for-agi-heres-another-way-to-read-its-manifesto-the-ai-beat/.
[117]

Gopireddy, R. (2024), Securing Al Systems: Protecting Against Adversarial Attacks and Data Poisoning, https://jsaer.com/download/vol-11-iss-5-2024/JSAER2024-11-5-276-281.pdf.
[136]

Government of Korea (2024), A New Chapter in the Age of Al: Basic Act on Al Passed at the National Assembly's Plenary Session, https://www.msit.go.kr/eng/bbs/view.do?bbsSeqNo=42&mId=4&mPid=2&nttSeqNo=1071.
[95]

Green, B. (2022), “The flaws of policies requiring human oversight of government algorithms”, Computer Law &amp; Security Review, Vol. 45, p. 105681, https://doi.org/10.1016/j.clsr.2022.105681.
[66]

Grzegorzek, J. (2024), Digital Taylorism: The Use of Data to Monitor Employees, https://medium.com/%40JerryGrzegorzek/digital-taylorism-the-use-of-data-to-monitor-employees-582b331d970a.
[161]

Gupta, T. and S. Roy (2024), "Applications of Artificial Intelligence in Disaster Management", Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence, pp. 313-318, https://doi.org/10.1145/3669754.3669802.
[75]

Hampole, M. et al. (2025), Artificial Intelligence and the Labor Market, National Bureau of Economic Research, Cambridge, MA, https://doi.org/10.3386/w33509.
[28]

Höchtl, J., P. Parycek and R. Schöllhammer (2015), “Big data in the policy cycle: Policy decision making in the digital era", Journal of Organizational Computing and Electronic Commerce, Vol. 26/1-2, pp. 147-169, https://doi.org/10.1080/10919392.2015.1125187.
[62]

Ho, D. (2023), Opportunities and Risks of Artificial Intelligence in the Public Sector, https://law.stanford.edu/2023/05/25/opportunities-and-risks-of-artificial-intelligence-in-the-public-sector/.
[89]

Horowitz, M. (2023), Bending the Automation Bias Curve: A Study of Human and Al-based Decision Making in National Security Contexts, https://arxiv.org/abs/2306.16507.
[115]

Horvitz, E. (2014), Reflections and Framing: One-Hundred Year Study on Artificial Intelligence: Reflections and Framing, https://ai100.stanford.edu/reflections-and-framing.
[21]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# Page 1

| 49

[53]
Huang, M. and R. Rust (2021), "Engaged to a Robot? The Role of Al in Service”, Journal of
Service Research, Vol. 24/1, pp. 30–41, https://doi.org/10.1177/1094670520902266.

[131]
ICO (2023), Joint statement on data scraping and the protection of privacy,
https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2023/08/joint-statement-on-
data-scraping-and-data-protection/.

[139]
ITU (2023), Measuring digital development: Facts and Figures 2023, https://www.itu.int/en/ITU-
D/Statistics/Pages/facts/default.aspx (accessed on July 2024).

[76]
Jarrahi, M. et al. (2023), “Artificial intelligence and knowledge management: A partnership
between human and Al”, Business Horizons, Vol. 66/1, pp. 87-99,
https://doi.org/10.1016/j.bushor.2022.03.002.

[87]
Jeevanandam, N. (2024), Al in agriculture in 2025: Transforming Indian farms for a sustainable
future, https://indiaai.gov.in/article/ai-in-agriculture-in-2025-transforming-indian-farms-for-a-
sustainable-future.

[47]
Jones, C. (2022), "The Past and Future of Economic Growth: A Semi-Endogenous Perspective",
Annual Review of Economics, Vol. 14/1, pp. 125-152, https://doi.org/10.1146/annurev-
economics-080521-012458.

[120]
Klingbeil, A., C. Grützner and P. Schrec (2024), Trust and reliance on Al — An experimental
study on the extent and costs of overreliance on Al,
https://doi.org/10.1016/j.chb.2024.108352 (accessed on September 2024).

[61]
Kolkman, D. (2020), “The usefulness of algorithmic models in policy making", Government
Information Quarterly, Vol. 37/3, p. 101488, https://doi.org/10.1016/j.giq.2020.101488.

[57]
Kopponen, A. et al. (2024), “Personalised public services powered by Al: the citizen digital twin
approach", in Research Handbook on Public Management and Artificial Intelligence, Edward
Elgar Publishing, https://doi.org/10.4337/9781802207347.00020.

[152]
KPMG (2025), Trust in artificial intelligence: global insights 2025,
https://kpmg.com/au/en/home/insights/2025/04/trust-in-ai-global-insights-2025.html.

[151]
Lahusen, C., M. Maggetti and M. Slavkovik (2024), “Trust, trustworthiness and Al governance",
Scientific Reports, Vol. 14/1, https://doi.org/10.1038/s41598-024-71761-0.

[158]
Laplante, P. et al. (2020), “Artificial Intelligence and Critical Systems: From Hype to Reality",
Computer, Vol. 53/11, pp. 45-52, https://doi.org/10.1109/mc.2020.3006177.

[141]
Larsson, K. (2021), “Digitization or equality: When government automation covers some, but not
all citizens", Government Information Quarterly, Vol. 38/1, p. 101547,
https://doi.org/10.1016/j.giq.2020.101547.

[114]
Lima, G. et al. (2022), “The Conflict Between Explainable and Accountable Decision-Making
Algorithms", 2022 ACM Conference on Fairness, Accountability, and Transparency, pp. 2103-
2113, https://doi.org/10.1145/3531146.3534628.

[154]
Longoni, C., L. Cian and E. Kyung (2022), “Algorithmic Transference: People Overgeneralize
Failures of Al in the Government”, Journal of Marketing Research, Vol. 60/1, pp. 170-188,
https://doi.org/10.1177/00222437221110139.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 2

50|

[17]
Lorenz, P., K. Perset and J. Berryhill (2023), "Initial policy considerations for generative artificial
intelligence", OECD Artificial Intelligence Papers, No. 1, OECD Publishing, Paris,
https://doi.org/10.1787/fae2d1e6-en.

[70]
Ludwig, J. and S. Mullainathan (2022), “Algorithmic Behavioral Science: Machine Learning as a
Tool for Scientific Discovery”, SSRN Electronic Journal, https://doi.org/10.2139/ssrn.4164272.

[32]
Manning, B., K. Zhu and J. Horton (2024), Automated Social Science: Language Models as
Scientist and Subjects, https://arxiv.org/abs/2404.11794.

[138]
Mariani, J., P. Kishnani and A. Alibage (2025), Government's less trodden path to scaling
generative Al, https://www2.deloitte.com/us/en/insights/industry/public-sector/government-
faces-challenges-with-generative-ai-adoption.html.

[35]
Mellouli, S., M. Janssen and A. Ojo (2024), "Introduction to the Issue on Artificial Intelligence in
the Public Sector: Risks and Benefits of Al for Governments", Digital Government: Research
and Practice, Vol. 5/1, pp. 1-6, https://doi.org/10.1145/3636550.

[123]
Meng, J. (2024), Al emerges as the frontier in behavioral science,
https://doi.org/10.1073/pnas.2401336121.

[34]
Mergel, I. et al. (2023), “Implementing Al in the public sector”, Public Management Review,
pp. 1-14, https://doi.org/10.1080/14719037.2023.2231950.

[148]
Milanez, A. (2023), “The impact of Al on the workplace: Evidence from OECD case studies of Al
implementation", OECD Social, Employment and Migration Working Papers, No. 289, OECD
Publishing, Paris, https://doi.org/10.1787/2247ce58-en.

[124]
Milanez, A., A. Lemmens and C. Ruggiu (2025), "Algorithmic management in the
workplace: New evidence from an OECD employer survey”, OECD Artificial Intelligence
Papers, No. 31, OECD Publishing, Paris, https://doi.org/10.1787/287c13c4-en.

[58]
Mills, S., S. Costa and C. Sunstein (2023), "Al, Behavioural Science, and Consumer Welfare", J
Consum Policy, Vol. 46, pp. 387–400, https://doi.org/10.1007/s10603-023-09547-6.

[102]
Nikiforova, A. et al. (2023), “Towards High-Value Datasets Determination for Data-Driven
Development: A Systematic Literature Review", in Lecture Notes in Computer Science,
Electronic Government, Springer Nature Switzerland, Cham, https://doi.org/10.1007/978-3-
031-41138-0_14.

[20]
NIST (2025), Technical Blog: Strengthening Al Agent Hijacking Evaluations,
https://www.nist.gov/news-events/news/2025/01/technical-blog-strengthening-ai-agent-
hijacking-evaluations.

[49]
Noy, S. and W. Zhang (2023), "Experimental evidence on the productivity effects of generative
artificial intelligence", Science, Vol. 381/6654, pp. 187-192,
https://doi.org/10.1126/science.adh2586.

[90]
OECD (2025), How Innovation Ecosystems Foster Citizen Participation Using Emerging
Technologies in Portugal, Spain and the Netherlands, OECD Public Governance Reviews,
OECD Publishing, Paris, https://doi.org/10.1787/2cb37a30-en.

[79]
OECD (2025), Sharing trustworthy Al models with privacy-enhancing technologies, OECD
Publishing, https://doi.org/10.1787/a266160b-en.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 3

| 51

[162]
OECD (2025), "Towards a common reporting framework for Al incidents”, OECD Artificial
Intelligence Papers, No. 34, OECD Publishing, Paris, https://doi.org/10.1787/f326d4ac-en.

[5]
OECD (2024), “2023 OECD Digital Government Index: Results and key findings", OECD Public
Governance Policy Papers, No. 44, OECD Publishing, Paris,
https://doi.org/10.1787/1a89ed5e-en.

[129]
OECD (2024), “Al, data governance and privacy: Synergies and areas of international co-
operation", OECD Artificial Intelligence Papers, No. 22, OECD Publishing, Paris,
https://doi.org/10.1787/2476b1a4-en.

[14]
OECD (2024), "Assessing potential future artificial intelligence risks, benefits and policy
imperatives", OECD Artificial Intelligence Papers, No. 27, OECD Publishing, Paris,
https://doi.org/10.1787/3f4e3dfb-en.

[163]
OECD (2024), “Defining Al incidents and related terms", OECD Artificial Intelligence Papers,
No. 16, OECD Publishing, Paris, https://doi.org/10.1787/d1a8d965-en.

[7]
OECD (2024), “Explanatory memorandum on the updated OECD definition of an Al system",
OECD Artificial Intelligence Papers, No. 8, OECD Publishing, Paris,
https://doi.org/10.1787/623da898-en.

[92]
OECD (2024), Facts not Fakes: Tackling Disinformation, Strengthening Information Integrity,
OECD Publishing, Paris, https://doi.org/10.1787/d909ff7a-en.

[105]
OECD (2024), Global Trends in Government Innovation 2024: Fostering Human-Centred Public
Services, OECD Public Governance Reviews, OECD Publishing, Paris,
https://doi.org/10.1787/c1bc19c3-en.

[13]
OECD (2024), “Governing with Artificial Intelligence: Are governments ready?”, OECD Artificial
Intelligence Papers, No. 20, OECD Publishing, Paris, https://doi.org/10.1787/26324bc2-en.

[59]
OECD (2024), Modernising Access to Social Protection: Strategies, Technologies and Data
Advances in OECD Countries, OECD Publishing, Paris, https://doi.org/10.1787/af31746d-en.

[11]
OECD (2024), OECD Artificial Intelligence Review of Germany, OECD Publishing, Paris,
https://doi.org/10.1787/609808d6-en.

[15]
OECD (2024), OECD Digital Economy Outlook 2024 (Volume 1): Embracing the Technology
Frontier, OECD Publishing, Paris, https://doi.org/10.1787/a1689dc5-en.

[4]
OECD (2024), OECD Survey on Drivers of Trust in Public Institutions – 2024 Results: Building
Trust in a Complex Policy Environment, OECD Publishing, Paris,
https://doi.org/10.1787/9a20554b-en.

[6]
OECD (2024), Recommendation of the Council on Artificial Intelligence,
https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449.

[31]
OECD (2023), Artificial Intelligence in Science: Challenges, Opportunities and the Future of
Research, OECD Publishing, Paris, https://doi.org/10.1787/a8d820bd-en.

[80]
OECD (2023), "Emerging privacy-enhancing technologies: Current regulatory and policy
approaches", OECD Digital Economy Papers, No. 351, OECD Publishing, Paris,
https://doi.org/10.1787/bf121be4-en.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 4

52 |

[38]
OECD (2023), Global Trends in Government Innovation 2023, OECD Public Governance
Reviews, OECD Publishing, Paris, https://doi.org/10.1787/0655b570-en.

[25]
OECD (2023), OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market,
OECD Publishing, Paris, https://doi.org/10.1787/08785bba-en.

[88]
OECD (2023), "The state of implementation of the OECD AI Principles four years on”, OECD
Artificial Intelligence Papers, No. 3, OECD Publishing, Paris,
https://doi.org/10.1787/835641c9-en.

[109]
OECD (2022), Emerging future Al risks, OECD, https://wp.oecd.ai/app/uploads/2023/03/OECD-
Foresight-workshop-notes-1.pdf.

[93]
OECD (2022), "Measuring the environmental impacts of artificial intelligence compute and
applications: The Al footprint", OECD Digital Economy Papers, No. 341, OECD Publishing,
Paris, https://doi.org/10.1787/7babf571-en.

[40]
OECD (2022), "OECD Framework for the Classification of Al systems", OECD Digital Economy
Papers, No. 323, OECD Publishing, Paris, https://doi.org/10.1787/cb6d9eca-en.

[83]
OECD (2021), Data-Driven, Information-Enabled Regulatory Delivery, OECD Publishing, Paris,
https://doi.org/10.1787/8f99ec8c-en.

[100]
OECD (2020), “Dealing with digital security risk during the Coronavirus (COVID-19) crisis”,
OECD Policy Responses to Coronavirus (COVID-19), OECD Publishing, Paris,
https://doi.org/10.1787/c9d3fe8e-en.

[2]
OECD (2020), Embracing Innovation in Government - Global Trends 2020: Innovative responces
to the COVID-19 crisis, OECD Publishing, https://trends.oecd-opsi.org/trend-
reports/innovative-covid-19-solutions/.

[3]
OECD (2020), “The OECD Digital Government Policy Framework: Six dimensions of a Digital
Government", OECD Public Governance Policy Papers, No. 02, OECD Publishing, Paris,
https://doi.org/10.1787/f64fed2a-en.

[65]
OECD (2019), The Path to Becoming a Data-Driven Public Sector, OECD Digital Government
Studies, OECD Publishing, Paris, https://doi.org/10.1787/059814a7-en.

[82]
OECD (2018), OECD Regulatory Enforcement and Inspections Toolkit, OECD Publishing, Paris,
https://doi.org/10.1787/9789264303959-en.

[84]
OECD (2018), Open Government Data Report: Enhancing Policy Maturity for Sustainable
Impact, OECD Digital Government Studies, OECD Publishing, Paris,
https://doi.org/10.1787/9789264305847-en.

[103]
OECD (2017), Recommendation of the Council on Health Data Governance,
https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0433.

[1]
OECD (2014), Recommendation of the Council on Digital Government Strategies, OECD
Publishing, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0406.

[104]
OECD (1980), Recommendation of the Council concerning Guidelines Governing the Protection
of Privacy and Transborder Flows of Personal Data,
https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0188.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 5

| 53

[130]
OECD (forthcoming), Mapping Relevant Data Collection Mechanisms for Al Training, OECD
Publishing.

[16]
OECD.AI (2023), OECD Expert Group on Al Futures – Meeting 2 (18th & 20th September 2023),
https://wp.oecd.ai/app/uploads/2024/01/Expert-Group-on-Al-Futures-Meeting-2-Summary.pdf.

[159]
OECD.AI (2023), What do you see as the as the most significant potential benefits and risks of
Al 10+ years from now?, https://oecd.ai/en/network-of-experts/ai-futures/discussions/future-
benefits-risks.

[10]
OECD/CAF (2022), The Strategic and Responsible Use of Artificial Intelligence in the Public
Sector of Latin America and the Caribbean, OECD Public Governance Reviews, OECD
Publishing, Paris, https://doi.org/10.1787/1f334543-en.

[12]
OECD/UNESCO (2024), G7 Toolkit for Artificial Intelligence in the Public Sector, OECD
Publishing, Paris, https://doi.org/10.1787/421c1244-en.

[118]
Olson, P. (2023), Don't Go Down That Al Longtermism Rabbit Hole,
https://www.bloomberg.com/opinion/articles/2023-05-19/ai-longtermism-alarmists-are-
dragging-us-all-down-existential-rabbit-hole.

[157]
Pahlka, J. (2024), Al meets the cascade of rigidity, https://www.niskanencenter.org/ai-meets-the-
cascade-of-rigidity/.

[119]
Passi, S. and M. Vorvoreanu (2022), Overreliance on Al: Literature review,
https://www.microsoft.com/en-us/research/publication/overreliance-on-ai-literature-review/
(accessed on September 2024).

[146]
Peixoto, T., O. Canuto and L. Jordan (2024), Al and the Future of Government: Unexpected
Effects and Critical Challenges, https://www.policycenter.ma/publications/ai-and-future-
government-unexpected-effects-and-critical-challenges.

[42]
Pencheva, I., M. Esteve and S. Mikhaylov (2018), “Big Data and Al – A transformational shift for
government: So, what next for research?", Public Policy and Administration, Vol. 35/1, pp. 24-
44, https://doi.org/10.1177/0952076718780537.

[50]
Peng, S. et al. (2023), The Impact of Al on Developer Productivity: Evidence from GitHub
Copilot, https://arxiv.org/abs/2302.06590.

[143]
Perry, A. and N. Turner Lee (2019), Al is coming to schools, and if we're not careful, so will its
biases, https://www.brookings.edu/articles/ai-is-coming-to-schools-and-if-were-not-careful-so-
will-its-biases/.

[19]
Purdy, M. (2024), What Is Agentic Al, and How Will It Change Work?,
https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work.

[106]
Rainie, L. and J. Anderson (2024), Experts Imagine the Impact of Artificial Intelligence by 2040,
https://imaginingthedigitalfuture.org/wp-content/uploads/2024/02/Al2040-FINAL-White-Paper-
2-2.29.24.pdf.

[145]
Röttger, P. et al. (2024), "SafetyPrompts: a Systematic Review of Open Datasets for Evaluating
and Improving Large Language Model Safety", arXiv.org,
https://doi.org/10.48550/arXiv.2404.05399.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

54|

Russell, S. (2019), *Human Compatible: Artificial Intelligence and the Problem of Control*, Viking.
[113]

Saheb, T. (2022), “Ethically contentious aspects of artificial intelligence surveillance: a social science perspective”, *Al and Ethics*, Vol. 3/2, pp. 369-379, https://doi.org/10.1007/s43681-022-00196-y.
[99]

Salem, A. et al. (2018), *ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models*, https://arxiv.org/abs/1806.01246.
[134]

Santiso, C. (2023), *Public Governance in the Age of Artificial Intelligence*, https://www.chandlerinstitute.org/governancematters/public-governance-in-the-age-of-artificial-intelligence.
[39]

Santos, R. et al. (2024), “The use of Al in government and its risks: lessons from the private sector", *Transforming Government: People, Process and Policy*, https://doi.org/10.1108/tg-02-2024-0038.
[36]

Sanzogni, L., G. Guzman and P. Busch (2017), “Artificial intelligence and knowledge management: questioning the tacit dimension”, *Prometheus*, Vol. 35, pp. 37-56, https://doi.org/10.1080/08109028.2017.1364547.
[78]

Sapci, A. and H. Sapci (2019), “Innovative Assisted Living Tools, Remote Monitoring Technologies, Artificial Intelligence-Driven Solutions, and Robotic Systems for Aging Societies: Systematic Review”, *JMIR Aging*, Vol. 2/2, p. e15429, https://doi.org/10.2196/15429.
[45]

Shane, J. (2019), *You Look Like a Thing and I Love You: How Artificial Intelligence Works and Why It's Making the World a Weirder Place*, https://www.hachettebookgroup.com/titles/janelle-shane/you-look-like-a-thing-and-i-love-you/9780316525220/.
[98]

Singh, V. and J. Chobotaru (2022), “Digital Divide: Barriers to Accessing Online Government Services in Canada", *Administrative Sciences*, Vol. 12/3, p. 112, https://doi.org/10.3390/admsci12030112.
[140]

Staab, R. et al. (2023), *Beyond Memorization: Violating Privacy Via Inference with Large Language*, https://arxiv.org/abs/2310.07298.
[133]

Sunstein, C. (2023), “The use of algorithms in society", *The Review of Austrian Economics*, Vol. 37/4, pp. 399-420, https://doi.org/10.1007/s11138-023-00625-z.
[71]

Sun, W., P. Bocchini and B. Davison (2020), “Applications of artificial intelligence for disaster management", *Natural Hazards*, Vol. 103/3, pp. 2631-2689, https://doi.org/10.1007/s11069-020-04124-3.
[74]

Tegmark, M. (2017), *Life 3.0: Being Human in the Age of Artificial Intelligence*, Penguin, https://mitpressbookstore.mit.edu/book/9781101970317.
[110]

The Economist (2025), *How Al will divide the best from the rest*, https://www.economist.com/finance-and-economics/2025/02/13/how-ai-will-divide-the-best-from-the-rest.
[51]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 55

Tse, T. and S. Karimov (2022), Decision-making risks slow down the use of artificial intelligence in business, https://blogs.lse.ac.uk/businessreview/2022/05/18/decision-making-risks-slow-down-the-use-of-artificial-intelligence-in-business-1/.
[91]

Ubaldi, B. et al. (2019), “State of the art in the use of emerging technologies in the public sector", OECD Working Papers on Public Governance, No. 31, OECD Publishing, Paris, https://doi.org/10.1787/932780bc-en.
[9]

UC Berkeley (2021), Positive Al Economic Futures, World Economic Forum, https://www.weforum.org/reports/positive-ai-economic-futures.
[125]

UN (2024), Governing Al for Humanity, https://www.un.org/sites/un2.un.org/files/governing_ai_for_humanity_final_report_en.pdf.
[108]

UN (2022), E-Government Survey 2022: The Future of Digital Government, United Nations, https://desapublications.un.org/sites/default/files/publications/2022-09/Web%20version%20E-Government%202022.pdf.
[55]

UNESCO (2019), Artificial Intelligence in Education: Challenges and Opportunities for Sustainable Development, https://www.gcedclearinghouse.org/sites/default/files/resources/190175eng.pdf.
[142]

US GAO (2024), Fraud Risk Management: 2018-2022 Data Show Federal Government Loses an Estimated $233 Billion to $521 Billion Annually to Fraud, Based on Various Risk Environments, https://www.gao.gov/products/gao-24-105833.
[81]

USGS (2024), Landsat's Economic Value increased to $25.6 Billion in 2023, https://www.usgs.gov/news/featured-story/landsats-economic-value-increases-256-billion-2023.
[85]

Valle-Cruz, D. et al. (2020), “Assessing the public policy-cycle framework in the age of artificial intelligence: From agenda-setting to policy evaluation", Government Information Quarterly, Vol. 37/4, p. 101509, https://doi.org/10.1016/j.giq.2020.101509.
[60]

Valle-Cruz, D., R. Garcia-Contreras and R. Gil-Garcia (2023), "Exploring the negative impacts of artificial intelligence in government: the dark side of intelligent algorithms and cognitive machines", International Review of Administrative Sciences, https://doi.org/10.1177/002085232311870.
[96]

Williams, C. (2025), There will be no immediate productivity boost from Al, https://www.economist.com/the-world-ahead/2024/11/20/there-will-be-no-immediate-productivity-boost-from-ai.
[29]

Wirjo, A. et al. (2022), Artificial Intelligence in Economic Policymaking, Policy Brief No. 52, https://www.apec.org/docs/default-source/publications/2022/11/artificial-intelligence-in-economic-policymaking/222_psu_artificial-intelligence-in-economic-policymaking.pdf.
[63]

Xu, G., M. Xue and J. Zhao (2023), “The Relationship of Artificial Intelligence Opportunity Perception and Employee Workplace Well-Being: A Moderated Mediation Model", International Journal of Environmental Research and Public Health, Vol. 20/3, p. 1974, https://doi.org/10.3390/ijerph20031974.
[44]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

56

Zehnle, M., C. Hildebrand and A. Valenzuela (2025), “Not all Al is created equal: A meta-analysis revealing drivers of Al resistance across markets, methods, and time”, *International Journal of Research in Marketing*, https://doi.org/10.1016/j.ijresmar.2025.02.005. [156]

Zhang, Z., L. Wang and C. Lee (2023), “Recent Advances in Artificial Intelligence Sensors", *Advanced Sensor Research*, Vol. 2/8, p. 2200072, https://doi.org/10.1002/adsr.202200072. [77]

# Notes

¹ https://www.oecd.org/en/topics/policy-issues/digital-government.

² The United States alone has catalogued more than 2 000 use cases in civilian federal government agencies (https://github.com/ombegov/2024-Federal-Al-Use-Case-Inventory). Similarly, the European Commission has catalogue more than 1 300 (https://interoperable-europe.ec.europa.eu/collection/public-sector-tech-watch/cases). More than 700 use cases have been catalogued in Latin American and Caribbean (LAC) governments (https://sistemaspublicos.tech/sistemas-de-ia-en-america-latina).

³ See https://trends.oecd-opsi.org, https://cross-border.oecd-opsi.org, (OECD, 2023[38]), and (OECD, 2024[105]).

⁴ See https://oecd-opsi.org/innovation-tag/artificial-intelligence-ai and https://oecd.ai/en/dashboards/policy-initiatives?orderBy=startYearDesc&page=1&terms=&initiativeTypelds=123.

⁵ These findings are based on a survey of 1 000 senior executives from 20 sectors across 59 countries in Asia, Europe and North America.

⁶ Unless otherwise cited, the sections below on the benefits of Al in the public sector are based on analysis of the functions of government and use cases presented in Chapter 5 of this report.

⁷ “Noise” is also a term used in ML to mean “random or unpredictable fluctuations in data that disrupt the ability to identify target patterns or relationships. The result is decreased accuracy or reliability of a model's predictions or output" (DataHeroes, 2023[160]). This is not the concept of noise discussed in this chapter, which focuses on factors that can influence humans.

⁸ For more information on this topic, see https://www.oecd.org/en/topics/behavioural-science and https://oecd-opsi.org/work-areas/behavioural-insights.

⁹ See also https://www.oecd.org/en/topics/sub-issues/privacy-enhancing-technologies.

¹⁰ See the MIT Al Risk Repository, a living database of over 1 000 Al risks (https://airisk.mit.edu). The OECD Al Incidents Monitor (AIM) documents Al incidents and hazards to help policymakers, Al practitioners, and all stakeholders worldwide gain valuable insights into the risks and harms of Al systems (https://oecd.ai/incidents).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 57

11 See https://oecd.ai/dashboards and (OECD, 2024[14]).

12 Overfitting refers to cases where the algorithm is too specific to the extent that it captures and focuses too much on noise and anomalies (Berryhill et al., 2019[8]). During the training phase, an overfitting model may achieve a high level of accuracy and problems may go unnoticed. However, once the trained model is exposed to new data, accuracy can drop severely.

13 The index does not distinguish between legitimate and illegitimate uses of Al surveillance techniques. Rather, the purpose of the research is to show how new surveillance capabilities are transforming governments' ability to monitor and track individuals or groups.

14 Digital Taylorism refers to the modern adaptation of Frederick Winslow Taylor's principles of scientific management, utilising digital technologies to monitor and control employee activities with the goal of enhancing efficiency and productivity. This approach involves breaking down complex tasks into simpler components, standardising workflows, and employing data-driven methods to oversee and evaluate worker performance. While it aims to optimise organisational operations, critics argue that it may lead to decreased worker autonomy and increased surveillance in the workplace (Grzegorzek, 2024[161]).

15 https://oecd.ai/site/data-privacy.

16 The OECD Directorate for Science, Technology and Innovation (STI) has a dedicated line of work on digital security. See https://www.oecd.org/en/topics/policy-issues/digital-security for more information.

17 An Al incident is an event, circumstance or series of events where the development, use or malfunction of one or more Al systems directly or indirectly leads to any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations of human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; or (d) harm to property, communities or the environment. An Al hazard is an event, circumstance or series of events where the development, use or malfunction of one or more Al systems could plausibly lead to an Al incident, i.e. any of the following harms: (a) injury or harm to the health of a person or groups of people; (b) disruption of the management and operation of critical infrastructure; (c) violations to human rights or a breach of obligations under the applicable law intended to protect fundamental, labour and intellectual property rights; or (d) harm to property, communities or the environment. For more information, see https://oecd.ai/incidents-methodology and (OECD, 2025[162]; 2024[163]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# 2 Trends and early lessons from the use of AI across functions of government
| 59

This chapter synthesises 200 AI use cases across 11 government functions. It finds using AI is a priority for governments, but adoption is fragmented and uneven. Use concentrates on public facing services and internal operations, with fewer examples in policymaking. Governments pursue productivity, responsiveness and accountability, yet efforts to empower external actors are limited. Maturity varies by function and technology, with long-standing rules-based systems, selective machine learning and limited generative AI. Every use case can pose operational, ethical, resistance or exclusion risks if not trustworthy, underscoring the need for strong data foundations and coherent governance.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

60 |

## Key messages

*   The OECD analysed 200 use cases across 11 government functions. It found that while AI is a priority for most governments, efforts are not systematic.
*   This analysis helped to better understand the current state of AI in government and to identify overarching trends. These trends are that:
    *   AI is unevenly distributed across government functions
    *   AI is most used for public-facing public service activities and internal operations
    *   Governments are using AI to pursue a variety of potential benefits
    *   Some government functions are more mature regarding governing and adopting AI
    *   Different functions of government have different contexts and needs.
*   The OECD found that every one of the 200 use cases analysed could post one or more types of risk (operational, ethical, public resistance or exclusion) if not designed and used in a trustworthy way.
    *   These risks vary across use cases and functions of government; therefore, it is important to acknowledge the main drivers of risks in each use and field.
    *   While governments are vigilant of several AI risks, some receive less focus.

## OECD analysis of 200 use cases across 11 government functions

In its latest cross-cutting work on AI in government, the OECD (2024[1]) found the need for the systematic collection, documentation and analysis of AI use cases to monitor trends on policy options across countries. The OECD also found that more and better evidence of the impact of AI on governments will help ensure the technology is used for optimal impact. Ease of access to such evidence as well as information on policies, practice and use of AI in government could promote progress in trustworthy AI adoption, structured dialogue and exchanges among countries. Overall, there is a need for a holistic, systems approach to maximise the value of AI in government, including establishing enablers, guardrails and engagement mechanisms.

To help address these needs, this chapter considers and builds upon OECD and other relevant research to better understand the current state of AI in government and to illuminate overarching trends. This chapter analyses and synthesises 200 AI use cases spanning 11 government functions, as listed in Table 2.1 and discussed in-depth in Chapter 5.1 These use cases were identified through, and the findings discussed in this chapter informed by, desktop research, OECD meetings and discussions with public officials in relevant OECD working parties and networks, and ongoing data collections from the OECD Observatory of Public Sector Innovation (OPSI) and the OECD.AI Policy Observatory.2

Based on this methodology, the findings in this chapter are not generalisable to the broader universe of AI efforts in government. In addition, adoption of AI in government will vary across countries, depending on their national realities and levels of AI readiness. The findings do provide, however, observations rooted in real-world practice, the latest research and policymakers’ present points of view. In doing so, the chapter seeks to take the pulse of current activities and their characteristics, as well as potential gaps where there may be untapped potential or need for further research.

In the coming months, the OECD will establish a living global repository of relevant initiatives and case studies as part of the OECD.AI Policy Observatory.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 61

## Table 2.1. Functions of government analysed for Governing with Al

| Category | Function | Scope of analysis |
| :--- | :--- | :--- |
| Government policy functions | Tax administration | OECD experts in each function of government leveraged OECD and external research and analysed 200 use cases to determine: - current state of play, including government actions and benefits pursued, - relevant challenges and how governments are managing them, and - untapped potential and the way forward. |
| | Public financial management | |
| | Regulatory design and delivery | |
| | Civil service reform | |
| Key government processes | Public procurement | |
| | Fighting corruption and promoting public integrity | |
| | Policy Evaluation | |
| | Civic participation and open government | |
| Government services and justice functions | Public service design and delivery | |
| | Law enforcement and disaster risk management | |
| | Justice administration and access to justice | |

## Al is a priority, but efforts are not systemic

In all, 48 countries and the European Union (EU) have adhered to the OECD AI Principles (Table 2.2), committing to promoting the trustworthy design, development, deployment and use of AI, including in the public sector. The OECD is tracking and reporting on the implementation of these principles over time (2023[2]; 2021[3]). Findings suggest that government are less focused on using AI than on their efforts to promote trustworthy AI adoption in the broader economy and society.

## Table 2.2. OECD Al Principles

| | Principle | Description |
| :--- | :--- | :--- |
| **Value-based principles** | **Inclusive growth, sustainable development and well-being** (Principle 1.1) | Highlights the potential for trustworthy AI to contribute to overall growth and prosperity for all – individuals, society, and planet – and advance global development objectives. |
| | **Respect for the rule of law, human rights and democratic values**, including fairness and privacy (Principle 1.2) | AI systems should be designed in a way that respects the rule of law, human rights, democratic values and diversity, and should include appropriate safeguards to ensure a fair and just society. |
| | **Transparency and explainability** (Principle 1.3) | About transparency and responsible disclosure around AI systems to ensure that people understand when they are engaging with them and can challenge outcomes. |
| | **Robustness, security and safety** (Principle 1.4) | AI systems should function in a robust, secure and safe way throughout their lifetimes, and potential risks should be continually assessed and managed. |
| | **Accountability** (Principle 1.5) | Organisations and individuals developing, deploying or operating AI systems should be held accountable for their proper functioning in line with the OECD's values-based principles for AI. |
| **Recommendations for policymakers** | **Investing in Al research and development** (Principle 2.1) | Governments should facilitate public and private investment in research & development to spur innovation in trustworthy AI. |
| | **Fostering an inclusive Al-enabling ecosystem** (Principle 2.2) | Governments should foster accessible AI ecosystems with digital infrastructure and technologies, and mechanisms to share data and knowledge as well as ensure the quality of such information. |
| | **Shaping and enabling interoperable governance and policy environment for Al** (Principle 2.3) | Governments should create a policy environment that will open the way to deployment of trustworthy AI systems. |
| | **Building human capacity** and preparing for labour market transformation (Principle 2.4) | Governments should equip people with the skills for AI and support workers to ensure a fair transition. |
| | **International co-operation for trustworthy Al** (Principle 2.5) | Governments should co-operate across borders and sectors to share information, develop standards and work towards responsible stewardship of AI. |

Source: https://oecd.ai/en/ai-principles.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

62 |

Governments are realising the potential of AI in public administrations and making it a strategic priority. **Almost all OECD countries have put in place strategies and agendas for AI that establish a high-level vision and approach for its use in government.** These are mainly embedded in broader national AI strategies. However, countries like Canada (2025[4]), Switzerland (2025[5]) and Uruguay (2021[6]) have developed dedicated strategies. Many governments have also sought to convert strategy into practice through cross-cutting or domain-specific policies and initiatives. Such efforts are discussed further in Chapter 4. In addition, many governments have adopted AI through hands-on use and, increasingly, custom development.

Progress has been made since the OECD began exploring AI in government in 2019; however, **efforts to date are limited and not systematic**. The potential opportunities of AI in government are significant but not easy to attain. Governments in two-thirds of OECD countries have started to explore the use of AI for internal efficiency by enhancing processes. Yet more progress is needed not only in using AI for other purposes, such as improving policies, but also in building the foundational components needed for AI in government to flourish (OECD, 2024[1]). In addition, the review of use cases suggests a proliferation of AI tools, with implementation often occurring in a piecemeal manner. These efforts are frequently undertaken without overarching governance mechanisms to steer initiatives across sectors or government as a whole, or to draw lessons from their implementation. As a result, the potential for coordinated learning, scaling and impact remains limited. Establishing robust governance frameworks could help ensure AI systems are deployed in a cohesive, efficient and accountable way, aligned with strategic priorities and public values.

The sections below seek to uncover the current status of AI use in government, including key patterns and trends among early adopters. In doing so, these sections seek to identify the extent to which governments extend beyond principles to take action in using AI, what results and outcomes they are achieving and what limitations they face.

## General trends in government Al use cases

### Uneven distribution of Al use across government functions

The 2023 OECD Digital Government Index (DGI) ([7]) found that while some countries have deployed a wide range of initiatives to enhance their capacity to use AI in government, implementation is still a challenge across most countries. In digging deeper into the use cases analysed for this report, OECD analysis suggests government AI efforts may cluster around public service design and delivery, civic participation and open government, and justice administration and access to justice. Conversely, only few initiatives in functions such as policy evaluation were identified (Figure 2.1).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 63

## Figure 2.1. Use cases are most present in public service, civic participation and justice functions

### Number of use cases

*   **Public service design & delivery:** 45
*   **Civic participation & open government:** 29
*   **Justice administration & access to justice:** 25
*   **Law enforcement & disaster risk management:** 22
*   **Regulatory design & delivery:** 21
*   **Public financial management:** 14
*   **Civil service reform:** 11
*   **Public procurement:** 10
*   **Fighting corruption & promoting public integrity:** 9
*   **Tax administration:** 9
*   **Policy evaluation:** 5

Source: OECD analysis of identified use cases.

There are several potential explanations for this distribution:
*   Public service design and delivery extends horizontally across many different types of organisations and issue areas, making it more prevalent in terms of total use cases than more vertical functions of government, such as tax administration.
*   Civic participation and open government’s prevalence may be partially because it is unencumbered by many of the risks (Chapter 1) and challenges (Chapter 3) faced by other functions. For instance, concerns around data access and security are largely non-applicable because the point of such engagement is generally to gather data on issues and questions that are public by nature. In addition, government teams engaging in civic participation are often among the more innovative groups in the public service, and thus, perhaps more prone to embracing new technological approaches.
*   The policy functions most represented tend to be public facing, potentially suggesting a focus on areas with immediate visibility to citizens. Factors comprising this could be more demands from citizens, as well as a desire among government and political leaders to visibly demonstrate value.
*   Some functions face barriers or complexities, such as stringent rules on data access and sharing in tax administration and requirements for thorough audit trails in public integrity.
*   Some functions appear to be more mature than others pertaining to AI readiness, including their underlying foundations for AI, such as sufficient and quality data, as discussed below.
*   Some functions may have pre-existing structures and processes that cannot be easily substituted or complemented by AI systems.

The prevalence of AI use in justice and the related function of law enforcement is particularly interesting. In general, the OECD (2024[1]) has encouraged governments to aim for low-hanging fruit in their initiation of AI – focusing on areas that represent high-benefit, low-risk uses of AI. The use of AI in justice and law enforcement can be high benefit but also high risk. One reason for the prevalence of use cases in some of these areas may be the prevalence of more comprehensive and structured data. Another reason may align with the sheer volume of tasks required for some of these functions. In the case of justice administration and access to justice, justice systems worldwide often operate under tight resource

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

64 |
constraints, including limited budget and court staff, even as the volume of cases continues to grow
(Harvard Kennedy School, 2023[8]; Columbia University, 2020[9]). This mismatch has led to chronic case
backlogs in many jurisdictions, creating intense pressure on court administrators to explore technologies
that can boost productivity and mitigate the backlog problem. This might be reflected in the higher number
of Al use cases in justice linked to internal operations, compared to other government functions
(Figure 2.3).

An additional reason for this distribution may be the data available for review, with the OECD tending to
identify, or governments tending to submit, information on initiatives in some functions more than others.
This seems somewhat tempered by validation in OECD discussions and reviews by the OECD Working
Party on Senior Digital Government Officials (E-Leaders), as well comparisons with results from larger
databases. Regarding the latter, the data collection for this report aligns with the trends seen in the EU
and Latin America and the Caribbean (LAC), as recorded by the European Commission (EC) Public Sector
Tech Watch observatory (2025[10]) and the “Al Systems in the Public Sector in LAC" database (Muñoz-
Cadena et al., 2025[11]) (Figure 2.2). In the EU, the top three functions identified in their repository of nearly
1 500 Al uses, as of 31 March 2025, are general public services, economic affairs, and public order and
safety.³ The public order and safety category includes use cases in both law enforcement and justice
administration. The economic affairs category is mainly represented by use cases in sectors like transport,
agriculture and energy. About 70% of economic affairs Al use cases are related to regulation and targeted
public services and engagement. LAC exhibits a comparable trend in the top three functions within the
reviewed repository of approximately 700 Al systems, as updated on 19 March 2025.

# Figure 2.2. EU and LAC follow a similar trend with the Al use cases sample collected for this report
Percentage of use cases categorised according to the United Nation's Classification of the Functions of Government

**Chart Data**
*   **Legend:** EU, LAC
*   **General public services:**
    *   EU: 29%
    *   LAC: 31%
*   **Economic affairs:**
    *   EU: 18%
    *   LAC: 26%
*   **Public order and safety:**
    *   EU: 16%
    *   LAC: 17%
*   **Health:**
    *   EU: 12%
    *   LAC: 9%
*   **Education:**
    *   EU: 3%
    *   LAC: 8%
*   **Social protection:**
    *   EU: 4%
    *   LAC: 8%
*   **Environmental protection:**
    *   EU: 7%
    *   LAC: 4%
*   **Housing and community amenities:**
    *   EU: 2%
    *   LAC: 3%
*   **Defence:**
    *   EU: 1%
    *   LAC: 2%
*   **Recreation, culture and religion:**
    *   EU: 2%
    *   LAC: 1%
*   **Supranational:**
    *   EU: 0%
    *   LAC: 1%

Source: Data analysed by the OECD from (EC, 2025[10]; Muñoz-Cadena et al., 2025[11]).

A final factor that may also influence the results is a variation on the "Al effect", whereby "as soon as [Al]
researchers achieve a milestone long thought to signify the achievement of true artificial intelligence, e.g.
beating a human at chess, it suddenly gets downgraded to not true Al” (Bailey, 2016[12]). In discussions
with the E-Leaders working party, delegates have suggested that narrow and traditional applications of Al
may have become so integrated or commonplace, they no longer trigger external reporting or a response
to data collection efforts. This could potentially occur more in areas with longstanding use of such systems,
such as tax administration, resulting in less representation in examined initiatives. It is difficult to determine
the extent to which this may occur; however, the analysis for this report did identify and include many such
use cases.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 65
# Al is most used for public-facing public service activities and internal operations
Across the 11 core functions covered by this report, governments are using Al in four general activities:
public-facing service delivery, internal operations, internal and external oversight activities and assisting
policymaking. The use of Al is most common in public-facing service delivery. Activities related to internal
operations are not far behind (Figure 2.3). Internal and external oversight activities and assisting
policymaking were not as prevalent. This is not unexpected, as service delivery and internal operations
constitute the majority of what government organisations do. Oversight activities are important, though
they are more often limited to certain offices or teams. Al use in policymaking activities is also not as
prevalent throughout governments. This finding aligns with previous measurements by the OECD DGI
(2024[7]), which also indicated that governments could make more effort in this area. Many remain cautious
or lack the necessary skills to incorporate Al into decision-making processes.

Al's prevalence in government activities varies according to the nature of each core function. In the function
of public service design and delivery, most Al applications naturally involve public-facing government-
citizen interactions, with some use cases also addressing internal operations regarding how public services
are designed or delivered. The significant number of service-related use cases in the justice sector,
comprising almost three quarters (16 of 25 cases, noting that one case may address more than one activity)
of the documented instances in that function, indicates that this function has prioritised responsiveness to
citizens, along with enhancing efficiency in its internal operations. This focus may be influenced by greater
societal demands, pressure to reduce case backlogs and manage scarce resources. Functions such as
civic participation and regulatory design and delivery encompass most of the use cases related to
policymaking activities. Related use cases include supporting the processing of evidence and stakeholder
inputs for policy formulation, and various applications aiding decision making through analytics, simulations
or forecasting.

# Figure 2.3. Al use cases per core function and government activity

**Chart Data**
*   **Legend:**
    *   Public-facing service delivery (93)
    *   Internal operations (87)
    *   Policymaking (48)
    *   Internal & external oversight (33)

*   **Function of government (number of use cases per function of government)**
    *   **Public design & delivery (21):**
        *   Public-facing service delivery: 8
        *   Internal operations: 7
        *   Policymaking: 8
    *   **Civic participation & open government (28):**
        *   Public-facing service delivery: 12
        *   Internal operations: 14
        *   Policymaking: 16
    *   **Justice administration to justice (25):**
        *   Public-facing service delivery: 19
        *   Internal operations: 15
    *   **Law enforcement management (22):**
        *   Public-facing service delivery: 8
        *   Internal operations: 13
        *   Internal & external oversight: 4
    *   **Regulatory delivery (21):**
        *   Public-facing service delivery: 7
        *   Internal operations: 12
        *   Policymaking: 3
        *   Internal & external oversight: 2
    *   **Public financial management (14):**
        *   Public-facing service delivery: 4
        *   Internal operations: 7
        *   Internal & external oversight: 1
    *   **Civil reforms (11):**
        *   Internal operations: 10
    *   **Public procurement (10):**
        *   Internal operations: 6
        *   Internal & external oversight: 2
    *   **Fighting corruption & promoting public integrity (9):**
        *   Public-facing service delivery: 1
        *   Internal operations: 1
        *   Internal & external oversight: 3
    *   **AI tax administration (9):**
        *   Public-facing service delivery: 3
        *   Internal operations: 3
    *   **Policy evaluation (5):**
        *   Internal operations: 3
        *   Policymaking: 5

Note: The four activities in this figure are not mutually exclusive (e.g. one Al use case could seek to both improve internal operations and service
delivery). Thus, the sum of activities is greater than the total number of use cases.
Source: OECD analysis of identified use cases.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

66 |
These results are generally in line with findings from the EU (2025[10]) and LAC (2025[11]) databases.
Although there is not a uniform methodology for categorising government activities, these and OECD's
databases do tend to show a common trend, particularly around services. Both the EU and LAC databases
include a classification of use cases under government activities (Figure 2.4), where “public services and
engagement" represent a significant share of all use cases, being the most prominent in EU and the second
most in LAC. However, in LAC, most use cases are categorised as part of "enforcement” activities, which
include predictive enforcement, registration and data notarisation, smart recognition, supporting
inspections, among others. These processes would generally coincide with OECD's internal operations
and oversight (internal and external) categories. This means that the "internal management" category in
EU and LAC, which is generally less representative for these databases, is not the only one containing
uses cases that the OECD could categorise as “internal operations". Therefore, it is not possible to
conclude whether the OECD dataset contains a higher share of use cases belonging internal operations
of government, compared to EU and LAC. Finally, it is worth highlighting that processes under the
"analysis, monitoring, and regulatory research" category in EU and LAC generally match with OECD's
"policymaking" category and have a similar share (about 20-30% of all use cases).

# Figure 2.4. Public services and engagement represent an important share of use cases under government processes in the EU and LAC
Percentage of use cases categorised by how the technology supports government decision-making and
implementation

**Chart Data**
*   **Legend:** EU, LAC
*   **Public services and engagement:**
    *   EU: 33%
    *   LAC: 24%
*   **Analysis, monitoring and regulatory research:**
    *   EU: 28%
    *   LAC: 19%
*   **Enforcement:**
    *   EU: 19%
    *   LAC: 41%
*   **Internal management:**
    *   EU: 18%
    *   LAC: 13%
*   **Adjudication:**
    *   EU: 3%
    *   LAC: 2%

Source: Data analysed by the OECD from (EC, 2025[10]; Muñoz-Cadena et al., 2025[11]).

# Governments are using Al in pursuit of a variety of potential benefits
The use cases analysed by the OECD have the potential to address all the Al benefits introduced in
Chapter 1, and most use cases have the potential to yield multiple benefits. However, certain benefits
receive stronger focus from governments than others (Figure 2.5):

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 67
*   About six out of every 10 of the examined use cases seek to contribute to the automation,
    streamlining and tailoring and personalisation of processes and services, particularly within justice,
    public services, civic participation and regulatory design and delivery.
*   Nearly half of all use cases seek to enhance decision-making, sense-making and forecasting, with
    most concentrated in public services, regulation and civic participation.
*   About a third of the use cases have the potential to improve accountability and anomaly detection,
    mainly within law enforcement and disaster risk management, civic participation, fighting corruption
    and promoting public integrity, public procurement and regulation.
*   A small proportion of use cases have the potential to unlock opportunities for external stakeholders,
    such as citizens, civil society organisations and businesses, especially in civic participation, access
    to justice and disaster risk management.

The lack of emphasis on unlocking opportunities for external stakeholders through Al as a good for all
stands out as a potential gap. Al experts have suggested that this type of empowerment is important and
that governments could take more action to seize it (OECD, 2024[13]). However, such efforts could
potentially be more prevalent in areas not covered by this report (e.g. specific sectors, such as agriculture
or education). While the results of this benefit may be less directly felt by governments, they can pay
dividends through strengthened trust in government or even economic gains.

# Figure 2.5. Potential benefits of Al use cases across functions of government
Percentage of use cases for the corresponding function of government

**Chart Data**
*   **Legend:**
    *   Automated, streamlined, & tailored processes & services (115)
    *   Better decision-making, sense-making & forecasting (90)
    *   Enhanced accountability & anomaly detection (59)
    *   Unlocking opportunities for external stakeholders through AI as a good for all (7)

*   **Function of government (number of use cases per function of government)**
    *   **All functions of government (200):**
        *   Automated...: 57%
        *   Better decision-making...: 45%
        *   Enhanced accountability...: 30%
        *   Unlocking opportunities...: 4%
    *   **Public service design & delivery (21):**
        *   Automated...: 69%
        *   Better decision-making...: 58%
        *   Enhanced accountability...: 9%
        *   Unlocking opportunities...: 4%
    *   **Civic participation & open government (29):**
        *   Automated...: 66%
        *   Better decision-making...: 100%
        *   Enhanced accountability...: 28%
        *   Unlocking opportunities...: 17%
    *   **Justice administration & access to justice (25):**
        *   Automated...: 100%
        *   Better decision-making...: 32%
        *   Enhanced accountability...: 20%
        *   Unlocking opportunities...: 4%
    *   **Law enforcement & disaster risk management (22):**
        *   Automated...: 18%
        *   Better decision-making...: 41%
        *   Enhanced accountability...: 59%
        *   Unlocking opportunities...: 5%
    *   **Regulatory delivery (21):**
        *   Automated...: 52%
        *   Better decision-making...: 48%
        *   Enhanced accountability...: 38%
    *   **Public financial management (14):**
        *   Automated...: 43%
        *   Better decision-making...: 36%
        *   Enhanced accountability...: 50%
    *   **Civil service reform (11):**
        *   Automated...: 100%
        *   Better decision-making...: 9%
        *   Enhanced accountability...: 9%
        *   Unlocking opportunities...: 30%
    *   **Public procurement (10):**
        *   Automated...: 50%
        *   Better decision-making...: 50%
        *   Enhanced accountability...: 11%
    *   **Fighting corruption & promoting public integrity (10):**
        *   Automated...: 67%
        *   Enhanced accountability...: 67%
    *   **Tax administration (9):**
        *   Automated...: 44%
        *   Better decision-making...: 56%
        *   Enhanced accountability...: 33%
    *   **Policy evaluation (5):**
        *   Automated...: 60%
        *   Better decision-making...: 40%
        *   Enhanced accountability...: 60%

Note: The potential benefits in this figure are not mutually exclusive (i.e. one use case may have the potential to yield more than one type of
benefit). Thus, the sum of potential benefits observed is greater than the total number of use cases.
Source: OECD analysis of identified use cases.

When examining the specific benefits within the four general activity categories mentioned above, more
detailed insights into the direct gains governments aim to achieve through the use of Al can be ascertained

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

68 |
(as shown in Figure 2.6). The sections below further detail these benefits and provide examples of some
of the use cases that informed such trends.

# Figure 2.6. Specific benefits of Al use cases

**Chart Data**
*   **Legend:**
    *   Automated, streamlined, & tailored processes & services (115)
    *   Enhanced accountability & anomaly detection (59)
    *   Better decision-making, sense making & forecasting (90)
    *   Unlocking opportunities for external stakeholders through AI as a good for all (7)

*   **Benefits (number of use cases per benefit) vs Percentage of use cases**
    *   **Category: Automated, streamlined, & tailored processes & services (115)**
        *   Improve productivity in analytical tasks: 31%
        *   Tailored services to address personalised citizen needs: 15%
        *   Automate mundane tasks: 9%
        *   Tailored approaches to strengthen the civil service: 3%
    *   **Category: Better decision-making, sense making & forecasting (90)**
        *   Better forecasting of the future: 18%
        *   Enhanced decision making & sense making of the present: 15%
        *   Improved information management & accessibility: 12%
    *   **Category: Enhanced accountability & anomaly detection (59)**
        *   Detecting improper transactions & assessing integrity risks: 25%
    *   **Category: Unlocking opportunities for external stakeholders through AI as a good for all (7)**
        *   Enabling non-governmental actors to understand & engage with government & promote accountability: 5%
        *   Unlocking opportunities for external stakeholders through AI as a good for all: 4%

Note: The potential benefits in this figure are not mutually exclusive (i.e. one use case may have the potential to yield more than one type of
benefit). Thus, the sum of potential benefits observed is greater than the total number of use cases.
Source: OECD analysis of identified use cases.

## Automated, streamlined and tailored processes and services
About a third (31%) of the analysed use cases aim to improve productivity in analytical tasks. To a lesser
extent, 15% of use cases represent government efforts to use Al to tailor services to address personalised
citizen needs. This relatively lower adoption of Al for personalisation could be partly attributed to data
governance limitations or restrictions due to the large volume of personal data required for such
applications (see Chapter 3 for discussion on implementation challenges). This appears to be a gap
warranting further analysis. Interestingly, the automation of mundane tasks comes in at 9% of the analysed
use cases. This is contrary to conventional expectations of Al primarily being used for automating repetitive
tasks that require little analytical consideration (Figure 2.6). While a case review methodology is not fully
generalisable to the universe of Al in government, this suggests a potential shift of Al's use towards
enhancing more complex decision-making processes and supporting more specialised work of public
servants and policymakers. Yet, it could also suggest governments are not fully capitalising on Al with
respect to repetitive tasks, which public servants spend a significant amount of time on, and for which
tremendous efficiencies can be made through Al (The Alan Turing Institute, 2024[14]; Berryhill et al.,
2019[15]).
Table 2.3 provides examples of how Al is being used for these purposes. Use cases intended to improve
productivity in analytical tasks include uses like estimating compliance costs in regulatory impact

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 69
assessments (Germany), analysing and scoring candidates' recorded responses in certain recruitment
processes (United Kingdom), or supporting government staff with common procurement queries (North
Carolina, United States). Automation in repetitive tasks that require less intellectual engagement
encompasses various domains, including repetitive judicial tasks or financial and HR processes. This is
the case of Prometea in Argentina, the Al Litigation Project in Brazil or Finland's use of RPA and Al in
financial management. Uses aimed at tailoring services and personalisation can be seen in functions such
as public services, tax, regulation or justice. For example, the Public Employment Service in Sweden uses
BÄR to tailor job-finding support, optimising resource allocation through personalised training and guidance
recommendations. In the case of Singapore, the tax authority developed a chatbot to enhance self-service
by assisting taxpayers with inquiries and payments. Finally, Al is being used to strengthen civil service
hiring and professional development programmes, such as the Australian Public Service Commission trial
to use Al to expedite the design, structuring and deployment of digital skills training; or the Spanish National
Institute for Public Administration use to transform how civil servants access and use learning resources
by improving searchability and recommendations of relevant materials.

# Table 2.3. Examples of Al for automated, streamlined and tailored processes and services

| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| Argentina | Prometea and ChatGPT in the justice sector | The Public Prosecution Service of Buenos Aires adopted Prometea in 2017 to automate repetitive judicial tasks and expedite case proceedings. In 2024, it began to also is exploring explore the use of ChatGPT to analyse legal cases and draft decisions. This Al tool reduces sentencing drafting time from an hour to 10 minutes, increasing efficiency in case management. | Automate mundane (and recently, analytical) tasks | Justice (Box 5.62) |
| Australia | Al to generate an online learning | The Australian Public Service Commission (APSC) trialled accelerating course creation for public servants by using Al to design, structure and deploy digital skills training in minutes rather than weeks. The pilot trialled feeding in controlled materials to generate course outlines and quizzes and refine content through feedback loops. | Tailored approaches to strengthen the civil service | Civil service reform (Box 5.22) |
| Brazil | Al Litigation Project | Brazil's tax courts use Al to group similar tax appeal cases, assigning them to the same officers for faster processing. Initial trials demonstrated high accuracy, significantly reducing case backlog and improving decision speed. | Automate mundane tasks | Tax administration (Box 5.2) |
| Finland | RPA and Al in Financial Management | Finland leverages a tool that automates financial and HR processes through RPA and Al, optimising tasks such as invoice processing. Its structured automation strategy improves scalability and efficiency. | Automate mundane tasks | Public finance |
| Germany | Al for regulatory impact assessments | Germany's Federal Statistical Office is exploring the use of Al to estimate compliance costs in regulatory impact assessments. Al identifies relevant legal text passages and predicts cost implications, allowing officials to focus resources on complex cases. | Improve productivity in analytical tasks | Regulation (Box 5.13) |
| Singapore | Chatbot for taxpayer services | Singapore's tax authority developed a chatbot using Al and NLP to assist taxpayers with inquiries and payments. The system enhances self-service options, reducing administrative workload and improving user satisfaction. | Tailored services to address personalised needs | Tax administration (Box 5.4) |
| Spain | Knowledge graph | The National Institute for Public Administration (INAP) Al-enhanced knowledge graph transforms how civil servants access and use vast learning resources. By creating a "resource bank" that improves searchability and recommends relevant materials, INAP enables public officials to efficiently find and apply critical knowledge. | Tailored approaches to strengthen the civil service | Civil service reform |
| Sweden | BÄR | The Public Employment Service uses BÄR, an Al tool within the Prepare and Match program, to tailor job-finding support. By analysing jobseekers' profiles and predicting employment chances, it guides decisions and optimises resource allocation through personalised training and guidance recommendations. | Tailored services to address personalised needs | Civil service reform (5.43) |
| United Kingdom | Outmatch | The UK tax authority (HMRC) employs Outmatch to automate junior role recruitment by analysing and scoring candidates' recorded responses. This speeds up high-volume hiring while ensuring consistency in | Improve productivity in analytical tasks | Civil service reform (Box 5.20) |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
70 |
| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| United States | Chatbot to support procurement | evaluation. North Carolina's IT department introduced a 24/7 Al-powered chatbot to support government staff with common procurement queries. It provides instant answers, streamlining processes and reducing wait times. | Improve productivity in analytical tasks | Public procurement |

# Better decision-making, sense-making and forecasting
The use of Al for enhanced decision-making and sense-making of the present was measured across 18%
of cases, while 15% of use cases aimed at better forecasting of the future, and 12% at improving
information management and accessibility to support these activities (Figure 2.6). Such uses of Al not only
support policymaking processes — which are indeed a minority when it comes to government Al efforts
(OECD, 2024[7]) — but also contribute to smarter policy implementation and internal operation, and better
quality and pertinence of service design and delivery.

Table 2.4 provides some examples of how Al is being used for these purposes. Governments are using
open-source tools like Polis to make better sense of the present, specifically in deliberative exercises,
where it clusters public opinions and identifies areas of consensus. Other uses allow governments to better
optimise decision-making. An example is Korea's dBrain+, which analyses real-time financial management
data and integrates risk assessment, budget management and performance evaluation tools. Most
forecasting use cases aim to predict certain conditions to take decisions in advance and pre-position
resources — such as predicting slippery conditions for winter road maintenance in Belgium or forecasting
the likelihood of wildfires in Canada — to improve risk mitigation and authorities' response times. Some
other forecasting uses aim to simulate alternative scenarios. One example is Helsinki's (Finland) use of
UrbanistAl to generate visualisations of alternative urban planning scenarios in order to support
consensus-building among stakeholders. Finally, the use of Al to improve information management and
accessibility can take the form of tools available for stakeholders both inside and outside of government to
access vast amounts of data. Examples include the European Parliament's search tool that allows users
to analyse over 20 years of parliamentary documents, or the Netherland's Court of Audit GenAl pilot
platform for analysing public audit reports. It might also take the form of support tools to quickly retrieve
accurate government information and ensure reliable responses in customer support services, such as the
virtual assistants Caddy in the UK, and Albert in France. While those assistants span domains, some are
focused on specific areas, such as France's Sofia conversational agent for ecological information.

# Table 2.4. Examples of Al for better decision-making, sense-making and forecasting

| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| Belgium | Al for road safety | Belgium predicts slippery conditions and optimises resource allocation for winter road maintenance. By analysing weather and traffic data, the tool helps authorities proactively deploy de-icing measures, improving road safety and reducing accidents. | Better forecasting of the future | Public services; related to disaster management |
| Canada | Anticipating wildfire risks | Alberta's Al wildfire prediction system forecasts the likelihood of wildfires across the province's protected forests using historical fire, weather and ecological data. The tool assists authorities in pre-positioning resources, improving response times and mitigating risks. | Better forecasting of the future | Law enforcement and disaster management (Box 5.54) |
| European Union | Al for examining parliamentary documents | The European Parliament's search tool enables citizens and policymakers to efficiently analyse over 20 years of parliamentary documents, including 38 000 motions for resolutions and parliamentary questions. By automating information retrieval, the Al system improves accessibility and facilitates informed decision-making. | Improved information management/ accessibility | Civic participation and open government (Box 5.35) |
| Finland | UrbanistAl | The City of Helsinki used UrbanistAl to generate visualisations of alternative urban planning scenarios, helping citizens and local businesses engage in discussions about pedestrianising key streets. With Al-generated renderings, the tool supported consensus-building among stakeholders. | Better forecasting of the future | Civic participation (Box 5.38) |
| France | Albert and | Albert is a GenAl tool developed to assist public administration employees | Improved | Public services |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 71
| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| | Sofia | in responding to citizen inquiries. The tool helps civil servants search for regulations, summarise information and draft responses, while human agents verify the final output. Sofia is a conversational agent that facilitates access to the Ministry of Ecological Transition's scientific and technical knowledge. | information management accessibility | (Box 5.46) |
| International | Polis | Polis is an Al-powered open-source platform designed to facilitate large-scale deliberative processes by clustering public opinions and identifying consensus statements. It has been used in multiple countries to inform climate policy, referendum debates, municipal decision-making and political party platforms. | Enhanced decision-making and sense-making of the present | Civic participation (Box 5.36) |
| Korea | dBrain+ | dBrain+ is an Al-driven financial management system that analyses real-time economic, fiscal and financial data to optimise public finance decision-making. It integrates risk assessment, budget management and performance evaluation. | Enhanced decision-making and sense-making of the present | Public finance (Box 5.8) |
| Netherlands | GenAl platform on public audit work | The Netherland's Court of Audit, a public GenAl platform is currently being piloted to allow citizens and other stakeholders to roam through public reports and find answers and sources to their questions on public audit work. | Improved information management/ accessibility | Fighting corruption and promoting integrity |
| United Kingdom | Caddy | Caddy, an Al-powered assistant developed in the UK, supports customer service agents by quickly retrieving accurate government information. With a human-in-the-loop validation system, Caddy ensures reliable responses while improving efficiency in handling citizen inquiries. | Improved information management/ accessibility | Public services |

# Enhanced accountability and anomaly detection
Regarding uses for enhanced accountability and anomaly detection, 25% of the analysed use cases
focused on detecting improper transactions and assessing integrity risks, and 5% on improving
governments' ability to engage non-governmental actors and promote accountability (Figure 2.6). The
former covers use cases related to oversight, preventive controls, and risk assessment and management.
Those are generally linked to the core mandates of some specific functions of government, such as those
responsible for fighting corruption and promoting public integrity or enforcing regulatory compliance. The
use cases that better connect government with non-governmental actors, ultimately contributing to greater
accountability and responsiveness, are often related to the civic participation and transparency practices
used in various government functions and organisations.

Table 2.5 provides some examples of how Al is being used to pursue this benefit. Some uses focus on
prioritising cautionary actions based on the analysis of patterns and statistical anomalies. For example,
Portugal's Court of Audit uses Al to detect critical and priority cases in public procurement that might
require concentrating audit efforts. In Chile, Al is used in the country's public procurement platform to
detect irregularities and improve compliance monitoring. Other uses are intended to detect loopholes or
insufficient safeguards in policymaking, such as assisting corruption prevention officers in evaluating
legislation to assess corruption risk factors in legal texts in Lithuania. Al can also support governments'
connection with the public to reinforce accountability. This is the case of some online platforms and tools,
the virtual assistant Chatico from Bogotá (Colombia), which has an open government module that eases
participation in public campaigns and decision-making processes.

# Table 2.5. Examples of Al for enhanced accountability and anomaly detection

| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| Chile | ChileCompra | ChileCompra's Public Contracting Observatory uses LLM's to analyse procurement data for irregularities and improve compliance monitoring, enabling more efficient oversight and promoting ethical standards in public procurement. | Detecting improper transactions and assessing integrity risks | Public procurement (Box. 5.24) |
| Colombia | Chatico | The city of Bogotá launched Chatico, an Al-powered virtual assistant, to facilitate interactions between citizens and the local administration. Through its website and WhatsApp interfaces, the | Enabling non-governmental actors to understand and | Civic participation (Box 5.41) |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
72 |
| Country | Initiative | Description | Sub-benefit | Function |
| :--- | :--- | :--- | :--- | :--- |
| | | chatbot eases citizen participation in public campaigns and decision-making processes and offers as well enhanced accessibility to public services. | engage with government and promote accountability | |
| European Union | DATACROS | DATACROS uses Al to detect anomalies in corporate ownership structures that may indicate corruption or money laundering. The system analyses data from over 70 million companies across 44 European countries, flagging hidden patterns and potential illicit activities. | Detecting improper transactions and assessing integrity risks | Fighting corruption and promoting integrity (Box 5.27) |
| Lithuania | Al to assist corruption prevention officers | Lithuania is developing an Al-powered tool that uses large language models (LLMs) to assist corruption prevention officers in evaluating corruption risk factors in legal texts, such as loopholes or insufficient safeguards. | Detecting improper transactions and assessing integrity risks | Fighting corruption and promoting integrity (Box 5.30) |
| Portugal | Assessing procurement risks | Portugal Court of Audit is implementing Al-driven risk assessment methods to enhance its audits, ensuring the most critical cases in public procurement receive priority. This initiative optimises resources and strengthens accountability in public contracting. | Detecting improper transactions and assessing integrity risks | Public procurement |

# Unlocking opportunities for external stakeholders through Al as a good for all
Finally, a small minority of use cases (4%) have the potential to unlock opportunities for external
stakeholders, such as citizens, civil society organisations and businesses. Such activities are different from
general service delivery or new forms and channels of interaction for participation and accountability
purposes. Here, Al can empower external actors by enhancing their capabilities and access to information
and use government-supported Al systems to achieve their missions and objectives more effectively. Such
uses remain marginal and represent a potential gap in government efforts warranting further research and
action. As noted above, however, such use cases could potentially be more prevalent in areas not covered
by this report.

Table 2.6 provides some examples of how Al is being used for these purposes. Use cases generally
include tools in participatory platforms that can be used according to the needs and objectives of users.
For example, the participatory platform Decide Madrid (Spain) experimented with Al tools to assist citizens
in aggregating and developing their own proposals for action. Similarly, the Al tool MAPLE helps citizens
by summarising draft legal texts and allowing them to submit inputs and comments on pending legislation.
In the field of disaster risk management, governments can also contribute to goods that can empower
citizens for greater resiliency to natural disasters. For example, the Bencana Bot in Indonesia prompts
residents to report floods via social media, generating real-time online maps that, combined with official
data, can be reused by non-governmental stakeholders. Although the examples here help address the
relevant benefit, they do so in a somewhat tangential way, with external elements sometimes benefiting
as a positive spillover effect from government activities. Emergent opportunities for governments to open
or provision Al systems more directly for external stakeholders may result, such as in areas not currently
serviced or appealing to the private sector.

# Table 2.6. Examples of Al unlocking opportunities for external stakeholders through Al as a good for all

| Country | Initiative | Description | Function |
| :--- | :--- | :--- | :--- |
| Greece | DidaktorikaAl | Greece's DidaktorikaAl platform, launched by the National Documentation Centre (EKT), improves the accessibility of academic and scientific knowledge for policymakers and the broader society through an Al-powered online library gathering more than 50 000 publications. | Civic participation and open government |
| Indonesia | Bencana Bot | In Jakarta (Indonesia), the Al-powered chatbot Bencana Bot prompts residents to report floods via social media, generating real-time, freely accessible online maps on PetaBencana.id. Combined with official data provided by the Jakarta Disaster | Law enforcement and disaster |

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 73
| Country | Initiative | Description | Function |
| :--- | :--- | :--- | :--- |
| | | Mitigation Agency, the platform helps residents stay safe during emergencies, with usage surging by 2 000% during major floods. | risk management |
| Spain | Decide Madrid | In 2021, the participatory platform Decide Madrid (Spain), based on the open-source software Consul, experimented with a Natural Language Processing (NLP) system to assist citizens in aggregating and developing proposals. | Civic participation and open government |
| United States | MAPLE | The Al-powered tool MAPLE (Massachusetts Platform for Legislative Engagement), which allows citizens to better understand the context and objectives of draft legal texts through Al-generated summaries and to submit their inputs and comments to pending legislation. | Civic participation and open government |

# Some government functions are more mature regarding governing and adopting Al
Al's potential is recognised across all functions of government, but the maturity of its adoption and
governance varies significantly. A few functions are already implementing Al initiatives in a structured
manner, learning from their implementation, and in some instances, scaling up successful solutions into
other issue areas and in broader contexts. For instance, in public service design and delivery, Al is widely
used to automate tasks, retrieve and synthesise information, and improve digital service effectiveness and
usefulness for users. In law enforcement and disaster risk management, Al is widely used to prioritise
police resources, accelerate investigations and better anticipate and recover from disasters. However,
other functions of government have only begun experimenting with limited, ad-hoc prototypes and pilots.
In fields such as policy evaluation, public financial management, and regulatory design and delivery, Al
adoption is largely found in isolated pilots. In some functions, such as justice administration and fighting
corruption and promoting public integrity, there is significant geographical variation. Some countries, like
Argentina (Box 5.62 on Prometea) and Spain (Box 5.67 on Al-enabled domestic violence response),
actively deploy sophisticated Al solutions in even high-risk areas that manage to mitigate risks otherwise
resulting in scandals with similar systems in other contexts. Yet, other countries are still in the early stages
of digital transformation. As Al continues to appear in additional use cases, governments must mitigate
risk in order to promote responsible Al adoption.

In terms of technical maturity, Al adoption varies not only in scale but also in the types of systems used.
Some functions of government, such as tax administration and procurement, rely heavily on rules-based
systems, which have been effective in automating structured decision-making processes for many years.
Others, like law enforcement and disaster management, and fighting corruption and promoting public
integrity, use more advanced ML systems to identify patterns, enhance risk assessments and support
decision-making. However, in most functions of government, there is very little use of the latest GenAl
models, such as LLMs, which offer new capabilities in knowledge synthesis and content generation that
could be more transformational. This trend can be seen in other databases as well — only 61 of the 1 343
(4.5%) Al use cases in the EC Public Sector Tech Watch repository are GenAl (Brizuela et al., 2025[16]). A
survey from Deloitte (2024[17]) also found an uneven level of preparedness for GenAl adoption across
different sectors of government, though their sector categorisations do not align directly to the government
functions in this report. The use of GenAl systems can be seen in a handful of government functions in
Chapter 5, such as the design and delivery of regulations and public services, and in civic participation
efforts, though many of these efforts appear sporadic or experimental. Some of the most advanced uses
take the form of chatbots, which may be highly impactful but may not fully exploit the technology's potential
for large-scale synthesis, tailored content generation or making services more proactive or personalised.
The slow adoption of these advanced systems in many domains, in addition to the relative recency of the
technology and relevant Al use cases, suggests that while Al experimentation is widespread, the transition
to more sophisticated, high-impact systems remains uneven across government functions and countries.
This is not to say that governments should abandon all efforts in using more established forms of Al in
pursuit of GenAl, as chasing the latest "cool tech" in areas where it is not a good match for the problem to
be solved can contribute to Al project failure (Ryseff and Narayanan, 2025[18]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

74|

A key factor shaping Al adoption across functions of government is data availability and quality. In tax administration, for example, Al has been widely deployed due to the abundance of structured data, which has enabled automation and risk assessment for years. Yet, because of the complex legal landscape in this function and regarding taxpayer data, most efforts rely on classic rules-based systems, with challenges in pursuing more modern ML systems that could unlock productivity gains even leveraging unstructured data. By contrast, while Al is increasingly used in private sector HRM functions, its application in civil service reform remains limited due to the insufficiency of comprehensive workforce data – covering employee skills, job demands and performance indicators. The abundance of data in governments does not necessarily translate to the availability of Al-ready data (see Chapter 3 on implementation challenges).

Beyond data, other fields could be facing challenges in Al maturity because the nature of their tasks requires technical capabilities that only recent advanced Al systems could provide. This suggests the potential for rapid acceleration in the coming months. For instance, Al adoption in regulatory design and delivery appears to have increased and accelerated through the use of LLMs to assist with analytical tasks that could have not been performed by other systems (for example, see Box 5.12 for legal and regulatory querying and drafting aids). In another example, Al is enabling mass deliberative civic participation efforts at scales never before feasible.

# Different functions of government have different contexts and needs

Al adoption in government is often discussed in broad terms, but its impact and risks vary significantly across functions. Different functions have unique challenges, regulatory constraints and levels of Al readiness. For example, when Al is used in public services to improve healthcare, the applications need to navigate stringent data privacy regulations and ethical concerns around medical decision-making, while Al in other fields, such as civic participation, can be more experimental, using real-time optimisation with less potential to infringe the rights of individuals. Actors in one function of government could use a similar Al solution as in another with vastly different results, impacts and implications. Thus, the discussion of function of government in this section cannot be seen as a likewise comparison, and further research is needed to understand differences, including with a larger scope of analysis.

# Use cases could pose risks if not implemented in a trustworthy manner

As discussed in Chapter 1, this report categorises five types of risks faced by governments in adopting Al. In addition to the risks shown in Figure 2.7, the risk of inaction involves missed opportunities and the growing capacity gap between the public and private sector. Such risks, possibly realised by not building capacities for and using Al in government, cannot be visualised and may be difficult or impossible to precisely measure.

The OECD found that every one of the 200 use cases analysed for this report could pose one or more types of risk if not designed and used in a trustworthy way.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 75

# Figure 2.7. The potential for operational risks is the most represented across government functions

## Number of use cases across functions of government categorised according to selected risk types

**Chart Legend:**
- Operational risks (185)
- Public resistance risks (99)
- Ethical risks (113)
- Exclusion risks (75)

**Chart Data:**
The Y-axis is "Percentage of use cases for the corresponding function of government", ranging from 0 to 100%. The X-axis is "Function of government (number of use cases per function of government)".

| Function of government (number of use cases) | Operational risks (%) | Public resistance risks (%) | Ethical risks (%) | Exclusion risks (%) |
| :--- | :--- | :--- | :--- | :--- |
| All functions of government (200) | 93% | 50% | 56% | 38% |
| Public service design & delivery (126) | 96% | 47% | 64% | 36% |
| Civic participation (29) | 90% | 76% | 52% | 48% |
| Justice admin. & open government (25) | 88% | 68% | 100% | 56% |
| Law enforcement & national security (22) | 100% | 36% | 48% | 27% |
| Regulatory monitoring (21) | 86% | 29% | 24% | 27% |
| Financial management (14) | 79% | 50% | 36% | 36% |
| Civil service reform (11) | 82% | 36% | 82% | 36% |
| Public procurement (10) | 100% | 70% | 50% | 20% |
| Fighting corruption & public integrity (9) | 67% | 78% | 73% | 44% |
| Tax administration (9) | 89% | 33% | 78% | 56% |
| Policy evaluation (5) | 100% | 22% | 20% | 20% |

Note: In parentheses, the number of occurrences of risk types. Use cases can involve more than one type of risk. Thus, the total number of potential risk occurrences is greater than the total number of use cases.
Source: OECD analysis of identified use cases.

Potential **operational risks** are the most prevalent among the analysed used cases (93%). An example of this is Australia's Robodebt scheme, where investigations revealed inadequacies in algorithmic design played a significant role in its failures and its calculations ultimately being ruled unlawful (Box 5.11). Specifically, the algorithm's oversimplification and lack of safeguards resulted in the issuance of 470 000 incorrect debt notices without human verification. This highlights the operational risks of automating complex social systems without sufficient human oversight or rigorous testing and additionally presented ethical risks resulting in real-world harm.4

Potential **ethical risks** were the second most prevalent among the analysed use cases (56%), such as in Al-supported applicant review tools used by HRM offices. In reality, ethical risks can be present in the large majority of Al uses cases. However, the lower presence of this risk in the analysed use cases could be due to the limited and specific scope, and manner of application, of use cases identified for this report. An example of an ethical risk that resulted in real-world harm is The Netherlands' Toeslagenaffaire (childcare benefits scandal), where an Al system wrongfully accused 26 000 families of fraudulently claiming childcare benefits due to a biased algorithm that targeted families with dual nationalities or migrant backgrounds; it forced many to repay undue debts (Box 5.6). This case illustrates how ethical risks can cause harm if not mitigated appropriately.

Potential **public resistance risks** were prevalent across 50% of the analysed use cases. Previous failures in Al deployment have significantly impacted reputations and eroded public trust in the government's capacity to use Al responsibly. These cases underscore the necessity for governments to take steps to prevent risks and to swiftly address potential failures in Al use, fostering public trust. This can be achieved with appropriate guardrails, including strong accountability and redress mechanisms, continuous monitoring and oversight, and effective risk management.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

76 |

Finally, the potential for **risks of exclusion** was identified in 38% of the analysed used cases. For example, citizen participation platforms that have deployed Al tools to assist citizens in aggregating and developing proposals may pose challenges for individuals lacking digital skills. This could inadvertently benefit the advantaged, thereby enhancing their ability to further promote their ideas (Duberry et al., 2021[19]; Wang et al., 2024[20]). Al use cases also help civil servants to efficiently process vast quantities of citizen inputs and enhance facilitation of participatory processes. However, the success of these applications is contingent upon the diversity incorporated in the training data of the Al system employed; there is a risk these tools may fail to adequately capture the diversity of public opinion (ECNL, 2024[21]). Many Al-assisted translation tools in participation platforms may also be subject to not capturing nuances and understanding different cultural contexts for languages of minorities, as they are usually trained on data from English and other dominant languages (ECNL, 2024[21]).5

The greater or lower presence of certain risks across the functions of government is of interest, too. For instance, observed cases in justice administration and civil service reform appear to more prominently feature ethical risks due to the potential for adverse outcomes in some of its cases. In the tax administration field, existing controls and regulations might create safeguards against ethical and exclusion risks, making operational risks more prevalent in the field. In civic participation, public resistance risks take more prevalence, compared to other functions. This is likely because most of its use cases include government-to-citizen interactions and thus exhibit greater dependence on public acceptance. This is similar for public procurement, where suppliers' perceptions of and public trust in Al systems play a key role in their success; thus featured more prevalently in resistance risks. This comparative analysis shows the importance of acknowledging the main drivers of potential risks in each field, which can inform how to mitigate and manage them.

# Governments are vigilant of several Al risks, though some may be overlooked

Overall, through conducting analysis and interacting with governments in the development of Chapters 4 and 5, it appears many national governments are well-informed with regard to, and have put in place, processes to manage risk associated with **data**, a **lack of transparency and explainability**, and **Al misuse** — either intentional or inadvertent — and the potential for resulting harms or privacy infringement. This is positive and not surprising, as these risks are often raised by Al experts and in research both within and beyond the public sector (OECD, 2024[13]).6 To a somewhat lesser extent, the risk of an overreliance on Al technologies also appears to be a consideration for government efforts. Overall, however, there appears to be less of an emphasis on ensuring that government use of Al does not further exacerbate digital divides. When complementary service channels are not made available, government ambitions to automate and streamline processes could result in the reduction of service opportunities for communities with less access to digital services or preference for non-digital approaches (Welby and Hui Yan Tan, 2022[22]). In addition, while governments are clearly aware of how Al could contribute to productivity and help shift public servants' efforts away from repetitive tasks and towards more meaningful work, there is seemingly less recognition of Al's potential to reduce job quality (e.g. through invasive algorithmic management) or for job displacement (Peixoto, Canuto and Jordan, 2024[23]). Even if Al adoption becomes systematic in public administrations, governments will need to ensure that all citizens are properly served and the concerns and any rights of the civil service are taken into account in order to promote Al adoption.

Finally, governments need to better consider the **risk of inaction**. Throughout Chapters 4 and 5, it is clear that many governments are working towards specific goals with their Al efforts, and that they are aware of and are seeking to mitigate a variety of Al risks by instantiating approaches to unlock the potential of Al. However, the analysis conducted for this report and discussions with relevant government officials indicate there may be limited awareness of missed opportunities due to slow Al adoption or the consequences of the widening gap in Al capabilities between the public and private sectors.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 77

Few governments have assessed the extent to which Al could make an impact in their internal operations and public-facing services. Furthermore, most have not fully articulated their ambitions for Al in government, determined the existing gaps, or proposed clarified roadmaps to close those gaps and meet the goals. Governments need to explore Al not only to enhance the design and implementation of public policies and services, but also to ensure they have the knowledge and capacity to regulate Al development and use in government and beyond. In an inquiry by the Parliament of Australia (2025[24]), the Joint Committee of Public Accounts and Audit expressed "very grave concern" that Al will soon outpace the government's ability to regulate it. Such committee findings are not necessarily representative of the Australian Government's views. Al experts have also noted the inability of governance mechanisms and institutions to keep pace with rapid Al evolutions is one of the most critical risks associated with Al (OECD, 2024[13]).

In addition to these critical risks associated with the Al use in government, the OECD's analysis of 200 use cases has identified a variety of challenges governments can face in adopting the technology. These implementation challenges are shared across all functions, while others are more prevalent in certain fields. They can translate into broader issues and can hinder the strategic use of Al in government. These issues are discussed in the following chapter.

# References

Austin, T. et al. (2024), A snapshot of how public sector leaders feel about generative Al, https://www2.deloitte.com/us/en/insights/industry/public-sector/ai-adoption-in-public-sector.html.
[17]

Bailey, K. (2016), Reframing the “Al Effect”, https://medium.com/@katherinebailey/reframing-the-ai-effect-c445f87ea98b.
[12]

Berryhill, J. et al. (2019), "Hello, World: Artificial intelligence and its use in the public sector", OECD Working Papers on Public Governance, No. 36, OECD Publishing, Paris, https://doi.org/10.1787/726fd39d-en.
[15]

Brizuela, A. et al. (2025), Analysis of the generative Al landscape in the European public sector, European Commission, https://op.europa.eu/s/z4XY.
[16]

Columbia University (2020), The Future of Al in the Brazilian Judicial System, https://www.sipa.columbia.edu/aidriven-innovations-brazilian-judiciary.
[9]

Duberry, J. et al. (2021), “Artificial intelligence and civil society participation in policy-making processes: Thinking about Al and participation.”, SSRN Electronic Journal, https://doi.org/10.2139/ssrn.3817666.
[19]

EC (2025), Public Sector Tech Watch latest dataset of selected cases, http://data.europa.eu/89h/e8e7bddd-8510-4936-9fa6-7e1b399cbd92 (accessed on 4 April 2025).
[10]

ECNL (2024), Can Al tools and platforms make public engagement truly meaningful and inclusive?, https://ecnl.org/news/ai-public-participation-hope-or-hype (accessed on 17 March 2025).
[21]

Government of Canada (2025), Al Strategy for the Federal Public Service, https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/gc-ai-strategy-overview.html.
[4]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

78 |

Government of Switzerland (2025), Strategy Use of Al systems in the Federal Administration, [5]
https://www.bk.admin.ch/bk/en/home/digitale-transformation-ikt-lenkung/ikt-vorgaben/strategien-teilstrategien/sb021-strategie-einsatz-von-ki-systemen-in-der-bundesverwaltung.html.

Government of Uruguay (2021), Al Strategy for the Digital Government, [6]
https://www.gub.uy/agencia-gobierno-electronico-sociedad-informacion-conocimiento/comunicacion/publicaciones/ia-strategy-english-version/ia-strategy-english-version/ai-strategy-for.

Harvard Kennedy School (2023), Al, judges and judgement: setting the scene, [8]
https://www.hks.harvard.edu/centers/mrcbg/publications/awp/awp220.

Muñoz-Cadena, S. et al. (2025), Sistemas de IA en el sector público de América Latina y el Caribe (Versión V2), https://sistemaspublicos.tech/sistemas-de-ia-en-america-latina/ (accessed on 29 April 2025).
[11]

Netherlands Court of Audit (2024), Central government often does not assess risks of Al, [25]
https://english.rekenkamer.nl/latest/news/2024/10/16/central-government-often-does-not-assess-risks-of-ai.

OECD (2024), “2023 OECD Digital Government Index: Results and key findings", OECD Public Governance Policy Papers, No. 44, OECD Publishing, Paris, [7]
https://doi.org/10.1787/1a89ed5e-en.

OECD (2024), “Assessing potential future artificial intelligence risks, benefits and policy imperatives", OECD Artificial Intelligence Papers, No. 27, OECD Publishing, Paris, https://doi.org/10.1787/3f4e3dfb-en.
[13]

OECD (2024), “Governing with Artificial Intelligence: Are governments ready?”, OECD Artificial Intelligence Papers, No. 20, OECD Publishing, Paris, https://doi.org/10.1787/26324bc2-en.
[1]

OECD (2023), "The state of implementation of the OECD AI Principles four years on”, OECD Artificial Intelligence Papers, No. 3, OECD Publishing, Paris, https://doi.org/10.1787/835641c9-en.
[2]

OECD (2021), “State of implementation of the OECD AI Principles: Insights from national Al policies", OECD Digital Economy Papers, No. 311, OECD Publishing, Paris, https://doi.org/10.1787/1cd40c44-en.
[3]

Parliament of Australia (2025), Report 510: Inquiry into the use and governance of artificial intelligence systems by public sector entities - 'Proceed with Caution', [24]
https://parlinfo.aph.gov.au/parlInfo/download/committees/reportjnt/RB000567/toc pdf/Report510Inquiryintotheuseandgovernanceofartificialintelligencesystemsbypublicsectorentities-'ProceedwithCaution'.pdf.

Peixoto, T., O. Canuto and L. Jordan (2024), “Al and the Future of Government: Unexpected Effects and Critical Challenges", Policy briefs on Economic Trends and Policies, Vol. 2408, https://ideas.repec.org/p/ocp/pbecon/pb_10-24.html.
[23]

Ryseff, J. and A. Narayanan (2025), Why Al Projects Fail, [18]
https://www.rand.org/pubs/presentations/PTA2680-1.html.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 79

The Alan Turing Institute (2024), Al for bureaucratic productivity: Measuring the potential of Al to help automate 143 million UK government transactions, https://www.turing.ac.uk/news/publications/ai-bureaucratic-productivity-measuring-potential-ai-help-automate-143-million-uk.
[14]

Wang, C. et al. (2024), “The artificial intelligence divide: Who is the most vulnerable?", New Media &amp; Society, https://doi.org/10.1177/14614448241232345.
[20]

Welby, B. and E. Hui Yan Tan (2022), “Designing and delivering public services in the digital age", OECD Going Digital Toolkit Notes, No. 22, OECD Publishing, Paris, https://doi.org/10.1787/e056ef99-en.
[22]

Yigitcanlar, T. et al. (2024), Local governments are using Al without clear rules or policies, and the public has no idea, https://theconversation.com/local-governments-are-using-ai-without-clear-rules-or-policies-and-the-public-has-no-idea-244647.
[26]

# Notes

1 Not all of the use cases analysed appear in this report. The OECD made a selection of cases for the report that best illustrated various themes and findings presented.

2 See https://oecd-opsi.org/innovation-tag/artificial-intelligence-ai and https://oecd.ai/dashboards/policy-instruments/Al_use_cases_in_the_public_sector, respectively. The OPSI collection included a global open "Call for Innovations" crowdsourcing exercise focused on innovations in public services in 2024.

3 As categorised in the observatory's Classification of the Functions of Government. See https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary%3AClassification_of_the_functions_of_government_%28COFOG%29.

4 The Robodebt scheme leveraged automated data-matching, income averaging and overpayment calculation. As discussed in Box 1.1 of this report, many argue that such systems should not be considered Al at all. Thus, the Robodebt scheme could be better described as an automated decision-making system. Nevertheless, it helps to illustrate issues in governance, ethical oversight and algorithmic design.

5 See also the related discussion on Exclusion Risks in Chapter 1.

6 While governments may be informed on these and other issues, and as indicated in Chapter 4, many have frameworks and processes in place to mitigate risks, they need to take action and follow through on their frameworks and processes in order to manage risks. There are instances in which governments may not fully comply with internal requirements or may face incentives to consider systems as low-risk, thus reducing accountability requirements (Netherlands Court of Audit, 2024[25]). In addition, some research suggests that local governments may not be as informed or prone to undergoing risk mitigation activities as national governments (Yigitcanlar et al., 2024[26]). Finally, this report does not seek to evaluate the quality and effectiveness of government processes and mechanisms, though it does seek to highlight those that appear sound and are emerging as best practices.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 81

# 3 Implementation challenges that hinder the strategic use of Al in government

This chapter examines challenges seen in analysed use cases and broader research and analysis. It finds that many government Al initiatives remain in pilots. It highlights common system-wide barriers – skills gaps, difficulties accessing and sharing high-quality data, limited actionable guidance, risk aversion, and weak measurement of results and return on investment. Other challenges vary by function, including inflexible or ambiguous regulation, high or uncertain costs, and outdated legacy information technology systems.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

82

# Key messages

*   The OECD's review of Al use cases in government indicates a high presence of early-stage initiatives, such as experiments and pilots. This indicates:
    *   Possible challenges in transitioning from experimentation to implementation
    *   A need for increased monitoring and sharing of information
    *   A possible need for policy actions to encourage implementation and scaling.
*   Implementation challenges that are shared across all government functions are:
    *   Skills gaps
    *   Challenges to obtaining or sharing quality data
    *   A lack of actionable frameworks and guidance on Al usage, including for specific policy areas
    *   Risk aversion
    *   Demonstrating results and return on investment (ROI).
*   Government functions face a variety of other challenges, with some more prevalent in some functions than others:
    *   Inflexible or outdated legal and regulatory environments
    *   High or uncertain costs of Al adoption and scaling
    *   Outdated legacy information technology (IT) systems.

Governments face a variety of implementation challenges in adopting Al. Some of these challenges span all functions of government, while others appear more acute in certain ones. For instance, nearly all areas struggle with skills gaps and accessing and sharing quality data. Al implementation should account for distinct regulatory landscapes in different functions, with compliance requirements varying significantly between functions such as public procurement, law enforcement and tax administration. Additionally, some functions are more challenged than others with securing funding or with outdated systems, as only now are we seeing the emergence of digital infrastructure that share services with greater interoperability and integration. These challenges can translate into broader issues, such as difficulties in scaling up solutions and risk aversion that hinders innovation. This chapter discusses the various implementation challenges faced by functions of government, as further discussed as related to each function in Chapter 5. Many of these challenges mirror specific regional analysis on Al in government (OECD/CAF, 2022[1]; Brizuela et al., 2025[2]).

# Most government Al efforts exist in exploratory or pilot phases, with limited scaling and documentation

## Possible challenges in moving from experimentation to implementation

The OECD's review of Al uses in government indicate a high presence of early-stage initiatives, such as experiments and pilots. This is consistent with discussions held among relevant OECD working parties and networks, in which government officials at both national and local levels report being in the early stages of using Al government, seeking to learn by starting small and testing different approaches.

Overall, this approach is a good one. The OECD has long encouraged governments at both national and local levels to experiment with new approaches in a controlled and iterative manner to minimise risks and

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 83
costs and to promote failures - which are inevitable to occur quickly and generate lessons learned for
future efforts (OECD, 2017[3]; 2024[4]). This is critical, especially when first getting used to using Al, as
some estimates suggest that more than 80% of Al projects fail, double the rate of non-Al projects (Ryseff,
De Bruhl and Newberry, 2024[5]). For instance, a successful path to Al adoption can involve incorporating
Al into low-risk areas and processes and using internally-generated or open data to demonstrate value
and establish quick wins. An example of this case is the Finnish Government Shared Services Centre for
Finance and HR (Palkeet), which began with modest applications of RPA, paving the way towards "hyper-
automation" with machine learning (ML) (see Chapter 5, “Al in public financial management").

Yet the end goal of most Al projects is the eventual implementation, and as appropriate, the scaling up of
successful solutions. In many countries and functions of government, Al use cases largely exist in the
exploratory phase (e.g. proofs of concept, pilot projects) and have not yet been more broadly implemented
or scaled beyond limited use. For instance, in the United Kingdom (UK) — generally one of the more
advanced governments when it comes to using Al — a report by the Parliament's Public Accounts
Committee (PAC) (2025[6]) found the government had “no systematic mechanism for bringing together
learning from pilots and there are few examples of successful at-scale adoption across government". The
results of a Deloitte survey (2024[7]) in 14 countries reinforce challenges in scaling GenAl in particular,
noting also this challenge is not unique to government. According to the survey, "a significant number of
both commercial and government respondents have transitioned fewer than one-third of their GenAl
experiments into full production". This is attributed to other challenges discussed in this chapter: lack of
expertise and difficulty in measuring mission value from GenAl.

Existing data sources provide insights about the current state of Al adoption in government. For example,
the use cases analysed for this report show most have moved beyond small pilots to be more fully
implemented in some way. Of these implemented cases, most have not scaled beyond their original
contexts (e.g. in certain offices or for certain processes) to address other needs. Although this is not always
a goal, and Al uses in some government functions are often not appropriate for others. Al use cases in
public service design and delivery in Chapter 5 demonstrate, however, that successful approaches can
indeed be scaled up. In this report, the preponderance of implemented cases that go beyond pilots is in
part due to a tendency for the OECD to select more implemented use cases because there is more public
information available about them, and governments are somewhat more likely to report on them as part of
OECD data collection exercises.

Other data sources offer complementary perspectives. The Public Sector Tech Watch observatory of the
European Commission (EC) has systematically collected Al uses cases for several years. Its data on nearly
1 500 Al use cases indicate that most Al solutions are still in the planned, pilot or in-development phase
(58%), suggesting across the EU public sector the majority of cases remain experimental or not fully
implemented (Figure 3.1). Although moving from pilots to production appears to be a challenge — as
reinforced in OECD discussions with governments — the proportion of implemented projects has
increased in the latest data collections. This suggests that administrations may be transitioning their
initiatives from initial testing to fuller implementation (EC, 2024[8]). This data does not consider the extent
to which implemented projects have scaled beyond their initial context.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

84|

# Figure 3.1. Most European Union (EU) Al use cases are in pilot or development phases

**Chart Data:**

- **Legend:**
    - Planned
    - In development
    - Pilot
    - Implemented
    - Not in use

- **Data Points (Pie Chart):**
    - In development: 13%
    - Pilot: 43%
    - Implemented: 40%
    - Not in use: 3%
    - Planned: 2%

Source: Data analysed by the OECD from (EC, 2024[9]).

The "Al Systems in the Public Sector in Latin America and the Caribbean” database indicates a much higher proportion of implemented use cases (70%) (Muñoz-Cadena et al., 2025[10]). However, this is likely due to the data collection for this database, which was built by researchers using publicly available information. Publicly available information may be less likely to include details on planned or piloted use cases compared to submissions from governments, which largely informed the OECD and EU databases.

Overall, based on the OECD's work on Al in government since 2019, including directly with many governments, it seems the expected state of implementation should be higher relative to early-stage testing. The high presence of early-stage cases would be easily explained if government use cases had a heavy emphasis on leveraging the latest Al technologies, such as generative Al foundation models. However, OECD research for this report indicates this is largely not the case; governments still tend toward more longstanding approaches. These observations suggest further work in this area is warranted to gain additional understanding about governments planning-to-implementation and scale-up journeys, and to derive more specific lessons learned and factors for success.

As discussed in Chapter 2, it may be possible that some narrow but traditional applications of Al — which may be more likely to be implemented or even scaled up — may have become so integrated or commonplace that they no longer trigger external reporting or a response to data collection efforts. This could skew the numbers through underrepresentation of implemented initiatives that do not rely on newer Al systems and approaches.

## Lack of evidence on continuity calls for increased monitoring

Additional information is required to gain a better understanding of the status and evolution of government Al use cases. Future research should investigate this further by monitoring the progression of solution development over time, which could generate lessons from both successes and failures. The OECD sought

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 85

to explore the progress in relevant Al use cases discussed in previous products; however, there are generally few updated reports on the results of pilots or the status of implemented use cases, making it challenging to follow them in a longitudinal way. Most of the research done to determine whether a use case is operational relies on the ability to access a functional product (if public), or the presence of government press releases, news coverage, blog articles or public presentations. Another source is use cases shared through periodic public reports or official repositories, including those by the OECD. Current inventories or catalogues are often static; they depict projects as a snapshot in time, without providing insights into their development and evolution, and are often not updated. Primary data collection by researchers (i.e. directly surveying government organisations to further identify new efforts and obtain updates and lessons learned on known initiatives) would be useful for further research, though demands greater resources and time.

These challenges in accessing up-to-date information on individual use cases underscores the importance of governments' monitoring of Al use cases, along with a systematic and regular sharing of information, which would further reinforce the OECD AI Principles on transparency and accountability. This would not only be valuable for external audiences; documenting and disseminating successful (and unsuccessful) methods and use cases can help government organisations to replicate and scale Al projects more effectively. This approach helps avoid common errors, helps ensure consistency and accelerates the adoption of Al technologies across various government entities (OECD/UNESCO, 2024[11]). Inadequate or absent monitoring can also affect future use cases, as potentially effective Al innovations may be overlooked or, conversely, disproven approaches may be scaled up inappropriately. Further discussion and examples of how some governments are doing this can be found in Chapter 4, “Promoting transparency in how government uses Al”.

## Policy actions may be needed to encourage implementation and scaling

The fact that many Al initiatives are in the planning and pilot phases, or are unclear regarding their progression, suggests governments need to enhance their implementation capabilities to advance projects beyond initial testing stages, secure successful deployment and sustain long-term impact (EC, 2024[8]). This involves establishing foundational elements such as ensuring access to datasets, computing resources and the necessary expertise required to develop and scale Al projects. Such factors are discussed in-depth in Chapter 4. It also requires overcoming other implementation challenges, as discussed below.

# Common challenges shared across core government functions

## Skills gaps, the most common challenge

A recent survey in five countries from Salesforce (2024[12]) found a lack of internal skills for using Al to be the primary barrier to government Al adoption, with 60% of public sector respondents highlighting this challenge.1 Public sector respondents were a third more likely to indicate a skills gap in their organisation compared to the industry average. National-level reviews find comparable results, with 70% of UK government bodies reporting skills as a barrier to Al adoption (UK NAO, 2024[13]). In a National Trade Union Study of 2 000 Australian Public Service (APS) employees from August to October 2024, 92% said they had received no training on using Al, and only 16% said they felt equipped to use the technology.2 The Australian government has released and made available to all APS employees an Al in Government Fundamentals training module (in October 2024) and a series of MasterClass sessions on Al run by practitioners. The Australian Government has a number of capability building structures in place to enhance Al capability. The Al CoLab initiative provides a framework for cross-sector collaboration,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

86 |

codesign and regular events. Access to a government Al tool through a closed Beta Trial of GovAl commenced on 5 May 2025 with expanded access available to all APS employees on 31 August 2025.

Skills gaps are also a significant challenge when focusing specifically on sub-national governments (UN Habitat, 2024[14]). For instance, United States (US) surveys of state Chief Information Officers and local-level IT executives found that only 20% of state CIOs and 25% of local respondents were even slightly confident their technology workforce possessed the expertise necessary to respond to the advent of generative Al (NASCIO, 2024[15]; PTI, 2024[16]). Beyond the commonly discussed challenge of governments competing with the private sector for talent, in some instances, national and sub-national governments are in competition with one another for the same limited talent pool. Smaller cities can also suffer from "brain drain”, with young talent moving to larger cities that provide more career possibilities (de Mello and Ter-Minassian, 2020[17]).

Skills gap challenges can be seen across nearly all functions of government discussed in Chapter 5. Skills challenges limit governments' ability to take advantage of the latest developments in Al and can contribute to reluctance among public servants to accept the use of Al in general. In several functions, governments are struggling to determine exactly what kinds of skills are needed, and for whom.

Skills gaps can exacerbate other risks and challenges (Trajkovski, 2024[18]). For instance, they can lead to poor outcomes, the overestimation and misplaced trust in Al capabilities and systems, inadvertent misuse and general non-compliance with laws and other rules. Inconsistent levels of skill in governments can lead to pockets of innovation, but with little ability to scale beyond them.

In addition, a lack of skills internal in public administrations can result in an overreliance on outsourcing through public procurement (Mitchell, 2025[19]; Autio, Communigs and Elliott, 2023[20]). While procurement is an important and normal aspect of obtaining Al-related goods and services, relying too heavily on procurement relative to building internal capacities can result in a hollowing-out of government capacities (Trajkovski, 2024[18]). This can form a vicious cycle, where governments lack the right skills to design upskilling programmes, understand which skills to recruit for, and fully understand vendor offerings to procure the right goods and services at a fair price. Overall, without proactive skills development, "public agencies will find themselves merely reacting to technological shifts rather than steering these emerging technologies to serve societal interests effectively” (Trajkovski, 2024[18]). If government cannot demonstrate efficient and effective use of and self-control of Al, then it is unlikely that it will be able to regulate the technology. This also contributes to the challenge of high costs for Al adoption, as discussed below; hiring contractors can cost three to four times as much per person as government employees (UK DSIT, 2025[21]).

Several governments have instantiated upskilling and targeted recruitment programmes (see Chapter 4, "Fostering skills and talent"), with some even using Al as a tool to achieve these goals (see Chapter 5, "Al in civil service reform").

## Lack of high-quality data and the ability to share it

Through all levels of government and nearly every government function discussed in-depth in Chapter 5, data challenges are an impediment to developing and using Al in government. Recent work by RAND (2024[5]; 2025[22]) found that data issues were one of the main drivers in failed Al projects, including a lack of suitable data, and noted the importance of work often perceived to have low "activity prestige" (e.g. data cleaning).

For some functions, the needed data may simply not exist or were never digitised from paper (e.g. as seen often in justice administration), or the quality of data available is deficient (e.g. poorly structured, incomplete or mistyped records, discrepancies in data formats). This can arise from a variety of reasons, including poorly controlled data input processes, or even previous lack of foresight that such data could someday

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 87

be important. While time-consuming and burdensome, such quality issues can often be overcome, such as through digitisation, data cleaning and validation processes.

The repeated emphasis on a lack of sufficient, quality data may seem counterintuitive, as governments hold tremendous amounts of data and often make it available as open government data (OGD) to, among other things, help serve as inputs for training Al systems (OECD, 2023[23]). However, in many cases, it is the ability for government agencies to share data amongst themselves that is a challenge. This can be due to rules that prevent sharing or are unclear to public servants, months-long approval processes, or less commonly, governments signing away data reuse rights in contracts with companies. These issues are also reflected when sharing data between jurisdictions and levels of government, adding challenges for Al adoption in subnational governments. Some countries are grappling with how to comply with data protection and management rules, such as the EU General Data Protection Regulation (GDPR), though these data management issues generally existed long before such rules were put into force. In other cases, there is a lack of technical or policy protocols for sharing, or lack of interoperability across IT systems and data formats. In most cases, these issues are symptoms of a more systemic problem — inadequate data governance resulting in non-strategic, sporadic and fragmented data collection and management — and associated rules across government. Antiquated or burdensome rules around data sharing also contribute and may need to be reconsidered to account for technological advancements while still protecting privacy.

Overall, it is critical that governments establish sound data governance and management activities to succeed in adopting Al — although only 59% of OECD countries have a data strategy in place for the public sector, with even fewer providing actionable guidance for implementation (OECD, 2024[24]). Without strong data governance in place, governments risk developing and deploying Al systems that use poor quality data, resulting in outcomes ranging from simple inaccuracies to systemic bias and unfair outcomes for citizens. Without robust data governance across organisations and levels of government, governments' Al ambitions would largely need to be limited to the small experiments and pilots in limited settings that are the norm today, as discussed above.

Fostering the development of data-driven public sectors has long been a focus of the OECD (2019[25]; 2023[23]), and a number of governments are putting in place the data foundations needed for governments to reap Al's benefits (see Chapter 4, "Creating a strong data foundation").

## Lack of actionable frameworks and guidance on Al usage

National strategies for Al in government — either dedicated strategies or those embedded in broader instruments — are now common, and they are important in defining a vision for Al success. However, they generally provide only high-level details on commitments and aspirations, offering limited concrete guidance to facilitate the materialisation of Al's benefits while safeguarding against its risks. They also often fail to address key operational considerations that would make them effective. Investments and procurement, for instance, are often overlooked, despite being crucial for Al in government (van Noordt, Medaglia and Tangi, 2023[26]; Monteiro, Hlacs and Boéchat, 2024[27]). To bridge this gap, governments need actionable guidance that is aligned to strategies and provides their institutions with tangible direction and assurances. Guidance is also important for sub-national governments, such as cities. This can be important for both ensuring alignment with national approaches — as sub-national governments often follow or take inspiration from national efforts — as well as for helping sub-national governments meet their own digital and Al ambitions as well as the needs of their citizens and residents.

Such guidance can be either boundary spanning, addressing system-wide issues to promote trustworthy Al adoption, or targeted, focusing on specific government functions and applications. Cross-cutting guidance provides clarity and direction for fundamental elements such as data governance, talent development and investment. Vertical guidance, in contrast, helps public servants navigate Al's opportunities and risks via means effectively tailored to different policy domains. These approaches are not exclusive and can both be pursued complementarily.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

88 |

Overall, there is a lack of concrete cross-cutting and vertical guidance for Al in government. For instance, an inquiry by the Australian Parliamentary Joint Committee of Public Accounts and Audit (2025[28]) — which does not necessarily reflect the views of the Australian government — found that while some government entities are starting to adopt Al, they lack guidance in doing so. It recommended that a whole-of-government working group be established to consider what rules and governance frameworks necessary for Al systems across the public administration. However, there are notable exceptions, such as the "Al Playbook for the UK Government" (Chapter 4, Box 4.2) and France's structured approach to integrating Al in HRM (Box 5.19). Governments need to move beyond statements of intent to providing clear, practical guidance on Al adoption, investment, data governance, procurement and workforce development (Morley et al., 2019[29]).

This gap is cited as a challenge in many functions of government in Chapter 5. Overall, a lack of guidance can contribute to risk aversion, as guidance can clarify uncertainty and reduce doubts among civil servants. The need for guidance has been raised specifically in the functions of regulatory design, public procurement, fighting corruption and promoting public integrity, and tax administration to address legal and governance uncertainties that leave public servants uncertain if and how they can use Al in these functions. In some instances, guidance is needed to clearly interpret laws and regulations and their practical application. In others, they provide clarity in situations where formal rules may not yet exist. Given sectoral variations, cross-cutting Al approaches need to be complemented by specialised guidance accounting for unique policy challenges, risk profiles and data landscapes. Governments will also need to keep in mind that Al is a rapidly evolving field, and such guidance should be flexible and will likely need adaptation and iteration to keep up with the pace of change.

Further discussion on government actions to overcome this challenge can be found in Chapter 4, "Establishing key governance mechanisms and processes" and "Using policy levers to guide trustworthy Al".

## Driving innovation while mitigating risks

OECD work last year ([30]) found that when it comes to Al in government, governments tend to focus on the negatives (i.e. Al risks and how to mitigate them), but not so much on the positives (i.e. Al benefits and how to take advantage of them). This is not unique to governments' approaches to internal Al activities. With regard to the broader economy and society, Al experts have found that government policy discussions and initiatives often recognise that Al may yield significant benefits, but government actions often do not explicitly target achievement of benefits. Rather, they indirectly address them through positive spillover effects when seeking to mitigate risks (OECD, 2024[31]). These experts have urged governments to take more direct action to seize the opportunities presented by Al.

Much of this risk-oriented focus can be attributed to risk aversion, which has long hindered digital government and public sector innovation efforts, fostering a culture resistant to change in which failure should be avoided at all costs, including with regard to Al (OECD, 2021[32]; 2017[3]; 2019[33]; Desouza, 2018[34]; SAS, 2020[35]; Richter, 2024[36]). A survey from Deloitte (2024[7]) showed that 63% of public sector leaders believed GenAl would erode the overall level of trust in national and global institutions. This caution contributed to slower adoption of Al in government than in industry. Instances of risk aversion can be seen in several government functions in Chapter 5, especially in public procurement, fighting corruption and promoting public integrity. For instance, integrity institutions can be risk averse due to fear of making mistakes in the Al adoption process — with government guidance emphasising what not to do rather than the provision of actionable guidance on how to adopt Al in a trustworthy manner. Issues also arise as a result of over-correction in response to Al incidents, especially ones covered in media. Examples include instances when government chatbots provided misinformation or were hacked (Hodges, 2024[37]; Fagan, 2024[38]). Risk aversion is also a common topic of conversation when discussing Al in government in meetings of relevant OECD working parties and fora.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 89
Governments should pursue one of the generally accepted best practices to Al development in use, such as considering the level of potential risk or impact that an Al system might have and developing tailored and commensurate measures to overcome potential adverse issues. Yet governments often seem to treat most Al efforts as if they were of a high level of risk or impact, requiring exacting requirements across the board and imposing cumbersome bureaucratic requirements, daunting to public servants seeking to innovate. This can serve as sufficient disincentive to prevent the process of exploration and can be seen in a study from Deloitte (2023[39]), which analysed all policy initiatives in the OECD.AI Database of National Policies & Strategies. It found risk-weighted policies, which aim to shift from one-size-fits-all approaches to a data-driven and risk-based approach, were rare, representing 2% of initiatives in the database. The problem is also recognised in the April 2025 policy from the US on “Accelerating Federal Use of Al through Innovation, Governance, and Public Trust” ([40]), which charges government agencies to "remove unnecessary and bureaucratic requirements that inhibit innovation and responsible adoption".

Public servants can also develop “algorithmic aversion”. This is somewhat the opposite of "automation bias" discussed in Chapter 1, where "humans are reluctant to use algorithms despite their superior performance" (Cheng and Chouldechova, 2023[41]; Sunstein and Gaffe, 2024[42]), often after seeing mistakes in Al outputs. This suggests potential skills issues pertaining to the understanding of Al, its relative strengths and weaknesses and how to optimally use its outputs. It also suggests a lack of confidence in their abilities for human-machine collaboration as well as a lack of controlled environments for testing and safely experimenting with Al. These biases, which can distort perceptions of Al's reliability, can be mitigated through structured interventions, such as trainings on Al's strengths and limitations, as discussed further in Chapter 4 (Featherson, Shlonsky and Lewis, 2019[43]). Workers also need to feel they have a voice in inputs used for an Al system, and be able to use their professional judgement in how the outputs are used (Dietvorst, Simmons and Massey, 2018[44]; Cheng and Chouldechova, 2023[41]).

There is some evidence that risk aversion for Al in government may be receding as governments become more familiar with the technology. A recent study by Google Public Sector found that Al concerns among public IT leaders in the US over issues such as privacy and security are receding (Teale, 2025[45]). However, governments will need to be more active to overcome this risk-oriented focus to better consider trade-offs that better target opportunities. A variety of Al enablers and safeguards discussed in Chapter 4 can help divert from a culture of risk aversion and towards more controlled adoption and informed risk management.

# Demonstrating results and return on investment
Governments have made significant strides in implementing Al solutions across various public domains, demonstrating tangible benefits in efficiency, accuracy and service delivery. However, monitoring of progress and thorough retrospective evaluation of impact remain underdeveloped aspects of government Al implementation. While isolated cases of success are well-documented, as seen below, comprehensive efforts to assess Al's contribution to public value creation are often lacking. This can be seen in the case of the UK, where "only 8% of Al projects show measurable benefits and only 16% show forecast costs, making it difficult to assess these against a cost-benefits analysis” (UK DSIT, 2025[21]). Specific to generative Al, a survey from Deloitte (2024[7]) in 14 countries shows that, despite anticipating increasing Al investments, 78% of government leaders surveyed report struggling to measure impacts from GenAl— significantly higher than those in other sectors, which poses a barrier to Al adoption and scaling even when other challenges, such as talent gaps, are resolved.

A handful of Al solutions have demonstrated concrete, measurable results that illustrate the technology's potential to transform government delivery. These quantifiable results provide valuable benchmarks for understanding Al's direct impact on operational efficiency and service quality:

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
90 |
* Peru's Amauta Pro Al system has transformed the speed at which courts can respond to victims of domestic violence. This Al-powered system has reduced the time needed to draft resolutions for protection measures from a lengthy 3 hours to 40 seconds. (see Box 5.63).
* In the EU, DATACROS Project developed a tool to detect anomalies in corporate ownership structures that may indicate risks of corruption, money laundering and other financial crimes. In 2021, the predictive tool correctly identified 83% of companies targeted by sanctions and 88% of companies with sanctioned owners (see Box 5.27).
* The US Federal Emergency Management Agency (FEMA) developed an Al system to assess structural damage across areas affected by Hurricane lan, which reduced the number of structures requiring human review from over 1 million to just 77 000. Within 72 hours of the hurricane's landfall in 2022, FEMA had insights into the extent of damage across affected regions, enabling faster resource allocation and recovery planning. (see Box 5.58).

Particularly notable are cases where Al systems have been explicitly compared against human performance, highlighting significant improvements in speed, scale and resource utilisation that exceed human capability. In Singapore, government agencies transformed hiring with Al tools available on the market, enabling one agency to process over 3 000 applications for its Management Associate Program efficiently, saving EUR 44 000 (equivalent) and over 150 days of staff productivity.4 Comparisons with human performance are important because they focus on the key counterfactual that is needed for evidence-based decision-making. Further, they push for a deeper understanding of human performance, making it possible to unveil implicit assumptions and biases that affect human delivery.

Beyond individual use cases, some governments have begun documenting Al's impact at organisational and national levels, revealing substantial financial benefits and operational improvements. These broader assessments help establish the cumulative value of Al investments across government functions. The Australian Taxation Office, for instance, reported that their Al approach combining real-time analytics, pre-filled forms, and anomaly detection systems helped protect approximately AUD 78.9 million in revenue across over 636 000 interactions with users in 2023-2024 (Box 5.5). Similarly, substantial results were observed in Austria with the activity of the Federal Ministry of Finance's Predictive Analytics Competence Centre (PACC), which made it possible to analyse 6.5 million cases across income, corporate and value-added tax sectors as well as customs transactions in 2023 (Box 5.3). These analyses detected instances of false reporting in employee tax assessments and identified fraudulent activities, resulting in additional tax revenues of approximately EUR 185 million. Looking to the future, a recent study by The Alan Turing Institute (2024[46]) on UK public services found Al could help automate 84% of the central government's service-related transactions, saving an equivalent of approximately 1 200 person-years of work every year.

Despite these successes, such considerations are rare, and governments face significant challenges in systematically monitoring Al's progress and impact. One key barrier is the lack of well-defined measurement and evaluation frameworks that can assess Al's contributions in a standardised manner. Many Al applications are integrated into complex administrative processes, making it difficult to isolate and measure their specific effects. Additionally, the challenge of benchmarking Al against human performance is compounded by the fact that many Al-enabled tasks would be infeasible or prohibitively time-consuming absent automation. There is also a limited understanding of the long-term impact of use of LLM's on human cognition, and whether their consistent use impacts the creativity, critical thinking skills and productivity of those that use them.

A final consideration is that different contexts may call for different methodologies. For instance, a theme of discussion at the latest OECD (2024[4]) Roundtable on Smart Cities was that cities need to explore different methodologies for measuring and evaluating success that align with their own objectives to allow them to set measurable goals. Some initial governments efforts to address these problems are emerging, such as the UK government publication on best practice for evaluating the impact of Al evaluation methods (Frontier economics, 2024[47]). The US (2025[48]) has also recently issued Al acquisitions policy that

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 91
recognises government agencies need to be "safeguarding taxpayer dollars by tracking Al performance and managing risks". Without robust monitoring mechanisms, governments risk wrongly estimating Al's value, potential risks and missing opportunities for improvement.

Establishing effective impact measurement frameworks is crucial for ensuring Al investments deliver real value to public administrations and citizens. As governments allocate increasing resources to Al development and deployment, demonstrating a clear return on investment (ROI) will become imperative. Reliable retrospective impact assessment mechanisms can help policymakers make informed decisions about scaling Al solutions, optimising resource allocation and justifying further funding. Furthermore, impact assessment provides essential feedback for refining Al systems and approaches, enabling continuous improvement cycles. Documented outputs also facilitate knowledge sharing across government entities, helping to scale successful approaches and avoid repeating unsuccessful ones. Perhaps most importantly, transparent reporting on Al's impacts — both positive and negative — is essential for maintaining public trust and accountability as these technologies become more deeply embedded in core government functions and activities. Different evaluation methods are appropriate for each context, but governments should try and compare the implementation of Al to the situation of its absence. The OECD has produced guidance on choosing an evaluation approach based on a variety of key considerations (Varazzani et al., 2023[49]).

# Challenges that are somewhat less common or vary among government functions
## Inflexible or outdated legal and regulatory environments
Inflexible, outdated or otherwise inadequate (e.g. excessive, lacking) regulatory environments pose many challenges. Many functions face regulatory or legal restrictions in data access and sharing, as discussed above. Beyond this, there can be confusion about Al accuracy and whether inadvertent errors introduced through the use of Al could lead to non-compliance with regulations and other rules, such as in fiscal reporting. Complexity in regulations is also a factor. For instance, tax administration officials face highly complex laws around tax processes, contributing to them largely relying on classic rules-based approaches. These challenges are as common at the local level as they are in national governments (OECD, 2024[4]).

Sometimes, issues with existing regulation is not the challenge, but gaps in regulation that lead to confusion over what is acceptable with Al. This confusion can contribute to other challenges, such as risk aversion or the preference for the maintenance of one's existing state of affairs (Samuleson and Zeckhauser, 1988[50]). For instance, because it is not specifically addressed in many countries, public procurement officials are often unclear on whether Al can be used in procurement processes, fearing that doing so could expose them to challenges from unsuccessful bidders or others who question the fairness of the process. This provides a general lack of incentive for change. Confusion also exists around whether using advanced Al systems, which are often highly capable but function in an opaque manner, can meet regulatory standards, such as International Standards on Auditing or evidentiary rules in the criminal justice system. In contrast, people may continue to operate without Al to forego these risks and also the benefits of Al use.

Regulatory environments pose a unique challenge regarding regulatory design and delivery. Beyond rules that restrict Al use, regulators should also be cautious and avoid making frequent changes to regulations, and to how they are implemented and enforced. Regulated entities need a level of clarity and predictability so they comply with regulations in a manner that causes minimal disruption with business operations. Frequent regulatory shifts, even if based on quality Al-informed insights, can lead to a volatile regulatory environment, making it difficult for businesses to plan long-term strategies and for the public to stay informed about current laws.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
92 |
Governments can overcome these challenges by ensuring regulations and other formal rules are up to date, agile and minimise ambiguity. There is some evidence that governments are moving in this direction, with Deloitte (2023[39]) finding adaptive regulation — shifting from a "regulate and forget" mode to a responsive and interactive approach — to be one of the most common type of policies tracked by the OECD.Al Policy Observatory. Further guidance that helps contextualise regulations in particular functions of government is also important. Discussion on how governments are doing this can be found in Chapter 4, "Establishing key governance mechanisms and processes" and "Using policy levers to guide trustworthy Al".

# High or uncertain costs of Al adoption and scaling
While Al adoption has the potential to reduce costs through enhanced productivity and efficiency, many government organisations struggle to make the initial financial investments to begin their Al adoption journeys, or to scale up use cases that prove successful. These costs can sometimes range from paying licensing fees per employee for service-based Al offerings, such as ChatGPT or Microsoft Copilot, to extensive development, customisation and support costs for more tailored or in-house solutions (Shark, 2025[51]; Barrett and Greene, 2024[52]). In the UK, a survey of government officials by SAS (2025[53]) found cost and budget restrictions to be the main challenge (raised by 67% of respondents), closely followed by a lack of internal skills (63%). Despite the critical nature of funding for Al, the OECD (2024[24]) Digital Government Index (DGI) highlights that only 15% of OECD countries have an investment framework in place for public Al investments.

Chapter 5 cites financial challenges in adopting Al for several functions of government, including in regulatory design and delivery, public services, tax administration, fighting corruption and promoting public integrity, and civic participation. In some instances, financial challenges also relate to the costs of recruiting or procuring skilled talent, with skills gaps discussed as a separate challenge above. Functions like tax administration have also indicated the process for securing budgets in government is a challenge.

This challenge can contribute to the OECD finding that governments often seem stuck in exploratory and pilot phases, with limited scaling of successful solutions. For instance, tax authorities have told the OECD that conducting small pilots is inexpensive and easy, even with advanced systems obtained from the private sector. However, such costs can grow exponentially as Al offerings are implemented more broadly within organisations or scaled up across other parts of government. Costs are particularly high for purpose-built solutions, with a group of 10 countries focusing on Al in the Public Interest stating that "the barrier to scaling Al models has been assumed to be primarily the lack of availability and affordability of compute" (France Élysée, 2025[54]).

Governments need to recognise that underinvestment in technology increases long-term costs and total costs of ownership (UK DSIT, 2025[21]). Some governments are seeking to address these issues through targeted investments, as well as the provisioning of central services that help to ease the need for each agency to build or buy their own solutions. These can be seen in Chapter 4 under “Investing purposefully", "Building out digital infrastructure" and "Creating spaces to experiment". Some are also using open-source models or exploring smaller models that can be designed to respond to specific societal and community needs, requiring less computational power and data (France Élysée, 2025[54]).

Although the costs governments and Chapter 5 highlight tend to focus on are financial, it is useful for governments to keep in mind that not only monetary costs impact Al adoption and scaling. Psychological costs related to Al use can also impact the extent to which individuals use Al tools in their day-to-day work, even if the investments are made to make them available. These costs can include search costs — which occur when people are searching for information but encounter outdated information, unclear language or confusing requirements — or cognitive costs, the mental resources people expend understanding complex information (Shahab and Lades, 2021[55]). "Sludge audits” are structured behavioural assessments of a decision-making process which aim to identify, prevent and reduce unnecessary frictions and

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 93
psychological costs, which prevent people from taking actions they would otherwise take (OECD, 2024[56]). By conducting sludge audits on the use of Al tools, governments can understand and address the barriers to acceptance that may limit Al adoption and scaling.

Governments can lack clarity on how much Al development and use can or should cost

The challenges discussed above are most relevant when such costs are known. Governments have reported to the OECD that there is often uncertainty or confusion about how much the development or use of different types of Al systems could or should cost. This makes it difficult for public institutions to plan effectively and evaluate vendor offerings when considering public procurement to source solutions. Gaining clarity on these costs can help ensure governments are prepared to adopt Al systems in a strategic and sustainable way. Yet, the OECD could identify no research discussing cost for the development or use of different types of Al systems in government. This suggests an optimal area for further research and analysis. Still, understanding costs in a broader sense or from specific government Al projects can help governments arrive at estimates for planning purposes. This section aims to take the first steps in helping governments do this, with the potential for more in-depth OECD work on this topic in the future.

The cost of adopting Al can vary significantly depending on the type of system and its scale of use. For instance, governments can pursue a variety of options in adopting Al, such as those touched on below.

## Licensing private sector tools with fixed pricing per user or license
Companies offering Al tools often charge per user. This is the case for services such as Microsoft 365 Copilot, OpenAl's ChatGPT or Anthropic's Claude. Licenses for these services can be purchased at the enterprise level, with prices ranging between USD 30-100 per user per month. The enterprise version Microsoft 365 Copilot costs USD 30 per month, for example.5 Thus, a government running a pilot project comparable to Australia's six-month pilot of 7 600 staff across 60 agencies (2024[57]) could estimate costs to be around USD 1.37 million for licenses alone; that does not include additions such as staff time for pilot administration and reporting results, as well as other overhead. For Australia's pilot, the Australian Treasury (2025[58]) estimated the license fee could pay for itself for a mid-level government staffer if it mitigated 13 minutes of their time per week for higher-value tasks. ChatGPT Enterprise costs are not published on OpenAl's website, although when asked, ChatGPT suggested a cost of USD 60-100 per user per month, varying based on volume and features. Anthropic's Claude Enterprise Plan pricing also depends on business needs and characteristics. While the prices are not available on Anthropic's website, third-party websites estimate a cost of USD 60 per person per month.6

## Using private sector generative Al systems with volume-based pricing, such as tokens
GenAl systems are often offered through volume-based pricing, where the volume is calculated through API traffic. Whereas provision through licenses is more relevant when public servants use the Al tools directly (e.g. using Copilot to help draft documents), volume-based pricing is more relevant when governments build internal or public-facing services that interface with a proprietary model, or when they want to customise (i.e. fine-tune) the content the model considers or how it produces outputs. The main functions of the price include:
* Input tokens: tokens included in a prompt, such as instructions, context or data sent to the model.
* Output tokens: tokens generated by the model in response to an input.
* Training tokens: data (e.g. chunks of text) that an Al model learns from during training.

Models see data as tokens, not sentences or paragraphs. The cost of tokens depends on the company and may be based on the level of complexity and resources needed for an individual model. For instance, the costs for some commonly use models are in Table 3.1.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

94 |

# Table 3.1. Costs for 1 million tokens on common Generative Al models (USD)

One million tokens represent approximately 750 000 words, 100 000 lines of code, 11 hours of transcribed audio speech, or 1 hour of transcribed video

| Model | Input tokens | Output | Training (if applicable) |
| :--- | :--- | :--- | :--- |
| **OpenAI GPT-40** | USD 2.50 | USD 10 | |
| **OpenAI GPT-40 (if fine-tuning to customise)** | USD 3.75 | USD 15 | USD 25 |
| **OpenAI GPT-3.5-turbo** | USD 0.50 | USD 1.50 | USD 8 |
| **Google Gemini 2.5 Pro** | USD 1.25 | USD 10 | |
| **Google Gemini 2.0 Flash** | USD 0.10 | USD 0.40 | |
| **Mistal Large 24.11** | USD 2 | USD 6 | USD 9 |
| **Mistral NeMo** | USD 0.15 | USD 0.15 | USD 1 |

Note: As of 10 April 2025. The inference costs for using a particular model or its equivalent tends to decrease over time (Stanford HAI, 2025[59]).
Source: https://openai.com/api/pricing, https://ai.google.dev/gemini-api/docs/pricing, https://mistral.ai/products/la-plateforme, https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them, https://prompt.16x.engineer/blog/code-to-tokens-conversion, https://prompt.16x.engineer/blog/code-to-tokens-conversion, https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024.

Further, some companies are offering foundation models through specific tiers dedicated to government agencies. These services seek to meet governments' stringent security standards. Further, they aim to be tailored to the needs of governments, providing solutions that make it easier to manage their own security, privacy and compliance requirements, as well as enable them to use the services for activities that may fall outside the standard usage policies.

The experiences of one central government Al lab in pursuing this approach is discussed in Box 3.1. Proprietary models can also be used in concert with open-source models, as touched on below.

---

# Box 3.1. Government Al lab's experience using proprietary Al

## Operations and expenses

A central government Al lab in one county follows a phased approach to exploring, piloting and scaling Al projects for use in the public sector by civil servants. Overall, there may be as many as 100 projects being considered, around 15 undergoing limited testing, and around five to seven accessible to real users for a pilot or full deployment.

The lab uses cloud hosting and Al from Azure OpenAl, Vertex Al (Google), and Amazon Web Services (AWS). It has a budget of around EUR 17.5 million. All work is conducted in-house. Most of its expenses are staff costs, including roughly:

*   15 full-time equivalent staff (FTE) for technical talent (seven for development and Al engineering, four for design and user research, four for cloud/infrastructure).
*   Six FTEs for delivery management, which is critical for ensuring technical talent can focus on technical challenges, while delivery managers focus on addressing challenges regarding policy and bureaucracy.
*   Six FTEs for impact analysts who use data science to study project results and impact.

Its largest deployed project has around 4 000 users, with around eight FTEs working on it. Other projects are smaller, with some having one or two FTEs. Overall, the lab's products have around 10 000 monthly users. The total costs for Al cloud services, including tokens, are around EUR 3 500 per month.

---
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

| 95

## Lessons learned
*   The first few projects are by far the most expensive and time consuming, with significant investments in setting up cloud infrastructure and deployment templates that can be easily re-used for future projects. Deployments that took three weeks each for the first few projects now take 30 minutes.
*   Having robust cloud infrastructure in place is important, optimally shared among projects to promote synergies.
*   The lab considered the pros and cons of using proprietary Al models versus custom deployments of open-source models (e.g. Meta's Llama). It determined volume-priced proprietary models to be more effective because civil servants tend to use the Al systems from 9:00-18:00. For a custom deployment, they would need to pay for GPU usage all day, even when the models are not being used. Overall, token-based pricing was less expensive for their needs. In addition, this approach allows the lab to spin-up new model instances more quickly and easily. For instance, it can deploy a new GPT-4.1 model in around five minutes, whereas custom deploying an open-source model could take weeks of infrastructure work.
    *   Overall, the lab estimated it would have cost EUR 9 300 per month to self-host host a Llama model, where they current spend around EUR 3 500 for tokens.
*   As usage of the lab's Al tools has grown, the lab is reaching the limits of what cloud providers are willing to provide in terms of pay-as-you-go pricing. As their usage continues to increase, they face the choice of either 1) purchasing GPU capacity from the cloud providers, or 2) self-hosting open-source models and paying for GPU access directly (as mentioned in the previous bullet). For the lab, option 1 may be optimal because it still allows for rapid deployment.
*   The cost of developing Al, in terms of both technical resources (e.g. cloud services, tokens) and human resources is decreasing rapidly. The lab is finding that they can increasingly use Al to build Al, potentially changing labour demands. The implications for this have yet to be determined.

Source: OECD interview with officials from an undisclosed country on 18 April 2025. The OECD is not publishing the name of the country or lab because of the preliminary nature of the estimates and analysis.

---

# Developing narrow, purpose-built custom ML applications (either in-house or procured)

Narrow Al systems tailored for specific public-sector tasks can range from relatively small expenses to multi-million-dollar projects. These systems involve ML approaches developed for a specific use case, such as fraud detection, traffic optimisation or document classification. Simple pilots might be built for a few thousand dollars, whereas complex national systems can cost millions or tens of millions (USD), especially if scoping in defence applications (Barnett, 2020[60]). As one example, the South Australian government is piloting four Al-enabled cameras aimed at cutting traffic congestion by analysing congestion and adjusting traffic light cycles at a cost of USD 218 000 (equivalent) (Jackson, 2025[61]).

However, costs vary widely depending on complexity and context, and additional costs may be needed for data preparation, infrastructure and ongoing monitoring and maintenance. Because approaches and associated costs vary significant depending on the use case, it is difficult to provide estimates beyond these examples. Further analysis may be warranted to consider different aspects of such use cases and what different governments around the word have paid for them.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

96|

# Developing systems using pre-trained open-source models

Compared to the custom development and training of a GenAl model, discussed below, pre-trained open-source Al models (such as Meta's Llama models) can offer reduced costs with government still able to highly customise the model to meet their needs. Open-source models can be self-hosted either on the cloud or on-premises, offering governments greater control over their data and long-term cost efficiency. While leveraging a pre-trained open-source model can reduce training costs to those incurred for fine-tuning, still other remaining costs can be significant. For instance, self-hosting eliminates recurrent fees for tokens or licenses, but it requires significant upfront investment in hardware and infrastructure, cloud resources, energy consumption, and maintenance and support costs.

Despite the higher initial investment compared to licence or volume-based pricing, some governments have found that self-hosting can be cost-effective at scale and unlock use cases not feasible to them through commercial APIs (e.g. sensitive intelligence tasks, always-on local services, or offline operations in critical infrastructure). For instance, Chinese Taipei invested USD 7.4 million to develop its own foundation model called Trustworthy Al Dialogue Engine (TAIDE), which uses Meta's Llama open-source models (Creery, 2024[62]).9

Government use of the open-source platform Polis (Box 5.36) represents a narrower use of open-source Al than the TAIDE efforts to develop a foundation model. One government organisation that built a customised and self-deployed version of Polis for a large-scale public engagement campaign, consisting of 33 regional and national Polis discussions with 30 000 participations, incurred overall costs of around EUR 422 500 over a 14-month period.10 These expenses consisted of EUR 195 000 for expert web development, cloud services and an outsourced user experience (UX) co-design sprint, and EUR 227 500 in staff time to implement Polis into the organisation's existing workflows and to coordinate and conduct civic engagement activities. The same organisation has since invested EUR 200 000 in further enhancing their Polis application, split 50/50 between technical and staff costs. This enhancement work included user interface (UI) design and implementation and other technical development work, which have been open sourced for other Polis users. Overall, the organisation estimates that two full-time equivalent staff (FTE) is sufficient to manage the work, with a mix of expertise needed (such as technical development, project management, UX design and digital participation).

Open-source models can also be used in conjunction with proprietary models. For instance, one of the virtual assistants discussed in Chapter 5 uses both Google's Gemini 1.5 Flash and a Llama model from Meta, with the chat interface and orchestration of the two models developed in-house using open-source technologies.11 The system is being piloted with 18 000 users, with the main costs being associated with the use of the Gemini LLM and cloud web hosting for the chat application. While the LLM platform costs the government around EUR 18 000 per month, they expect a substantial reduction as they understand how to use the model most efficiently. The web hosting costs around EUR 2 300 per month. Overall, they estimate their costs at EUR 0.93-1.55 per user per month. Officials are in early discussions to scale the pilot up in other departments. The development and coordination team consists of approximately 10 FTEs.

## Developing custom GenAl models built and trained from scratch

Developing custom built and trained GenAl models is generally the most expensive option (for comparable performance) due to high initial investment and operational complexity. Costs of training an LLM depend on model size (larger models with more parameters require more computational power and consume more energy), the quality and quantity of the training data (influencing the cost of data acquisition and curation), choices of infrastructure (whether training occurs on premises or cloud based), and the efficiency of training algorithms used.

Al companies often do not publicly disclose the training costs associated with their models, although researchers estimate that current popular models cost around USD 41-192 million (Stanford HAI, 2025[59]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

| 97

With the cost of training state-of-the-art models increasing two- to threefold each year, some research estimates that training the largest models may cost over EUR 1 billion by 2027 (Cottier et al., 2024[63]). While these costs can seem high, they can pale in comparison to the significant research and development investments, staff costs and data gathering efforts needed to achieve the latest foundation models (Stanford HAI, 2025[59]). Leading Al companies also have other prerequisites for developing such models, such as deep technical talent, and often, strategic partnerships with other companies.

Yet governments do not necessarily need to embark on building such extensive and powerful systems that seek to beat market competitors. Training from scratch of government-funded LLMs, for instance, can require fewer staff and cost resources, especially for those with fewer parameters or seeking to maximise relevance for a specific country, region or language. For instance, OpenEuroLLM has a total budget of EUR 37.4 million, implying a fraction of this sum will be dedicated to training its foundation model with another fraction for staff (EC, 2025[64]).12 In another example, one European country custom developed and trained an LLM in the national language, with the total cost, including personnel, coming in around EUR 500 000, of which EUR 300 000 was dedicated to GPU usage.13 Another example is GPT-NL in the Netherlands, which is investing around EUR 13.5 million provided by the Netherlands Ministry of Economic Affairs and Climate (EZK) to train a model (2023[65]). Other efforts have been undertaken in in Japan, Singapore, Spain, Sweden and the United Arab Emirates (Chavez, 2024[66]). The collaboratively developed BigScience Large Open-science Open-access Multilingual Language Model (BLOOM)14 involved significant contributions from government agencies. The project was primarily led by Hugging Face and the French National Centre for Scientific Research (CNRS), supported by a public compute grant on the French public supercomputer “Jean Zay”. The estimated cost of training is USD 2-5 million.

# Outdated legacy information technology systems

Many governments' Al ambitions are slow to materialise because of outdated legacy IT systems not suitable for Al development or use, or inadequate to manage and exchange large amounts of quality, interoperable data (Irani et al., 2023[67]). Such systems can result in significant missed opportunities. For example, in the UK alone, "taxpayer funded services from the NHS to local councils are missing out on GBP 45 billion in productivity savings — more than enough to pay for every primary school in the UK for a full year — because they are too often dependent on old and outdated technology” (UK DSIT, 2025[68]). The government (2025[21]) estimates 28% of central government IT systems are outdated, reaching 70% in some organisations, and 57% of UK government officials surveyed by software company SAS (2025[53]) cited legacy systems as a barrier to Al adoption. The issue has also been raised by the UK PAC (2025[6]) as an impediment to the use of Al in government.

Chapter 5 discusses how outdated legacy technology impacts Al adoption. For instance, the potential for Al in public financial management is limited by outdated financial management information systems in governments around the world, with such systems exceeding a decade old in most OECD countries (Rivero del Paso et al., 2023[69]; OECD, 2024[70]). Despite the significance of the challenge, considerations and analysis for legacy technology's adverse effects in Al adoption appear light in most countries and government functions. While the previous paragraph includes significant detail about the scale of the challenge in the UK to illustrate the point, this is largely because most other governments have not conducted the analysis necessary to articulate the problem in such a manner.

This challenge is dependent on others, including the significant costs of funding the remediation of legacy systems. Outdated legacy technology also contributes to other challenges, such as data issues and an "overreliance on contractors sending costs rocketing", including to maintain outdated systems, with "maintenance of legacy systems costing often three to four times that of modern alternatives” (UK DSIT, 2025[68]). These expenses could be better placed in innovation and modernisation efforts.

Governments are taking a variety of measures to modernise their systems to be more Al-ready. In a novel instance, the US Department of Defence is using Al to modernise legacy code (Harper, 2024[71]). More

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

98 |

traditionally, some governments are providing targeted funding for modernisation efforts (see Chapter 4, "Funding Al and supporting coherent investments across government").

To overcome the implementation challenges outlined in this chapter, as well as mitigate the risks outlined in Chapter 1, governments can turn to policy. Indeed, some governments are already doing so. The following chapter looks at policy measures governments can take — and actions some are already taking — to deliver Al that is trustworthy and to benefit from Al's full potential.

# References

Austin, T. et al. (2024), A snapshot of how public sector leaders feel about generative Al, https://www2.deloitte.com/us/en/insights/industry/public-sector/ai-adoption-in-public-sector.html. [7]

Australia DTA (2024), Evaluation of whole-of-government trial into generative Al: Now available, https://www.dta.gov.au/blogs/evaluation-whole-government-trial-generative-ai-now-available. [57]

Australia Treasury (2025), Evaluation of a trial of generative Al (Copilot) in The Treasury, https://evaluation.treasury.gov.au/publications/evaluation-generative-artificial-intelligence. [58]

Autio, C., K. Communigs and B. Elliott (2023), A Snapshot of Artificial Intelligence Procurement Challenges, https://files.thegovlab.org/a-snapshot-of-ai-procurement-challenges-june2023.pdf. [20]

Barnett, J. (2020), JAIC awards biggest contract yet to buy Al for the battlefield, https://fedscoop.com/battlefield-ai-jaic-booz-allen. [60]

Barrett, K. and R. Greene (2024), The Future of Al For the Public Sector: The Challenges and Solutions, https://www.businessofgovernment.org/blog/future-ai-public-sector-challenges-and-solutions. [52]

Brizuela, A. et al. (2025), Analysis of the generative Al landscape in the European public sector, European Commission, https://op.europa.eu/s/z4XY. [2]

Chavez, P. (2024), Sovereign Al in a Hybrid World: National Strategies and Policy Responses, https://www.lawfaremedia.org/article/sovereign-ai-in-a-hybrid-world--national-strategies-and-policy-responses. [66]

Cheng, L. and A. Chouldechova (2023), “Overcoming Algorithm Aversion: A Comparison between Process and Outcome Control", Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1-27, https://doi.org/10.1145/3544548.3581253. [41]

Cottier, B. et al. (2024), The rising costs of training frontier Al models, https://arxiv.org/abs/2405.21015. [63]

Creery, J. (2024), Taiwan Builds Own Al Language Model to Counter China's Influence, https://www.bloomberg.com/news/articles/2024-01-25/taiwan-builds-own-ai-language-model-to-counter-china-s-influence?. [62]

de Mello, L. and T. Ter-Minassian (2020), “Digitalisation challenges and opportunities for subnational governments", OECD Working Papers on Fiscal Federalism, No. 31, OECD Publishing, Paris, https://doi.org/10.1787/9582594a-en. [17]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 99
Desouza, K. (2018), Delivering Artificial Intelligence in Government: Challenges and
[34]
opportunities,
https://www.businessofgovernment.org/sites/default/files/Delivering%20Artificial%20Intelligen
ce%20in%20Government.pdf.
Dietvorst, B., J. Simmons and C. Massey (2018), “Overcoming Algorithm Aversion: People Will
Use Imperfect Algorithms If They Can (Even Slightly) Modify Them", Management Science,
Vol. 64/3, pp. 1155-1170, https://doi.org/10.1287/mnsc.2016.2643.
[44]
EC (2025), A pioneering Al project awarded for opening Large Language Models to European
languages, https://digital-strategy.ec.europa.eu/en/news/pioneering-ai-project-awarded-
[64]
opening-large-language-models-european-languages.
EC (2024), Adoption of Al, blockchain and other emerging technologies within the European
public sector – A public sector Tech Watch report, Publications Office of the European Union,
https://data.europa.eu/doi/10.2799/3438251.
[8]
EC (2024), Public Sector Tech Watch latest dataset of selected cases,
http://data.europa.eu/89h/e8e7bddd-8510-4936-9fa6-7e1b399cbd92 (accessed on
4 March 2025).
[9]
Fagan, M. (2024), Al for the People: Use Cases for Government,
https://www.hks.harvard.edu/sites/default/files/centers/mrcbg/working.papers/M-
RCBG%20Working%20Paper%202024-02_Al%20for%20the%20People.pdf.
[38]
Featherson, R., A. Shlonsky and C. Lewis (2019), “Intervetions to Mitigate Bias in Social Work
Decision-Making: A Sytematic Review”, Research on Social Work Practice, Vol. 29/7,
https://doi.org/10.1177/1049731518819160.
[43]
France Élysée (2025), The Paris Charter on Artificial Intelligence in the Public Interest,
https://www.elysee.fr/en/emmanuel-macron/2025/02/11/the-paris-charter-on-artificial-
intelligence-in-the-public-interest.
[54]
Frontier economics (2024), Guidance on the impact of Al interventions, https://www.frontier-
economics.com/uk/en/news-and-insights/news/news-article-i21121-analysing-the-impact-of-
ai-interventions-in-government.
[47]
Government of the Netherlands (2023), The Netherlands is building its own open language
model GPT-NL, https://www.digitaleoverheid.nl/nieuws/nederland-bouwt-eigen-open-
taalmodel-gpt-nl/.
[65]
Harper, J. (2024), Pentagon using Al to modernize legacy code,
https://defensescoop.com/2024/09/12/pentagon-artificial-intelligence-modernize-legacy-code-
john-hale/.
[71]
Hodges, D. (2024), Fumbles can't kill the government's Al appetite,
https://www.themandarin.com.au/249756-red-faces-and-fumbles-cant-kill-governments-ai-
appetite/.
[37]
Irani, Z. et al. (2023), “The impact of legacy systems on digital transformation in European public
administration: Lesson learned from a multi case analysis", Government Information
Quarterly, Vol. 40/1, p. 101784, https://doi.org/10.1016/j.giq.2022.101784.
[67]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
100 |
Jackson, B. (2025), South Australian drivers to be monitored by Al cameras,
https://www.news.com.au/technology/south-australian-drivers-to-be-monitored-by-ai-
cameras/news-story/8a63be3e80d4bba60735d58ec8c473db?utm_source=chatgpt.com.
[61]
Mariani, J., W. Eggers and P. Kishnani (2023), The Al regulations that aren't being talked about,
https://www2.deloitte.com/us/en/insights/industry/public-sector/ai-regulations-around-the-
world.html.
[39]
Mitchell, S. (2025), Skills gap in public sector IT fuels outsourcing reliance,
https://itbrief.co.uk/story/skills-gap-in-public-sector-it-fuels-outsourcing-reliance.
[19]
Monteiro, B., A. Hlacs and P. Boéchat (2024), "Public procurement for public sector
innovation: Facilitating innovators' access to innovation procurement", OECD Working Papers
on Public Governance, No. 80, OECD Publishing, Paris, https://doi.org/10.1787/9aad76b7-en.
[27]
Morley, J. et al. (2019), “From What to How: An Initial Review of Publicly Available Al Ethics
Tools, Methods and Research to Translate Principles into Practices", Science and
Engineering Ethics, Vol. 26/4, pp. 2141-2168, https://doi.org/10.1007/s11948-019-00165-5.
[29]
Muñoz-Cadena, S. et al. (2025), Sistemas de IA en el sector público de América Latina y el
Caribe (Versión V2), https://sistemaspublicos.tech/sistemas-de-ia-en-america-latina/
(accessed on 29 April 2025).
[10]
NASCIO (2024), Generative Artificial Intelligence and its Impact on State Government IT
Workforces, National Association of State Chief Information Officers,
[15]
https://www.nascio.org/resource-center/resources/generative-artificial-intelligence-and-its-
impact-on-state-government-it-workforces/.
OECD (2024), “2023 OECD Digital Government Index: Results and key findings", OECD Public
Governance Policy Papers, No. 44, OECD Publishing, Paris,
https://doi.org/10.1787/1a89ed5e-en.
[24]
OECD (2024), "Assessing potential future artificial intelligence risks, benefits and policy
imperatives", OECD Artificial Intelligence Papers, No. 27, OECD Publishing, Paris,
https://doi.org/10.1787/3f4e3dfb-en.
[31]
OECD (2024), “Financial Management Information Systems in OECD countries”, OECD Papers
on Budgeting, No. 2024/02, OECD Publishing, Paris, https://doi.org/10.1787/ce8367cd-en.
[70]
OECD (2024), Fixing Frictions: 'Sludge audits' around the world, OECD Publihing,
https://doi.org/10.1787/14e1c5e8-en-fr.
[56]
OECD (2024), “Governing with Artificial Intelligence: Are governments ready?”, OECD Artificial
Intelligence Papers, No. 20, OECD Publishing, Paris, https://doi.org/10.1787/26324bc2-en.
[30]
OECD (2024), Shaping smart cities of all sizes, OECD Publishing,
https://www.oecd.org/content/dam/oecd/en/about/programmes/cfe/the-oecd-programme-on-
smart-cities-and-inclusive-growth/Proceedings-4th-Roundtable-Smart-Cities-Inclusive-
Growth.pdf/_jcr_content/renditions/original./Proceedings-4th-Roundtable-Smart-Cities-In.
[4]
OECD (2023), “2023 OECD Open, Useful and Re-usable data (OURdata) Index: Results and
key findings", OECD Public Governance Policy Papers, No. 43, OECD Publishing, Paris,
https://doi.org/10.1787/a37f51c3-en.
[23]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 101
OECD (2021), “The OECD Framework for digital talent and skills in the public sector", OECD
Working Papers on Public Governance, No. 45, OECD Publishing, Paris,
https://doi.org/10.1787/4e7c3f58-en.
[32]
OECD (2019), The Path to Becoming a Data-Driven Public Sector, OECD Digital Government
Studies, OECD Publishing, Paris, https://doi.org/10.1787/059814a7-en.
[25]
OECD (2017), Fostering Innovation in the Public Sector, OECD Publishing, Paris,
https://doi.org/10.1787/9789264270879-en.
[3]
OECD/CAF (2022), The Strategic and Responsible Use of Artificial Intelligence in the Public
Sector of Latin America and the Caribbean, OECD Public Governance Reviews, OECD
Publishing, Paris, https://doi.org/10.1787/1f334543-en.
[1]
OECD/UNESCO (2024), G7 Toolkit for Artificial Intelligence in the Public Sector, OECD
Publishing, Paris, https://doi.org/10.1787/421c1244-en.
[11]
Parliament of Australia (2025), Report 510: Inquiry into the use and governance of artificial
intelligence systems by public sector entities - 'Proceed with Caution',
[28]
https://parlinfo.aph.gov.au/parlInfo/download/committees/reportjnt/RB000567/toc_pdf/Report5
10Inquiryintotheuseandgovernanceofartificialintelligencesystemsbypublicsectorentities-
'ProceedwithCaution'.pdf.
PTI (2024), Al and City/County Government: Survey Results, Public Technology Institute,
[16]
https://fusionlp.org/wp-content/uploads/2024/11/Al-Survey-City-and-County-Final-2024.pdf.
Richter, A. (2024), Navigating Generative Al in Government,
[36]
https://businessofgovernment.org/report/navigating-generative-ai-government.
Rivero del Paso, L. et al. (2023), Digital Solutions Guidelines for Public Financial Management,
https://www.imf.org/en/Publications/TNM/Issues/2023/10/06/Digital-Solutions-Guidelines-for-
Public-Financial-Management-537781.
[69]
Ryseff, J., B. De Bruhl and S. Newberry (2024), The Root Causes of Failure for Artificial
Intelligence Projects and How They Can Succeed, RAND,
https://www.rand.org/pubs/research_reports/RRA2680-1.html.
[5]
Ryseff, J. and A. Narayanan (2025), Why Al Projects Fail,
[22]
https://www.rand.org/pubs/presentations/PTA2680-1.html.
Salesforce (2024), 6 in 10 IT Workers Report Shortage of Al Skills in the Public Sector,
https://www.salesforce.com/news/stories/public-sector-ai-statistics/.
[12]
Samuleson, W. and W. Zeckhauser (1988), “Status quo bias in decision making”, Journal of Risk
and Uncertainty, Vol. 1, pp. 7-59, https://doi.org/10.1007/bf00055564.
[50]
SAS (2025), Slow uptake of Al in government hindering strategic goals, new research finds,
https://www.sas.com/en_gb/news/press-releases/2024/september/slow-uptake-of-ai-in-
government-hindering-strategic-goals.html.
[53]
SAS (2020), Al in government: The path to adoption and deployment,
[35]
https://www.sas.com/en_sa/insights/articles/analytics/ai-in-government.html.
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
102 |
Shahab, S. and L. Lades (2021), “Sludge and transaction costs”, Behaviorual Public Policy,
Vol. 1/22, https://doi.org/10.1017/bpp.2021.12.
[55]
Shark, A. (2025), What the Rising Costs of Al Means for Government,
[51]
https://statetechmagazine.com/article/2025/01/what-rising-costs-ai-means-government.
Stanford HAI (2025), Artificial Intelligence Index Report 2025, https://hai-
[59]
production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf.
Sunstein, C. and J. Gaffe (2024), An Anatomy of Algorithm Aversion, Elsevier BV,
https://doi.org/10.2139/ssrn.4865492.
[42]
Teale, C. (2025), Public-sector concerns over Al are lessening, survey says, https://www.route-
fifty.com/artificial-intelligence/2025/02/public-sector-concerns-over-ai-are-lessening-survey-
says/403328.
[45]
The Alan Turing Institute (2024), Al for bureaucratic productivity: Measuring the potential of Al to
help automate 143 million UK government transactions,
[46]
https://www.turing.ac.uk/news/publications/ai-bureaucratic-productivity-measuring-potential-
ai-help-automate-143-million-uk.
Trajkovski, G. (2024), “Bridging the public administration-Al divide: A skills perspective”, Public
Administration and Development, Vol. 44/5, pp. 412-426, https://doi.org/10.1002/pad.2061.
[18]
Ubaldi, B. et al. (2019), “State of the art in the use of emerging technologies in the public sector",
OECD Working Papers on Public Governance, No. 31, OECD Publishing, Paris,
https://doi.org/10.1787/932780bc-en.
[33]
UK Committee of Public Accounts (2025), Use of Al in Government,
[6]
https://committees.parliament.uk/publications/47199/documents/244683/default/.
UK DSIT (2025), Archaic tech sees public sector miss £45 billion annual savings,
[68]
https://www.gov.uk/government/news/archaic-tech-sees-public-sector-miss-45-billion-annual-
savings.
UK DSIT (2025), State of digital government review,
[21]
https://www.gov.uk/government/publications/state-of-digital-government-review/state-of-
digital-government-review.
UK NAO (2024), Use of artificial intelligence in government, National Audit Office,
[13]
https://www.nao.org.uk/wp-content/uploads/2024/03/use-of-artificial-intelligence-in-
government.pdf.
UN Habitat (2024), Global assessment of Responsiuble Al in cities,
[14]
https://unhabitat.org/sites/default/files/2024/08/global_assessment_of_responsible_ai_in_citie
s_21082024.pdf.
US OMB (2025), Accelerating Federal Use of Al through Innovation, Governance, and Public
Trust, https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-
Federal-Use-of-Al-through-Innovation-Governance-and-Public-Trust.pdf.
[40]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 103
US OMB (2025), Driving Efficient Acquisition of Artificial Intelligence in Government, White
House Office of Management and Bydget, https://www.whitehouse.gov/wp-
content/uploads/2025/02/M-25-22-Driving-Efficient-Acquisition-of-Artificial-Intelligence-in-
Government.pdf.
[48]
van Noordt, C., R. Medaglia and L. Tangi (2023), “Policy initiatives for Artificial Intelligence-
enabled government: An analysis of national strategies in Europe", Public Policy and
Administration, https://doi.org/10.1177/09520767231198411.
[26]
Varazzani, C. et al. (2023), “Seven routes to experimentation in policymaking: A guide to applied
behavioural science methods”, OECD Working Papers on Public Governance, Vol. 64,
https://doi.org/10.1787/918b6a04-en.
[49]
Waters, R. (2024), Meta under fire for 'polluting' open-source,
https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f.
[72]
# Notes
1 "Salesforce conducted a double-anonymous survey of 600 IT professionals (200 IT leaders and 400 IT
individual contributors) in Australia, France, Germany, the United Kingdom and the United States.
Respondents work across industries, including technology, financial services, media and entertainment,
manufacturing, retail, healthcare, the public sector and more. The survey was fielded in December 2023
and January 2024" (2024[12]).

2 The source for this sentence is a report by the Joint Committee of Public Accounts and Audit, Parliament
of Australia (2025[28]). The findings of the Committee and are not necessarily representative of the
Australian Government's views

3 https://oecd.ai/dashboards.

4 https://impress.ai/case-studies/publicsector.

5 Based on Microsoft's US-oriented website (https://www.microsoft.com/en-us/microsoft-365/copilot) as of
10 April 2024. Annual subscription pricing.

6 https://team-gpt.com/blog/claude-pricing.

7 See, for example, https://openai.com/global-affairs/introducing-chatgpt-gov and
https://www.anthropic.com/news/expanding-access-to-claude-for-government.

8 The use of "open-source” models for this report does not imply that such models are released under an
open-source license approved by the Open Source Initiative (OSI), a nonprofit steward of The Open Source
Definition (https://opensource.org/osd). OSI has criticised some companies that call their models open
source because they only provide the weights for the model, and not other elements, such as the training

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

104 |

data, code and training practices (Waters, 2024[72]). Some argue that such models should be called “open weight" instead of "open source".

9 https://en.taide.tw.

10 Information provided by an undisclosed country to the OECD. The OECD is not publishing the name of the country or project because of the preliminary nature of the estimates and analysis.

11 Information provided by an undisclosed country to the OECD. The OECD is not publishing the name of the country or project because of the preliminary nature of the estimates and analysis.

12 https://openeurollm.eu.

13 Figures reported to the OECD by a non-disclosed country.

14 https://huggingface.co/bigscience/bloom.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 105

# 4 Enablers, guardrails and engagement for unlocking trustworthy Al

This chapter sets out how governments can realise Al's potential while managing risks. It establishes three pillars — enablers, guardrails and engagement — that together form the OECD Framework for Trustworthy Al in Government. Enablers include governance, data, digital infrastructure, skills and talent, purposeful investment, procurement and partnerships; guardrails cover non-binding and binding instruments, transparency and risk management, and oversight; engagement spans citizens, civil servants and cross-border collaboration. The chapter calls for a systems approach, proportionate, risk-based application of measures, and practical mechanisms such as experimentation and impact assessment and auditing to support trustworthy adoption at scale.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

106 |

# Key messages
*   Governance and policy initiatives can help governments to fully exploit Al's potential and address its various risks and implementation challenges. Governments should take a systems approach and seek to anticipate future changes. Proposed measures should strengthen enablers, establish guardrails and engage with stakeholders.
*   Enablers include establishing key governance mechanisms and processes, understanding data's role as the foundation for Al, building digital infrastructure, fostering skills and talent, investing purposefully, effectively using public procurement and expanding Al's potential through partnerships.
*   Guardrails can be binding and non-binding policy levers, transparency processes and accountability mechanisms.
*   Engagement with stakeholders can take the form of citizen assemblies, engaging with civil servants, involving users in Al development and collaborating across borders.
*   Taken together, these policy measures form a Framework for Trustworthy Al in Government, which can help governments to align their actions with the OECD AI Principles. Future OECD work will address elements of the framework more in-depth.

# Policy action to unlock Al's potential
While the rest of this report discusses governments' opportunities and challenges in governing with Al, this chapter focuses on how to realise success through governing Al in government. To fully leverage the potential of Al in the government while mitigating risks, governments need to take an intentional, strategic and responsible approach. This approach should align with the OECD AI Principles, but contextually specific and appropriate for the development and use of Al for and by governments. In particular, governments should pursue three courses of action:

1. strengthening **enablers** (e.g. quality data, digital and Al skills, funding and digital infrastructure) to overcome key implementation challenges and deliver the expected results
2. establishing **guardrails** (e.g. transparency, accountability and risk management tools) to anticipate and manage associated risks, and
3. fostering **engagement** with stakeholders (including the public) to develop Al systems that take their needs into account.

These actions aim to harness opportunities and address the various risks and implementation challenges associated with Al through targeted policy measures. For instance, issues related to the need for sufficient and quality data are addressed through enablers that focus on building robust data governance and infrastructure. In another example, insufficient guidance and outdated regulations can be addressed through guardrails such as binding and non-binding policy levers, including agile regulatory instruments, helping to ensure Al operates within clearly established ethical, operational and legal boundaries. Active stakeholder engagement throughout the Al system lifecycle (development, deployment and use of Al technologies) and the policy cycle (for designing, implementing and evaluating Al governance and policy) can enrich the understanding, attitudes and behaviours of stakeholders, including the public, and align technology and governance developments with societal needs.

The sections below seek to address the main points of attention for governments to create an environment that enables the strategic and responsible use of Al across government systems and functions. They

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 107
provide a comprehensive analysis of specific policy actions and priorities along the three action areas.
Each section outlines key policy options that governments should consider for a coherent and sustainable
approach. Governments should consider these options in light of their own context, including their current
digital government maturity. For instance, instead of seeking to put in place all of the items discussed at
once, governments could consider progressive governance and Al adoption roadmaps based on
institutional, cultural and technological capacities.

# A holistic, systems approach can maximise the value of Al in government

In establishing the enablers, guardrails and engagement mechanisms discussed in this chapter,
governments should take a systems approach to Al, seeking to understand and address public problems
by viewing them as part of a larger, interconnected system rather than in isolation (OECD, 2017[1]).
Traditionally, public policymakers have addressed social problems through discrete interventions layered
on top of one another, building on a “cause and effect” relationship. However, these interventions may shift
consequences from one part of the system to another, simply addressing symptoms while ignoring causes.
Al represents an opportunity to reimagine how government works, in terms of both internal operations and
public-facing services. Governments should think beyond how Al can fit within existing government
systems and structures; they need to think about how Al can contribute to entirely rethinking processes
and systems. Otherwise, governments run the risk of simply automating inefficiency and further reinforcing
misaligned incentives and governance approaches. Emerging practices can assist, such as “sludge
audits”, which are structured behavioural assessments of a process to identify frictions that result in people
being less likely to complete the process or expend undue psychological effort while doing so (OECD,
2024[2]). The OECD has a dedicated line of work to systems approaches that can further assist.¹

## Governments should recognise the potential for and seek to anticipate future changes

There is still much to learn about Al and much remains unknown about its ongoing evolution. Establishing
the enablers, guardrails and engagement mechanisms discussed in this chapter may only take into
account today’s knowledge — what is known about the uses and implications of current Al and about the
potential for tomorrow. Yet, there are major unknowns that will only be resolved over time as the technology
develops and its potential uses explored. Al in government will be an ongoing journey of discovery, both
welcome and unwelcome, and unexpected and unintended developments. Governments should employ
an agile and adaptive approach to adjust to new opportunities and changing behaviours. Many tasks Al
cannot satisfy today will likely become feasible in the future. Al strategies and frameworks should be
flexible enough to evolve with changing capabilities and contexts. Governments need to improve their early
engagement with weak signals that indicate how the future may transpire. This will enable them to
understand where and when to best intervene, without waiting for processes and trends to become
established, and thus expensive and difficult to shift.

These considerations are relevant not only for Al governance, but also for its use in government. The use
cases discussed in this report (in-depth in Chapter 5 and synthesised in Chapter 2) generally represent
incremental improvements and productivity gains. This, however, should not obscure that emergent or
future uses of Al could be completely new or handle previously impossible, impractical or even
inconceivable tasks and create new opportunities and risks for government. This can lead to use cases
and governance approaches that will need to be created, reinvented or stopped. OECD efforts on
Anticipatory Innovation Governance (AIG) and Strategic Foresight can help government better understand
and shape potential Al futures.²

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

108 |

# Strengthening enablers to facilitate the adoption of trustworthy Al

Enablers are the foundational elements and resources necessary for Al implementation in government.3
They create an environment where skilled public servants can effectively and reliably design and deploy
Al. Their practical support allows government institutions to fully harness Al's potential. The sections below
review seven key enablers: **governance, data (including open government data), digital
infrastructure, skills and talent, Al investments, public procurement and partnering with non-
governmental actors.** These were initially defined by the OECD in 2024 ([3]) and are further developed in
the sections below. Each section considers policy options governments can adopt to deploy these enablers
in their contexts, drawing on international best practices.

## Establishing key governance mechanisms and processes

Governments are accelerating their adoption of Al, and in most cases, have outlined their goals in national
Al strategies. Yet, this adoption is often piecemeal in practice at a high-level, without establishing
comprehensive and robust governance arrangements to ensure Al's responsible use, long-term impact
and sustainability. As Al becomes increasingly integrated into government operations, robust governance
arrangements should be established domestically to ensure the trustworthy, sustainable and effective use
of Al. They can also promote a clear narrative of the benefits of Al to build support within and outside
government.

### Using strong leadership for a cohesive vision

Strong leadership is a critical factor in achieving Al adoption in government. It is vital to setting the right
tone from the highest levels of government and actively communicating the potential benefits of Al (Berryhill
et al., 2019[4]). While establishing strategies and principles to help ensure trustworthy Al adoption is critical,
solid and effective leadership can build a cohesive vision for Al and set a "tone at the top” that builds
confidence in Al, both within and beyond government. For instance, in the United Kingdom (UK), the past
two prime ministers (PMs), Rishi Sunak and Keir Starmer, have championed Al's adoption both inside and
outside government. Under Sunak's leadership, the UK catalysed global attention and international
collaboration on Al through convening the first global Al Summit in November 2023, with subsequent
events organised by Korea and France. Each has concluded with a declaration signed by many
governments outlining Al-related commitments.4 More targeted on government, the UK's Incubator for Al
(i.Al), which aims to improve lives, drive growth and deliver better public services, was also launched during
Sunak's tenure. Under current PM Starmer's leadership, the UK (2025[5]) launched the Al Playbook for the
UK Government (Box 4.2) and has put forth a bold plan to use Al in "reshaping the state to make it work
for working people", including through the creation of 2 000 tech and Al apprentices in government. Finally,
in cascading strong leadership throughout UK government organisations, (2025[6]) “A blueprint for modern
digital government” requires all public sector organisations to include a digital leader on their executive
committee by 2026.

Those at the top have the power to set a strategic direction that can permeate levels below, helping to
frame the use of Al within the culture at large. As stated in the OECD Framework for Digital Talent and
Skills in the Public Sector (2021[7]), “leadership that creates an environment to encourage digital
transformation will communicate a clear vision for digital government and actively champion its benefits.
[Such] leaders will be engaged, visible and approachable, and empower their teams through decentralising
decision making”.5 A study by the European Commission (EC) (2024[8]), based on a survey of 576 public
managers in seven countries, found that leadership can especially influence Al adoption by offering robust
incentives and/or financial resources to implement Al initiatives, with respondents generally finding the
current state of these to be unsatisfactory.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 109

Strong leadership for Al can foster a “mission-oriented" approach to its innovation. This approach
emphasises a problem-solving focus, where policy interventions are designed to mobilise resources,
coordinate stakeholders, and stimulate innovation and collaboration across government and sectors to
tackle the identified challenge and meet set mission targets. Mission-oriented policies often involve a
combination of regulatory measures, financial incentives, research funding and targeted investments to
drive progress towards the mission. Leaders play a critical role by providing top-down direction and
galvanising support in order to align all pieces of government to move in unison towards the same goal
(OECD, 2021[9]). 6 Some governments and intergovernmental organisations have taken a mission-oriented
approach to Al policy, although these are generally aimed at catalysing economic growth in the private
sector (UCL IIPP, 2019[10]; Vinnova, 2022[11]).

## Taking a strategic and directed approach
Governments can implement whole-of-government strategies and guidance on Al to identify and prioritise
its coherent use and development in line with overarching government values and objectives. For example,
the Dominican Republic's (2024[12]) 2023 national Al strategy focuses heavily on Al in government. Canada
(2025[13]), Switzerland (2025[14]) and Uruguay (2021[15]) have each developed a dedicated strategy for Al
in government, and another is under development in the United Kingdom (2024[16]). The April 2025 policy
from the United States (US) on "Accelerating Federal Use of Al through Innovation, Governance, and
Public Trust", although not called a "strategy", fits many of the hallmarks of a strategy that seeks to drive
change throughout federal government and has the added benefit of being binding in nature (Box 4.1).
Many others have substantive aims for Al in government to be embedded in broader national strategies.
Overall, these high-level strategies tend to touch on many of the enablers, guardrails, engagement
processes and types of use cases discussed in this report. Targeted strategies also exist to guide Al efforts
in certain government functions. For instance, France has developed a strategy for using Al in HRM (see
Chapter 5, Box 5.19), and the aforementioned US policy gives government agencies 180 days to develop
and publish their own Al strategy.

# Box 4.1. Accelerating federal government use of Al in the United States
In the United States, pursuant to requirements of the Al in Government Act of 2020, on 3 April 2025,
the White House Office of Management and Budget (OMB) issued M-25-21 Accelerating Federal Use
of Al through Innovation, Governance, and Public Trust. The policy promotes Al innovation, responsible
adoption and use of Al, and safeguarding American protections on privacy, civil rights, and civil liberties.
According to the policy, among other things, agencies must:

*   Identify a Chief Al Officer (CAIO) to serve as a senior advisor, champion agency Al goals,
    coordinate Al efforts within in their agency, and represent the agency with coordination bodies
    and external fora; with OMB committing to convening an interagency CAIO Council to support
    coordination to maximise efficiencies.
*   Remain accountable by meeting reporting requirements, including updating an Al use case
    inventory at least annually.
*   Implement minimum risk management practices for Al that could have significant impacts when
    deployed ("high-impact Al") in a manner proportionate to the anticipated risk from its intended
    use, as described further (Box 1.3).
*   Publish agency Al strategies for identifying and removing barriers to the responsible use of Al
    and achieving enterprise-wide improvements in the maturity of their applications (CFO Act
    agencies).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

110 |

*   Strategies must include an assessment of the agency's current state of Al maturity and a
    plan to achieve the agency's Al maturity goals, by addressing plans and processes to,
    among other things, develop Al-enabling infrastructure (e.g. high-performance computing
    infrastructure) across the Al lifecycle; ensure access to quality data; develop enterprise
    capacity for Al innovation; recruit, hire, train, retain and empower an Al-ready workforce and
    achieve Al literacy for non-practitioners involved in Al; and develop the necessary
    operations, governance and infrastructure to manage risks from the use of Al.
*   Develop a GenAl policy that sets the terms for acceptable use of GenAl for their missions and
    establishes adequate safeguards and oversight mechanisms that enable GenAl to be used in
    the agency without posing undue risk.
*   Proactively share data and Al assets across the federal government, including custom
    developed code, including models, whether agency developed or procured, and to the extent
    practicable, release and maintain the code as open-source software in a public repository (some
    exceptions apply).
*   Develop and publish agency compliance plans to achieve consistency with M-25-21 (to be
    updated every two years).
*   Revisit and update where necessary internal policies on IT infrastructure, data, cybersecurity
    and privacy to align with M-25-21 and other relevant executive orders and laws.
*   Responsibly procure Al capabilities (Box 4.7).

Note: The policy generally applies to all Executive Branch departments and agencies, including independent regulatory agencies. Some
parts of the policy apply only to "CFO Act" (Chief Financial Officers Act of 1990) agencies. National intelligence agencies and the Department
of Defense are also excluded from some requirements. The source document includes more specific details on applicability.
Source: (US OMB, 2025[17]), https://www.congress.gov/bill/116th-congress/house-bill/2575/text, https://www.congress.gov/bill/116th-
congress/house-bill/133.

In an attempt to move beyond strategy, some governments have developed comprehensive guidance. For
instance, in addition to the Al Playbook for the UK Government (Box 4.2), New Zealand (2025[18]) has
established a Public Service Al Framework, and Ireland (2025[19]) has published Guidelines for the
Responsible Use of Al in the Public Service. Such guidance is helpful not only to implement strategies but
can help overcome risk aversion in implementing more formal laws and regulations (see Guardrails
discussion below) by removing the need for each organisation or team to make its own interpretations. As
stated by the co-founder of Code for America, “well-meaning and well-written legislation originates at the
top of a very tall hierarchy, and as it descends, the flexibility that its authors intended degrades. Laws often
have an effect entirely different from what lawmakers intended because of this cascade of rigidity" (Pahlka,
2024[20]).

To further counteract risk aversion, guidance could promote experienced public servants' use of judgement
and discretion. It could also acknowledge that, as with any human action, leveraging Al cannot be risk free.
Techniques such as behavioural science can be used to craft guidance and communications in a way that
helps ensure the desired behavioural effect on users, maximising the value of Al adoption while mitigating
risks, increasing the likelihood of meaningful behavioural change and responsible Al adoption (OECD,
2021[21]).7

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 111

# Box 4.2. Artificial Intelligence Playbook for the UK Government
The UK Government Digital Service (GDS), with the support of a variety of central government
departments, private sector technology companies, academic institutions and users, published the
Playbook in February 2025. It includes 10 principles alongside guidance on several issues.

## 10 principles to guide Al in government organisations
1.  You know what Al is and what its limitations are.
2.  You use Al lawfully, ethically and responsibly.
3.  You know how to use Al securely.
4.  You have meaningful human control at the right stage.
5.  You understand how to manage the Al life cycle.
6.  You use the right tool for the job.
7.  You are open and collaborative.
8.  You work with commercial colleagues from the start.
9.  You have the skills and expertise needed to implement and use Al.
10. You use these principles alongside your organisation's policies and have the right assurance in
    place.

## Explainers and guidance
The Playbook includes informational material on what Al is, fields of Al, applications of Al in government,
limitations, building Al solutions, building a team, defining the goal, buying Al, using Al safely and
responsibly, ethics, legal considerations, data protection and privacy, security and governance. It also
includes a series of Al uses cases that illustrate real-world efforts in the UK government.

Source: (UK Government Digital Service, 2025[22]).

## Determining whether Al is the best solution
Guidance should exist that includes a focus on determining whether Al is the best solution for a given
problem, thus taking a step back from focusing on Al. While Al has tremendous capabilities, it is not always
the best solution and in many cases is inviable. A key finding from a recent report from the Ada Lovelace
Institute (2025[23]) is that "there is a surprising lack of evidence on the effectiveness and impact of Al tools,
even from a purely technical standpoint. Evaluating Al interventions in context is crucial to determining
their performance and value compared to existing manual or traditional methods". Work by RAND found
that an inadequate of understanding of the problem to be solved and projects that use Al unnecessarily
are two main drivers of Al project failure (2024[24]; 2025[25]).

A common issue with Al is that people start with solutions then look for problems for the technology to
solve. In general, governments should seek to understand and focus on the outcomes both governments
and citizens seek to achieve and the problems preventing that. Armed with this knowledge and priorities,
they can then identify whether Al (or something else) is the best solution to help achieve these goals
(Berryhill et al., 2019[4]; Mulgan, 2019[26]). Accordingly, governments need capacities for problem
identification and understanding. They will also need to leverage other enablers presented in this chapter,
including workforce skills for understanding Al's strengths and weaknesses relative to other technologies
and processes to engage users to understand their needs.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

112 |

Some governments have built in considerations for this in government-wide guidance. For instance, the Al
Playbook for the UK Government indicates that public servants should "be open to the conclusion that,
sometimes, Al is not the best solution for your problem: it may be more easily solved with more established
technologies". The United Kingdom's (2020[27]) Guidelines for Al Procurement advises Al procurement
officials to "start with [a] problem statement” and articulate “why you consider Al to be relevant to the
problem, and be open to alternative solutions". In the United States, the Al Guide for Government ([28])
includes components to "focus on the root problem", and to consider "Is it the best option to solve this
particular problem? Have you evaluated alternative solutions?"

A processes for making these determinations could be integrated as part of an ex ante impact evaluation
(see Guardrails section below on “Impact assessments”), or could be established as an independent
process before entering the pipeline of Al projects.

## Defining clear roles and responsibilities
Governments should define clear roles and responsibilities to facilitate the coherent development, use and
potential scaling of Al. These roles and responsibilities should be defined and agreed upon with relevant
stakeholders and assigned to government institutions, incorporating them into the institutions' mandates.
This enables a solid institutional structure to support the implementation of national strategies within and
across individual institutions, and it facilitates accountability and oversight across the public administration.
Several European countries are expanding the mandates of existing ministries or agencies to ensure
coherent Al deployment. Examples include Norway's Ministry of Digitalisation and Public Governance, and
Spain's Secretary of State for Digitalisation and Al within the Ministry of Digital Transformation and Public
Management (OECD, 2024[3]). The United Kingdom has consolidated most Al roles and responsibilities
across sectors into its Department for Science, Innovation and Technology (DSIT) (OECD/UNESCO,
2024[29]). At the individual level, the US policy in Box 4.1 requires federal government agencies to
designate a CAIO to lead their Al efforts. Governments may also need to parse out various roles and
responsibilities to achieve a variety of strategic objectives. For instance, in Chile and Colombia, the national
Al strategies define responsible actors linked to each commitment as defined in the strategy. Colombia
also details the time frames in which responsible actors need to achieve them, as well as budget and
monitoring indicators (OECD/CAF, 2022[30]; CONPES, 2025[31]). In establishing roles and responsibilities,
governments should make clear which entity or entities have the authority to establish policy over Al use
in government. Indeed, OECD work with countries has uncovered confusion around who is responsible for
rule-setting, potentially hindering digital transformation efforts.

## Coordinating efforts within and across government
Governments can reinforce coordination and collaboration efforts to ensure a holistic approach to Al
adoption and governance. Establishing inter-ministerial task forces or committees can facilitate decision-
making, communication and collaboration across different institutions. These mechanisms enable all
actors to take part in setting overarching objectives and work together towards achieving them. For
instance, the US policy discussed in Box 4.1 requires the establishment of a cross-government CAIO
Council. In another example, Australia, established a temporary Al in Government Taskforce (September
2023 to June 2024) to develop policy, standards and guidance to enable the safe, ethical and responsible
use of Al in public service (OECD, 2024[3]).8 At the sub-national level, in the government of Dubai in the
United Arab Emirates, 22 CAIOs from across the government are charged with leading and coordinating
Al efforts (WAM, 2024[32]).

Coordination is also important transversally, across levels of government. Many Al applications have
significant local impact, particularly in public service delivery and social welfare, as local governments are
closest to citizens and residents. However, without coordination, fragmentation in Al approaches can
emerge. Where municipalities and regional governments develop Al solutions in isolation, inefficiencies,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 113

duplication of efforts and inconsistencies in governance frameworks and user experience can result
(Verhulst and Sloane, 2020[33]). Similarly, designing national strategies policies without consideration for
local needs can result in approaches that are mismatched or unworkable for realities on the ground.
Denmark has taken steps to address this challenge through its new Digital Taskforce for Al, which is
working to scale Al adoption across all levels of government, ensuring alignment in priorities, standards
and governance approaches.9 Similarly, in Sweden, Al Sweden and Vinnova launched the Collaboration
for Al in Municipalities and Civil Society initiative (Kraftsamlingen) to help municipalities and civil society
organisations integrate Al into their operations. Since 2022, this initiative has provided tailored support,
including guidance on Al adoption and funding opportunities for concrete projects, fostering a more
coordinated and effective Al ecosystem across local governments.

## Creating spaces to experiment
Governments need to allocate time and space to explore using Al, as both experimentation and iterative
learning are crucial to developing Al capacity (OECD/CAF, 2022[30]). In addition to helping promote learning
and identify new possibilities and approaches, controlled environments for Al experimentation and testing
facilitate the timely identification of potential technical flaws, behavioural biases of both Al systems and
people using them, and associated governance challenges. Furthermore, through experimentation, Al
systems can be incubated until the solutions are technically robust enough to scale up. In doing so, they
can also highlight public concerns especially through testing under quasi real-world conditions (OECD,
2019[34]). Such approaches entail engaging stakeholders throughout the development phase, evaluating
user needs, assessing data availability and quality, and continuously monitoring progress from the
prototyping and piloting phases (OECD/UNESCO, 2024[29]). Such environments include innovation
centres, labs and sandboxes. Experiments can operate in "start-up mode" — whereby they are deployed,
evaluated and modified then be scaled up or down, or abandoned quickly (OECD, 2023[35]). Beyond in-
house experimentation, governments can also work with non-governmental actors, such as GovTech
startups, to design and execute Al experiments (see “Turning to GovTech startups” below).

Additionally, these environments foster collaboration between government, academia and industry,
promoting the exchange of ideas and accelerating the development of Al technologies. By simulating real-
world conditions, these facilities enable rigorous validation of Al systems, ensuring they are robust, reliable
and safe prior to deployment. This approach to testing and experimentation not only enhances the
effectiveness of Al solutions but also builds public trust by validating these technologies through early
identification and addressing potential risks, biases or inefficiencies before wide deployment.

For example, the EU, in collaboration with its Member States, has launched a network of permanent
Testing and Experimentation Facilities (TEFs), including CitCom.ai, which focuses on smart cities and
communities. The initiative accelerates the development of trustworthy Al in the European Union by
providing innovators — both companies and public agencies — access to test and experimentation of Al-
based products in real-world conditions. Other examples include:

*   In the United States, the Mitre Corporation, a government-funded research and development
    (R&D) centre, is developing an Al supercomputer to power a new Al sandbox, which will be capable
    of training new, government-specific advanced Al systems. 10
*   In the United Kingdom, the Incubator for Al (i.Al) promotes Al experimentation and eventual scale-
    up through four key approaches: 1) prototyping to quickly test and evaluate ideas for Al
    applications; 2) delivery to scale up successful prototypes to relevant government teams where
    they can have an impact; 3) modularisation to share technical work across government, including
    open sourcing code; and 4) convening and advising to identify areas for sharing learning and
    products. 11
*   In France, ALLiaNCE, an interministerial Al incubator launched by the Interministerial Directorate
    for Digital Affairs (DINUM) in July 2023, illustrates a government-led initiative to structure the

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

114 |
• experimentation and scaling of Al across core government functions.12 The ALLiaNCE incubator applies an agile, user-centric "product mode" methodology — originally developed by beta.gouv.fr — focusing on fast iteration, user feedback and measurable impact, thereby accelerating Al adoption in government. ALLiaNCE's structured selection criteria — based on impact, mutualisation potential, user engagement and ethical compliance — demonstrates a rigorous approach to testing and scaling responsible Al projects.
• In Australia (2024[36]), over 60 Australian Public Service (APS) agencies conducted a six-month trial of Microsoft Copilot. Over 7 700 public servants participated in the trial, the results of which were varied; however, aggregately, users experienced perceived improvements in the efficiency and quality of Al for summarisation and preparing a first draft of documents. Despite this, Al's adoption requires concerted efforts to address technical, cultural and capability barriers.
• Portugal and Spain have each engaged with GovTech organisations to promote experimentation with digital technologies, including Al, in justice administration.13 Also on GovTech but with a broader scope, Spain's GovTechLab is an Al use case incubator that identifies scenarios where generative Al can have an impact on public administrations — whether by achieving greater efficiency in the provision of public services, reducing workloads or improving citizen service.14 Twenty out of the 300 identified use cases will be piloted in areas such as document classification, Al assistants and the preparation of tenders and grants. Those that are successful will be scaled and offered as a service to the entire administration.

In establishing small Al experiments and pilots, governments should consider their definition of success and establish measurements and evaluation framework to determine whether a project was successful, determine what worked and what did not and help capture and disseminate lessons learned. The United Kingdom's Guidance on the Impact Evaluation of Al Interventions serves as a good example, providing considerations on Al projects from small-scale testing through full implementation.15

The OECD is currently developing a dedicated report on Al experimentation in government to review current practices and derive key lessons learned to help inform and guide policymakers in establishing their own experimentation guidance for their organisations (OECD, forthcoming[37]).

# Creating a strong data foundation
Data serves as the foundational asset driving the capacity of Al to function, evolve and create public value. Drawing on the concept of "garbage in, garbage out," Al performance directly correlates to the quality and representativeness of inputs it is trained with; Al systems often require vast amounts of data across the Al system cycle to deliver valuable outputs.

Relevant data can be derived from government, the private sector or other sources. This section mainly focuses on government data, though the OECD (forthcoming[38]) is conducting work that systematises the sources from which Al developers obtain data for Al training and highlights their main attributes.

Access to and sharing government data for Al brings complex data governance challenges. Governments face regulatory and operational hurdles, from safeguarding privacy, non-biased results and data security to navigating policy and legal frameworks for governing data sharing and use and intellectual property rights. Public sector organisations also have to tackle technical issues, from ensuring interoperability across data systems to building the technical capacity to manage data effectively.

## Ensuring privacy, security and intellectual property rights
Governments are building frameworks, guidelines and mechanisms to promote strong data governance that safeguard privacy, intellectual property and security. These often result from collaborations among regulatory bodies, industry stakeholders and civil society. For example:

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 115
• Korea's Personal Information Protection Commission (2023[39]) has released a guide for personal information processing and Al development. This guide outlines the legal basis for processing personal data, establishes safety standards, and suggests measures to protect individuals' rights within Al systems.
• New Zealand's (2025[18]) Public Service Al Framework and the United Kingdom's (2025[22]) Al Playbook for the UK Government each cover principles for safe and privacy-preserving use of Al in government.
• In bridging the concepts of experimentation (discussed above) with personal data protection, France has established a data sandbox to provide an enabling environment for safe experimentation, coupled with training and hands-on support in managing personal data and ensuring regulatory compliance (Box 4.3).
• Some governments are exploring privacy-enhancing technologies (PETs), such as data anonymisation, on sensitive data used for Al training. These technologies can, in turn, be enhanced through AI (OECD, 2024[40]).16

---
**Box 4.3. France's personal data sandbox for Al in public services**

In 2023, France's data protection authority (CNIL) launched a “sandbox” initiative to support innovation in Al for public services. This sandbox offers selected organisations expert guidance to help them navigate personal data regulations early in their project development. While it does not remove any legal requirements, it aids in identifying solutions to compliance challenges. Four projects were selected to receive guidance from CNIL's new Al department:
• Albert (DINUM): assists civil service agents with a language model to improve responses to user inquiries, with pilots in "France Services" centres.
• Job Intelligence (Pôle Emploi): provides personalised job search guidance using professional data to match job seekers with tailored services.
• Ekonom Al (Nantes Métropole): offers water consumption insights and recommendations for residents, supporting ecological goals and potentially adaptable to other public policies.
• RATP Video Project: develops Al to detect events through matrix data capture, ensuring privacy by design with no personal data collection.

Source: (CNIL, 2023[41]; [42]).

---

## Ensuring representativeness in data
Ensuring Al systems are trained on representative data is crucial for delivering accurate and relevant outcomes. In some countries, different populations have unique languages and traditions. In others, different demographic or other contextual factors shape the data needed for Al to be effective. As described in the OECD Good Practice Principles for Data Ethics in the Public Sector (2021[43]), using data that is not representative to train Al can lead to significant issues, particularly for government applications that require fair and accurate policies and decisions that can tangibly impact the target population. These issues include biased algorithms and decisions, and an inability to develop tailored services and policies for groups underrepresented in data, as discussed in Chapter 1.

Governments are taking actions to address this issue. For instance, a number of countries have taken action to invest in efforts to promote representativeness in languages (OECD, 2023[44]; Peixoto, Canuto and Jordan, 2024[45])17. Examples include:

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
116 |
• To promote language representation, the Common Danish Language Resource initiative and the Danish Platform for Danish Language Resources, led by the Danish Agency for Digital Government (2024[46]), aim to collect, develop and display language data and other tools that can support the development of Danish Al solutions.
• Greece (2024[47]) is pursuing the development of a Greek Language and Culture Data Space, which focuses on integrating Greece's linguistic and cultural heritage into Al applications.18 Also related to the Greek language, the development of the “Meltemi” and “Llama-Krikri” LLMs represent promising steps in this direction, highlighting the importance of open access and collaborative efforts in expanding the available linguistic resources.19
• India's Bhashini platform, launched under the National Language Translation Mission (NLTM), is India's flagship Al-led language infrastructure project. It supports real-time translation across 22 official Indian languages and dozens of dialects and provides support for multilingual voice assistants and Al service delivery interfaces.20 It was made possible by through a massive citizen engagement exercise to build multilingual datasets that boost data representativeness, with models and application programming interfaces (APIs) made available as open source.
• In Saudi Arabia, the Saudi Data and Artificial Intelligence Authority (SDAIA) has launched ALLaM, an LLM developed with 500 billion tokens and over 300 000 Arabic texts, including encyclopaedias, scientific research and historical works (M Saiful Bari, 2024[48]). ALLaM aims to reflect the linguistic and cultural richness of the Arabic language.
• Spain is working on a family of Al models, called ALIA, that are heavily trained on native Spanish and other official language data and will be available as open source.21 The first use cases include an assistant for diagnosing heart failure in the public health sector and an assistant to facilitate tax officials' replies to citizens.
• Language models for native American languages have also been developed. Although not developed by government, researchers have developed LakotaBERT to support language revitalisation efforts for “Lakota, a critically endangered language of the Sioux people in North America" (Parankusham, Rizk and Santosh, 2025[49]).

## Enabling effective and trusted data access and sharing
As discussed in Chapter 3, governments often face a significant shortage of easily available, relevant, high-quality data necessary for training Al systems effectively (OECD, 2025[50]). Addressing this gap requires a focused effort on enhancing data access, including through collaborative data collection and open arrangements (Box 4.4).

---
**Box 4.4. Sweden's collaborative data gathering for Svea**

Svea is a Swedish initiative coordinated by Al Sweden that unites government agencies, municipalities, regions and industry to address the challenges of creating Al solutions for public services. The primary focus is pooling resources to gather Swedish-language data that reflects the unique needs of government — a task too large for any single organisation.

By collaborating, government organisations can share the workload of data collection essential for developing a useful Al assistant. In the first phase, participants identified specific needs and began generating data from within their organisations to train the system. In the upcoming phase, they will gain access to shared databases of relevant national information to further inform the Al assistant.

Source: (Al Sweden, 2024[51]).

---

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 117
Another key initiative is open government data. On average, of only 46% of high-value government datasets are available as open data across the OECD (2023[52]), compared to more than 80% in France and Korea. Challenges remain in terms of fostering open data re-use by actors and the integration of these datasets into Al systems. Results from the 2023 edition of the Open, Useful and Re-usable data (OURdata) Index show that countries perform better in data availability and data accessibility compared to government support for data re-use (Figure 4.1).

# Figure 4.1. OECD Open, Useful and Re-usable data (OURdata) Index, 2023

### Chart Data Extraction
The following data represents the estimated values from the bar chart "Figure 4.1. OECD Open, Useful and Re-usable data (OURdata) Index, 2023". The index is composed of three categories: Data availability, Data accessibility, and Government support for data re-use. The Y-axis scale is from 0.0 to 1.0.

- **Legend**:
    - Data availability
    - Data accessibility
    - Government support for data re-use

- **Data Points by Country (Approximate Values)**:
    - **Korea**: Total ~0.92; Data availability ~0.22, Data accessibility ~0.4, Government support ~0.3
    - **France**: Total ~0.86; Data availability ~0.18, Data accessibility ~0.38, Government support ~0.3
    - **Poland**: Total ~0.80; Data availability ~0.15, Data accessibility ~0.35, Government support ~0.3
    - **Estonia**: Total ~0.78; Data availability ~0.15, Data accessibility ~0.33, Government support ~0.3
    - **Spain**: Total ~0.75; Data availability ~0.1, Data accessibility ~0.3, Government support ~0.35
    - **Ireland**: Total ~0.72; Data availability ~0.1, Data accessibility ~0.32, Government support ~0.3
    - **Slovenia**: Total ~0.70; Data availability ~0.1, Data accessibility ~0.3, Government support ~0.3
    - **Denmark**: Total ~0.68; Data availability ~0.08, Data accessibility ~0.3, Government support ~0.3
    - **Sweden**: Total ~0.65; Data availability ~0.05, Data accessibility ~0.25, Government support ~0.35
    - **Lithuania**: Total ~0.63; Data availability ~0.05, Data accessibility ~0.28, Government support ~0.3
    - **Norway**: Total ~0.62; Data availability ~0.05, Data accessibility ~0.27, Government support ~0.3
    - **Canada**: Total ~0.50; Data availability ~0.05, Data accessibility ~0.2, Government support ~0.25
    - **Colombia**: Total ~0.49; Data availability ~0.05, Data accessibility ~0.19, Government support ~0.25
    - **Finland**: Total ~0.48; Data availability ~0.05, Data accessibility ~0.18, Government support ~0.25
    - **Czechia**: Total ~0.47; Data availability ~0.05, Data accessibility ~0.17, Government support ~0.25
    - **OECD**: Total ~0.45; Data availability ~0.05, Data accessibility ~0.15, Government support ~0.25
    - **Italy**: Total ~0.44; Data availability ~0.05, Data accessibility ~0.14, Government support ~0.25
    - **Switzerland**: Total ~0.43; Data availability ~0.05, Data accessibility ~0.13, Government support ~0.25
    - **Slovakia**: Total ~0.42; Data availability ~0.05, Data accessibility ~0.12, Government support ~0.25
    - **Austria**: Total ~0.41; Data availability ~0.05, Data accessibility ~0.11, Government support ~0.25
    - **Netherlands**: Total ~0.40; Data availability ~0.05, Data accessibility ~0.1, Government support ~0.25
    - **Luxembourg**: Total ~0.39; Data availability ~0.05, Data accessibility ~0.09, Government support ~0.25
    - **Portugal**: Total ~0.38; Data availability ~0.05, Data accessibility ~0.08, Government support ~0.25
    - **Germany**: Total ~0.37; Data availability ~0.05, Data accessibility ~0.07, Government support ~0.25
    - **United Kingdom**: Total ~0.36; Data availability ~0.05, Data accessibility ~0.06, Government support ~0.25
    - **Japan**: Total ~0.35; Data availability ~0.05, Data accessibility ~0.05, Government support ~0.25
    - **Israel**: Total ~0.34; Data availability ~0.05, Data accessibility ~0.04, Government support ~0.25
    - **Latvia**: Total ~0.33; Data availability ~0.05, Data accessibility ~0.03, Government support ~0.25
    - **Australia**: Total ~0.32; Data availability ~0.05, Data accessibility ~0.02, Government support ~0.25
    - **New Zealand**: Total ~0.31; Data availability ~0.05, Data accessibility ~0.01, Government support ~0.25
    - **Mexico**: Total ~0.30; Data availability ~0.05, Data accessibility ~0.1, Government support ~0.15
    - **Belgium**: Total ~0.29; Data availability ~0.05, Data accessibility ~0.09, Government support ~0.15
    - **Greece**: Total ~0.28; Data availability ~0.05, Data accessibility ~0.08, Government support ~0.15
    - **Iceland**: Total ~0.27; Data availability ~0.05, Data accessibility ~0.07, Government support ~0.15
    - **Costa Rica**: Total ~0.20; Data availability ~0.05, Data accessibility ~0.05, Government support ~0.1
    - **Chile**: Total ~0.18; Data availability ~0.05, Data accessibility ~0.03, Government support ~0.1
    - **Türkiye**: Total ~0.15; Data availability ~0.05, Data accessibility ~0.0, Government support ~0.1
    - **Brazil**: Total ~0.50; Data availability ~0.1, Data accessibility ~0.2, Government support ~0.2
    - **Peru**: Total ~0.40; Data availability ~0.1, Data accessibility ~0.1, Government support ~0.2
    - **Croatia**: Total ~0.30; Data availability ~0.1, Data accessibility ~0.1, Government support ~0.1
    - **Romania**: Total ~0.28; Data availability ~0.1, Data accessibility ~0.08, Government support ~0.1

Source: (OECD, 2023[52]).

A key question is how to increase the value of open government data for Al systems by design, and thus its accessibility and Al-readiness. On the one hand, the standardisation (e.g. in terms of structure and formats) of open government data can reduce the time Al-developers need to invest in preparing data to train Al-systems. On the other hand, the increased use of tools, such as APIs, can also support data integration with Al-systems by providing a standardised method for sharing and accessing data automatically, directly from its source. Today only 47% of high-value datasets are released with APIs (OECD, 2023[52]).

Beyond open data, other relevant initiatives include increasing access to large government-held or publicly funded datasets, such as Korea's Al Hub Data Finder (2024[53]), which provides access to text, imagery, video, audio and sensor datasets relevant for Al-training in areas such as healthcare, public transportation and disaster and safety.

## Using private sector data
Both public and private sector data can play a vital role in developing Al applications for government. While government data provides essential insights into demographics and public services, private sector data — such as on mobility patterns, consumer behaviour and financial trends — can enhance these insights. For example, Al systems for urban planning can benefit from telecommunications data to analyse traffic flow, while healthcare Al can leverage anonymised patient data from private clinics to improve disease prediction. By combining both sources responsibly and ethically, Al applications can become more accurate, efficient and responsive to public needs. One example of pooling and combining data from the public and private sectors is the Common European Data Spaces. The purpose of the data spaces is to

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
118 |
make more data available for access and re-use across the European Union in a trustworthy and secure environment for the benefit of European businesses and citizens (OECD, 2024[54]; EC, 2025[55]).

## Creating a conducive environment with data governance
From enabling data access and sharing to building the foundations necessary to make Al in government a possibility, governments need to develop robust "data governance" arrangements, which can be integrated into broader Al strategies and policies (OECD, 2024[3]).

> Data governance refers to “diverse arrangements, including technical, policy, regulatory and institutional provisions, that affect data and their creation, collection, storage, use, protection, access, sharing and deletion, including across policy domains and organisational and national borders” (OECD, 2022[56]).

Originally developed to explore the specific arrangements that should be in place to enable data access and sharing, the OECD framework for data governance in the public sector can be applied to the context of data for Al-systems (Figure 4.2). Governments can develop data governance capabilities in the public sector by prioritising the development of comprehensive data strategies, defining leadership roles and establishing a vision for managing and governing data at a more technical level to realise Al's intended benefits and outcomes.

# Figure 4.2. Data governance in the public sector

### Diagram Extraction

**Central Element:** PUBLIC SECTOR DATA

**Layers and Components:**

**STRATEGIC LAYER**
- **A. LEADERSHIP AND VISION**
    - E.g. CDOs, Data policy (incl. data openness, access, sharing, security and protection), Data strategy (milestones, timeframes), policy levers

**TACTICAL LAYER**
- **B. CAPACITY FOR COHERENT IMPLEMENTATION**
    - E.g. Data committees, task forces, data stewards, skills and training, funding, experimentation and data innovation
- **C. REGULATION**
    - E.g. Rules, guidelines, guides (e.g. for data publication, data sharing and interoperability)

**DELIVERY LAYER**
- **D. DATA VALUE CYCLE**
    - E.g. Actors, roles and technical skills. Data management (e.g. data validation, process re-engineering, data sharing and integration, openness and reuse, data ownership and consent, bias and data integrity
- **E. DATA INFRASTRUCTURE**
    - E.g. Data federation, data registers, data catalogues, data lakes, APIs, cloud-based solutions
- **F. DATA ARCHITECTURE**
    - E.g. Standards, reference data, interoperability, semantics, relationships

Source: (OECD, 2019[57]).

For example, Canada's 2023-2026 Data Strategy for the Federal Public Service outlines the desired outcomes and guiding principles to advance sound data governance across the federal government as a whole, along with expectations for roles and responsibilities.22 Other examples include the United Kingdom's National Data Strategy and Australia's Data and Digital Government Strategy.23 Greece (2024[47]) is pursuing a flagship programme on Data Governance and Al Strategy Coordination to establishing elements necessary to support an Al-ready public and private sector. The US policy discussed in Box 4.1 puts in place several requirements to improve data governance. It is also important to embed stakeholder engagement with data rights holders, such as with citizens, businesses and civil society representatives, who could be impacted by the use of data for Al — either in the context of intellectual

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# | 119

property rights or personal data rights (OECD, 2022[58]), or by the potential use of inadequate or skewed data.

Governments should support their vision and strategy on data for Al with adequate capacity for consistent implementation across the public administration, along with guidelines and legal frameworks to ensure effectiveness (OECD, 2019[59]). This can include numerous areas, such as improving data literacy and skills for Al, with examples such as Brazil's CAPACITA GOV.BR initiative24 and Argentina's National Programme for Enhancing the Protection of Personal Data. This can also include efforts to boost coordination and institutional collaboration, with examples such as the Norwegian Resource Centre for Sharing and Use of Data (Digdir, 2024[60]). Finally, it is essential to recognise the enabling role of legal frameworks that orchestrate and accelerate the integration and exchange of data between public institutions, while safeguarding individual rights and privacy. Clear, modern and applicable legislation on data governance and personal data protection is important for deploying trustworthy Al systems at scale. In Chile, a draft Data Governance Bill is currently under discussion, which defines principles, roles and interinstitutional coordination mechanisms for data governance. In addition, a new Personal Data Protection Law, aligned with international standards, is entering into force. Other examples include Ireland's Data Sharing and Governance Act 2019 and the EU General Data Protection Regulation (GDPR), Data Act, Data Governance Act, Open Data Directive and data interoperability frameworks.25

Finally, the delivery portion of data governance refers to the processes, mechanisms and tools that enable the operational implementation of data governance at the organisational and team level, ensuring that sound data governance and management practices are implemented and integrated across the Al data value cycle (OECD, 2019[59]). One example is the United States (2024[61]) assessment for Data Operations (DataOps) maturity across federal agencies as part of its Al Guide for Government. This framework evaluates how well organisations can discover, access and utilise data to support Al development throughout the data value lifecycle. Key components include securing a comprehensive data asset catalogue, flexible data access methods and tools that facilitate documented Al experiments. Other key components of delivering data governance are the technical skills and job profiles needed, including data scientists, domain experts, data engineers and data providers, who are involved in data collection and processing for AI (OECD, 2022[58]). Issues related to data infrastructure are covered in the next section.

# Building out digital infrastructure

Ensuring the availability of reliable and scalable digital infrastructure can assist in supporting and scaling Al in government. In addition to data itself, as discussed in the previous section, data infrastructure, scalable computing platforms, Al foundation models and common Al tools are important building blocks for Al in government. Other forms of digital infrastructure also exist and are discussed in OECD work (2024[62]). This section focuses on those most relevant to Al.

In their attempts to purse trustworthy and scalable Al systems, governments are confronted with strategic decisions with regards to Al systems. On one hand, building national capacity through the development of national digital infrastructure can help a country in implementing its own data protection and privacy rules. A number of countries are seeking to develop such capacity (Letzing, 2024[63]; France Élysée, 2025[64]; African Union, 2024[65]; Ray, 2025[66]; EC, 2025[67]; Brizuela et al., 2025[68]). On the other hand, this could also contribute to technological fragmentation and closed ecosystem that limit international collaboration (Komaitis, Ponce de León and Thibaut, 2024[69]; Frazier, 2025[70]). Governments need to consider various options in determining a balance that is appropriate to them for developing solutions in-house versus in collaboration with the private sector and with other countries.

Digital infrastructure is not only relevant for national governments; it can also be formative in Al adoption in subnational governments, such as cities. The development of shared and reusable digital tools can help local governments overcome the entry costs due to the underlying economies of scale and allow Al solutions to be tailored to local needs and contexts.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# 120 |

## Computing power and data infrastructure

Access to computing infrastructure resources can be key to the effective development and use of Al in government (OECD, 2022[71]). Choosing between on-premises and cloud solutions for Al deployment depends on specific needs, political choices, regulatory requirements, budget constraints and long-term goals.

On-premises solutions offer greater control, customisation and security, making them suitable for highly sensitive applications and to conform with data localisation laws (Redapt, 2023[72]). Cloud solutions, on the other hand, provide unparalleled scalability, cost efficiency and access to cutting-edge Al technologies, making them ideal for dynamic and rapidly evolving projects and more practical than on-premises solutions for small projects or newer or smaller entrants to Al development (Dombo, 2023[73]). More than half of OECD countries have cloud technology initiatives in place, including storage and computing capabilities (Infrastructure as a Service, or laaS). Notably, access to cloud technologies relies on both public and private solutions (48% vs. 52% respectively), with several countries pursuing the development of public-sector-led cloud technologies (OECD, 2024[74]). In many cases, a hybrid approach combining both on-premises or otherwise dedicated infrastructure and public cloud (shared, third-party) resources (“hybrid cloud") can offer a balanced solution, leveraging the strengths of each. Notably, work by RAND (2024[24]; 2025[25]) found that among companies, those who are able to use cloud solutions generally did not face challenges in securing adequate compute, but those who could not transfer data to the cloud faced significant challenges that contribute to Al project failure.

The global demand for Al-ready data centre capacity could triple by 2030, demonstrating the growing use of Al (McKinsey, 2024[75]). Carbon emissions produced by data centres and data transmission networks are already estimated to be 1% of all energy-related emissions, but have generally grown only modestly despite rapidly growing demand for digital services due in part to increased hardware and model efficiencies over time (OECD, 2022[71]; IEA, 2023[76]). Recent analysis from the International Energy Agency (IEA) (2025[77]) found that data centres are among the fastest growing sources of emissions and that such emissions could increase significantly in the next ten years, but also that “widespread adoption of existing Al applications could lead to emissions reductions that are far larger than emissions from data centres". Nevertheless, the sizeable carbon emissions linked to data highlights the need for practices to manage Al's energy requirements. Increasing amounts of water needed to cool data centres is also important to recognise (Metz et al., 2025[78]). Recent research and industry developments indicate a growing trend in Al towards the adoption of smaller and/or more specialised models, such as small language models (SLMs) that consume fewer resources, require less data and are less expensive (Hassani et al., 2022[79]; Jones, 2025[80]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 121

## Box 4.5. Korea's shared data centres and government cloud

Korea's National Information Resources Service (NIRS) has been working with the Ministry of the Interior and Safety to upgrade key hardware, networks and management tools to help modernise Korea's technology and enable migration to the cloud. A critical part of this has been the construction of new government data centres, which can help ensure compliance with government requirements, cost-efficiencies with a reduced technology footprint, and job creation and local investment in target areas. These data centres have also been made available to the government's main partners in the private sector, which helps ensure that companies holding or handling sensitive data are doing so in an environment that meets the government's requirements for security, back-up and redundancy, among others. With measures around sustainability and renewable energy, the data centres help reduce the environmental impact of Korea's digital government, particularly as it prepares to make greater use of Al solutions.

Source: OECD Digital Government Review of Korea (forthcoming).

In seeking a holistic approach, some countries are establishing compute and data infrastructure as part of a package of efforts, including approaches to digital public infrastructure (DPI),26 to support the secure and meaningful exchange of data across government, underpinned by strong data integration and analytics capabilities. Such infrastructures not only help scale Al use but can also foster interinstitutional collaboration and the generation of public value from data. Take, for example, Brazil's National Data Infrastructure (IND).27 This strategic initiative establishes a set of policies, standards, technologies and governance mechanisms to organise, share and manage public sector data securely and efficiently. Its main objective is to make government data findable, accessible, interoperable and reusable (FAIR principles), promoting transparency, the improvement of public services, administrative efficiency and evidence-based decision-making throughout government, serving as a foundation for digital transformation and innovation. The country's gov.br platform serves as a central hub for integrating access to nearly 5 000 digital public services and includes a Conecta gov.br platform as a data interoperability layer across government. These platforms and other digital infrastructure are a foundation for Al in government. In another example, Saudi Arabia's national cloud platform, Deem Cloud, developed by the Saudi Data and Artificial Intelligence Authority (SDAIA), consolidates digital infrastructure across more than 190 public entities and over 260 data centres (SDAIA, 2025[81]). It provides a suite of cloud services to support secure and efficient digital operations, and has contributed to energy and cost savings, as part of broader efforts to modernise public sector infrastructure and support national digital strategies. Focused more on compute, Greece (2025[82]) is building DAEDALUS, which is set to be one of the most powerful supercomputers in Europe and will be accessible to public institutions.

## Developing Al foundation models

Foundation models are a form of Al models trained on large amounts of data — generally using self-supervision at scale — that can be adapted to a wide range of downstream tasks (OECD, 2024[83]). Governments can develop their own foundation models or build upon existing ones to create approaches tailored to the specific context of a country and/or its public. Foundation models can be "fine-tuned” through further training on narrower datasets related to a particular task or domain, enhancing its performance for that specific context (Montgomery, Rossi and New, 2023[84]).

Building a clean sheet foundation model is generally considered expensive and typically requires significant data and power resources. Examples of privately developed, proprietary foundation models include Mistral Large and those that power Anthropic's Claude (e.g. Claude 3.7 Sonnet), Google Gemini (e.g. Gemini Ultra) and OpenAl's ChatGPT (e.g. GPT-5).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# 122 |

Although they can be costly and require vast data assets and energy use, governments can indeed train and build their own foundation models, as discussed in Chapter 3. Governments can also fine-tune and tailor a proprietary foundation model to better meet its own context, which can significantly reduce the financial and time costs associated with deploying Al for specific tasks. An example of this approach is Portugal's ChatGPT-enabled public virtual assistant for public services (Box 5.46).

Governments can also use "pre-trained” open-source models. These are foundation models that have been trained by a company or other organisation that made its “model architecture and weights freely and publicly accessible for anyone to modify, study, build on and use” (Seger et al., 2024[85]).28 Most open-source models are created by large technology companies, such as Meta's Llama series, although more organic, open-source community-driven models have been developed, such as the BigScience Large Open-science Open-access Multilingual Language Model (BLOOM).29 An example of a government leveraging open-source Al models is France's Albert virtual assistant for public servants (Box 5.46).

A foundation model that is tailored to a national and governmental context — such as through fine-tuning a proprietary model or customising an open-source model — can significantly reduce the cost of adoption for teams wanting to deploy Al. Yet development and use of foundation models comes with risks that governments should keep in mind, as discussed in Chapter 1.

Governments are increasingly demonstrating interest in investing in national or regional foundation models to enhance technological sovereignty and better reflect different languages and cultures. For instance, Latam-GPT, led by Chile, is being developed by over 30 Latin American institutions to create a model trained on regional data (Gob.cl, 2025[86]), OpenEuroLLM is an EU-funded initiative to build open-source models covering all official European languages (EC, 2025[87]), and context and language-tailored models have emerged in Southeast Asia (Noor and Kanitroj, 2025[88]). Similarly, Italy's Minerva project has developed the first LLM trained from scratch for the Italian language and is one of the few examples in this context of tailored foundation models being developed from the ground-up (University of Rome Sapienza, 2024[89]).

## Common Al tools

Common Al tools that can be used across an entire government, and tailored to specific governmental needs, can serve as a form of DPI that enables and enhances other services. Sometimes built with foundation models — sometimes provided as another type of DPI — these tools provide a shared service layer and can support the automation of routine tasks, improve user interaction and enhance service delivery.

For instance, chatbots can handle a large volume of citizen inquiries, providing instant responses to common questions and relinquish human resources for more complex tasks. This not only improves efficiency but helps ensure that public services are more accessible and responsive to the needs of the community. To be considered DPI, these Al tools should solve a common, basic need and thus be usable across a wide range of public sector organisations. An example of this approach is Singapore's Virtual Intelligent Chat Assistant (VICA), provided as a shared service and used by more than 60 government agencies to create over 100 chatbots.30

Common tools for supporting Al do not always use Al. In other examples:
*   Singapore's Whole of Government Application Analytics (WOGAA) has been developed as a government tool for monitoring the performance of government websites and digital services, including those enabled by Al, providing a central dashboard to track website traffic, automated reports with key metrics, benchmark performance compared to other government websites and more.
*   In Estonia, to implement the once-only principle, all public databases are mandatorily described in the catalogue of interoperability resources (RIHA), which serves as the national registry of systems,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 123

components, services, data models, semantic assets and more, guaranteeing the transparent, balanced and efficient management of public information systems.
*   France's aforementioned ALLiaNCE Al incubator fosters the development of reusable Al products across administrations, aiming to mutualise efforts and reduce duplication. ALLiaNCE provides a multi-layered service offering, including Al-enabled tools embedded in France's digital suite (La Suite Numérique), as well as a foundational layer — Albert API — to support cross-sectoral re-use of GenAl systems. As a digital common, Albert API provides open, reusable GenAl systems, lowering the adoption threshold for public agencies and contributing to a national DPI for Al. The ALLiANCE incubator also prioritises data sovereignty and open, sovereign digital solutions, reflecting government efforts to mitigate dependency risks and ensure trust in Al systems.

The OECD.Al Catalogue of Tools & Metrics for Trustworthy Al includes a variety of tools from inside and outside governments that may help inform them in determining their own needs.31

# Fostering skills and talent

As discussed in Chapter 3, skills gaps are one of the most significant challenges to the adoption of trustworthy Al in government. Governments should therefore take commensurate actions to build internal competency and capacity.

Governments should equip civil servants with the right skills to maximise Al's effectiveness, while ensuring safe, secure and trustworthy use. An Al-ready public service is instrumental for the development and deployment of Al solutions, as well as for the effective use of Al-powered tools to enhance daily tasks and policymaking. A strategic and coordinated approach to Al skills and talent can help target different groups within the workforce, identify skills gaps, develop the right skills and attract and retain more specialised Al talent. Strong in-house skills can also contribute to building national capacity, a topic discussed in the previous section.

This may include recruiting individuals with the skills needed to work with Al, as well as the upskilling of existing roles. Governments will need to anticipate that as Al evolves, the necessary skills will also, calling for continuous learning. A solid approach will require a needs assessment to map the current level of capability for data and Al in the existing workforce, to identify the key gaps and inform the strategy to addresses these needs. This would mean being able to take informed decisions among recruitment, retention and development of digital talent. This could also inform tailored training programmes to address skills gaps, and an approach to manage and train (i.e. through skilling, upskilling or reskilling) the roles most affected by the integration of Al.

## Assessing the needs of different user groups

Government institutions should assess the needs of different user groups to take up Al and use it effectively. An Al-ready workforce ranges from general users of Al systems to institutional leaders, data and digital professionals, and the more specialist roles. As illustrated in Figure 4.3, user groups become narrower and more specialised further down the pyramid.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# 124 |
Figure 4.3. Considering the level of Al literacy needed for different user groups in the workforce

**Users within the public sector**

**General users (e.g. non-specialised public servants)**
of AI systems in government.
Critical to the uptake and the effective and trustworthy use of AI.
Focus on broad AI literacy and trustworthy use.

**Leaders**
Decision makers who consider, manage and integrate AI.
Where technology meets the business of government.
Focus on skills needed to drive awareness, adoption and training.

**Data and digital professionals**
Key roles for data, user-centred design, product
management and service design and delivery.

**Specialists**
Technical roles for those developing, deploying and managing AI systems.
Small but specialised workforce (internal and external capabilities).
Enhanced Al literacy for specialist legal, procurement and project management roles.

General, non-specialised public servants are critical to the adoption and effective use of Al. Their training should focus on general literacy around data and Al technologies, their effective use with respect to given tasks and the ethical and legal consideration for their use.

Leaders will be integral to the adoption of Al, being the layer where the technology meets the business of government. They help raise awareness among users, drive adoption of Al and promote learning and development opportunities in public administration. This user group needs a strategic vision and executive-level understanding of what Al technologies can do, their impact and how to address risks, compliance, funding and workforce management.

Data and digital professionals spearhead and facilitate the design, development and implementation of specific services. This user group needs a higher degree of Al literacy to comprehend how Al should be deployed to deliver the intended objectives for the services they are responsible for. Along with specialists, this group may be responsible for procuring Al through public procurement processes. Thus, the right set of skills can empower them in negotiations with vendors seeking to sell Al products and services.

While a smaller part of the workforce, Al specialists are critical for the development, deployment, management and use of Al systems. They extend beyond direct Al development, including roles in procurement, legal and project management. To develop this user group, governments need to target attraction, retention and learning and development. Additionally, to overcome potential skill shortages in the market, government organisations can also consider leveraging external capabilities through public procurement and partnerships, as discussed below.

## Preparing civil service users
A civil service ready for Al will require a combination of foundational digital skills and more specific literacy in data and Al. The OECD Policy Framework for Digital Talent and Skills in the Public Sector (OECD, 2021[7]) outlines the various foundational digital skills applicable to every public servant, essential for supporting digital transformation:

*   understanding potential of digital transformation
*   understanding users and their needs
*   collaborating openly for iterative delivery
*   trustworthy use of data and technology
*   skills to enable a data-driven public sector
*   digital government socio-emotional skills
*   digital government leadership skills.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

# | 125
For an Al-ready workforce, it is necessary to build on these foundations with the literacy needed for "individuals to critically evaluate Al technologies, communicate and collaborate effectively with Al, and use Al as a tool online, at home, and in the workplace" (Long and Magerko, 2020[90]). This includes understanding Al systems, data handling and management, and ethics. One approach, for example, is the Al Skills for Business Competency Policy Framework developed by The Alan Turing Institute in the United Kingdom (2023[91]), which has five dimensions:

*   **Privacy and stewardship:** to mitigate risks around data security and protection, especially with regards to legal, regulatory and ethical considerations.
*   **Specification, acquisition, engineering, architecture, storage and curation:** for the handling and management of data to enable more effective and ethical use of Al systems.
*   **Problem definition and communication:** to identify, define and communicate those 'problems' that benefit most from the application of Al solutions.
*   **Problem solving, analysis, modelling, visualisation:** including range of tools and methods that can be used for analysis, Al application and communication.
*   **Evaluation and reflection:** to understand the impact of work on Al, assess efficiency and effectiveness of Al projects and identify opportunities to improve.

The level of competency and the extent to which each is required varies depending on the user group, existing capability or level of capability required for their roles. However, this combination of digital foundations and Al skills should lead to a more effective use of Al in government.

## Developing skills and talent
To develop Al skills and talent in the public service, governments should consider both internal development practices, as well as the broader recruitment of key talent. Key mechanisms for developing existing talent include the items below, with additional examples provided in the OECD/UNESCO (2024[29]) G7 Toolkit for Al in the Public Sector.

*   **Competency frameworks** outline the key skills and learning pathways for the workforce, which should be tailored according to the needs assessments and user groups outlined above. This could also contribute to the professionalisation of key Al roles for government. For example, the EC's Joint Research Centre (JRC) has developed a comprehensive competency framework (Box 4.6). India has also developed a dedicated competency framework to prepare public officials to lead Al transformation responsibly, tailoring content for different types of officials.32
*   **Formal learning** can include courses, workshops and online modules. For example, Ireland provides a number of relevant courses, including training on Al in the Public Service and on the country's Guidelines for the Responsible Use of Al in the Public Service; and Greece's Hellenic Ministry of Internal Affairs in collaboration with Google has created Al training courses for public servants.33 The globally available free and open course Elements of Al can help improve foundational Al literacy for public servants and citizens alike.34
*   **Informal learning**, including through communities of practice, mentoring or job rotations, among others, can help raise awareness and drive adoption. Such approaches are discussed further below.

## Box 4.6. European Union competency framework for Al in government
The EU has developed a comprehensive competency framework to guide public servants in effectively adopting and managing Al. This framework, elaborated by the Joint Research Centre (JRC), is based

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

# 126 |
on empirical research, including literature reviews, expert workshops and case studies, and identifies key competencies necessary for Al integration in public administration.

The framework classifies competencies into three main dimensions:

*   **technical competencies:** encompassing knowledge and skills related to data management, machine learning and Al system implementation
*   **managerial competencies:** addressing project ownership, knowledge brokering and decision-making in Al-related initiatives
*   **policy, legal and ethical competencies:** covering Al procurement literacy, auditing and collaboration with domain experts to ensure compliance and ethical considerations.

Additionally, competencies are grouped into three cross-cutting clusters related to (i) attitudinal competencies (know-why), referring to mindsets and dispositions that support Al adoption, such as technology inquisitiveness and a data-oriented culture; (ii) operational competencies (know-how), covering practical skills for Al implementation, including database management, algorithm training and decision-making processes; and (iii) literacy competencies (know-what), related to fact-based knowledge of Al concepts, regulatory frameworks and fundamental machine learning principles.

Beyond developing the framework, the JRC's work gives three key recommendations on competencies:

1.  develop focused, interdisciplinary Al competence training programmes
2.  promote applied interdisciplinary research on Al competences
3.  establish dedicated hiring processes and devote additional resources to attracting specialists with Al competences.

Source: https://publications.jrc.ec.europa.eu/repository/handle/JRC138702.

Developing Al-related skills internally should be complemented by external strategies to attract top talent and retain skilled public servants. The European Union's competency framework for Al in government highlights the need for a structured approach to Al skills development, emphasising technical, managerial and policy-related competencies. Canada's *Digital Talent Strategy* aligns with these principles, recognising that Al adoption in the public sector requires a balance of attitudinal (know-why), operational (know-how) and literacy (know-what) competencies to build an Al-ready workforce.35

To address critical skill gaps, targeted recruitment efforts and dedicated hiring processes are essential. The US Office of Personnel Management's (OPM) Skills-Based Hiring Guidance and Competency Model for Al offers a structured approach to defining and assessing Al job classifications, 36 while the EU framework underscores the importance of interdisciplinary training programmes and applied research. Governments should also focus on competitive compensation, clear career pathways and workplace flexibility to attract and retain Al talent.

Where internal capacity remains limited, partnerships with industry and academia, as well as strategic procurement of external expertise, can provide necessary support. The sections below on public procurement and Al partnerships explore these strategies further, offering policy examples. Additionally, continuous assessment of workforce alignment, progress in closing Al skill gaps and the effectiveness of learning initiatives is critical. By integrating competency-based insights from global best practices, governments can ensure their digital workforce evolves alongside technological advancements, ethical considerations and shifting labour market demands.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

# | 127
## Facilitating connections and knowledge exchange
Communities of practice and networks allow for collaboration, learning, the sharing of expertise across organisational boundaries and the identification of collective or common problems. They can also serve as a useful conduit for soliciting user feedback on internal Al systems and services. The EC JRC competency framework (Box 4.6) notes that such activities can be critical for helping public servants gain know-how on Al and to help overcome challenges with early Al adoption. This framework outlines three action points for developing communities of practice: 1) create associations with relevant stakeholders, 2) deploy digital platforms for the communication and collaboration of involved entities, and 3) finance synergy grants for public-private collaboration and knowledge exchange, which can help reduce knowledge asymmetries and spark joint ventures.

Disseminating successful methods, strategies and use cases through such methods can help government organisations replicate and scale Al projects more effectively (OECD/UNESCO, 2024[29]). This approach helps avoid common mistakes, helps ensure consistency and accelerates the adoption of Al technologies across various government entities. For example:

*   Estonia's skills development programme includes a data expert network with 500+ participants, Al meetups and experimentation events (e.g. hackathons, competitions) (OECD/UNESCO, 2024[29]).
*   Chile's Network of Public Innovators connects over 30 000 public servants from all levels of government and other relevant actors for collective learning, creation and experimentation, including on Al.37
*   Canada's Data Conference serves as the primary forum for public servants and data leaders to enhance awareness, share knowledge and advance data applications throughout the Canadian government.38 Additionally, department-led working groups on Al topics enable public servants across various departments to share experiences and insights, fostering collaboration and innovation in Al implementation (OECD/UNESCO, 2024[29]).
*   The International Smart Cities Network, led by Germany, promotes international exchange and knowledge transfer at national and local level by serving as a place for international dialogue and sharing of ideas and best practices.39
*   France established ALLiaNCE and Communauté des labos; informal inter-ministerial groups for sharing Al best practices.40
*   In Switzerland, the Competence Network for Al has promoted communities of practice to understand common challenges in the implementation of Al systems, including in public administration.41

Such communities and networks need not be specifically focused on Al; in fact, more general groups can help surface a broader base of relevant issues and better consider alternative approaches. However, governments may want to develop additional Al-focused communities and networks or to ensure that general communities and networks include individuals with Al expertise in order to help identify links between problems and Al approaches that may constitute an optimal solution.

## Bringing together multi-disciplinary skillsets and perspectives
Digital and Al skills are not the only ones relevant to designing and using Al in government. Some governments have sought to create one or more multidisciplinary teams to ensure Al initiatives benefit from diverse perspectives and expertise. The sensitivity and complexity around Al require the involvement of experts from a range of disciplines, including technology, ethics, law and public policy, to set a strategic approach to the use of Al. Such teams can provide a diversity of perspectives and expertise, thereby facilitating the identification of potential risks, and ensuring comprehensive and inclusive Al use across public administration (Berryhill et al., 2019[4]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

# 128 |
# Investing purposefully
Governments are increasingly investing in Al by funding government Al initiatives. Estimates indicate that governments may increase their annual spending on Al-related technologies by 19% in 2025 and continue increasing thereafter (Gartner, 2024[92]). It is essential governments strategically plan, implement and monitor Al investments in government to ensure value for money, identify and mitigate potential investment risks, implement and deploy technologies in a timely manner and evaluate whether intended benefits are realised (OECD, 2025[93]).

The 2023 OECD DGI (2024[74]) shows countries have not yet developed robust capabilities for managing digital investments in the public sector. While 88% of OECD countries have a standardised approach to developing value propositions, only 41% have developed a risk assessment mechanism for digital government investments, including operational (e.g. cybersecurity, service access disruption or related to use of legacy technologies) and financial (e.g. ROI uncertainty, sustainability of funding or overhead and maintenance) risks. To advance towards trustworthy Al investments in government, countries can develop assurance mechanisms, including:

*   strengthening strategic planning
*   supporting coherent investments across government
*   reinforcing investment monitoring mechanisms.

A whole-of government coordination across these three domains will allow governments to invest in Al systems capable of delivering governments' policy objectives on time and on budget. The following sub-sections review these domains.

## Strengthening strategic planning for coherent investment
Governments should coordinate with key stakeholders to plan and manage Al investments based on clear principles. Establishing such principles can help to ensure that investment decisions are consistent with overarching strategic objectives. For instance, articulating a commitment to developing more proactive services could result in increased funding and management support for the implementation of Al chatbots for government-citizen interaction. Moreover, coordination among budgeting, digital government and public procurement authorities can help identify Al needs and align them with available resources and potential acquisitions from and partnerships with the private sector. Germany has sought to achieve this through a 2024 Al mission statement that is complemented by a new Centre for Al in Public Administration (BeKI) as an initiating and coordinating body for Al investments and guidance in the federal administration (OECD, 2024[94]).42

Governments can also use existing management tools, such as value proposition and investment risks assessment mechanisms to reinforce assurance and secure coherence in investment decisions on Al systems. Adapting value proposition mechanisms to the specificities of Al systems allows governments to strengthen assurance processes for trustworthy development and use of Al. This includes the assessment of key Al aspects such as compliance with regulation and policy standards. The value proposition can include a risk and impact assessment that measures and evaluates the benefits and potential risks of Al systems in government, as well as the plans to comply with regulations. For example, Australia has released a Pilot Al Assurance Framework to guide agencies in aligning Al use cases to Australia's Al Ethics Principles, identify impacts and risks, and apply mitigations.43

## Funding Al and supporting coherent investments across government
Although often overlooked in national Al strategies, funding and financing mechanisms are an important consideration for government applications of Al (van Noordt, Medaglia and Tangi, 2023[95]). Even simple initiatives need some level of funding and financial support to make their way from idea to reality, with

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 129
significantly more funding needed to scale-up a successful project. The availability and nature of this
financing can contribute greatly to the eventual success of Al-based innovation. Conversely, a lack of
funding for Al development and implementation is a top barrier to government Al adoption (EC, 2024[96];
UK NAO, 2024[16]). Targeted financial resources can support Al experimentation and scaling, as well help
in reducing fragmented efforts and uneven adoption of Al. The European Commission (EC) (2024[96]) has
recently noted this in a 2024 study on strategic Al adoption for public services, recommending governments
increase funding and resources for their use of Al. Examples of specific funding vehicles include:

*   The US Technology Modernization Fund (TMF) opened a special call for Al investments to support
    public agencies as part of a broader funding mechanisms designed to replace outdated legacy
    IT.44
*   In France, the Fund for the Transformation of Public Action offers financial support for public sector
    institutions seeking to improve policies and services with Al, in particular for project proposals with
    potential for scalability and replicability across the public administration.45
*   The United Kingdom is investing GBP 110 million to accelerate the Al use in the government,
    including adding capacity to its Incubator for Al (i.Al), and it has committed to providing GBP 10
    million to boost regulators' Al capabilities (Cover-Kus, 2024[97]; UK House of Commons, 2024[98]).
*   In Poland, government departments have been asked to set aside a percentage of their budget for
    Al procurements (van Noordt, Medaglia and Tangi, 2023 [95]).

# Monitoring mechanisms for coherent investment
Ensuring the on-budget and on-schedule development and deployment of Al investments contributes to
the realisation of benefits and delivery of intended results. In line with general investments on digital
technologies, governments can leverage monitoring tools to oversee the management and development
of Al systems across the administration. These activities should consider developing key performance
indicators (KPIs) and structured approaches to manage ongoing developments on Al systems through IT
portfolio management. Such management tools can enable or complement guardrails for Al development
focused on trustworthy development, deployment and use of Al in government. These approaches can
consider quality control mechanisms, linking them with the planning and monitoring of digital investments
to secure coherency across the Al system lifecycle. Countries have developed guidance to embed
monitoring and measurement actions in the investment cycle of Al initiatives. For example, France uses a
monitoring tool to track major digital state projects, including Al initiatives, costing over EUR 9 million. 46 It
lists strategic IT projects and helps identify actions for success. The tool monitors project distribution by
ministry, progress phase, functional area and estimated cost (OECD/UNESCO, 2024[29]). However, most
countries still face the challenge of deploying continuous or ad-hoc monitoring practices. Recognising the
need to develop specific capabilities and plans for Al policy monitoring, Norway's Office of the Auditor
General (OAG) started auditing the Al use in the central government as part of its pipeline of new
performance audits since 2023. At the executive level, the country is taking steps to strengthen the
monitoring and oversight of the portfolio of government Al projects through regular internal audits,
performance monitoring and impact assessments (OECD, 2024[99]).

# Using public procurement to obtain Al products and services and guide the market
Fit-for-purpose public procurement processes and mechanisms are key to enabling agile and cost-effective
access to Al systems developed by third parties, ranging from large companies to start-ups and
entrepreneurs. Beyond simply purchasing solutions or contracting resources, procurement serves a key
strategic approach, which uses purchasing as a bridge to connect public missions and objectives with
societal needs and values. To fulfil this role effectively, procurement officials should conduct a
comprehensive evaluation of Al's consistency with internal objectives, adherence to fairness and
transparency standards, resource efficiency, risk mitigation (e.g. biases or security vulnerabilities),

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
130 |
engagement with stakeholders and impacted groups, and compliance with relevant legal and regulatory
frameworks.

In promoting the effective deployment of Al technologies, public entities could consider adopting
procurement mechanisms that foster agility, iteration and innovation. The process needs to start with
careful preparation and planning to achieve flexible and efficient procurement processes that encourage
broad participation which is open and accessible to all (UK DSIT, 2020[27]). This preparatory phase should
include:

*   the establishment of a multidisciplinary team to support the procurement of the Al systems
*   an assessment of current data and governance approaches to evaluate readiness and existing
    capabilities and resources for the effective training and use of Al systems, as relevant
*   an assessment of potential risks throughout Al lifecycle and the identification of associated
    mitigation strategies.

## Agile and innovative procurement methods
Agile and innovative procurement methods provide opportunities to accelerate the adoption of new
technologies within governments and on the trustworthy development and use of Al (Monteiro, Hlacs and
Boéchat, 2024[100]). These can include technology contests, demonstrations, challenge-based
procurement processes and competitive dialogues (UK DSIT, 2020[27]). In addition, policy framework
agreements that set overarching procurement rules, priorities and guidelines — either specifically for Al or
with key vendors — can play a part in conducting business with the private sector, including for countries
with a less diverse set of procurement practices available to them. In Australia, for example, the
government used an existing agreement with a multinational technology company to deploy a widescale
pilot of an Al solution across its public administration (Australia DTA, 2024[101]). Policy framework
agreements can also take the form of predefined environments enabling Al procurement under broader
guiding principles. For instance, the EC (2024[96]) Adopt Al programme aims to modernise public
procurement for Al systems by fostering dialogue between public procurers and Europe's Al industry. It
promotes mutual understanding, drives industry investment and seeks to create a public procurement data
space. Sectoral dialogues bridge the gap between procurers seeking solutions and suppliers needing
insight into public administration plans (OECD/UNESCO, 2024[29]).

## Procurement as a lever for public good and trustworthy Al
Public procurement can be a strategic tool to shape the market and ensure Al systems align with
government standards. It also plays a critical role in setting requirements for Al systems that reflect public
values, ensuring accountability, security and fairness in Al adoption. For example, the EC set up model
contractual clauses to pilot procurements of Al in 2023, which were updated in 2025 to align with
requirements of the EU Al Act and provide comprehensive guidelines for high-risk applications and
customisable options for non-high-risk Al (2023[102]; 2025[103]).47 Australia, too, has established model
clauses. 48 At the sub-national level, the City of Barcelona, Spain, has introduced procurement clauses
emphasising data sovereignty, ensuring that data collected from the public, even by private companies,
remains publicly owned (Berryhill et al., 2019[4]). Public procurement guidelines are policy instruments that
can influence Al use globally. For instance, ChileCompra, Chile's public procurement agency, has
introduced a new tool to ensure procured Al systems are responsible and ethical (see Box 5.24).49
Internationally, initiatives such as the World Economic Forum's (WEF) (2025[104]) "Al Procurement in a
Box" provide structured guidance to help governments integrate Al procurement best practices and align
Al acquisitions with ethical and regulatory frameworks. In April 2025, the United States issued new Al
acquisitions policy that seems to promote agile procurement and the removal of unnecessary bureaucracy
and outdated procurement processes (Box 4.7).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 131

# Box 4.7. Driving efficient Al acquisitions in the United States
In the United States, the White House Office of Management and Budget (OMB) issued M-25-22 Driving
Efficient Acquisition of Artificial Intelligence in Government on 3 April 2025. It includes a variety of
requirements and recommendations for federal agencies regarding Al acquisitions across six
procurement phases. A non-exhaustive list of these include:

1.  **Identification of requirements:** convene a cross-functional team to inform the procurement of
    Al systems and assist in creating an initial list of potential risks to be evaluated. As practicable,
    consider which uses may be “high-impact Al” (Box 1.3).
2.  **Market research and planning:** seek state-of-the-art Al capabilities by conducting thorough
    market research, including through interagency knowledge sharing and considering novel
    capabilities from new entrants. Seek detailed demonstrations and tests of potentially useful Al
    to assess providers and identify obstacles to long-term cost effectiveness. Use performance-
    based techniques to identify requirements and contract terms to understand and assess vendor
    claims.
3.  **Solicitation development:** include in solicitations requirements that protect against vendor
    lock-in and terms related to IP rights and lawful use of government data, and when practicable,
    agencies must be transparent regarding whether the Al use could be considered “high-impact"
    and what this could mean to the vendor.
4.  **Selection and award:** test proposed solutions to understand their capabilities and limitations.
    Separately, agencies must evaluate proposals to identify any potential new Al-related risks that
    were not previously identified. Address in contract terms, where applicable, IP rights and the
    use of government data, privacy, vendor lock-in protections, compliance requirements for the
    policy discussed in Box 4.1, ongoing testing and monitoring, vendor performance requirements
5.  **Contract administration:** help ensure Al systems are authorised by an appropriate official prior
    to deployment, put in place contract oversight and monitoring processes for contract
    performance and to identify and mitigate emerging risks. Arrange for periodic evaluation of the
    Al system or service's value to the government, considering, as practicable, effectiveness,
    efficiency, risks, operations and maintenance costs and stakeholder feedback. Consider sunset
    criteria.
6.  **Contract close-out:** help ensure vendor lock-in protection, such as ensuring ongoing rights and
    access to any data or derived products.

To assist agencies, a centre of government agency will release publicly available guide(s) to assist the
acquisitions workforce with the procurement of Al systems, create a digital repository available to public
servants to facilitate the sharing of information, knowledge and resources about Al acquisitions (e.g.
best practices, tools, language for contract clauses, negotiated costs).

Source: (US OMB, 2025[105]).

# Procurement to shape the market
Beyond ensuring governments procure trustworthy Al for their own use, public procurement can act as a
powerful lever to influence more general market dynamics, driving innovation and aligning Al system
development with principles for trustworthy Al. Public procurement represents about 13% of GDP in OECD
countries (OECD, 2024[106]). By approaching procurement strategically, governments can use the
"economic weight of the government's purchasing power" to foster the development of Al solutions that

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
132 |
not only meet their needs but also promote broader alignment with ethical and regulatory standards (World
Bank, 2025[107]).

# Expanding Al's potential through partnerships
Governments can benefit greatly from ongoing, active cross-sector partnerships in which each sector has
a concrete role and contributions (OECD/CAF, 2022[30]). These partnerships can facilitate collaboration
among public entities and Al specialists in other sectors, including private sector companies and non-
governmental actors (e.g. academic institutions, foundations), promoting the development and
implementation of cutting-edge solutions. Public-private partnerships (PPPs) are perhaps the most
common type of arrangement. Some examples here include:

*   The European Union's InvestAl initiative seeks to mobilise EUR 200 billion in investment in Al
    through a PPP akin to a CERN for Al to enable to development of leading-edge Al systems across
    sectors. 50
*   As announced at France's February 2025 Al Action Summit, 10 countries are developing a Public
    Interest Al Platform and Incubator to support, amplify, decrease fragmentation between existing
    public and private initiatives on public interest Al, and address digital divides. It will support digital
    public goods, technical assistance and capacity building to foster a trustworthy Al ecosystem for
    public interest Al.51
*   Chile's Data Observatory (DO) is a non-profit organisation jointly led by government, industry and
    academia. It serves as is a technological centre that, through the management of large volumes of
    data, seeks to contribute to social well-being by promoting sustainable development of the country,
    contributing to the generation of enabling factors for optimal development of Al and promoting the
    creation of public policies and strategic decision-making based on evidence. 52
*   Portugal's ChatGPT-driven virtual assistant for public services (see Box 5.46) was developed
    through a PPP with the government and several companies.
*   Latvia's new Artificial Intelligence Centre is a private foundation co-founded by government,
    academia and industry, designed to promote the trustworthy and sustainable adoption of Al across
    sectors, including a specific focus on the integration of Al in public administration, and to ensure
    the incorporation of Latvian language and culture in Al systems.53

## Turning to GovTech startups
Bridging the concepts of public procurement and partnerships, GovTech is the collaboration between
government and start-ups, innovators, government “intrapreneurs” and academia on innovative digital
government solutions. It complements existing government capability for agile, user-centric, responsive
and cost-effective processes and services (OECD, 2024[108]). It aims to contribute to an agile government
and enhance digital government maturity. Not only does this help improve effectiveness and efficiency, but
it can also encourage the participation of start-ups and newer providers in the government market.
GovTech innovation is characterised by co-creation and experimentation. These collaborative interactions
aim to transcend traditional supplier-contractor relationships to build new forms of partnerships. Rather
than focusing on the detailed terms of reference and technical specifications, GovTech's focus is instead
on the solution's expected outcomes and on involving GovTech actors in building it. While many such
collaborations leverage public procurement (as discussed above), they can also use grants and monetary
prizes to incentivise the creation of innovative solutions (e.g. through demo days or incubator
programmes). The OECD has developed a GovTech Policy Framework to outline the factors important for
maximising GovTech engagements (Figure 4.4).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 133

# Figure 4.4. OECD GovTech Policy Framework

## GovTech Building Blocks
| Mature digital government infrastructure | Capacities for collaboration and experimentation | Resources and implementation support | Availability and maturity of suppliers |
| :--- | :--- | :--- | :--- |
| High quality data | Skills | Funding | Acceleration programmes |
| Data access and sharing | Processes, tools and methods | Procurement | VC and other investments |
| Flexible infrastructure | Culture | Scaling solutions | Access to procurements |

**Enabling layers** can initiate, improve and mobilise the elements of the building blocks to create an authorising environment for GovTech.

## GovTech Enablers
| Strategic layer | GovTech strategies |
| :--- | :--- |
| | GovTech leadership |
| **Institutional layer** | National GovTech teams |
| | Regional or local GovTech teams |
| | Policy-specific GovTech teams |
| **Network layer** | International community-of-practice |
| | Intragovernmental community |
| | Non-governmental leadership |

Source: (OECD, 2024[108]).

Governments can leverage GovTech collaborations to experiment with and develop Al systems to address
governmental and societal challenges. The 2023 OECD Digital Government Index (DGI) shows that 42%
of the 33 OECD countries surveyed are setting GovTech objectives to facilitate the testing and adoption of
emerging technologies, including Al. For example, Spain (2024[109]) is using its GobTech Lab to develop
Al pilots. A recent EC report (2024[110]) titled GovTech: influencing factors, common requirements and
recommendations provides several other use cases and findings.

# Establishing guardrails to guide strategic and responsible Al
Guardrails help to ensure the trustworthy deployment, development and use of Al in government. They
can be **binding and non-binding policy levers, transparency processes and accountability
mechanisms, such as monitoring and oversight bodies**. Guardrails are essential for managing the
risks associated with Al and deploying Al according to legal boundaries and social values. This ultimately
helps to build public trust in government. The sections below review key guardrails, together with available
policy options that governments can consider implementing in their own contexts, drawing on examples of
international good practices.

It is important to note, however, that these guardrails should be seen in conjunction with the enablers
above. Guardrails and their interpretation can be a leading driver in risk aversion, which contributes to risks
of inaction and missed opportunities (see Chapter 1). Governments should also consider the importance
of eliminating or revising guardrails that no longer serve their purpose or cause negative consequences
that do not outweigh their utility.

Finally, this section does not seek to suggest that governments should necessarily put in place all
guardrails discussed in this section, nor that they should apply to all uses of Al. That, too, could contribute
to risk aversion and hinder the trustworthy adoption of Al in government. Instead, governments should
determine which guardrails fit their operations and contexts and apply them to Al uses in a risk-based way
commensurate and proportionate to their potential level of risk.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

134 |
# Using policy levers to guide trustworthy Al
Policy levers to promote trustworthy Al can include non-binding instruments such as guidance
documents, ethical frameworks, technical standards and risk-management frameworks; and binding
instruments, such as laws and regulations. These policy levers work together and alongside other
guardrails to protect human rights. They do so through risk management approaches and by fostering the
responsible development and deployment of Al. They help mitigate Al misuse, skewed outcomes, privacy
infringements and unintended consequences, while also offering practical tools for implementing
governance principles and ensuring consistent performance across Al use (UNESCO, 2024[111]).
Generally, developing policy levers for Al in government should follow a set of good practices to ensure
they effectively promote trustworthy Al. The policy levers should:

*   Align with ethical principles and societal values to ensure that technology serves the common good.
    This is important for maintaining public trust, safeguarding the free exercise of human rights and
    ensuring that Al systems operate fairly and responsibly.
*   Take into account both innovation and risk management, helping government organisations
    navigate the evolving Al landscape responsibly by harnessing Al's transformative potential while
    addressing risks and challenges (OECD, 2023[35]; 2021[112]).
*   Continuously assess and identify potential risks associated with Al systems. Risk assessment tools
    offer a balanced approach, where both responsible use and cutting-edge advancements can
    coexist, ensuring that Al benefits society while meeting ethical standards (UNESCO, 2023[113]).
*   Engage stakeholders through different institutional arrangements to align Al use with the needs
    and values of those it impacts (see Engagement section of this chapter).

## Non-binding policy levers
One of the most common entry points for promoting trustworthy Al is the adoption and/or development of
principles or ethical frameworks. These instruments establish a set of values and best practices to guide
Al that is used transparently, fairly and responsibly. Around the world, over 200 such instruments have
been developed (Corrêa et al., 2023[114]), and often times, such principles are embedded in a country's
national Al strategy. They also often address a wide range of ethical concerns surrounding Al, such as
bias, transparency, accountability and the impact of Al on society.

Important progress has been made in global governance for Al, with several instruments developed by
intergovernmental and supranational organisations to standardise and unify Al development on a global
scale. These include the OECD Al Principles (see Table 2.2 in Chapter 2), the EC's Ethics Guidelines for
Trustworthy Al, and the G7 Hiroshima Al Process International Guiding Principles for Advanced Al
Systems. 54 The African Union (AU) is also working on its own charter on trustworthy Al (OECD.AI,
2025[115]). Other non-binding international efforts include the UN General Assembly's 2024 resolution on
the promotion of “safe, secure and trustworthy,” which was backed by more than 120 countries,55 as well
as declarations from international Al summits, which have been held in the UK, Korea and France. 56 At
the national level, governments also establishing their own ethical frameworks. For example:

*   Australia has the "Artificial Intelligence Ethics Principles”, which are designed to prompt
    organisations to consider the impact of using Al enabled systems and help businesses and
    governments to practice the highest ethical standards when designing, developing and
    implementing Al. Building upon this framework, Australia's Voluntary Al Safety Standard (VAISS)
    gives practical guidance to all Australian organisations on how to safely and responsibly use and
    innovate with Al.57
*   In Colombia, the "Ethical Framework for Artificial Intelligence" offers a set of principles and a
    methodology that should be considered in the design, development and deployment of Al systems
    (OECD, 2024[3]).58

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 135
*   Egypt has developed an “Egyptian Charter for Responsible Al” shaped around key principles. 59

Governments are increasingly developing guidance documents for using Al. These are comparable to the
guidance discussed above that serve as enablers, but with more of a focus on establishing the parameters
for trustworthy use of Al. Usually geared towards public officials responsible for developing Al projects and
managing extensive data collection and analysis, these documents are intended to equip public officials
with knowledge needed to ethically shape Al projects and to raise awareness about potential risks,
including, but not limited to, breaches of personal data (OECD/UNESCO, 2024[29]). Such guidance is more
concrete than principles, often addressing technical aspects that may affect Al deployment. For example:

*   In the UK, the government and The Alan Turing Institute jointly developed a guide to
    "Understanding Al Ethics and Safety" (2019[116]). In Canada, the "Guide on the Use of Generative
    Al" serves as a resource for federal institutions utilising generative Al technologies
    (OECD/UNESCO, 2024[29]).60
*   Germany has two primary sets of guidelines to ensure the ethical use of Al in public services:
    Guidelines for the Use of Al in Employment and Social Protection Services; and the Al Guidelines
    for Federal Administration (OECD/UNESCO, 2024[29]; Policy Lab Digital, Work & Society within the
    German Federal Ministry of Labour and Social Affairs, 2024[117]). The latter has already been
    published, while the former is under development.61

It is important to note that non-binding measures are limited in what they can achieve. For instance, when
it comes to Al in the workplace, most OECD countries' Al-specific measures to promote trustworthy Al in
the workplace are primarily non-binding and rely on organisations' capacity to self-regulate (i.e. soft law)
(OECD, 2023[118]). Because of its non-binding nature, soft law may not be enough to prevent or remedy
Al-related harm in the workplace. Government should also consider binding measures to overcome this
limitation in important areas.

## Binding policy levers
To date, most binding measures for Al in government have been put in place at national and sub-national
levels, as discussed below. However, some international mechanisms have recently come into action.
Perhaps the most notable example is the EU Al Act regulation (Box 1.2). More recently, the Council of
Europe (CoE) Framework Convention on Al and Human Rights, Democracy and the Rule of Law (2024[119])
was passed as the first international legally binding treaty on Al. Opened for signature in September 2024,
it applies to both the public and private sectors. It aims to ensure that activities within the lifecycle of Al
systems are fully consistent with human rights, democracy and the rule of law, while being conducive to
technological progress and innovation. As of September 2025, the treaty has 17 signatories, including the
European Union and the United Kingdom, as well as non-European countries, such as Canada, Japan and
the United States.

National Al laws and regulations can govern activities throughout the Al lifecycle and address issues
like data protection, privacy, misuse and other concerns. Such rules help ensure that Al development
aligns with societal values and legal norms by providing developers with clear guidance for compliance,
establishing boundaries through binding standards for transparency, accountability and fairness (OECD,
2025[120]). They can also define responsibility for Al outcomes and promote consistency and cooperation
across jurisdictions by harmonising standards. Ultimately, adequate and well-fitting laws and regulations
help promote innovation while instilling necessary protections, ensuring that Al serves the public interest.
These binding levers can be general Al governance laws that affect all sectors, Al-specific laws focused
on government use, and cross-cutting laws related to but not specifically targeting Al.

However, governments need to keep in mind the dynamic nature of Al in the present and its many potential
trajectories in the future. As discussed in Chapter 3, public servants face challenges with confusing or
outdated rules that hinder their ability to adopt Al. In developing national binding instruments, they should

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
136 |
seek alignment with the OECD (2021[121]) Recommendation Agile Regulatory Governance to Harness
Innovation. The United Kingdom has sought to achieve this through its “pro-innovation approach to Al
regulation". 62

General Al governance laws are broad rules that govern Al systems across various economic sectors,
policy domains and regions. They focus on establishing frameworks for Al risk management, ethical use
and societal impact. While many countries have laws that may influence Al (e.g. data protection laws), few
have formal laws specifically on Al. Existing or proposed national laws and regulations include:

*   Korea's Basic Act on the Development of Al and the Establishment of Foundation for
    Trustworthiness, or "Al Basic Act" (2024[122]), which will come into effect in January 2026,
    establishes a comprehensive framework to promote Al innovation while ensuring ethical standards,
    safety and public trust for all organisations using Al in the Korean market.
*   Bahrain and Oman put forward draft Al legislation in 2024, with Oman holding a public
    consultation. 63
*   Governments in Latin America (including Argentina, Brazil, Chile, Colombia, Costa Rica, Ecuador,
    Mexico, Panama, Peru and Uruguay) are discussing general Al legislation (UNESCO, 2024[111]).

Specific laws and regulations can also be developed to govern the use of Al systems in government. These
often focus on transparency, accountability, Al governance in public organisations, ethical considerations
and responsible Al use in functions and services. In the United States, at the sub-national level, states
have taken steps in this direction. For instance, New York introduced the LOADinG Act in 2024 to limit the
use of automated decision-making systems by state agencies and provide some protections for public
servants as related to Al (Werner, 2024[123]). Delaware has strengthened oversight of Al and generative Al
in the state (2024[124]). However, the adoption of dedicated Al laws or regulations for government use
remains limited, with most frameworks emerging as part of broader Al governance efforts. Besides hard
laws and regulations, formal policy guidance can also provide binding rules for government organisations.
For example, the 2025 US policy on "Accelerating Federal Use of Al through Innovation, Governance and
Public Trust" covers a range of issues and measures to ensure trustworthy Al in government while
removing barriers to innovation (Box 4.1).64

Cross-cutting laws are broader laws that, while not exclusively for Al, have significant implications for its
deployment and use in government. These might include regulations on data protection, privacy, cyber
risks and human rights, which shape how Al systems can be used in public sector contexts. For instance,
data protection and privacy law safeguard personal information by setting rules on how Al systems collect,
store and process data, ensuring individuals' privacy rights are upheld. While not typically designed
specifically for Al, they have significant implications for its use. For example, the EU GDPR outlines specific
requirements for managing personal data for all sectors, covering aspects such as data collection, storage,
processing and the rights of individuals.

# Promoting transparency in how government uses Al
To be transparent about Al use, governments should, to the extent practicable and appropriate, make
algorithms open, understandable and accessible to public scrutiny, as well as disclose the processes and
decisions Al systems contribute to. This means governments should provide clear, context-appropriate
information about how its Al systems work, the data they use and how they reach conclusions and outputs,
and mechanisms to challenge outcomes. Such transparency allows stakeholders to access information,
make informed decisions, and if necessary, seek redress for potential harms. Designing a coherent,
sustainable and impactful approach on Al algorithmic transparency involves disclosing key information
about Al systems and algorithms used. This includes complementary assets such as training data;
engaging with a broad and diverse set of stakeholders to ensure their needs and concerns are considered
(see the "Engagement" section of this chapter); promoting Al literacy to empower communities to have an

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 137
informed voice in the issues that affect them; and strengthening existing national rules on transparency
and accountability to effectively address the challenges and risks posed by Al.

Transparency not only promotes trust and enhances public value but also underpins government
accountability. As covered by the OECD Al Principles, transparency and accountability are two different
but complementary concepts. Transparency enables more informed oversight, fosters trust and increases
the accountability of those who develop or control these systems. Transparency also enhances the fairness
of Al-driven systems and helps ensure that their implementation can be effectively monitored and
evaluated, particularly when decisions have a direct impact on people's lives in areas such as healthcare,
finance and criminal justice.

Countries should employ a variety of transparency policies, tools, methods and approaches that are suited
to their audience and provide clear information. These instruments can be broadly classified as either
proactive or reactive (GPAΙ, 2024[125]).

## Proactive transparency instruments
Overall, "the public sector's understanding of its own Al usage is severely lacking, which hinders both
democratic accountability and internal knowledge sharing" (Ada Lovelace Institute, 2025[23]). Instruments
are needed that allow governments to understand its own Al use, and by extension, enable them to
proactively share information about the Al systems used in the public administration without being
prompted by requests (GPAI, 2024[125]). Policy options for proactive transparency include public registries
of Al systems, publishing algorithm source code and documentation, user-driven proactive publications
and automated responses triggered by interactions.

Public registries of Al systems are increasingly common, serving as centralised repositories that
consolidate information about Al systems currently used in government. The goal is to create a "one-stop
shop" where citizens and stakeholders can easily access information about the Al systems in use, their
purposes, the sectors they apply to and the jurisdictions they affect. Examples include:

*   Colombia's dataset on automated decision systems in the Colombian public administration 65
*   the United Kingdom's Algorithmic Transparency Records 66
*   the US government's Al use case inventory, which federal agencies are required to update at least
    annually (US OMB, 2025[17])67
*   national government public algorithm inventories in Chile, France and the Netherlands Public
    Algorithms Inventory68
*   sub-national algorithm registers Amsterdam, the Netherlands, and Helsinki, Finland.69

Developing a central, public and searchable registry of Al systems is a best practice that enhances
transparency. Yet doing so can be challenging, in part due to how rapidly governments are deploying Al
systems in a variety of domains. In Chile, challenges in making Al uses cases transparent prompted the
Chilean Transparency Council, an independent body created by law, to issue recommendations on
improving algorithmic transparency in government (2024[126]). In the Netherlands, only about 5% of Al
systems have been published in the Dutch Al registry, as of October 2024 (Netherlands Court of Audit[127]).
In the United Kingdom, the Public Accounts Committee (PAC) (2025[128]) found that relatively few (33)
Algorithmic Transparency Records had been published, jeopardising public trust in the adoption of Al in
government. However, such registries could be populated automatically, depending on if and how impact
and risk assessments are carried out in a government (OECD, 2024[94]). For instance, Canada's Directive
on Automated Decision-Making requires the completion of an Algorithmic Impact Assessment (AIA) for
automated decision systems. The AIA results must be published as open information on Canada's Open
Government Portal. If required for all Al systems, such a process could automatically populate a public
registry.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
138 |
Publishing algorithm source code and documentation also promotes transparency. Open sourcing the
code for public algorithms is regarded as a best practice in algorithmic transparency and is especially
valuable for technical and expert audiences (Ada Lovelace Institute, 2021 [129]). This allows those with the
necessary skills to examine, test and verify how these systems operate, promoting accountability and trust.
Some efforts are a step shy from releasing full source code but require the publication of thorough
documentation than can have a similar effect.

*   In France, the Digital Republic law mandates government agencies to "make publicly available, in
    an open and easily re-usable format, the rules defining the main algorithmic processing used in the
    accomplishment of their mission when such processing is the basis of individual decisions”. 70
*   The United Kingdom's the Algorithmic Transparency Recording Standard (ATRS) mandates public
    sector organisations to transparently disclose details about their use of algorithmic methods in
    decision-making processes (OECD, 2023[130]).71
*   In Canada, the Directive on Automated Decision-making explicitly outlines, in detail, explainability
    requirements for Al systems differentiated by levels of risk, determined by use of an Algorithmic
    Impact Assessment tool (the results of which must also be published).72
*   The US policy discussed in Box 4.1 requires federal government agencies, when practicable and
    subject to some exclusions, to release and maintain Al code as open-source software in a public
    repository.

Transparency efforts can also be iterative, as seen in user-driven proactive publications. This type of
proactive publications involves public entities choosing to proactively disclose information after receiving
numerous similar requests. By publishing this information proactively, future requests are avoided, saving
time for both officials and requestors. While its use in ensuring algorithmic transparency is not well-
documented, this approach could be a relevant and cost-effective method for disclosing frequently
requested information related to algorithms (GPAI, 2024[125])

Some types of disclosures may only be made for some users in context-specific situations. Automated
responses triggered by interactions occur when information about an automated decision-making
system is automatically provided during specific governmental processes. For instance, when someone
engages with a public body's website or online platform for a service or administrative procedure involving
an automated decision-making system, relevant information about the system could be automatically
disclosed, without the user needing to request it explicitly (GPAI, 2024[125]).

## Reactive transparency instruments
Reactive disclosure transparency instruments allow government to respond to specific requests for
information from individuals, groups or authorities. Unlike proactive disclosure, this approach is initiated by
external demand rather than the government's proactive disclosure (GPAI, 2024 [125]). These involve
submitting a request under the country's relevant Access to Information (ATI) law to obtain information
about an algorithm or its use, leveraging an existing policy instrument widely available in most contexts or
countries. 73 However, these regimes are not specifically designed for algorithmic transparency and can be
ineffective when applied in this context (Valderrama, Hermosilla and Garrido, 2023 [131]). For example,
requesting information about an algorithm's source code or its application is unlikely to produce the desired
results due to issues with record management practices and common exceptions in ATI laws, such as
conflicts with intellectual property restrictions and trade secrets of private providers of public services (Fink,
2017[132]; Brauneis and Goodman, 2017 [133]).

# Advancing accountability through risk management throughout the Al system lifecycle
For some government Al systems, the context of their development or use may pose a higher risk. This
can relate to their scale (seriousness and probability of adverse impact), scope (breadth of application,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 139
such as number of individuals affected) or optionality (degree of choice as to whether to be subject to the
effects of an Al system) (OECD, 2022[58]). Risk management procedures can help to identify which systems
or contexts pose higher risks to mitigate them (OECD, 2023[134]).

Risk management for Al systems that may carry high risks should be informed by guidance on which levels
of risk are acceptable for different uses and contexts. Risk management is needed both before such as
through ex ante impact and risk assessments and after the deployment of Al systems. One of the most
well-known examples is the US National Institute of Standards and Technology (NIST) (2023[135]) Al Risk
Management Framework. This framework helps public or private organisations identify unique risks posed
by generative Al and proposes actions for generative Al risk management that best align with their goals
and priorities. While designed for the US, it has been translated in several other languages and used in
other countries. The G7 Hiroshima Al Process International Guiding Principles for Advanced Al Systems
and Code of Conduct also sets baseline standards to manage risks (2023[136]; [137]). The US also requires
risk assessments for Al use and puts in place risk management practices for uses deemed "high-impact"
(see Box 1.3) (US OMB, 2025[17]). As another national example, Türkiye's Digital Transformation Office
conducts the "Al Risk Management Recommendation" and "Trustworthy Al Seal" studies to closely monitor
the use of Al for public benefit (OECD, 2024[3]).

Al experts recommend that governments make establishing or adopting such processes a top priority for
mitigating Al harm (OECD, 2024 [138]). Yet the proliferation of frameworks can make it difficult for
governments to determine which is the most appropriate to follow. As calls for the development of risk
management frameworks continue to grow, interoperability would enhance efficiency and reduce
enforcement and compliance costs. The OECD (2023[139]) is actively working to promote policy coherence
and interoperability among these frameworks.74

## Impact assessments
Impact assessments, including Algorithmic Impact Assessments (AIA), can help public organisations to
anticipate and evaluate how an algorithm may function in a specific context. They are evaluations of an Al
system that use prompts, workshops, documents and discussions with the developers of an Al system and
other stakeholders to explore how the system will affect people or society in positive or negative ways
(Valderrama, Hermosilla and Garrido, 2023[131]). These tend to occur in the early stages of a system's
development before it is in use (ex-ante) but may occur after a system has been deployed (ex-post).

The primary aim of ex-ante AlAs is to assess the potential impacts of an algorithmic system on economies
and societies and to provide a mechanism for accountability (Valderrama, Hermosilla and Garrido,
2023[131]). AlAs also help to better understand, classify and mitigate potential risks or harms associated
with the algorithm. An example employing such a technique is Canada's "Directive on Automated Decision-
Making," which requires an AlA that considers various factors and, in turn, provides a risk score that
prescribes certain actions. The approach has been adapted in other countries, like Uruguay, where it
informed their Guide for Algorithmic Impact Study (OECD/CAF, 2022[30]). In 2024, the Council of Europe
issued the Human Rights, Democracy and Rule of Law Impact Assessment (HUDERIA).75 Its methodology
provides for the creation of a risk assessment and a mitigation plan to minimise or eliminate the identified
risks, protecting the public from potential harm.

Ex-ante AlAs are the most common approach in use today. The OECD has generally been supportive of
this approach because they help to convert principles into actions.76 However, some argue that evaluating
impacts is not the same as evaluating harms, and that in some instances, doing so can obscure true harms.
That is, in part, because the metrics used for impact assessments often are not measuring emotional or
psychological harm (Gupta et al., 2021[140]). This work also suggests that AlAs often do not consider the
voices of all who may be impacted by an Al system. Other critics of AlAs argue that these assessments
are not designed to continuously monitor the effects of deployed systems and adapt accordingly based on
feedback and real-world ramifications (Mehta, Rogers and Gilbert, 2023[141]). Recent findings from the Ada

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
140 |
Lovelace Institute (2025[23]), on lessons learned from six years of studying Al in government, further
underscore this point. One of its main findings is that "Al is 'sociotechnical', in that it influences and is
influenced by the social contexts in which it is deployed, often with unintended ripple effects. The success
and acceptance of Al tools depends on their interaction with existing social systems, values and trust.
Focusing exclusively on technical criteria while failing to consider these factors can lead to scepticism, and
ultimately hinder adoption and use".

To ensure AlAs are valuable, governments will need to conduct thorough sociotechnical assessments that
engage appropriate stakeholders and integrate diverse perspectives (Lam et al., 2023[142]). However, ex-
ante evaluations alone are often insufficient; they should be complemented by ex-post impact assessments
that build on top of the ex-ante AlAs. This implies the development of mechanisms for continuous
monitoring, adaptation and accountability, ensuring that Al systems evolve in response to real-world
evidence. The US NIST has launched an Assessing Risks and Impacts of AI (ARIA) to advance
sociotechnical testing and evaluation for Al.77

As related to ex-ante impact assessments, governments should consider in advance whether Al is the best
solution to address a given problem, as discussed in the enablers section on "Determining whether Al is
the best solution".

## Algorithmic audits
After deployment, it is important that governments continue monitoring system behaviours to determine
what expected or unexpected risks may be materialising, and to ensure that government organisations
carry on with implementation in a responsible manner. This usually takes the form of algorithmic audits.
These involve independent, usually external, scrutiny of an Al system or the processes around it. These
can be technical audits of the system's inputs or outputs; compliance audits of whether an Al development
team has completed processes or regulatory requirements; regulatory inspections by regulators to monitor
behaviour of an Al system over time; or sociotechnical audits that evaluate the ways in which a system is
impacting wider societal processes and contexts in which it is operating. Because audits usually occur
after a system is in use, they serve as accountability mechanisms to verify whether a system behaves as
developers intend or claim. Examples of algorithmic auditing process can be seen in Box 4.8.

Governments need to design their audits carefully, however. Inadequacies in Al auditing could create false
confidence and “obscure problems with algorithmic systems and create a permission structure around
poorly designed or implemented Al” (Goodman and Trehu, 2022[143]). Some experts argue that insufficient
audits may prove meaningless or could exacerbate the problems they are designed to address, as well as
being used as "audit washing" to give the appearance of due diligence.

## Al system capabilities risk assessments
Al systems capabilities risk assessments are similar to impact assessments but look specifically at the
likelihood of harmful outcomes occurring from an Al system due to a system's capabilities. These also tend
to occur in the early stages of a system's development before it is in use but may occur after a system has
been deployed. Such approaches should take into account risks related to Al systems' limitations and
capabilities, as well as contexts of use. For example, the government of Queensland, Australia issued a
"foundational Al risk assessment guideline” for public servants.78 Risk assessment have become
increasingly common in the private sector for advanced Al systems, such as with "responsible scaling
policies" (RSPs), which commit to actions based on risk assessment of Al system capabilities (OECD,
2024[138]). When identifying potentially dangerous capabilities, RSPs often set thresholds that trigger
actions to slow or cease development (METR, 2023[144]).79

Testing and assessment bodies and national, multilateral or regional bodies, such as Al safety or security
institutes, are increasingly playing a role in facilitating risk management, including through building testing

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 141
and assessment ecosystems (OECD, 2024 [138]). For instance, the UK DSIT provided guidance on
responsible capability scaling. 80

Relative to the abundance of examples on governments using impact assessments or algorithmic audits,
there are few examples of governments developing or using other Al risk assessments for Al in
government. This may be because most government Al systems are procured from private sector
companies, which may conduct risk assessments prior to putting their products on the market. It may also
be because government Al systems, as discussed in Chapter 2, often do not leverage the latest
approaches and instead rely on rules-based systems or more established ML approaches. Still,
governments should consider and use such risk assessment approaches as they seek to use more
advanced and capable Al systems. For example, in addition to structured testing, governments could
conduct adversarial testing—commonly known as red-teaming—especially for complex foundation models
used or acquired by governments, to proactively identify vulnerabilities, misuse risks and harmful system
activities or outputs in sensitive government applications. Capability assessments could go also include
language-specific evaluations, particularly for LLMs used in multilingual public services. These
assessments could help ensure fair performance, address data imbalances in foundation models and help
verify that models are suitable for the languages they serve.

# Empowering oversight and advisory bodies to guide responsible Al
## Oversight entities
The role of oversight bodies is evolving to meet new challenges posed by the expansion of Al use across
government. For instance, Supreme Audit Institutions (SAIs)81 are increasingly required to extend their
audit activities to include the scrutiny of Al algorithms that underpin government operations and public
decisions. This shift necessitates a comprehensive evaluation of Al algorithms not only for their accuracy,
security and effectiveness but also for their transparency and fairness. Box 4.8 illustrates how SAls have
adapted their role to conducting algorithmic audits and developing the frameworks for doing so.

Audits serve a range of purposes, including evaluating the performance of algorithmic systems against
established standards, ensuring regulatory compliance, detecting unlawful discrimination, enhancing
transparency and explainability, assessing security and robustness, evaluating broader social and ethical
impacts and holding organisations accountable for their systems. Additionally, audits may be used to
identify systemic failures in the use of algorithmic systems, offering valuable insights that can inform their
application in another context (Ada Lovelace Institute, 2021[129]).

### Box 4.8. Public sector algorithmic auditing approaches and tools
#### France
In 2024, the French Cour des Comptes evaluated the integration of Al within the Ministry of Economy
and Finance. Since 2015, the ministry has implemented 35 Al programmes aimed at detecting individual
fraud risks, identifying business difficulties and providing faster responses to users. While technological
aspects are well managed, the report found that ethical, human resources and environmental
considerations remain underexplored. The Cour recommended robust ministerial oversight to ensure
trustworthy public Al, better assessment and transparent allocation of productivity gains, and proactive
anticipation of Al's impact on staff roles

#### Netherlands
The independent Netherlands Court of Audit has audited the Dutch government's use of algorithms.
Through its evaluation, the Court developed an audit framework specifically designed to assess the use

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
142
of algorithms within government. The framework evaluates a wide range of aspects, from governance
and accountability to technical aspects like the Al systems and data, privacy, IT general controls and
ethical considerations. The framework is being used across several Dutch institutions to guide their
development of new algorithms. In 2022, it audited nine major public sector algorithms and found that
six (67%) did not meet basic requirements, exposing the government to bias, data leaks and
unauthorised access.

#### Sweden
The National Audit Office of Sweden conducted an audit of three automated decision-making systems
used by the Swedish Government: the parental benefit at the Swedish Social Insurance Agency, annual
income taxation of private individuals at the Swedish Tax Agency and driving licence learner's permits
at the Swedish Transport Agency. The audit aimed to assess whether these systems operated
effectively and efficiently while safeguarding legal certainty in decision-making. It evaluated the
performance of the systems against legislative standards for efficiency and legal certainty, identifying
specific shortcomings.

#### United Kingdom
In 2024, the UK National Audit Office (NAO) published a Report on Al in Government examining how
effectively the UK government bodies are using Al for public services. It found that only 21% of the 87
bodies analysed had an Al strategy, as required by policy, while 61% had plans to develop one. Notable
initiatives include the Department for Work and Pensions' establishment of an Al steering board and a
separate advice and assurance group, and the Ministry of Justice setting up of an Al steering group to
review individual Al use cases, coupled with the adoption of algorithm consultation panels, including
end users and data ethicists.

#### United States
The US Government Accountability Office (GAO) issued Artificial Intelligence: An Accountability
Framework for Federal Agencies and Other Entities, which identifies key accountability practices —
centred around the principles of governance, data, performance and monitoring — to help federal
agencies and others use Al responsibly.

#### Cross-border collaboration
The Supreme Audit Institutions (SAls) of Finland, Germany, the Netherlands, Norway and the United
Kingdom collectively issue Auditing machine learning algorithms: A white paper for public auditors,
which is updated over time.

Source: https://www.ccomptes.fr/fr/publications/lintelligence-artificielle-dans-les-politiques-publiques-lexemple-du-ministere-de,
https://english.rekenkamer.nl/publications/reports/2021/01/26/understanding-algorithms,
https://www.riksrevisionen.se/download/18.2008b69c18bd0f6ed3f25040/1608291082190/RiR_2020_22_en-GB.pdf, (Ada Lovelace
Institute, 2021[129]), https://www.gao.gov/products/gao-21-519sp, https://www.auditingalgorithms.net, (OECD, 2023[130]),
https://www.nao.org.uk/reports/use-of-artificial-intelligence-in-government.

Oversight bodies serve as platforms that bring together diverse expertise and perspectives, which is
important for the effectiveness of any accountability mechanism (Ada Lovelace Institute, 2021 [129]). For
example:
*   In 2023, Spain created the independent Spanish Agency for the Supervision of AI (AESIA)
    (Pehlivan and Valín, 2023[145]).
*   In 2024, the EU Al Act established a supervisory European Artificial Intelligence Board (Al Board). 82

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 143
*   Ombudsman are playing a key oversight role in public organisations' use of Al. For instance, the
    European Ombudsman has investigated the use of Al by the EC,83 and the Dutch Ombudsman
    and Data Protection Authority have actively examined algorithmic decision-making and Al's impact
    on citizens' rights in the Netherlands. 84
*   Parliaments and their oversight committees are taking a more active role in different countries,
    including Australia and the United Kingdom,85 where they have conducted inquiries into Al and
    algorithmic transparency. Some parliamentary bodies establish ad hoc committees to investigate
    specific Al-related concerns, particularly when emerging risks or controversies arise.

## Advisory bodies
Advisory bodies can also help to ensure governments are using Al in a trustworthy manner. They can
provide expert guidance, insights and recommendations in response to specific requests from government
on emerging issues in Al. Some can be more hands-on, with Ireland's Al Advisory Council, for example,
developing and delivering its own workplan of advice.86 Other examples include:
*   New Zealand Data Ethics Advisory Group offers non-binding guidance on the use of algorithmic
    systems by public agencies. Its recommendations address issues such as human rights
    compliance, scientific validity, privacy and ethics (Ada Lovelace Institute, 2021[129]). 87
*   Greece established a High-Level Advisory Committee on Al in November 2023, which plays a
    pivotal role in shaping national Al policy. It focuses on promoting economic and societal growth
    while addressing the risks associated with unchecked Al use. It has developed “A Blueprint for
    Greece's Al Transformation" (2024[47]). The country has also established a National Committee of
    Technoethics and Bioethics to provide independent expertise in providing strategic guidance and
    recommendations on the ethical implications of Al, among other things.88
*   Spain (2024[146]) has created the Artificial Intelligence Advisory Council as a formal independent
    body to provide the government with analysis, advice and support on the topic of Al. It held its first
    meeting in June 2024.
*   The government of Western Australia formed an Al Advisory Board in 2025 to provide advice to
    Western Australian government agencies on risk mitigation and to support the safe, responsible
    and ethical use of Al in the Western Australian public sector. 89

## Al safety and security institutes and units
Governments around the world are also focusing on this topic through efforts including the establishment
of Al safety and security institutes and units in several countries (OECD, 2024[138]). For instance, Canada,
the EU, France, Japan, Korea Singapore, the UK and the US have each launched such an institute or
unit, 90 with these and three additional countries deciding to form an international network of institutes (UK
DSIT, 2024[147]). The mandate of such institutes or units is generally broader than Al's use in government,
but some do include a focus on this. For instance, the upcoming IndiaAl Safety Institute will serve as a
think-and-do tank for governance innovation and offer policy, legal and technical guidance to public
institutions deploying Al, among other objectives.91

# Engagement to shape strategic and responsible Al
Al systems have the potential to radically reshape the interaction between citizens and their governments,
and among citizens themselves. Key stakeholders, including members of the public, should have a say in
how governments use and govern Al-based technologies. Involving citizens and stakeholders can lead to
greater trust in and legitimacy of Al systems used by government, as well as to Al systems that better

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

144 |
reflect the needs of all (OECD, 2024[148]). Such efforts can help promote transparency, accountability and
fairness in Al systems, preventing biases and potential harms.

Engaging citizens and stakeholders – such as scientists and engineers, affected communities, investors,
companies or institutions — can enrich the understanding of issues related to Al technology, help
policymakers anticipate problems of public acceptance and promote good communication (OECD,
2024[148]). This engagement is crucial for aligning the use and governance of Al with the goals and needs
of society. It helps stakeholders to understand, question and influence how algorithms and Al governance
mechanisms are designed and operated.

Early engagement allows for a comprehensive assessment of potential consequences and risks for various
groups, fostering more inclusive and ethical development of Al systems and governance. This collaborative
approach helps to identify and address concerns from diverse perspectives, ensuring that Al systems are
designed and implemented in a way that is both responsible and beneficial to all stakeholders involved
(OECD, 2021[112]). Citizens and stakeholders can be involved in different aspects of policymaking:

*   **Agenda-setting.** In the United Kingdom, the Centre for Data Ethics and Innovation has been
    engaging citizens through the Public Attitudes to Data and Al tracker survey, now at its fourth wave,
    which can inform the government's approach to future policy development. 92
*   **Technology design.** In 2020, the French government launched PIAF, a collaborative initiative with
    citizens, academia and civil society to build databases in French language to train Al systems. 93
    Greece's Pharos Al Factory is being shaped to be a central hub a central hub collaboration,
    knowledge sharing, resource pooling and joint project development among the public sector,
    academic institutions and private industry.
*   **Technology assessment.** In the United States, the Expert & Citizen Assessment of Science &
    Technology (ECAST) Participatory Technology Assessment is bringing public perspectives to bear
    on critical government science and technology decisions. 94
*   **Regulation.** In 2024, the European Union opened a multi-stakeholder consultation on trustworthy
    general-purpose Al models under the Al Act,95 as well as a call for expressions of interest to
    participate in the drawing-up of the first general-purpose Al Code of Practice. 96

Governments have several options to consider in enhancing public engagement when shaping the
strategic and operational development of Al. The sections below explore deliberative processes, such as
**citizen assemblies, engagement with civil servants and the involvement of users in Al
development.** In addition to civic engagement for government Al use and governance, governments can
also use Al for civic engagement, which is discussed in depth in Chapter 5 (section on "Al in civic
participation and open government").

# Citizen assemblies
Citizens assemblies, also called citizens juries or panels, generally refer to a randomly selected group of
people who are broadly representative of a community spending significant time learning and collaborating
through facilitated deliberation to form collective recommendations for policymakers (OECD, 2020[149]).

A representative deliberative process is most suited to address issues such as values-based dilemmas;
complex problems that require trade-offs and affect a range of groups in different ways; or long-term
questions that go beyond electoral cycles (OECD, 2022[150]). Al's development and governance are well
suited for such a process. Al involves ethical and societal discussions to decide on its uses in specific
contexts (e.g. facial recognition) and can be considered as a technical issue with trade-offs between
innovation and regulation. Most importantly, the adoption of Al technologies will certainly shape social
interactions in the long term, with impacts that can span through generations.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 145

As an example of a citizen assembly on Al, in 2024, the Belgian Presidency of the Council of the European
Union convened a representative group of 60 Belgians to collect citizens' views on Al with the bloc (BeEU,
2024[151]). In another example, in the United States in 2023, a professor from Syracuse University partnered
with the Center for New Democratic Processes (CNDP) to conduct the first national deliberative event on
Al in the United States (Atwood and Bozentko, 2023[152]). International and sub-national examples of
assemblies to shape Al governance also exist. In 2025 and 2026, the Global Coalition for Inclusive Al, a
partnership between the Stanford Deliberative Democracy Lab and the Missions Publiques citizen
participation consulting firm, will conduct deliberative assemblies that intend to reach more than 10 000
citizens in more than 100 countries. Follow-up events with decision-makers are planned to ensure the
impact of the deliberative processes (Vergne and Siu, 2025[153]). Citizen participation is also a strong
component of another emerging trend in Al governance: Al Localism, in which communities, including local
governments, act to discuss and regulate the use of Al technologies according to their needs (Marcucci,
Kalkar and Verhulst, 2022[154]). For example, in 2018, Mexico City's innovation lab, Laboratorio para la
Ciudad de Mexico (LabCDMX), conducted a deliberative exercise build an Anticipatory Governance
Framework for Mexico City on Al (Ramos, 2018[155]).

# Engaging with civil servants and social partners
Engaging civil servants, who are at the frontline of public service delivery, is critical to the use of Al in
government. Their roles and responsibilities are directly impacted by the introduction of Al technologies,
and their insights and experiences are invaluable in shaping a responsible and effective Al use. As
discussed in Chapter 1, the automation, creation or transformation of tasks due to the introduction of Al
can bring about opportunities for improved efficiency and effectiveness. But those changes can also raise
concerns about job security, work conditions and workers' right for these individuals.

The design and implementation of Al initiatives should be carried out in a manner that respects labour
rights, promotes civil servants' well-being and uses their insights (OECD, 2023[118]). Transparent and
inclusive dialogue with public servants and social partners, such as trade unions and employee
associations, is important for achieving this. Workers should be informed about the objectives of Al
initiatives, the potential impacts on their roles and the measures in place to mitigate any negative impacts.
They should also be given opportunities to voice their concerns, provide feedback and contribute their
insights to Al approaches.

Social dialogue and collective bargaining are essential for successful Al adoption in government (OECD,
2023[118]). They are key to building trust and effective collaboration among public servants and ensuring
access to training to develop the skills and capabilities needed to work with Al. Social partners should also
be involved, as they play a critical role in negotiating conditions for work.

# Involving users in Al development
Involving end-users in Al development in government helps ensure that Al solutions are user-centric and
effectively tackle real-world issues. Figure 4.5 shows key steps to understanding users and their needs.
Governments can use research methods — such as reviewing existing evidence, conducting interviews
and observing users — to develop a deep understanding of these aspects, thereby enhancing the
relevance and acceptance of Al applications (OECD/UNESCO, 2024[29]). In line with OECD Good Practice
Principles for Service Design and Delivery in the Digital Age, users can help identify insights for iterating
the design of services, simplifying underlying procedures and increasing access for all user groups
(2022[156]). Moreover, making the design and delivery of Al-driven services a participatory and inclusive
process empowers users, giving them an active role in co-creating and co-designing public services. This
can include implementing mechanisms to involve users in testing, iterating and improving the service, as
well as conducting rigorous and ethically-designed experiments with user groups to help ensure the use

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

146 |
of Al has its intended effects and that any risks are identified on a small scale before scaling more broadly
(see further discussion on "Creating spaces to experiment" above).

Figure 4.5. Key steps to understand the users and their needs in government Al developments

**Chart Data Extraction:**
- Step 1: Identifying potential users
- Step 2: Working with them to understand their current tasks and activities
- Step 3: Working with them to uncover their problems and challenges
- Step 4: Collectively determining their needs

Source: (OECD/UNESCO, 2024[29]).

# Collaborating across borders
Like other digital technologies, Al knows no borders. Its risks and impacts, as well as its potential positive
uses, can be transnational.97 Cross-border engagement and collaboration can be instrumental in bridging
knowledge and development gaps among countries, tackling common and complex challenges, managing
risks and implementing innovative policies and services. International co-operation can help in building
government Al capacity across the globe and in specific regions, such as been seen in Latin America and
the Caribbean (LAC) (OECD/CAF, 2022[30]). This can include sharing open algorithms, infrastructure and
intergovernmental datasets, as well as conducting joint efforts for the responsible development of emerging
technologies. OECD (2021[157]) work has identified three mechanisms governments are using to connect
and collaborate in order to tackle issues that cut across borders between administrative entities or area,
including in areas related to digital innovation and Al in government.

**Cross-border governance bodies** can address complex issues or those spanning the remit of multiple
jurisdictions, such as seeking to integrate and harmonise Al approaches and interoperability. Governance
bodies allow governments to coordinate and harness the collective efforts of actors divided by borders.
This can be seen in the European Union's creation of the Al Office responsible for implementing,
supervising and enforcing the Al Act. Beyond the EU sphere, the OECD Working Party of Senior Digital
Government Officials (E-Leaders) and its thematic group on Al have been platforms for countries to work
together to develop guidance and analytical products on Al in government, with the potential to propose
relevant OECD non-binding legal instruments. Further, countries have been collaborating on international
standards enforced by international bodies, such as ISO/IEC 42001 on Al management systems, relevant
for public sector agencies as well as companies or non-profits. However, there is currently no evidence of
formal cross-border governance bodies set up to specifically address government development and use
of Al.

Second, countries are also using **innovative networks** tackling cross-border collaboration. Networks are
horizontal, often informal and ground-up structures that allow for the organic convergence of ideas and
expertise across borders. For instance, the European Public Administration Network (EUPAN) promotes
knowledge sharing on Al.98

And third, some countries are exploring **emerging governance systems dynamics**, which are entirely
new ways of working together across borders. For instance, governments have worked together to develop
collective digital infrastructure and data sharing approaches to promote seamless operations
internationally. The European Union is perhaps the most advanced in this area, as its Interoperable Europe
Act, which came into force in April 2024, establishes a framework to enhance interoperability within public
sector organisations, ensuring seamless cross-border services. Key elements include creating an

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 147

interoperability governance structure, promoting innovation and knowledge exchange, implementing
regulatory sandboxes for testing solutions, and mandating interoperability assessments for public
administration.99

# A framework for trustworthy Al in government
When taken together, the policy measures discussed in this chapter form a Framework for Trustworthy Al
in Government that can help governments align their actions in developing and adopting Al with the value-
based principles and recommendations laid out in the OECD AI Principles (2024[158]). The framework
outlines how governments can seize Al's promise of productivity, responsiveness and accountability by
putting in place the right mix of enablers, safeguards and engagement mechanisms.
Figure 4.6 presents a visual representation of the framework and Table 4.1 details the policy questions
and measures that underpin its elements.

Figure 4.6. OECD Framework for Trustworthy Artificial Intelligence in Government

**Chart Data Extraction:**
*   **Central Theme:** Trustworthy AI in government
*   **Main Outcomes (Outer Arcs):**
    *   Productivity
    *   Responsiveness
    *   Accountability
*   **Pillar Categories (Middle Ring):**
    *   **Enablers (Green Section):**
        *   Governance
        *   Investments
        *   Data
        *   Infrastructure
        *   Procurement & partnerships
        *   Skills & talent
    *   **Guardrails (Red Section):**
        *   Policy areas
        *   Ethics & risk management
        *   Laws and policies
        *   Monitoring & oversight
        *   Enforcement
    *   **Engagement (Blue Section):**
        *   Across borders
        *   Civil servants & social partners
        *   General public
        *   Broader ecosystem
        *   Levels of government

Source: (OECD, 2024[3]), as enhanced and finalised through the work conducted for this report.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

148 |

Table 4.1. Policy questions and measures underpinning the Framework for Trustworthy Al in
Government

| Policy question | Policy measure | Description |
| :--- | :--- | :--- |
| What concrete policy actions and tools can governments develop to address existing challenges for a trustworthy use of Al in government? | Enablers | Policy actions and tools for areas where policymakers currently identify constraints and shortcomings, in order to establish a solid enabling environment and unlock the full-scale adoption of Al in government. These include governance, infrastructure, data, skills and talent, investments, procurement and partnerships. |
| | Guardrails | Policy tools that governments can consider developing for a responsible, trustworthy and human-centred use of Al in government. These may include non-binding instruments; laws and regulations; transparency and risk management instruments; or oversight (beyond the executive) and monitoring (within the executive) bodies. |
| Who should governments engage when developing and implementing the enablers and guardrails, as well as individual use cases, for the trustworthy use of Al in government? | Engagement | Different stakeholders to engage in building the foundations for a responsible use of Al in government. Various actors across government (e.g. ministries, civil servants, sub-national governments), in the broader ecosystem and beyond national jurisdictions would need to be engaged through targeted actions to effectively address policy opportunities and challenges related to the use of Al in government. |
| What impact does government strive to achieve when using trustworthy Al? | Impact | Al in government can help to increase productivity, responsiveness and accountability. |

Source: (OECD, 2024[3]).

# Future OECD work on these issues
The enablers, guardrails and engagement processes that comprise the OECD Framework for Trustworthy
Al in Government serve as a strong foundation upon which governments can take a strategic and
responsible approach to Al. However, one report cannot fully convey the complexities of this vast spectrum
of activities needed to adopt rapidly evolving Al technology while managing both critical risks and significant
implementation challenges. Future OECD work will address elements of the framework more in-depth, with
actionable insights about how governments can put in place these foundations. For instance, a report on
Al experimentation in government is already underway and will be released in the coming months.

Critically, governments need to be able to identify where to prioritise Al investments and resources based
on various trade-offs when considering the potential benefits and risks of particular Al applications. The
OECD has recommended (2024[3]) and continues to encourage governments to prioritise high-benefit, low-
risk applications of Al, especially when building an initial level of maturity. However, most do not have the
processes in place for holistic measurement of potential or realised results — efficiency of spend, quality
of services, potential harms — that would allow them to make these determinations. This should be a
priority for governments as a cross-cutting step that helps unlock the potential of Al, and it will be a focus
of future OECD work.

# References
Ada Lovelace Institute (2025), *Learn fast and build things: Lessons from six years of studying Al
in the public sector*, Ada Lovelace Institute, https://www.adalovelaceinstitute.org/policy-
briefing/public-sector-ai/. [23]

Ada Lovelace Institute (2021), *Algorithmic accountability for the public sector*, Ada Lovelace
Institute (Ada), Al Now Institute (Al Now), and Open Government Partnerships (OGP),
https://www.adalovelaceinstitute.org/report/algorithmic-accountability-public-sector/. [129]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 149

African Union (2024), Continental Artificial Intelligence Strategy, [65]
https://au.int/en/documents/20240809/continental-artificial-intelligence-strategy.

Agency for Digital Government (2024), A Common Danish Language Resource, [46]
https://en.digst.dk/digital-governance/new-technologies/a-common-danish-language-
resource/ (accessed on November 2024).

Al Hub (2024), “Al Data Finder", aihub.or.kr, [53]
https://www.aihub.or.kr/aihubdata/data/list.do?currMenu=115&topMenu=100 (accessed
on November 2024).

Al Sweden (2024), A shared digital assistant for the public sector, [51]
https://www.ai.se/en/project/shared-digital-assistant-public-sector (accessed
on October 2024).

Atwood, S. and K. Bozentko (2023), U.S. Public Assembly on High Risk Artificial Intelligence [152]
2023 Event Report, https://www.cndp.us/wp-content/uploads/2023/12/2023-U.S.-PUBLIC-
ASSEMBLY-ON-HIGH-RISK-AI-EVENT-REPORT-final.pdf.

Australia DTA (2024), APS trials generative Al to explore safe and responsible use cases for [101]
government.

Australian Government (2024), Evaluation of the whole-of-government trial of Microsoft 365 [36]
Copilot, https://www.digital.gov.au/initiatives/copilot-trial.

BeEU (2024), A citizen's view of artificial intelligence within the EU, https://belgian- [151]
presidency.consilium.europa.eu/media/Izxauu4i/rapport-ia-en-web-v2.pdf.

Berryhill, J. et al. (2019), “Hello, World: Artificial intelligence and its use in the public sector", [4]
OECD Working Papers on Public Governance, No. 36, OECD Publishing, Paris,
https://doi.org/10.1787/726fd39d-en.

Brauneis, R. and E. Goodman (2017), “Algorithmic Transparency for the Smart City", SSRN [133]
Electronic Journal, https://doi.org/10.2139/ssrn.3012499.

Brizuela, A. et al. (2025), Analysis of the generative Al landscape in the European public sector, [68]
European Commission, https://op.europa.eu/s/z4XY.

Chilean Transparency Council (CPLT) (2024), CPLT lanza recomendaciones de transparencia [126]
algorítmica en servicios públicos, https://www.consejotransparencia.cl/cplt-lanza-
recomendaciones-de-transparencia-algoritmica-en-servicios-publicos/.

CNIL (2023), « Bac à sable » données personnelles : la CNIL lance un appel à projets sur [41]
l'intelligence artificielle dans les services publics, https://www.cnil.fr/fr/bac-sable-donnees-
personnelles-la-cnil-lance-un-appel-projets-sur-lintelligence-artificielle-dans.

CNIL (2023), « Bac à sable » intelligence artificielle et services publics : la CNIL accompagne 8 [42]
projets innovants, https://www.cnil.fr/fr/bac-sable-intelligence-artificielle-et-services-publics-la-
cnil-accompagne-8-projets-innovants.

CONPES (2025), CONPES 4144, Política Nacional de Inteligencia Artificial, [31]
https://colaboracion.dnp.gov.co/CDT/Conpes/Econ%C3%B3micos/4144.pdf.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

150 |

Corrêa, N. et al. (2023), “Worldwide Al ethics: A review of 200 guidelines and recommendations [114]
for Al governance", Patterns, Vol. 4/10, p. 100857,
https://doi.org/10.1016/j.patter.2023.100857.

Council of Europe (2024), Framework Convention on Artificial Intelligence and Human Rights, [119]
Democracy and the Rule of Law, https://www.coe.int/en/web/artificial-intelligence/the-
framework-convention-on-artificial-intelligence.

Cover-Kus, H. (2024), UK Government doubles down efforts to deploy Al across the public [97]
sector, https://www.techuk.org/resource/uk-government-doubles-down-efforts-to-deploy-ai-
across-the-public-sector.html.

Deleware General Assembly (2024), House Bill 333: An Act to Amend Title 29 of the Deleware [124]
Code Relating to the Artificial Intelligence Commission,
https://legis.delaware.gov/BillDetail/140866.

Digdir (2024), The Norwegian Resource Centre for Sharing and Use of Data, [60]
https://www.digdir.no/datadeling/norwegian-resource-centre-sharing-and-use-data/2766
(accessed on November 2024).

Dombo, F. (2023), Public Sector Considerations for Successful Cloud Adoption, [73]
https://news.sap.com/africa/2023/05/public-sector-considerations-for-successful-cloud-
adoption/.

EC (2025), A pioneering Al project awarded for opening Large Language Models to European [87]
languages, https://digital-strategy.ec.europa.eu/en/news/pioneering-ai-project-awarded-
opening-large-language-models-european-languages (accessed on 10 March 2025).

EC (2025), Common European Data Spaces, European Commission, https://digital- [55]
strategy.ec.europa.eu/en/policies/data-spaces.

EC (2025), The Al Continent Action Plan, European Commission, https://digital- [67]
strategy.ec.europa.eu/en/library/ai-continent-action-plan.

EC (2025), Updated EU Al model contractual clauses, European Commission, https://public- [103]
buyers-community.ec.europa.eu/communities/procurement-ai/resources/updated-eu-ai-
model-contractual-clauses.

EC (2024), Adopt Al study, European Commission, https://op.europa.eu/s/z2tg. [96]

EC (2024), GovTech: influencing factors, common requirements and recommendations, [110]
European Commission, https://interoperable-europe.ec.europa.eu/collection/public-sector-
tech-watch/document/govtech-influencing-factors-common-requirements-and-
recommendations.

EC (2024), What factors influence perceived artificial intelligence adoption by public managers, [8]
European Commission Joint Research Centre,
https://publications.jrc.ec.europa.eu/repository/bitstream/JRC138684/JRC138684_01.pdf.

EC (2023), EU model contractual Al clauses to pilot in procurements of Al, https://public-buyers- [102]
community.ec.europa.eu/communities/procurement-ai/resources/eu-model-contractual-ai-
clauses-pilot-procurements-ai.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 151

Fink, K. (2017), "Opening the government's black boxes: freedom of information and algorithmic [132]
accountability”, Information, Communication & Society, Vol. 21/10, pp. 1453-1471,
https://doi.org/10.1080/1369118x.2017.1330418.

France Élysée (2025), Make France and Al Powerhouse, [64]
https://www.elysee.fr/admin/upload/default/0001/17/d9c1462e7337d353f918aac7d654b896b
77c5349.pdf.

Frazier, K. (2025), The Dangers of Al Sovereignty, https://www.lawfaremedia.org/article/the- [70]
dangers-of-ai-sovereignty.

G7 (2023), Hiroshima Process International Code of Conduct for Advanced Al Systems, [137]
https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-
advanced-ai-systems.

G7 (2023), Hiroshima Process International Guiding Principles for Advanced Al system, [136]
https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-
principles-advanced-ai-system.

Gartner (2024), Compare Al Software Spending in the Government Industry, 2023-2027, [92]
https://www.gartner.com/en/documents/5318363.

Gob.cl (2025), Latam GPT: Learn about the Latin American Al model developed in Chile, [86]
https://www.gob.cl/en/news/latam-gpt-learn-about-the-latin-american-ai-model-developed-in-
chile/ (accessed on 10 March 2025).

Goodman, E. and J. Trehu (2022), Al Audit-Washing and Accountability, [143]
https://www.gmfus.org/news/ai-audit-washing-and-accountability.

Government of Canada (2025), Al Strategy for the Federal Public Service, [13]
https://www.canada.ca/en/government/system/digital-government/digital-government-
innovations/responsible-use-ai/gc-ai-strategy-overview.html.

Government of Greece (2025), The implementation of the new National Supercomputer [82]
"DAIDALOS” and the Data Center at the Lavrio TPP begins - The country acquires one of the
most powerful computing systems in Europe, https://mindigital.gr/archives/7331.

Government of Greece (2024), A Blueprint for Greece's Al Transformation, [47]
https://foresight.gov.gr/wp-
content/uploads/2024/11/Blueprint_GREECES_AI_TRANSFORMATION.pdf.

Government of Ireland (2025), Guidelines for the Responsible Use of Al in the Public Service, [19]
https://www.gov.ie/en/department-of-public-expenditure-ndp-delivery-and-
reform/publications/guidelines-for-the-responsible-use-of-ai-in-the-public-service.

Government of Korea (2024), A New Chapter in the Age of Al: Basic Act on Al Passed at the [122]
National Assembly's Plenary Session,
https://www.msit.go.kr/eng/bbs/view.do?bbsSeqNo=42&mId=4&mPid=2&nttSeqNo=1071.

Government of New Zealand (2025), Public Service Al Framework, [18]
https://www.digital.govt.nz/standards-and-guidance/technology-and-architecture/artificial-
intelligence/public-service-artificial-intelligence-framework.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

152 |

Government of Spain (2024), Spain sets up the International Artificial Intelligence Advisory [146]
Council, https://www.lamoncloa.gob.es/lang/en/gobierno/news/Paginas/2024/20240621-ai-
advisory-council-meeting.aspx.

Government of Spain (2024), The Government approves the Artificial Intelligence Strategy 2024, [109]
https://portal.mineco.gob.es/en-us/comunicacion/Pages/20240514-Gobierno-aprueba-
Estrategia-IA-2024.aspx.

Government of Switzerland (2025), Strategy Use of Al systems in the Federal Administration, [14]
https://www.bk.admin.ch/bk/en/home/digitale-transformation-ikt-lenkung/ikt-
vorgaben/strategien-teilstrategien/sb021-strategie-einsatz-von-ki-systemen-in-der-
bundesverwaltung.html.

Government of the Dominican Republic (2024), Estrategie Nacional de Inteligencia Artificial, [12]
https://innovacionrd.gob.do/enia/.

Government of Uruguay (2021), Al Strategy for the Digital Government, [15]
https://www.gub.uy/agencia-gobierno-electronico-sociedad-informacion-
conocimiento/comunicacion/publicaciones/ia-strategy-english-version/ia-strategy-english-
version/ai-strategy-for.

GPAI (2024), Algorithmic Transparency in the Public Sector: A state-of-the-art report of [125]
algorithmic transparency instruments, Global Partnership on Artificial Intelligence,
https://gpai.ai/projects/responsible-ai/algorithmic-transparency-in-the-public-
sector/algorithmic-transparency-in-the-public-sector.pdf.

Gupta, A. et al. (2021), The State of Al Ethics Report (Volume 5), [140]
https://arxiv.org/abs/2108.03929.

Hassani, A. et al. (2022), Escaping the Big Data Paradigm with Compact Transformers, [79]
https://arxiv.org/abs/2104.05704.

IEA (2025), Energy and Al, https://iea.blob.core.windows.net/assets/34eac603-ecf1-464f-b813- [77]
2ecceb8f81c2/EnergyandAl.pdf.

IEA (2023), Data Centres and Data Transmission Networks, https://www.iea.org/energy- [76]
system/buildings/data-centres-and-data-transmission-networks.

Jones, N. (2025), Where Al Is Now: Smaller, Better, Cheaper Models, [80]
https://www.scientificamerican.com/article/ai-report-highlights-smaller-better-cheaper-models.

Komaitis, K., E. Ponce de León and K. Thibaut (2024), The sovereignty trap, [69]
https://www.atlanticcouncil.org/blogs/geotech-cues/the-sovereignty-trap.

Lam, M. et al. (2023), “Sociotechnical Audits: Broadening the Algorithm Auditing Lens to [142]
Investigate Targeted Advertising”, Proceedings of the ACM on Human-Computer Interaction,
Vol. 7/CSCW2, pp. 1-37, https://doi.org/10.1145/3610209.

Leslie, D. (2019), Understanding artificial intelligence ethics and safety, The Alan Turing Institute, [116]
https://doi.org/10.5281/zenodo.3240529.

Letzing, J. (2024), What is 'sovereign Al' and why is the concept so appealing (and fraught)?, [63]
https://www.weforum.org/stories/2024/11/what-is-sovereign-ai-and-why-is-the-concept-so-
appealing-and-fraught/.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 153

Long, D. and B. Magerko (2020), “What is Al Literacy? Competencies and Design [90]
Considerations", Proceedings of the 2020 CHI Conference on Human Factors in Computing
Systems, pp. 1-16, https://doi.org/10.1145/3313831.3376727.

M Saiful Bari, Y. (2024), “ALLaM: Large Language Models for Arabic and English”. [48]

Marcucci, S., U. Kalkar and S. Verhulst (2022), Al Localism in Practice: Examining How Cities [154]
Govern Al, https://files.thegovlab.org/ailocalism-in-practice.pdf.

McKinsey (2024), Al power: Expanding data center capacity to meet growing demand, [75]
https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-
insights/ai-power-expanding-data-center-capacity-to-meet-growing-demand.

Mehta, S., A. Rogers and T. Gilbert (2023), Dynamic Documentation for Al Systems, [141]
https://arxiv.org/abs/2303.10854.

METR (2023), Responsible Scaling Policies (RSPs), https://metr.org/blog/2023-09-26-rsp/. [144]

Metz, C. et al. (2025), How A.I. is Changing the Way the World Builds Computers, [78]
https://www.nytimes.com/interactive/2025/03/16/technology/ai-data-centers.html.

Monteiro, B., A. Hlacs and P. Boéchat (2024), “Public procurement for public sector [100]
innovation: Facilitating innovators' access to innovation procurement", OECD Working Papers
on Public Governance, No. 80, OECD Publishing, Paris, https://doi.org/10.1787/9aad76b7-en.

Montgomery, C., F. Rossi and J. New (2023), A Policymaker's Guide to Foundation Models, [84]
https://newsroom.ibm.com/Whitepaper-A-Policymakers-Guide-to-Foundation-Models.

Mulgan, G. (2019), Intelligence as an outcome not an input, [26]
http://www.nesta.org.uk/blog/intelligence-outcome-not-input.

Netherlands Court of Audit (2024), Focus on Al in central government, [127]
https://english.rekenkamer.nl/publications/reports/2024/10/16/focus-on-ai-in-central-
government.

NIST (2023), Al Risk Management Framework, https://www.nist.gov/itl/ai-risk-management- [135]
framework.

Noor, E. and B. Kanitroj (2025), Speaking in Code: Contextualizing Large Language Models in [88]
Southeast Asia, https://carnegieendowment.org/research/2025/01/speaking-in-code-
contextualizing-large-language-models-in-southeast-asia.

OECD (2025), "Effectively Managing Investments in Digital Government: An OECD Policy [93]
Framework", OECD Public Governance Policy Papers, No. 76, OECD Publishing, Paris,
https://doi.org/10.1787/5c324e91-en.

OECD (2025), Enhancing Access to and Sharing of Data in the Age of Artificial Intelligence, [50]
OECD Publishing Paris, https://www.oecd.org/en/publications/enhancing-access-to-and-
sharing-of-data-in-the-age-of-artificial-intelligence_23a70dca-en.html.

OECD (2025), OECD Regulatory Policy Outlook 2025, OECD Publishing, Paris, [120]
https://doi.org/10.1787/56b60e39-en.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# Page 1

154 |

OECD (2024), “2023 OECD Digital Government Index: Results and key findings", OECD Public Governance Policy Papers, No. 44, OECD Publishing, Paris, https://doi.org/10.1787/1a89ed5e-en.
[74]

OECD (2024), “Al, data governance and privacy: Synergies and areas of international co-operation", OECD Artificial Intelligence Papers, No. 22, OECD Publishing, Paris, https://doi.org/10.1787/2476b1a4-en.
[40]

OECD (2024), "Assessing potential future artificial intelligence risks, benefits and policy imperatives", OECD Artificial Intelligence Papers, No. 27, OECD Publishing, Paris, https://doi.org/10.1787/3f4e3dfb-en.
[138]

OECD (2024), “Digital public infrastructure for digital governments”, OECD Public Governance Policy Papers, No. 68, OECD Publishing, Paris, https://doi.org/10.1787/ff525dc8-en.
[62]

OECD (2024), Enabling Digital Innovation in Government: The OECD GovTech Policy Framework, OECD Digital Government Studies, OECD Publishing, Paris, https://doi.org/10.1787/a51eb9b2-en.
[108]

OECD (2024), “Fixing frictions: 'sludge audits' around the world: How governments are using behavioural science to reduce psychological burdens in public services", OECD Public Governance Policy Papers, No. 48, OECD Publishing, Paris, https://doi.org/10.1787/5e9bb35c-en.
[2]

OECD (2024), Framework for Anticipatory Governance of Emerging Technologies, OECD Publishing, https://doi.org/10.1787/0248ead5-en.
[148]

OECD (2024), G20 Compendium on Data Access and Sharing Across the Public Sector and with the Private Sector for Public Interest, OECD Publishing, Paris, https://www.oecd.org/en/publications/g20-compendium-on-data-access-and-sharing-across-the-public-sector-and-with-the-private-sector-for-public-interest df1031a4-en.html.
[54]

OECD (2024), “Governing with Artificial Intelligence: Are governments ready?”, OECD Artificial Intelligence Papers, No. 20, OECD Publishing, Paris, https://doi.org/10.1787/26324bc2-en.
[3]

OECD (2024), OECD Artificial Intelligence Review of Germany, OECD Publishing, Paris, https://doi.org/10.1787/609808d6-en.
[94]

OECD (2024), OECD Digital Economy Outlook 2024 (Volume 1): Embracing the Technology Frontier, OECD Publishing, Paris, https://doi.org/10.1787/a1689dc5-en.
[83]

OECD (2024), Public procurement, https://www.oecd.org/en/topics/public-procurement.html.
[106]

OECD (2024), Recommendation of the Council on Artificial Intelligence, OECD Publishing, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449.
[158]

OECD (2024), The Digital Transformation of Norway's Public Sector, OECD Digital Government Studies, OECD Publishing, Paris, https://doi.org/10.1787/1620e542-en.
[99]

OECD (2023), “2023 OECD Open, Useful and Re-usable data (OURdata) Index: Results and key findings", OECD Public Governance Policy Papers, No. 43, OECD Publishing, Paris, https://doi.org/10.1787/a37f51c3-en.
[52]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 2

| 155

OECD (2023), "Advancing accountability in Al: Governing and managing risks throughout the lifecycle for trustworthy Al”, OECD Digital Economy Papers, No. 349, OECD Publishing, Paris, https://doi.org/10.1787/2448f04b-en.
[134]

OECD (2023), “Al language models: Technological, socio-economic and policy considerations”, OECD Digital Economy Papers, No. 352, OECD Publishing, Paris, https://doi.org/10.1787/13d38f92-en.
[44]

OECD (2023), "Common guideposts to promote interoperability in Al risk management", OECD Artificial Intelligence Papers, No. 5, OECD Publishing, Paris, https://doi.org/10.1787/ba602d18-en.
[139]

OECD (2023), Global Trends in Government Innovation 2023, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/0655b570-en.
[130]

OECD (2023), OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market, OECD Publishing, Paris, https://doi.org/10.1787/08785bba-en.
[118]

OECD (2023), “Regulatory sandboxes in artificial intelligence”, OECD Digital Economy Papers, No. 356, OECD Publishing, Paris, https://doi.org/10.1787/8f80a0e6-en.
[35]

OECD (2022), Going Digital to Advance Data Governance for Growth and Well-being, OECD Publishing, Paris, https://doi.org/10.1787/e3d783b0-en.
[56]

OECD (2022), "Measuring the environmental impacts of artificial intelligence compute and applications: The Al footprint", OECD Digital Economy Papers, No. 341, OECD Publishing, Paris, https://doi.org/10.1787/7babf571-en.
[71]

OECD (2022), “OECD Framework for the Classification of Al systems", OECD Digital Economy Papers, No. 323, OECD Publishing, Paris, https://doi.org/10.1787/cb6d9eca-en.
[58]

OECD (2022), “OECD Good Practice Principles for Public Service Design and Delivery in the Digital Age", OECD Public Governance Policy Papers, No. 23, OECD Publishing, Paris, https://doi.org/10.1787/2ade500b-en.
[156]

OECD (2022), OECD Guidelines for Citizen Participation Processes, OECD Publishing, https://doi.org/10.1787/f765caf6-en.
[150]

OECD (2021), "Achieving cross-border government innovation: Governing cross-border challenges", OECD Public Governance Policy Papers, No. 10, OECD Publishing, Paris, https://doi.org/10.1787/ddd07e3b-en.
[157]

OECD (2021), G20 survey on Agile approaches to the regulatory governance of innovation: Report for the G20 Digital Economy Task Force, Trieste, Italy, August 2021, OECD Publishing, Paris, https://doi.org/10.1787/f161916d-en.
[112]

OECD (2021), Good Practice Principles for Data Ethics in the Public Sector - OECD, OECD Publishing, Paris, https://www.oecd.org/gov/digital-government/good-practice-principles-for-data-ethics-in-the-public-sector.htm (accessed on 14 April 2025).
[43]

OECD (2021), OECD Report on Public Communication: The Global Context and the Way Forward, OECD Publishing, https://doi.org/10.1787/22f8031c-en.
[21]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 3

156 |

OECD (2021), Public Sector Innovation Facets: Mission-oriented innovation, OECD Publishing, https://oecd-opsi.org/publications/facets-mission/.
[9]

OECD (2021), Recommendation of the Council for Agile Regulatory Governance to Harness Innovation, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0464.
[121]

OECD (2021), “The OECD Framework for digital talent and skills in the public sector", OECD Working Papers on Public Governance, No. 45, OECD Publishing, Paris, https://doi.org/10.1787/4e7c3f58-en.
[7]

OECD (2020), Innovative Citizen Participation and New Democratic Institutions: Catching the Deliberative Wave, OECD Publishing, Paris, https://doi.org/10.1787/339306da-en.
[149]

OECD (2019), Artificial Intelligence in Society, OECD Publishing, Paris, https://doi.org/10.1787/eedfee77-en.
[34]

OECD (2019), "Data governance in the public sector", in The Path to Becoming a Data-Driven Public Sector, OECD Publishing, Paris, https://doi.org/10.1787/9cada708-en.
[59]

OECD (2019), Recommendation of the Council on Public Service Leadership and Capability, OECD Publishing, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0445.
[159]

OECD (2019), The Path to Becoming a Data-Driven Public Sector, OECD Digital Government Studies, OECD Publishing, Paris, https://doi.org/10.1787/059814a7-en.
[57]

OECD (2017), Systems Approaches to Public Sector Challenges: Working with Change, OECD Publishing, Paris, https://doi.org/10.1787/9789264279865-en.
[1]

OECD (forthcoming), Generative Al Experimentation in Government: A review of current practices, OECD Publishing.
[37]

OECD (forthcoming), Mapping Relevant Data Collection Mechanisms for Al Training.
[38]

OECD.AI (2025), The OECD-African Union Al Dialogue 2.0: From strategy to implementation, https://oecd.ai/en/wonk/the-oecd-african-union-ai-dialogue-2-0-from-strategy-to-implementation.
[115]

OECD/CAF (2022), The Strategic and Responsible Use of Artificial Intelligence in the Public Sector of Latin America and the Caribbean, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/1f334543-en.
[30]

OECD/UNESCO (2024), G7 Toolkit for Artificial Intelligence in the Public Sector, OECD Publishing, Paris, https://doi.org/10.1787/421c1244-en.
[29]

Pahlka, J. (2024), Al meets the cascade of rigidity, https://www.niskanencenter.org/ai-meets-the-cascade-of-rigidity/.
[20]

Parankusham, K., R. Rizk and K. Santosh (2025), LakotaBERT: A Transformer-based Model for Low Resource Lakota Language, https://arxiv.org/abs/2503.18212.
[49]

Pehlivan, C. and E. Valín (2023), Spain establishes the EU's first Al supervisory agency, https://techinsights.linklaters.com/post/102intj/spain-establishes-the-eus-first-ai-supervisory-agency.
[145]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 4

| 157

Peixoto, T., O. Canuto and L. Jordan (2024), Al and the Future of Government: Unexpected Effects and Critical Challenges, https://www.policycenter.ma/publications/ai-and-future-government-unexpected-effects-and-critical-challenges.
[45]

Personal Information Protection Commission of Korea (2023), Policy direction for safe use of personal information in the era of artificial intelligence [translated], https://www.pipc.go.kr/np/cop/bbs/selectBoardArticle.do?bbsId=BS074&mCode=C020010000&nttld=9083.
[39]

Policy Lab Digital, Work & Society within the German Federal Ministry of Labour and Social Affairs (2024), Guidelines for the Use of Al in the Administrative Work of Employment and Social Protection Services, https://www.denkfabrik-bmas.de/fileadmin/Downloads/Publikationen/Guidelines_for_the_use_of_ai_in_the_administr ative_work_of_employment_and_social_protection_services.pdf.
[117]

Ramos, J. (2018), Laboratorio Para La Ciudad (CDMX), https://actionforesight.net/laboratorio-para-la-ciudad-cdmx/.
[155]

Ray, T. (2025), Sovereign remedies: Between Al autonomy and control, https://www.atlanticcouncil.org/in-depth-research-reports/issue-brief/sovereign-remedies-between-ai-autonomy-and-control/.
[66]

Redapt (2023), On-Premises vs. Cloud for Al Workloads, https://www.redapt.com/blog/on-premises-vs-cloud-for-ai-workloads.
[72]

Rudra, S. (2024), OSI Calls Out Meta for its Misleading 'Open Source' Al Models, https://news.itsfoss.com/osi-meta-ai/.
[160]

Ryseff, J., B. De Bruhl and S. Newberry (2024), The Root Causes of Failure for Artificial Intelligence Projects and How They Can Succeed, RAND, https://www.rand.org/pubs/research_reports/RRA2680-1.html.
[24]

Ryseff, J. and A. Narayanan (2025), Why Al Projects Fail, https://www.rand.org/pubs/presentations/PTA2680-1.html.
[25]

SDAIA (2025), Government Cloud (Deem), https://sdaia.gov.sa/en/Services/Pages/Deem.aspx.
[81]

Seger, E. et al. (2024), Open-Sourcing Highly Capable Foundation Models: An Evaluation of Risks, Benefits, and Alternative Methods for Pursuing Open-Source Objectives, https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models.
[85]

The Alan Turing Institute (2023), Al Skills for Business Competency Framework, https://www.turing.ac.uk/skills/collaborate/ai-skills-business-framework.
[91]

U.S. General Services Administration (2024), Al Capability Maturity - Operational maturity areas, https://coe.gsa.gov/coe/ai-guide-for-government/operational-maturity-areas/index.html#dataops.
[61]

UCL IIPP (2019), A Mission-Oriented UK Industrial Strategy, https://www.ucl.ac.uk/bartlett/public-purpose/sites/public-purpose/files/190515_iipp_report_moiis_final_artwork_digital_export.pdf.
[10]

UK Committee of Public Accounts (2025), Use of Al in Government, https://committees.parliament.uk/publications/47199/documents/244683/default/.
[128]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 5

158 |

UK DSIT (2024), Global leaders agree to launch first international network of Al Safety Institutes to boost cooperation of Al, https://www.gov.uk/government/news/global-leaders-agree-to-launch-first-international-network-of-ai-safety-institutes-to-boost-understanding-of-ai.
[147]

UK DSIT (2020), Guidelines for Al procurement, https://www.gov.uk/government/publications/guidelines-for-ai-procurement/guidelines-for-ai-procurement.
[27]

UK Government (2025), A blueprint for modern digital government, https://www.gov.uk/government/publications/a-blueprint-for-modern-digital-government/a-blueprint-for-modern-digital-government-html.
[6]

UK Government (2025), Prime Minister: I will reshape the state to deliver security for working people, https://www.gov.uk/government/news/prime-minister-i-will-reshape-the-state-to-deliver-security-for-working-people.
[5]

UK Government Digital Service (2025), Artificial Intelligence Playbook for the UK Government, https://www.gov.uk/government/publications/ai-playbook-for-the-uk-government/artificial-intelligence-playbook-for-the-uk-government-html.
[22]

UK House of Commons (2024), Governance of Artificial Intelligence (AI): Government Response, https://committees.parliament.uk/publications/46145/documents/230927/default/.
[98]

UK NAO (2024), Use of articial intelligence in government, https://www.nao.org.uk/wp-content/uploads/2024/03/use-of-artificial-intelligence-in-government.pdf.
[16]

UNESCO (2024), Consultation paper on Al regulation: emerging approaches across the world, https://unesdoc.unesco.org/ark:/48223/pf0000390979.
[111]

UNESCO (2023), Ethical impact assessment. A tool of the Recommendation on the Ethics of Artificial Intelligence, UNESCO, https://doi.org/10.54678/ytsa7796.
[113]

University of Rome Sapienza (2024), Al made in Italy: here is Minerva, the first family of large language models trained “from scratch” for Italian, https://www.uniroma1.it/en/notizia/ai-made-italy-here-minerva-first-family-large-language-models-trained-scratch-italian (accessed on 10 March 2025).
[89]

US IT Modernization Centers of Excellence (n.d.), Al Guide for Government, https://coe.gsa.gov/ai-guide-for-government.
[28]

US OMB (2025), Accelerating Federal Use of Al through Innovation, Governance, and Public Trust, https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-Al-through-Innovation-Governance-and-Public-Trust.pdf.
[17]

US OMB (2025), M-25-22 Driving Efficient Acquisition of Artificial Intelligence in Government, White House Office of Management and Budget, https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-22-Driving-Efficient-Acquisition-of-Artificial-Intelligence-in-Government.pdf.
[105]

Valderrama, M., M. Hermosilla and R. Garrido (2023), State of the Evidence: Algorithmic Transparency, https://www.opengovpartnership.org/wp-content/uploads/2023/05/State-of-the-Evidence-Algorithmic-Transparency.pdf (accessed on August 2024).
[131]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# Page 1

| 159

van Noordt, C., R. Medaglia and L. Tangi (2023), “Policy initiatives for Artificial Intelligence- [95]
enabled government: An analysis of national strategies in Europe", Public Policy and
Administration, https://doi.org/10.1177/09520767231198411.

Vergne, A. and A. Siu (2025), Global Coalition for an Inclusive Al, https://global-ai-dialogue.org/. [153]

Verhulst, S. and M. Sloane (2020), Realizing the Potential of Al Localism, https://www.project- [33]
syndicate.org/commentary/local-regulation-of-artificial-intelligence-uses-by-stefaan-g-
verhulst-1-and-mona-sloane-2020-02?barrier=accesspaylog.

Vinnova (2022), Designing missions, [11]
https://www.vinnova.se/contentassets/1c94a5c2f72c41cb9e651827f29edc14/designing-
missions.pdf?cb=20220311094952.

WAM (2024), Hamdan bin Mohammed appoints 22 Chief Al Officers across government entities [32]
in Dubai, https://www.wam.ae/en/article/b3kujwp-hamdan-bin-mohammed-appoints-chief-
officers-across.

Werner, J. (2024), New York Governor Signs Al Oversight Bill, https://babl.ai/new-york-governor- [123]
signs-ai-oversight-bill.

World Bank (2025), Global Trends in Al Governance: Evolving Country Approaches, [107]
https://openknowledge.worldbank.org/entities/publication/a570d81a-0b48-4cac-a3d9-
73dff48a8f1a.

World Economic Forum (2025), Al Procurement Guideline, [104]
https://www.weforum.org/publications/ai-procurement-in-a-box/ai-government-procurement-
guidelines/ (accessed on 10 March 2025).

# Notes

¹ See https://oecd-opsi.org/work-areas/systems-approaches.

² See https://oecd-opsi.org/work-areas/anticipatory-innovation and
https://www.oecd.org/en/about/programmes/strategic-foresight.

³ The context and use of “enablers” in this report are not the same as the “Al enablers” for Al systems
generally discussed by Al policy and technical communities, which consist of data, algorithms and
computational power (“compute").

⁴ See https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-
bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023,
https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-
seoul-summit-2024, and https://www.elysee.fr/en/emmanuel-macron/2025/02/11/statement-on-inclusive-
and-sustainable-artificial-intelligence-for-people-and-the-planet, respectively.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 2

160 |

⁵ See (OECD, 2021[7]) for additional relevant material, including skills and competencies for digital
government leadership. See also the OECD (2019[159]) Recommendation on Public Service Leadership
and Capability for information on how countries can instil values-driven culture and leadership, and ensure
skilled and effective public servants, and responsive and adaptive public employment systems.

⁶ The OECD is engaged in supporting mission-oriented innovations through its Mission Action Lab, a joint
initiative from the OECD Directorate for Science, Technology and Innovation (STI), Observatory of Public
Sector Innovation (OPSI) in the Public Governance Directorate (GOV), and the Development Co-operation
Directorate (DCD). See https://oecd-missions.org.

⁷ Behavioural science is an interdisciplinary approach that encompasses the study of human behaviour
and the design of strategies to change it. See https://www.oecd.org/en/topics/behavioural-science.

⁸ See https://www.apsc.gov.au/initiatives-and-programs/workforce-information/research-analysis-and-
publications/state-service/state-service-report-2023-24/fit-future/supporting-safe-and-responsible-use-
artificial-intelligence.

⁹ See https://www.digmin.dk/digitalisering/mere-om-digitalisering/digital-taskforce-for-kunstig-intelligens-.

¹⁰ See https://www.mitre.org/news-insights/fact-sheet/federal-ai-sandbox and https://www.mitre.org/news-
insights/news-release/mitre-establish-new-ai-experimentation-and-prototyping-capability-us.

¹¹ https://ai.gov.uk.

¹² https://alliance.numerique.gouv.fr.

¹³ See https://govtech.justica.gov.pt/en/govtech-justica-english and
https://www.ceej.es/legal&justiciatechlab/?r=vxpx6w6j70qr1jstvc6, respectively.

¹⁴ Details provided in Spain's 2024 Al strategy, https://avance.digital.gob.es/es-
es/notasprensa/paginas/20240514-gobierno-aprueba-estrategia-ia-2024.aspx.

¹⁵ https://www.gov.uk/government/publications/the-magenta-book/guidance-on-the-impact-evaluation-of-
ai-interventions-html.

¹⁶ See https://www.gov.uk/guidance/repository-of-privacy-enhancing-technologies-pets-use-cases for a
repository of use cases from different countries assembled by the UK.

¹⁷ Other countries include Brazil, Canada, China, Egypt, Estonia, Finland, Germany, France, Hungary,
Iceland, India, Israel, Japan, Korea, Latvia, Norway, Qatar, Singapore, Slovenia, South Africa, Spain,
Thailand, Türkiye, the UK, and Viet Nam.

¹⁸ See also https://www.ekt.gr/en/news/30774.

¹⁹ See https://www.athenarc.gr/el/news/meltemi-proto-anoihto-megalo-glossiko-montelo-gia-ta-ellinika
and https://www.athenarc.gr/en/news/llama-krikri-new-greek-ai-language-model-featured-kathimerini,
respectively.

²⁰ See https://static.pib.gov.in/WriteReadData/specificdocs/documents/2022/aug/doc202282696201.pdf
and https://www.indiatoday.in/technology/news/story/bhashini-ceo-amitabh-nag-talks-about-how-their-ai-

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 3

| 161

tool-is-bridging-indias-language-divide-2646101-2024-12-06; information supplemented by Government
of India officials.

²¹ See https://interoperable-europe.ec.europa.eu/collection/open-source-observatory-osor/news/spanish-
authorities-release-alia-ai-models.

²² https://www.canada.ca/en/treasury-board-secretariat/corporate/reports/2023-2026-data-strategy.html.

²³ See https://www.gov.uk/guidance/national-data-strategy and https://www.dta.gov.au/digital-
government-strategy, respectively.

²⁴ See https://www.gov.br/governodigital/pt-br/capacitacao/capacita-gov-br.

²⁵ See https://sbci.gov.ie/information-access/data-sharing-and-governance-act, https://eur-
lex.europa.eu/eli/reg/2016/679/oj, https://eur-lex.europa.eu/eli/reg/2023/2854, https://eur-
lex.europa.eu/eli/reg/2022/868/oj, https://eur-lex.europa.eu/eli/dir/2019/1024/oj, and
https://ec.europa.eu/isa2/eif_en, respectively.

²⁶ Digital Public Infrastructure (DPI) is defined as shared digital systems that are secure and interoperable
and that can support the inclusive delivery of and access to public and private services across society.
Such systems act as common digital building blocks that underpin government processes and services
and enable digital government transformation at societal scale (OECD, 2024[62]).

²⁷ https://www.gov.br/governodigital/pt-br/infraestrutura-nacional-de-dados.

²⁸ Model weights are “The variables or numerical values used to specify how the input (e.g. text describing
an image) is transformed into the output (e.g. the image itself). These are iteratively updated during model
training to improve the model's performance on the tasks for which it is trained" (Seger et al., 2024[85]). The
use of "open-source” models for this report does not imply that such models are released under an open-
source license approved by the Open Source Initiative (OSI), a nonprofit steward of the Open Source
Definition (https://opensource.org/osd). OSI has criticised some companies that call their models open
source because they only provide the weights for the model, and not other elements, such as the training
data, code and training practices (Rudra, 2024[160]). Some argue that such models should be called “open
weight" instead of "open source”.

²⁹ https://bigscience.huggingface.co/blog/bloom.

³⁰ https://www.tech.gov.sg/products-and-services/for-government-agencies/productivity-and-
marketing/vica.

³¹ See https://oecd.ai/catalogue.

³² https://indiaai.s3.ap-south-1.amazonaws.com/docs/empowering-public-sector-leadership.pdf.
Information supplemented by Government of India officials.

³³ See https://www.ipa.ie/ipa-overview/onelearning.2548.html and https://www.ypes.gr/ypourgeio-
esoterikon-google-enarxi-epimorfotikis-drasis-gia-dimosious-ypallilous-me-thema-tin-techniti-noimosyni,
respectively.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 4

162 |

³⁴ See https://www.elementsofai.com.

³⁵ See https://www.canada.ca/en/government/system/digital-government/digital-talent-strategy.html.

³⁶ See https://chcoc.gov/content/skills-based-hiring-guidance-and-competency-model-artificial-
intelligence-work.

³⁷ See https://innovadorespublicos.cl and https://innovadorespublicos.cl/events/652/.

³⁸ https://catalogue.csps-efpc.gc.ca/product?catalog=DDN3-E45&cm_locale=en.

³⁹ https://www.smart-city-dialog.de/en/about-us/international-smart-cities-network.

⁴⁰ https://alliance.numerique.gouv.fr.

⁴¹ See: https://cnai.swiss/en/products/community-of-practice/

⁴² See https://www.cio.bund.de/Webs/CIO/DE/digitale-loesungen/datenpolitik/daten-und-ki/daten-und-ki-
node.html. and https://www.digitale-
verwaltung.de/SharedDocs/downloads/Webs/DV/DE/Transformation/akteurssteckbrief-beki.pdf.

⁴³ See https://www.digital.gov.au/policy/ai/pilot-ai-assurance-framework,
https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-
ethics-principles and https://www.digital.gov.au/policy/ai, respectively.

⁴⁴ See https://www.gsa.gov/about-us/newsroom/news-releases/technology-modernization-fund-seeking-
proposals-fo-02082024.

⁴⁵ https://www.numerique.gouv.fr/services/guichet-financement-exploitation-valorisation-des-donnees/

⁴⁶ See https://www.numerique.gouv.fr/offre-accompagnement/pilotage-panorama/.

⁴⁷ https://public-buyers-community.ec.europa.eu/communities/procurement-ai/resources/eu-model-
contractual-ai-clauses-pilot-procurements-ai

⁴⁸ https://www.buyict.gov.au/sys_attachment.do?sys_id=e535e2ca935caa10438b39cdfaba103d.

⁴⁹ See also https://www.chilecompra.cl/2024/11/goblab-uai-presento-nueva-herramienta-para-una-ia-
responsable-y-etica.

⁵⁰ https://ec.europa.eu/commission/presscorner/detail/en/ip_25_467.

⁵¹ See https://www.elysee.fr/en/emmanuel-macron/2025/02/11/statement-on-inclusive-and-sustainable-
artificial-intelligence-for-people-and-the-planet and https://www.elysee.fr/en/sommet-pour-l-action-sur-l-
ia/public-interest-ai.

⁵² https://www.dataobservatory.net.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# Page 5

| 163

⁵³ See https://www.rtu.lv/en/university/for-mass-media/news/open/latvia-establishes-artificial-intelligence-
centre and https://digital-skills-jobs.europa.eu/en/latest/news/latvia-establishes-artificial-intelligence-
centre.

⁵⁴ See https://oecd.ai/ai-principles, https://www.unesco.org/en/articles/recommendation-ethics-artificial-
intelligence, https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai, and
https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-principles-
advanced-ai-system, respectively.

⁵⁵ https://docs.un.org/en/A/78/L.49.

⁵⁶ See https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-
bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023,
https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-
seoul-summit-2024 and https://www.elysee.fr/en/emmanuel-macron/2025/02/11/statement-on-inclusive-
and-sustainable-artificial-intelligence-for-people-and-the-planet, respectively.

⁵⁷ https://www.industry.gov.au/publications/voluntary-ai-safety-standard.

⁵⁸ See also https://oecd.ai/en/wonk/how-the-oecd-ai-policy-observatory-has-shaped-colombia-and-latin-
americas-approach-to-ai-policy.

⁵⁹ https://aicm.ai.gov.eg/en/Resources/EgyptianCharterForResponsibleAlEnglish-v1.0.pdf.

⁶⁰ https://www.canada.ca/en/government/system/digital-government/digital-government-
innovations/responsible-use-ai/guide-use-generative-ai.html.

⁶¹ https://www.cio.bund.de/Webs/CIO/DE/digitale-
loesungen/kuenstliche_intelligenz/kuenstliche_intelligenz-node.html.

⁶² https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper.

⁶³ See https://hyscaler.com/insights/bahrain-pioneers-ai-regulation and
https://www.ita.gov.om/itaportal/Data/SiteImgGallery/2024731125545486/National%20Artificial%20Intelli
gence%20Policy.pdf, respectively.

⁶⁴ https://www.whitehouse.gov/wp-content/uploads/2025/02/M-25-21-Accelerating-Federal-Use-of-Al-
through-Innovation-Governance-and-Public-Trust.pdf.

⁶⁵ https://research-
data.urosario.edu.co/file.xhtml?persistentId=doi:10.34848/YN1CRT/8OHRT0&version=1.0.

⁶⁶ https://www.gov.uk/algorithmic-transparency-records.

⁶⁷ See https://github.com/ombegov/2024-Federal-Al-Use-Case-Inventory for a centralised consolidation of
Al use case inventories from across US federal government agencies.

⁶⁸ See https://www.algoritmospublicos.cl/repositorio, https://odap.fr/inventaire, and
https://algoritmes.overheid.nl, respectively.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

164 |

69 See https://algoritmeregister.amsterdam.nl/en/ai-register and https://ai.hel.fi/en/ai-register, respectively.

70 https://stip.oecd.org/stip/interactive-dashboards/policy-
initiatives/2023%2Fdata%2FpolicyInitiatives%2F2329.

71 https://www.gov.uk/government/collections/algorithmic-transparency-recording-standard-hub.

72 https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592.

73 For useful context, the results of the Global Right to Information (RTI) Rating assesses the formal legal
framework for the right to information for each country against a variety of categories (e.g. scope of
applicability, requesting procedure, appeals process). See https://www.rti-rating.org/country-data.

74 See also the work of the of the OECD.AI Expert Group on Al Risk & Accountability
(https://oecd.ai/site/risk-accountability).

75 See https://www.coe.int/en/web/portal/-/huderia-new-tool-to-assess-the-impact-of-ai-systems-on-
human-rights.

76 See, for example, coverage of the topic in (OECD/CAF, 2022[30]).

77 See https://www.nist.gov/news-events/news/2024/05/nist-launches-aria-new-program-advance-
sociotechnical-testing-and.

78 https://www.forgov.qld.gov.au/information-and-communication-technology/qgea-directions-and-
guidance/qgea-policies-standards-and-guidelines/foundational-artificial-intelligence-risk-assessment-
guideline.

79 The OECD is further exploring the concept of Al risk thresholds, as demonstrated by a September 2024
public consultation on the topic (https://oecd.ai/wonk/seeking-your-views-public-consultation-on-risk-
thresholds-for-advanced-ai-systems-deadline-10-september).

80 See https://www.gov.uk/government/publications/emerging-processes-for-frontier-ai-safety/emerging-
processes-for-frontier-ai-safety#responsible-capability-scaling.

81 Supreme Audit Institutions (SAIs) are public bodies responsible for the audit of government revenue and
expenditure. By scrutinizing public financial management and reporting they provide assurance that
resources are used as prescribed. See https://sirc.idi.no/about/what-are-sais for additional details.

82 https://digital-strategy.ec.europa.eu/en/policies/ai-board.

83 https://www.ombudsman.europa.eu/en/doc/closing-note/en/196934.

84 https://www.autoriteitpersoonsgegevens.nl/en/themes/algorithms-ai.

85 See, for instance,
https://www.aph.gov.au/Parliamentary_Business/Committees/Joint/Public_Accounts_and_Audit/Publicse
ctoruseofAl/Report and https://committees.parliament.uk/work/6986/governance-of-artificial-intelligence-
ai, respectively.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 165

86 https://www.gov.ie/en/publication/a3be3-membership-of-the-ai-advisory-council.

87 https://data.govt.nz/leadership/advisory-governance/data-ethics-advisory-group.

88 https://bioethics.gr.

89 https://www.wa.gov.au/organisation/department-of-the-premier-and-cabinet/office-of-digital-
government/western-australian-artificial-intelligence-advisory-board.

90 See https://ised-isde.canada.ca/site/ised/en/canadian-artificial-intelligence-safety-institute,
https://digital-strategy.ec.europa.eu/en/policies/ai-office, https://www.economie.gouv.fr/actualites/la-
france-se-dote-dun-institut-national-pour-levaluation-et-la-securite-de-lintelligence, https://aisi.go.jp,
https://www.aisi.re.kr, https://t.ly/vCtd1, https://www.gov.uk/government/publications/ai-safety-institute-
overview, and https://www.nist.gov/aisi, respectively.

91 https://indiaai.gov.in/article/india-takes-the-lead-establishing-the-indiaai-safety-institute-for-responsible-
ai-innovation. Information supplemented by Government of India officials.

92 https://www.gov.uk/government/publications/public-attitudes-to-data-and-ai-tracker-survey-wave-
4/public-attitudes-to-data-and-ai-tracker-survey-wave-4-report.

93 https://www.etalab.gouv.fr/ia-decouvrez-et-participez-au-projet-piaf-pour-des-ia-francophones.

94 https://ecastnetwork.org and https://issues.org/thinking-like-citizen-participatory-technology-
assessment-weller-govani-farooque.

95 https://digital-strategy.ec.europa.eu/en/consultations/ai-act-have-your-say-trustworthy-general-
purpose-ai.

96 https://digital-strategy.ec.europa.eu/en/news/ai-act-participate-drawing-first-general-purpose-ai-code-
practice.

97 The OECD has issued a series of reports on “Achieving Cross-Border Government Innovation”, which
touch on challenges and success cases in a variety of areas, including Al. See https://cross-border.oecd-
opsi.org.

98 See, for example, https://www.eupan.eu/wp-content/uploads/2024/12/HU_eNews-on-Examples-of-
recently-launched-digital-public-service-innovations.pdf.

99 https://www.consilium.europa.eu/en/press/press-releases/2024/03/04/interoperable-europe-act-
council-adopts-new-law-for-more-efficient-digital-public-services-across-the-eu.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 167

# 5 Deep dive: The current status and future potential of Al in government

This chapter provides in-depth analysis regarding the current state of play, the untapped potential, the management of risks and challenges and the way forward for core functions of government. This consists of government policy functions (regulatory design and delivery, tax administration and public financial management), key government processes (civil service reform, public procurement, fighting corruption and promoting public integrity, policy evaluation, and civic participation and open government) and government services and justice functions (public service design and delivery, law enforcement and disaster risk management, and justice administration and access to justice). In doing so, it provides many examples of Al use cases that public administrations around the world are employing in pursuit of productivity, responsiveness and accountability. The contents of this chapter informed the findings of Chapter 2 on trends on Al in government.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

168 |

# Government policy functions

Government policy functions— which include tax administration, public financial management and regulatory design and delivery—are essential to effective governance. They shape legal frameworks and generate public revenue, as well as help ensure transparent, accountable use of resources, forming the foundation for stable and equitable policy outcomes. AI is being used in these functions to strengthen the backbone of effective and efficient public administrations.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 169

# Al in tax administration

For many years, tax administrations have been using Al to support activities across their operating model and have been actively exploring its potential to further enhance their operations, improve taxpayer services, increase tax compliance and prevent tax fraud. They are well placed to do this; collecting and analysing data are at the heart of many tax administration processes, which has facilitated the early adoption of rules-based Al systems. These systems have allowed tax administrations to analyse and extract insights from large volumes of data, enabling quicker identification of non-compliance and more precise targeting of limited resources towards high-risk cases.

This existing experience underpins investigations into how more advanced techniques can be deployed in a tax administration context. While technological advancements in Al offer significant potential to enhance and transform services, they can also amplify risks related to sensitive data processing and introduce new concerns. Therefore, tax administrations need to place a strong emphasis on privacy, security and the trustworthy application of Al.

## Current state of play

Since 2022, the OECD Inventory of Tax Technology Initiatives (ITTI) survey has provided insight into how Al is being applied across tax administrations around the world. The latest survey shows that the main areas of application in OECD countries are detection of tax evasion and fraud, decision-making assistance and improving tax services (Figure 5.1).

**Figure 5.1. Al deployments across OECD Members who use Al in tax administration**

This is a horizontal bar chart showing the percentage of OECD Members who use AI for various purposes in tax administration. The data is as follows:

- Detection of tax evasion and fraud: 79%
- Virtual assistants: 55%
- Assistance of tax officials in making administrative decisions: 45%
- Making recommendations for actions: 45%
- Other use cases: 31%
- To ensure the integrity of tax administration systems / processes: 14%
- Automated provision of personalised information to stakeholders: 10%

The horizontal axis is scaled from 0 to 80 in increments of 10.

Note: 29 of the 38 OECD members report using Al in tax administration in the 2024 Inventory of Tax Technology Initiatives.
Source: OECD Data Explorer - Inventory of Tax Technology Initiatives 2024 (https://oe.cd/dx/ITTI2024).

## Improving compliance and detection of evasion and fraud

To improve compliance and detect evasion and fraud, Al is frequently used to uncover hidden patterns of behaviour or new connections between transactions, assets or taxpayers within the data sources that a tax administration might already hold. As technological capabilities and internal expertise has grown, Al-driven techniques are now being used to analyse unstructured data sets, such as text from handwritten documents and information from public posts on social media, to further add depth to the analysis and

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

170 |

uncover connections about activities that could indicate tax evasion or non-compliance. These techniques are also used to support the detection or prevention of fraudulent attacks on the tax system by criminals who can use Al to create false claims for refunds on a potentially very large scale. As one example, Greece's Independent Authority for Public Revenue (IAPR) is leveraging Al to combat tax evasion by detecting compliance issues, automating complex procedures and enabling auditors to respond in real time.1

More recent use cases include applying pattern-detecting capabilities of tax administrations' Al systems to data from imaging systems to allow tax administrations to analyse maps and satellite imagery. By comparing satellite images over time, Al is being used, for example, to identify property alterations or new buildings or taxable assets that may not have been declared to the tax authority (Box 5.1). Greece has also developed an Al model for geo-locating swimming pools that have not been declared for tax obligations.2

### Box 5.1. Detecting undeclared property development in France

To improve the process of detecting undeclared constructions or developments, the French tax administration (DGFiP) uses artificial intelligence and data enhancement based on aerial photographs taken by the National Institute of Geographic and Forestry Information (Institut national de l'information géographique et forestière, or IGN) as part of the Innovative Land (Foncier Innovant) project.

The algorithms make it possible to extract the outlines of buildings and swimming pools from the IGN's public aerial images, which can be consulted on the website geoportail.gouv.fr.

A computer process then verifies, from the owners' declarations to the DGFiP, whether the elements detected on the images are correctly taxed (for property taxes, in particular). A DGFiP official then systematically verifies each anomaly detected before any action is taken to remind or ultimately tax the owner of the property.

Source: (OECD, 2022[1]).

## Assisting administrative decision-making processes

To make administrative processes more efficient, tax administrations are deploying Al to automate their internal processes, such as helping categorise and distribute similar cases or tasks. Similarly, Al is commonly used to differentiate simple, standardised cases, which can be resolved through automation, from complex cases, such as tax disputes, where the expertise and judgement of tax officials are most needed. This application allows a more efficient use of human and technological resources (Box 5.2).

### Box 5.2. Improving decision-making in Brazil

Brazil had around USD 140 billion in assessed taxes waiting for decisions in administrative court tax appeals. It takes about six years for the appeal ruling. Under the Al Litigation Project, Brazil employed supervised machine learning (ML) when distributing groups of similar files to the same officers, in order to increase their speed in administering the file and taking decisions. The first trials, conducted with a sample of 2 000 manually labelled files, showed that supervised algorithms can attain sensitivity and specificity of over 80%.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 171

Brazil also employed clustering algorithms to complete files either in full or in part. Additionally, a web-based report assistant tool is being developed to support officers' analysis and help in their goal of reusing blocks of text. The tool's resources include the presentation of suggested groups of files and paragraphs and the highlighting of sentences that turned out to be important for the clustering process. Officers can label files and paragraphs, and the labels are used to improve future suggestions.

Source: (OECD, 2022[1]).

## Enhancing risk assessment processes

A significant driver of tax administrations' embracing Al is its ability to analyse data to score and prioritise risks. With Al, tax administrations can process large volumes of taxpayer data — from historical filings to transaction records and digital payment information — to build sophisticated risk models and then assign risk scores to specific types of behaviour or transactions. These models help tax administrations quickly identify possible non-compliance and focus resources on them. As the predictive capabilities of these systems has increased, tax administrations can now to identify potential issues more quickly, prevent them from escalating, and better support taxpayers in getting their filings right. To ensure reliability of these risk models, it is essential that the training data is accurate. Box 5.3 provides an example in Austria. As another example, in the Greek fuel market, IAPR has developed an analysis system that uses data from various sources to compose over 100 different risk analysis criteria.3

### Box 5.3. Improving compliance checks with predictive analytics in Austria

Since 2014, the Austrian tax administration has applied machine-learning algorithms through the Predictive Analytics Competence Centre (PACC), a specialised unit within the Federal Ministry of Finance. Tasked with modernising risk management, the PACC works to improve tax collection, auditing and fraud detection. Organised into four subject areas (Predictive Analytics, Advanced Analytics, Tax Analytics, and Customs Analytics), the PACC addresses a broad range of challenges across the tax system.

In 2023, the PACC's risk models analysed around 6.5 million cases across income, corporate and value added tax sectors as well as customs transactions. The analyses detected instances of false reporting in employee tax assessments and identified fraudulent activities, resulting in additional tax revenues of approximately EUR 185 million. Nearly 27.5 million cases were also examined for compliance, with 375 000 cases flagged for further review due to implausible risk profiles. Advanced techniques, including decision trees, regression models and text mining, support both retrospective and real-time audits while ongoing projects seek to expand analytical capabilities to include, for instance, generative models.

Source: https://www.bmf.gv.at/en/press/press-releases/2024--New/August-2024/BMF-generated-around-EUR-185-million-in-tax-income-from-Al-in-2023-.html.

## Improving taxpayer services

Helping taxpayers meet their obligations is a long-standing activity of tax administrations that often uses labour intensive service delivery methods, such as call centres or visits at physical tax offices. To help taxpayers faster with simple enquiries or processes and to free up resources, tax administrations have for many years adopted Al-based virtual assistant technology. Basic assistants use rules-based techniques that can direct taxpayers to relevant information, make payments or check their status. According to recent

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

172 |

ITTI data, virtual assistants that follow a set of pre-programmed rules when interacting with taxpayers are a very common use case for Al.4 More recently, tax administrations have begun using more advanced Al techniques, such as large language models (LLMs) to enhance and personalise interactions with taxpayers. The example in Box 5.4 illustrates the range of services that are possible, and the growing levels of sophistication that allow more personalised responses. In another example, Greece's IAPR is developing an LLM-driven digital assistant to provide advisory support to taxpayers by answering questions during the submission of income tax returns.5

### Box 5.4. Enhanced taxpayer services in Singapore

The Inland Revenue Authority of Singapore (IRAS) has employed end-user automation (i.e. tools that simplify things for service users), data and Al tools to deliver seamless and personalised taxpayer services. In 2021, IRAS launched a chatbot to more efficiently handle common queries on individual income tax, corporate tax, goods and services tax, property tax, stamp duty, withholding tax and employer tax matters. The chatbot is powered by the Singapore Government Virtual Intelligent Chat Assistant (VICA) platform.

The IRAS VICA chatbot enhances user engagement through a humanised user experience, featuring interactive elements such as carousels and infographics. In 2023, the chatbot was upgraded with the integration of a Large Language Model (LLM) engine, significantly improving its ability to understand the intent of taxpayers' queries.

Beyond answering queries, the chatbot also enables access to authenticated services. Taxpayers can conveniently check their outstanding tax balance, view payment plans, check payment status, cancel or reinstate payment plans and make tax payments via self-service payment terminals and mobile channels. These bot transactions save taxpayers about 10 minutes per transaction compared to traditional digital service channels. In the financial year 2024, the IRAS VICA chatbot handled about 70 000 transactional queries, potentially saving an estimated 11 666 taxpayer hours.

Source: (OECD, 2022[1]), https://www.iras.gov.sg/digital-services/others/iras-bot, https://www.tech.gov.sg/products-and-services/for-government-agencies/productivity-and-marketing/vica, Government of Singapore officials.

## Assisting taxpayers in filing

Additionally, Al has facilitated the extensive pre-population of tax returns; algorithms and other tools examine tax administrations' extensive data sets and then place the data in the correct part of the tax returns. This can improve the accuracy of tax returns and simplify the filing processes, reducing the time taxpayers spend on filing their returns. In instances where taxpayers complete their returns, tax administrations are deploying pattern detection techniques that can find anomalies and errors and can prompt taxpayers to double check their returns.

### Box 5.5. Preventing errors in Australian tax returns

The Australian Taxation Office (ATO) is employing advanced technologies to enhance the accuracy and efficiency of tax return submissions. These include real-time analytics, pre-filled forms and anomaly detection systems to assist taxpayers in meeting their obligations and reducing errors.

As part of its efforts, the ATO provides a pre-filling service that automatically populates individual tax returns with data sourced from employers, banks, government agencies and other third parties. This

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 173

includes information such as salary, bank interest, dividends and private health insurance details. Taxpayers are required to review and confirm the pre-filled data before submission. This system not only reduces administrative burdens but also improves accuracy by minimising manual entry errors.

Additionally, the ATO uses real-time prompts during the submission process to address potential anomalies. For instance, if a taxpayer's reported figures are flagged by a model as abnormal,, the system generates a message encouraging them to double-check their inputs. A message might state, for example: "You have not reported any interest income. Please review and ensure any interest earned has been reported." In 2023-24, more than 636 000 prompts were issued to individuals, helping to protect approximately AUD 78.9 million in revenue.

Source: (OECD, 2022[1]), https://aws.amazon.com/institute/future_of_tax_technology_ai_ml_cloud_security, https://www.austlii.edu.au/au/journals/JCULawRw/2024/5.pdf, https://www.ato.gov.au/individuals-and-families/your-tax-return/how-to-lodge-your-tax-return/lodge-your-tax-return-online-with-mytax/pre-filling-your-online-tax-return.

## Managing risks and challenges

Whilst all deployments of Al in public administrations are generally accompanied by challenges, tax administration makes a particularly demanding environment for Al integration because of three critical factors:

1. Ensuring data protection and privacy: Tax administrations have access to a vast amount of sensitive taxpayer data and have the obligation to protect the privacy and confidentiality of this data. Governance and legal frameworks therefore need to be adapted to account for the use of Al.
2. Ensuring taxpayer rights: Taxpayers' ability to challenge tax decisions made by tax authorities mean that decision-making relying on Al systems and associated administrative processes need to be explainable, transparent and accountable.
3. Maintaining trust: Tax administrations rely heavily on taxpayers' voluntary compliance, which requires sustained trust in the impartiality and fairness of administrative processes. Taxpayers need to be able to trust the government's use of Al systems, continue to believe tax systems are fair and remain willing to comply with their tax obligations.

## Associated risks

- Inadequate or skewed data in Al systems
- Lack of transparency and explainability

If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for some individuals or groups. With regard to tax administration, this could result in inaccurate risk assessments and thereby the improper targeting of some individuals or groups for control measures (e.g. audits). See Box 5.6 for an example.

When adopting Al in tax administration, inadequate and poor data quality poses a significant risk to effective outcomes, which can undermine public trust. For Al systems to return reliable and trustworthy outcomes, the input dataset needs to be accurate, complete, and well-structured. Discrepancies in data formats, incomplete or mistyped records, outdated taxpayer data or data lacking the necessary context can lead to inaccurate predictions, flawed risk models and biased outcomes. Some machine learning (ML) systems do not require data to be as structured, but quality and accuracy are still critical. Incorrect inputs can make systems less efficient, undermine taxpayers' trust in government and have adverse consequences for taxpayers.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# 174 |

## Box 5.6. Challenges with algorithmic errors in tax administration
The "Toeslagenaffaire" was a child benefits scandal in the Netherlands. Between 2005 and 2019, the Dutch Tax and Customs Administration (Belastingdienst) wrongfully accused approximately 26 000 families of fraudulently claiming childcare benefits, due to the use of flawed data and a skewed algorithm. Many of these families were flagged due to administrative errors, such as missing signatures, and disproportionately targeted families with dual nationality or migrant backgrounds. These families were forced to repay tens of thousands of euros in benefits, plunging them into severe financial hardship, with some losing their homes, jobs and marriages. In extreme cases, children were removed from their families. The ensuing scandal resulted in the collapse of the government.

Following the Toeslagenaffaire, the Dutch Ministry of the Interior and Kingdom Relations tasked researchers at Utrecht University to develop Human Rights and Algorithms Impact Assessment (IAMA). In 2022 the Dutch House of Representatives approved a motion to “make it mandatory to conduct this impact assessment before using algorithms when algorithms are used to make evaluations or decisions about people.”

Source: (OECD, 2023[2]).

Challenges regarding the transparency, explainability and interpretability of complex Al systems can pose risks to rule of law and a taxpayer's legal recourse. The ability to challenge decisions is a fundamental component of tax administration processes. Al's “black box" nature for many ML systems can create a lack of transparency, explainability and interpretability that can impact on taxpayers' rights to understand how tax decisions are made, which in turn can limit their rights to dispute a decision.

To mitigate these risks, tax authorities need to invest in governance frameworks. These frameworks should ensure that Al is deployed in a way that respects the balance between the administration's tax collection and taxpayers' rights. Therefore, Al systems and associated operational processes in tax administrations need to be sufficiently transparent and explainable and operate with proper oversight and accountability mechanisms. These can include, for example, data governance (see Chapter 4, section on "Creating a strong data foundation"), including in terms of data cleaning, validation processes and regular updates to maintain the integrity and trustworthiness of the data used to inform Al-driven decision-making. Only with high-quality, reliable data can Al truly enhance tax administration by improving accuracy, compliance and operational efficiency for taxpayers.

# Implementation challenges
*   Skills gaps
*   High costs of Al adoption and scaling
*   Inflexible or outdated legal and regulatory environments

Taking advantage of the full range of opportunities that Al can bring to tax administration highlights three key challenges.

First, tax administrations report fierce competition for skilled employees who can develop and implement these technologies. Accompanying this is the requirement to train large numbers of existing employees in the use of this new technology and managing the associated changes in process.

Second, there are often significant investment costs associated with the deployment of this technology. The process for securing the budgets can be challenging, as the return on the investment may by uncertain

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 175
or over the long term. As well as helping to provide new services to taxpayers, this investment is also necessary to help defend the tax system against fraudulent attacks.

Finally, Al has the potential to disrupt existing legal frameworks that support many tax administration processes. Adapting these frameworks needs to be considered in parallel to the guidelines for ensuring the effective design of and deployment of Al. It is also worth noting that whilst countries may have general guidelines for Al deployment, they are often not tailored to the unique needs and specific complexities of tax administration, which needs further consideration.

# Untapped potential and way forward
Tax administrations across the globe have already begun leveraging the potential of Al, deploying it in wide range of activities to improve the efficiency of their operations. Al holds to the potential not only to optimise tax administrations' existing operational models but also to transform them. OECD's (2020[3]) Tax Administration 3.0 Framework sets out a vision for digital transformation where digital technology is used to create seamless, event-based tax ecosystems. These allow for tax collection and reporting to be built directly into the natural systems of individual and business taxpayers.

To fully realise the transformative potential of Al, tax administrations should adopt a systemic approach to Al application. Al is not a standalone tool; it should be used an integrated component embedded in a broader tax ecosystem, encompassing regulatory frameworks, organisational structures, existing technical infrastructures and human expertise. It is crucial that tax administrations take into account the need for adjusting the rule-making process. For example, applying Rules as Code (RaC) approaches, tax administrations can encode tax laws and regulations into machine-readable formats, enabling Al systems to interpret and apply rules with greater accuracy and consistency (Mohun and Roberts, 2020[4]).6

Given that taxpayer trust is an essential part of a well-functioning tax administration, tax administrations should also ensure that Al deployed is trustworthy, transparent and accountable manner. To support tax administrations in this effort, the OECD Forum for Tax Administration is currently piloting a framework to support tax administrations in their deployment of Al systems. Building on the OECD principles for trustworthy Al, the framework outlines key considerations for each stage of the Al lifecycle, describing learning and experiences from a range of administrations from their own implementations. Through this ongoing co-operation, tax administrations can adopt a structured, risk-based approach to enhancing the use of Al in tax administration, which can also adapt to the changing wider context. The Forum on Tax Administration plans to publish its findings from this work in 2026.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 177
while maintaining interpretability, supporting data-driven decision making. The initiative showcases how Al can be integrated into macroeconomic forecasting while ensuring accountability and trust.

Source: https://oecd-opsi.org/innovations/forecasting-gdp.

# Facilitating spending decisions
To facilitate decision-making in PFM, Al is backed by technological advancements that have become mainstream. These include big data for analysing vast quantities of information from multiple sources, data analytics tools to drill down into specific financial categories and beneficiaries and evaluate the effectiveness of expenditures based on trends and patterns, and data visualisations to allow effective communication of complex information.

Al can be used to build on these foundations by identifying trends and patterns and grouping data points based on similarity or shared characteristics. For spending decisions specifically, Al can analyse historical budget execution data to identify underspending or overspending patterns, predict future spending needs based on key parameters (e.g. demographic changes), and evaluate programme effectiveness by linking expenditure data with outcome metrics. This offers opportunities to accelerate and improve analyses in ways that can automate or augment the work of humans. ML techniques that leverage unstructured data open opportunities for combining datasets previously unused for such exercises (Box 5.8).

## Box 5.8. Al for public financial management in Korea
In 2022, South Korea developed and implemented dBrain+, an advanced financial management information system that leverages Al to analyse real-time economic, fiscal and financial data, optimising risk assessment and decision-making in public finance. Its key modules, the Korea Fiscal Information System (KFIS) and Korea Risk Assessment and Horizon Scanning (KORAHS), use Al-driven analytics to detect financial risks and support data-informed policy decisions. By centralising all national financial operations — from budgeting and fund management to debt oversight and performance evaluation — dBrain+ enhances efficiency, transparency and predictive capabilities across central and local governments.

A key strength of dBrain+ is its integration with 63 systems from 46 institutions, including the National Tax Service, Public Procurement Service and the Bank of Korea, enabling seamless coordination on contracts, tax collection and fund transfers. Al-powered analysis of this data in real time improves budget execution, accelerates financial reporting and supports the identification of risks, enabling better decision-making on fiscal policies and public spending. By providing tailored tools for different users — including civil servants, researchers and external stakeholders — dBrain+ strengthens accountability and modernises South Korea's approach to Al-driven fiscal governance.

Source: (Korea Fiscal Information Service (KFIS), 2023[9]), https://www.adb.org/sites/default/files/publication/928976/governance-brief-052-digital-transformation-tax-administration-rok.pdf.

# Supporting budget planning and monitoring
Al has the capacity to support budget planning and monitoring processes by providing outputs that support the formulation of accurate expenditure baselines and costing of new policies. For instance, Australia's Department of Veteran's Affairs developed predictive systems and tools to help simulate future financial impacts of the policy decisions. These include the annual fiscal expenditure for each beneficiary as well

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# 178 |
as their average years on benefits, which are used for costings, budget estimates and policy evaluation (Australian Government, 2020[10]).

Another promising domain of application for Al is the identification, monitoring and mitigation of fiscal risks through the analysis of large data sets. Government fiscal risks can arise due to a variety of causes, including unsustainable spending or investment levels, which need to be identified early to take preventive action. Al can support the identification of such risks, as seen in Box 5.9. In another example, Indonesia uses a system called Al Financial Advisor (AIFA) to process unstructured financial and performance data to provide analytics on subnational governments' fiscal performance in real time (Wisesa, 2023[11]).

## Box 5.9. France uses Al in budget monitoring
For several years, France's tax agency (DGFiP) has implemented an Al-enabled “warning system" that aims to identify municipalities with financial difficulties, provide them with financial advice and proactively support the implementation of corrective measures.

This warning system was based initially on an algorithm using historical tax and financial data to score municipalities. More recently, DGFiP developed a predictive Al system designed to identify municipalities' financial difficulties earlier. The system was trained on data spanning four years to predict outcomes for the fifth year. The predictive system also relies on unsupervised clustering techniques to categorise municipalities with similar financial characteristics without predefined outcome examples.

In 2022, an experiment with the system covered 2 500 municipalities, with around 40% of these identified as facing financial difficulties. Of these, around 17% had not been detected by the previous algorithm. Additionally, around 35% of municipalities were identified with temporary, non-structural difficulties, highlighting the system's capacity to differentiate between permanent and transient financial problems.

Source: (French Public Finances General Directorate (DGFIP), 2024[12]).

# Automating management, reporting and oversight activities
PFM and reporting activities involve important but sometimes repetitive tasks that are particularly well-suited for automation. Al techniques such as natural language processing (NLP) can be used to analyse digital images to extract information from documents (e.g. vendor information), identify and classify documents (e.g. invoices), perform document comparison (e.g. compare invoice and vendor information), or identify trends and patterns (e.g. internal controls on payment requests).

In France, for example, the French tax agency (DGFiP) (2024[13]) has developed an Al-based tool as part of the regular internal control processes that “automatises the selection of payment requests to be controlled [and] optimises the workload and the quality of controls performed". The Finnish Government Shared Services Centre for Finance and HR (Palkeet) established a Centre of Excellence for Robotic Process Automation (RPA). It focuses on developing and deploying RPA solutions across various financial and HR activities — such as the management of supplier information, balancing of accounting data and processing of financial transactions — and integrating Al into automation processes where complex decision-making or data processing are necessary (Palkeet, 2024[14]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 179

# Box 5.10. Al-driven fiscal transparency in Brazil
Brazil's National Treasury (STN) is using Al to enhance fiscal transparency by classifying subnational government expenditures according to the international COFOG standard. Previously a manual and resource-intensive task, the adoption of Al — using ML models with Convolutional and Recurrent Neural Networks — has reduced classification time from 1 000 hours of human work time to just 8 hours, while achieving over 97% accuracy. This breakthrough led to the publication of the Expenditure by Function of the General Government report in 2024, a milestone in Brazil's fiscal statistics.

Building on this success, STN is now expanding Al applications to new areas, including the classification of climate-related expenditures. In collaboration with the Inter-American Development Bank (IDB), Brazil is strengthening its capacity to assess the fiscal implications of climate change. By pioneering Al-driven public finance management, Brazil sets an example for other nations seeking to modernise fiscal statistics and enhance transparency in an increasingly complex economic landscape.

Source: https://blog-pfm.imf.org/en/pfmblog/2024/12/ai-is-enhancing-fiscal-transparency-in-brazil.

In addition to strengthening reporting, the development of targeted verifications to identify errors (e.g. improper payments) and fraud (e.g. identity theft) have become a major objective for many governments. This is especially true in the wake of the COVID-19 pandemic, which exposed vulnerabilities in several countries' payment systems. Al's capacity for identifying trends and patterns can help with this. For instance, during the pandemic, the Danish Business Authority developed Al-based controls for aid applications from companies for various support schemes (van Noordt and Tangi, 2023[15]).

## Facilitating engagement with stakeholders and users
As discussed throughout this chapter and synthesised in Chapter 2, chatbots powered by NLP and language models are increasingly employed in government to directly provide services. As related to PFM, the United Arab Emirates (UAE) has developed U-Ask, a unified Al-powered chatbot for government services that can also be used to answer simple fiscal reporting questions. In Mexico, the government has introduced an Al virtual assistance tool as part of its Intelligent Support Platform, designed to guide users through government programmes and supports (2023[16]). The tool provides information on benefits, eligibility and application processes for individuals, businesses and local governments, utilising a simple keyword search or personalised questionnaires to tailor the information to the user's profile.

## Managing risks and challenges
### Associated risks
*   Lack of transparency and explainability
*   Inadequate or skewed data in Al systems

Due to their black box nature, Al-based systems that have the best forecasting outputs represent both a step forward in accuracy and a step back in fiscal transparency (Jung, Patnam and Ter-Martirosyan, 2018[5]). This lack of transparency makes it difficult for governments to verify the decision-making processes of these models, which is crucial for accountability and regulatory compliance. Consequently, this limitation has prompted governments to prioritise the use of simpler Al systems to improve human modelling and sensitivity analysis.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

180 |

While governments and PFM organisations have become increasingly adept at identifying Al-related risks and challenges, many are still developing comprehensive frameworks and practical approaches to manage these risks. Their efforts focus on establishing governance structures, building technical capacity and creating clear protocols for Al deployment in public financial systems.

Governments are also working to develop methods to "unbox" Al systems and make their reasoning more transparent, explainable and interpretable — all important conditions for using these systems in PFM. For instance, as discussed above (Box 5.7), the Swedish National Financial Management Authority (ESV) has developed an application for analysing the impact that each data variable has on the prediction of the "black-box models", as part a wider work programme to integrate Al in the financial management of Swedish government (Boström et al., 2020[17]).

Al use cases show that ethical risks like incomplete or insufficient data and skewed algorithms can be significant in the field of PFM. Al can amplify patterns of inequality embedded in financial data, leading to financial exclusion of perceived high-risk individuals (Crisanto et al., 2024[18]). This phenomenon is observed in the banking industry, where biased credit distribution may perpetuate discriminatory lending practices (Bailey, 2023[19]; Klein, 2020[20]). In the realm of public financial management, biased algorithms can similarly affect the distribution of public funds, social benefits and access to government programs, perpetuating existing inequalities and hindering fair treatment. While more of an automated decision-making system than true Al, Australia's Robodebt scheme illustrates problems that can arise as a result of algorithmic errors if not caught and addressed by humans (Box 5.11).

# Box 5.11. The Robodebt scheme: Challenges with collecting improper payments
Australia's Robodebt scheme, introduced in 2016, was an automated debt recovery programme designed to identify and recoup welfare overpayments. It replaced a manual process with a data-matching algorithm that compared fortnightly income data reported to Centrelink, the agency responsible for social security payments, with averaged annual income figures from the Australian Taxation Office (ATO). Discrepancies were flagged as overpayments, and debt notices were automatically issued without human verification. This "income averaging" method ignored fluctuations in actual earnings, often generating false debts. The system also reversed the burden of proof, requiring recipients to provide historical pay records to contest debts — a demanding task for many. Over its operation, the scheme issued 470 000 incorrect debt notices totalling EUR 775 million, causing widespread distress and financial hardship.

The scheme's calculations were declared unlawful in 2019. A Royal Commission was set up in 2022 to enquire into the establishment, design and implementation of the Robodebt scheme; the use of third-party debt collectors under the Robodebt scheme; concerns raised following the implementation of the Robodebt scheme; and the intended or actual outcomes of the Robodebt scheme. The Royal Commission issued a report in 2023, which discussed impacts the scheme had on recipients, including those related to income withholdings and garnishees, emotional and psychological effects, and the loss of faith in the government. Robodebt exemplifies the risks of automating complex social systems without adequate human oversight or rigorous testing. The fallout included significant legal settlements and calls for stricter regulations on the use of algorithms in public policy. While the Royal Commission's findings were not necessarily representative of the Australian Government's views, the government agreed, or agreed in principle, to 56 of the commission's 57 recommendations.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 181

The Robodebt scheme — which used automated data-matching, income averaging and overpayment calculation — can be described as an automated decision-making system. While the scheme did not leverage Al, it helps to illustrate issues in governance, human oversight and algorithmic design.

Source: (OECD, 2023[2]), https://robodebt.royalcommission.gov.au, https://ministers.dss.gov.au/media-releases/13091.

## Implementation challenges the process in a way to minimise
*   Matching problems to Al solutions
*   Inflexible or outdated legal and regulatory environments
*   Outdated legacy information technology systems
*   Lack of high-quality data and the ability to share it
*   Skills gaps
*   Lack of actionable frameworks and guidance on Al usage

One challenge is to match PFM needs and Al technologies. Most finance ministries that have already implemented Al projects in PFM emphasise the importance of mapping processes and activities to pinpoint areas of inefficiency and potential efficiency gains as a prerequisite to deploying Al.9 Once this initial phase is complete, the next step is to assess the suitability of Al technology, or other technologies, for integration to help address them.

Despite Al's capacity to summarise or draft text using language models, finance ministries have been cautious in rolling out new technologies in fiscal reporting (e.g. the automatic production of fiscal reports). This may be due to concerns over accuracy and whether Al complies with current regulations. There may also be concerns over where responsibility lies when Al is used, and what its use means for people in positions of responsibility, such as external auditors, and people who use the reports, such as lawmakers.

Information technology (IT) systems are crucial for finance ministries to be able to take advantage of Al opportunities. Yet many OECD countries say they are locked into legacy technologies that are significantly fragmented, often outdated and lack the necessary infrastructure and compatibility to integrate advanced Al functionalities. For example, centrally managed FMIS systems are more than 10 years old in most OECD countries (OECD, 2024[21]). These technologies are not specific to OECD countries and are holding back use of Al in PFM across the world (Rivero del Paso et al., 2023[22]).

As with any IT system, the quality of output obtained from an Al system depends on the quality of inputs. Finance ministries also indicate that fragmented data, coupled with restrictions on data sharing, frequently impedes the initiation of Al projects (see Chapter 4, section on "Creating a strong data foundation"). These challenges underscore the need for improved data management practices and policies that facilitate more effective data accessibility and sharing. Accordingly, various OECD countries plan major upgrades to their FMIS, also recognising the need for stronger data foundations (Figure 5.2).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

182 |

## Figure 5.2. Objectives for FMIS upgrades in OECD countries, 2022
**Legend:**
0 = not at all important
1 = slightly important
2 = somewhat important
3 = very important
4 = extremely important

**Chart Data (Horizontal Bar Chart):**
*   Improvements in system technical performance: 3.1
*   Improved data analysis capability for central budget authority: 3.0
*   Enhanced integration of financial management functions: 2.8
*   Improvements in the operation of financial controls: 2.8
*   Improved financial reporting capabilities: 2.7
*   Improved data analysis capability to line ministries and agencies: 2.7
*   Expansion in institutional coverage: 2.1

**Horizontal Axis Scale:** 0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5

Note: Refers only to countries currently undertaking major development or replacements of their central FMIS (18 countries). Ratings present the average level of importance assigned to each objective on a scale of 0 to 4 by all respondents. Data for Chile, Colombia, Israel, Mexico, Slovenia and the United States are not available.
Source: (OECD, 2022[23]), Question 24.

Because PFM is a highly technical policy area, implementing Al systems requires substantial training that involves human intervention and supervision (and feedback) from PFM experts. A significant challenge is that while PFM organisations can effectively identify Al-related risks, many lack the specialised staff skills and institutional capacities needed to develop and implement necessary risk management frameworks. Further, it is tempting to overestimate Al's capabilities. Al systems produce outputs that are based on probabilities, which means they are by nature uncertain. They can produce data outputs that are wrong or texts that sound highly authoritative but are incorrect (“hallucinations”). Therefore, no matter how much training systems may receive, PFM specialists need to be able to exert critical judgment when using the outputs they generate. Such oversight requires specialists that combine technical PFM skills and basic understanding of how Al works.

Ensuring transparency and explainability in Al-driven decisions requires robust frameworks and standards that govern and oversee Al processes, including the traceability and accessibility of training datasets (e.g. data provenance, data records) and, when possible, the source code for Al algorithms. However, such frameworks and standards have until recently lacked in many OECD countries. Traditional oversight bodies, such as supreme audit institutions (SAIs) and independent fiscal institutions, are beginning to adapt their methodologies and develop new skills to effectively oversee Al-driven fiscal processes (Box 4.8). Additionally, identifying and implementing safeguards against potential misuse or over-reliance of Al in fiscal governance is crucial as Al systems become more prominent in decision-making processes. PFM specialists need to address these issues to shape a new fiscal governance framework that exploits Al's potential while maintaining transparency, accountability and integrity.

## Untapped potential and way forward
Finance ministries are currently adopting a cautious approach to Al, prioritising task automation and predictive applications over more prescriptive Al. While predictive Al focuses on forecasting outcomes, prescriptive Al goes further by suggesting courses of action to achieve desired goals or mitigate risks. However, a systematic application of prescriptive Al could profoundly impact the roles and responsibilities within PFM systems, potentially altering the activities of fiscal stakeholders and oversight bodies.

Any shift from human judgment to system-based outcomes in fiscal decisions necessitates a risk-based re-evaluation of accountability, and the assignment of roles and responsibilities in an increasingly automated environment. This also requires considering how Al could alter the letter and spirit of PFM institutions and processes, and how it could reshape the functions of fiscal stakeholders, including external

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 183

oversight bodies such as SAls and independent fiscal institutions. In this context, questions regarding the future of transparency and accountability need to be addressed.
*   What mechanisms will be needed to ensure transparency in automated PFM decisions? As forecasting and budget planning and monitoring could increasingly be conducted by Al, there should be robust frameworks to ensure transparency and explainability regarding governments' use of Al systems and their underlying data. This involves creating and implementing standards that govern Al use and oversight.
*   How will the roles of traditional oversight bodies evolve as Al is adopted? SAls and independent fiscal institutions will need to adapt their methodologies to effectively oversee and audit Al-powered fiscal processes. This might include developing data science and Al training for staff members or updating audit processes to incorporate Al-specific considerations, such as data integrity and completeness.
*   What new safeguards will be necessary to protect against misuse of Al in fiscal governance? As Al systems play a more prominent role in fiscal decision-making, identifying possible types of intended or unintended misuses and safeguarding against them becomes paramount.

By addressing these questions, PFM specialists can help shape a new fiscal governance framework that accommodates the full innovative potential of Al, while safeguarding the key principles of PFM.

Finance ministries' Al efforts need a coordinated approach and should integrate lessons from other governmental projects. This could greatly minimise risks of failure and implementation challenges, while enhancing the quality of outcomes. For instance, community of practice on Al projects can help to prevent common and avoidable mistakes and mitigate risks from inherently complex Al projects. These risks stem, for example, from the involvement of multiple stakeholders with diverse interests or lack of understanding of technologies and systems.

While many financial management agencies identify a potential for large-scale productivity gains from Al, public studies on feasibility and costs are rare and assessments on results and impacts remain anecdotal. Evidence on costs and impacts are either not collected or not publicly available due to the provisional nature of projects still in pilot or early development phases.

Ideally, the results and impact of Al use in PFM should be assessed by using evaluation frameworks to track costs of projects and key performance indicators from completed projects, including cost savings, effectiveness and efficiency gains, error reduction and compliance enhancement. This would involve, among other things, monitoring full costs of projects, comparing metrics from before and after Al implementation, conducting stakeholder surveys for satisfaction, and analysing data to see how Al outcomes match with fiscal policy goals.

Due to the lack of impact data, external oversight bodies recently called for greater transparency in Al projects across government; they said that greater scrutiny and evidence collection is required alongside substantial investment (see Chapter 4, sections on “Investing purposefully" and "Empowering oversight and advisory bodies to guide responsible Al").

Establishing robust project selection and evaluation frameworks within finance ministries is critical. These should be aligned with government-wide frameworks. They should track not only cost and performance indicators but also the qualitative impacts of Al, such as error reduction and compliance enhancement. This is needed, as multiple projects will likely compete in the future for limited investment resources.

To scale up their ambitions progressively and safely, finance ministries could adopt a sequenced approach to the introduction of Al technologies. This is well illustrated by the case of The Finnish Government Shared Services Centre for Finance and HR (Palkeet), as discussed above, which started with "small" uses of RPA and is now moving towards hyper-automation with ML. According to Palkeet, starting small with their

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

184 |
advanced digitalisation journey also helped increase the acceptability for civil servants of more
sophisticated Al technologies (Palkeet, 2024[14]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 185

# Al in regulatory design and delivery

Al has the potential to contribute to significant improvements in regulatory design and delivery. It can allow
governments to tailor regulatory strategies for better economic, societal and environmental outcomes, while
effectively addressing relevant challenges and concerns such as accountability, transparency and regulatory
burdens. To achieve this, governments need to move away from the traditional “regulate-and-forget”
approach of regulatory policymaking and adopt an “adapt-and-learn” approach (OECD, 2024[24]).10 Digital
technologies, including Al, play a pivotal role in this shift, not only by extending the regulatory toolbox but
also by enabling more innovative, effective and efficient rule making through data-driven design, decision-
making and enforcement (OECD, 2021[25]).

## Current state of play

With regards to improving **regulatory design**, Al offers policymakers a number of significant opportunities.
Regulatory systems can be complex, with thousands of pieces of legislation across numerous line
ministries and agencies. Al can help navigate an existing stock of regulations and can analyse vast and
complex datasets to identify gaps, overlaps and patterns in regulatory frameworks. This can enable more
informed and targeted design decisions to improve outcomes. Al can also automate routine tasks, which
can create efficiencies by streamlining process such as policy analysis, regulatory impact assessment
(RIA), and legal drafting. It can strengthen stakeholder engagement by facilitating simplified regulatory
understandings and analysing public consultations. Al can also enable anticipatory analysis and
experimentation that can inform risk management, improving the design of future-ready regulatory
frameworks.

Regarding **regulatory delivery**, Al can help improve the performance of delivery agencies. They can, for
instance, use Al algorithms to optimise inspection resources, improve safety and reduce regulatory
burdens for businesses. Regulators have been using Al to improve the activities and processes of these
institutions to better protect public interests and resource efficiency (OECD, 2021[25]). Specific approaches
include:

*   Enhancing risk-based approaches with data analysis that help increase the accuracy and
    parameters of risk assessments to improve how inspections are targeted;
*   Improving efforts to monitor and detect non-compliance, such as on social media platforms, which
    enhances oversight efficiency of regulatory agencies; and,
*   Enhancing the diverse activities of economic regulators to better understand and oversee their
    sectors and markets.

## Drafting regulations and related documents

Al systems that use NLP, such as LLMs, offer significant opportunities for simplifying and enhancing the
written aspects of regulatory governance. Governments can use such systems to generate drafts from
templates and existing regulation, ensuring that standards are met while saving time and resources. In the
United States (US), for example, the state legislature of California became the first in the country to use Al
to draft a resolution in 2023 (Tribune News Service, 2023[26]). This was closely followed by Costa Rica,
which used ChatGPT drafts law to regulate Al (Guio and Müller-Daubermann, 2024[27]). Al can also be

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

186 |
used to cross-reference new drafts with current laws, identifying conflicts and reducing human errors,
leading to simpler, more consistent and accessible regulations (Box 5.12).

---

**Box 5.12. Using Al for legislative drafting and responses in the United Kingdom**

The UK Government Incubator for Artificial Intelligence (i.Al) has developed two Al-powered systems,
Lex and Parlex, to enhance legislative drafting and policy formulation.

**Lex:** This system aims to improve the legislative drafting process by providing advanced Al tools to
navigate, explain and interrogate UK law. Key features include semantic search capabilities that allow
users to locate contextually relevant legislative materials efficiently, and Al-assisted drafting tools that
generate explanatory notes for government bills, reducing manual effort and increasing precision in
legal language. The system was also designed with a deep understanding of UK-specific legal terms,
allowing it to accurately capture the nuances of legal terminology, thus promoting innovation and
collaboration in the legal sector.

**Parlex:** This Al system is designed to assist policymakers by forecasting parliamentary reactions to
proposed policies. By analysing historical parliamentary records, Parlex provides insights into how MPs
might respond to new policies, enabling officials to develop effective strategies for policy
implementation. For example, it can perform a "parliamentary vibe check" on potential laws, predicting
support or opposition among MPs based on past debates. This tool helps policymakers understand the
political climate and anticipate challenges or support for policies before formal proposals are made.

Both Lex and Parlex exemplify the United Kingdom's commitment to integrating Al into public services,
aiming to enhance efficiency, accuracy and strategic planning in legislative and policy development.

Source: https://ai.gov.uk/projects/parlex-and-lex, https://www.thetimes.com/uk/politics/article/parlex-ai-to-advise-ministers-on-how-policies-
will-be-received-99txwlwph.

---

## Enhancing the agility of regulatory assessments

Ex ante regulatory impact assessment (RIA) and ex-post evaluation are foundational elements of sound
regulatory governance. They should not be seen as discrete requirements to be conducted successively,
but rather as mutually complementary tools embedded in the policy cycle to inform the appropriate
adaptation of regulatory (or alternative) approaches (OECD, 2024[24]; 2021[28]).

Regulators can use Al to enhance each of these elements, using Al to improve the speed and accuracy of
assessment, while minimising the burden of such activities. This can allow for more frequent assessment
of regulation to help create adaptive and future-fit regulations that remain relevant and effective in a rapidly
changing environment. This use of Al may be especially necessary for ensuring appropriate governance
of Al. Al experts note as a top risk that governance mechanisms and institutions are unable to keep up
with the rapid pace of technological developments (OECD, 2024[29]).

As an initial step, Al can help estimate the burdens of potential new regulations and other policies, which
can have a bearing on how easily companies can accommodate regulatory changes and how likely they
are to comply. This naturally affects the success of any regulatory measure. It is also an important
consideration for regulators comparing different governance approaches and their associated cost-benefit
trade-offs for more efficient and economically sound policymaking (Box 5.13).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 187

---

**Box 5.13. Developing Al for measuring regulatory compliance costs in Germany**

In Germany, the Service Centre for Better Regulation in the Federal Statistical Office is developing a
ML system to help estimate compliance costs to support regulatory impact. This approach involves
identifying passages of legal drafts that influence compliance costs, using Al for web scraping of legal
texts. Then it uses Al to predict which new legal text changes compliance costs and to estimate whether
these costs are low or high. If the costs are likely to be low, the Office will use Al to derive the compliance
costs. But if the costs are likely to be high, the estimation will be done manually by humans to help
ensure accuracy. This process should allow the Office to focus on high-effort estimates and free up
resources for other projects. However, there are still challenges relating to the structure of data scraped,
the understandability of German legal texts, data quality, explainability of variables used in the system
and matching across data sources.

Source: (Walprecht and Lewerenz, 2024[30]).

---

Al can also enhance policy assessment and support more informed, iterative decision-making by enabling
sophisticated policy experimentation and evaluation. Through simulation of regulatory scenarios of the
future, Al allows policymakers to model and predict the potential impacts of different regulatory choices
(OECD, 2025[31]). This helps with regulatory impact assessments, as it supports decision-makers
understand the consequences of proposed regulations on different sectors and stakeholders. It can help
pre-emptively forecast the effectiveness of potential policies by uncovering patterns that may not be
immediately apparent through traditional analysis methods.

For example, the University of Dublin led the development of the Innovation Policy Simulation for the Smart
Economy (IPSE), a tool that simulates the effect of policy instruments based on regional profiles and sector
information. The aim is to better understand the potential drivers of innovation and their impact before
policy instruments are rolled out (Nesta, 2024[32]). Similarly, PolicyEngine is a tool that uses digital-ready
legislation to inform policy changes and model changes to see how changes would affect governments
and citizens. Users can select their country (Canada, United Kingdom, United States and Nigeria are
currently available), relevant policy area and policy parameters that are to be changed, and calculate the
economic and budgetary impact to see how the changes affect government income, for example.
PolicyEngine has been integrating ChatGPT into its system to provide further analysis and explainability
to users (Martin, 2023[33]).

## Promoting stakeholder engagement in regulatory design

While governments are slowly improving their stakeholder engagement activities for regulatory
governance, most OECD countries have significant scope to improve these efforts (OECD, 2023[34]). Al
can improve the process efficiency and effectiveness in engaging stakeholders when designing policy. It
can do so by using advanced analytics and intelligent user interfaces, contributing to a more inclusive
regulatory design process, improving governments responsiveness, and enhancing transparency and trust
in government. A growing number of Al chatbots are facilitating public consultations on new or revised
regulations by interacting with many stakeholders simultaneously, and synthesising data for governments
to further adjust their regulatory proposals. Chatbots can also respond instantly to stakeholder queries,
guide them through the consultation process, and simplify complex legislative text to enhance the public's
understanding. This makes the process of regulatory consultation more accessible to stakeholders and
lowers burdens for regulators when it comes to participatory policy design. The "Al in civic participation
and open government" section of this chapter further analyses how Al is being used for stakeholder
engagement and public participation.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

188 |

## Enhancing economic regulators' functions

Economic regulators handle diverse functions where Al can be applied, including tariff-setting, authorising
activities, handling complaints, mediating disputes, monitoring markets, and conducting inspections and
enforcement activities. Beyond core regulatory functions, economic regulators carry out many activities to
be effective at their work, such as research to better understand the sectors and markets they oversee.

While some efforts are underway, regulators are in the early stages of using Al, with few exploring or
piloting its use.11 According to a survey by the Body of European Regulators for Electronic Communications
(BEREC), "the adoption of Al by the National Regulatory Agencies is still at its infancy” and very few
regulators have “undertaken or are planning to conduct studies to explore ways how Al can be adopted"
(BEREC, 2023[35]). Nonetheless, the current and potential uses of Al in regulatory approaches reflect a
broader trend towards increased use of data and digital technologies. OECD (OECD, 2025[31]; 2020[36])
analysis shows that digital tools help regulators by enabling better data use and informed decision-making.
Facing pressure to do more with less, regulators are increasingly turning to Al to make processes more
efficient and effective.

Recent discussions among the OECD Network of Economic Regulators (NER)12 and examples in recent
literature reveal that Al is already used in inspections, market monitoring and consumer-facing areas like
complaints handling or responding to consumer queries. For example:13

*   EU e-communications regulators are using Al for radio channel modelling and optimising spectrum
    sharing, detecting illegal or prohibited content online, conducting customer relations management
    such as complaint classification, and measuring people's online experiences and platform
    behaviours at scale. This can be coupled with monitoring the market to ensure that products for
    sale online comply with product safety rules (Box 5.14) (BEREC, 2023[35]; Faculty, 2021[37]).
*   Austria's energy regulator (E-control) is developing an Al application to help consumers understand
    their energy bills and a chatbot to respond to consumer queries.
*   Peru's water regulator (Sunass) (2024[38]) is applying Al in the development of inspection reports.
    The application automates the generation of reports based on variables recorded by inspectors in
    tables, significantly simplifying the process and reducing the time spent on report writing. The
    reports are validated by the specialists to ensure their accuracy. Sunass has also developed a tool
    that uses geospatial analysis and a classification algorithm to calculate the investment needs and
    gaps in Peru's water sector.
*   The Israeli Capital Market Authority has begun developing an Al-powered tool that aggregates
    information from websites on insurance and savings. The project integrates advanced financial
    models, ML and NLP to enable earlier and more accurate identification of risks, anomalies and
    suspected cases of fraud in the capital markets. Additionally, it provides tools to increase
    transparency for the general public and investors. The system — currently at the proof-of-concept
    stage — offers visual tools for training models, monitoring performance, decision-making and
    generating actionable insights for Authority employees.14
*   Brazil's National Agency for Land Transportation (ANTT) uses Al in its supervision of transport
    infrastructure to support an effective delivery of its mandate as an economic regulator in the sector.
    The Road Information System combines data on aspects including accidents, roadside assistance,
    possible offenders, toll gates, speed cameras and traffic sensors on 26 concessionaires. The
    system records 15 000 entries per second with real-time data and combines Al tools with a human
    interface with a team on a 24/7 basis. The information allows the ANTT to supervise activities in
    the road transport sector more effectively and supports data-driven regulatory decision-making by
    the ANTT and other public actors.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 189

# Box 5.14. Denmark's SAFE Al tool
Denmark developed an Al tool in 2021 to scrape the internet for dangerous products in 16 European
countries, thereby automating a process that previously required manual searches. The tool, called
SAFE, was developed by the Danish Safety Technology Authority in co-operation with a private IT
company to automate resource-demanding work and improve safety for consumers.

The SAFE tool uses image and text recognition to search the web for dangerous or deficient products,
using information from Safety Gate, the European rapid alert system for dangerous products (RAPEX),
and the Information and Communication System on Market Surveillance. The tool is continuously
trained by using user feedback to improve the accuracy of its findings. SAFE's findings can be used to
warn authorities of any non-compliant products for sale in their markets.

SAFE follows on an earlier Al tool by the authority, called AIME, developed for the Danish market in
2020. The authority received funds from the European Commission to develop a similar tool for use
throughout the EU, which led to the creation of the SAFE tool.

Source: https://www.sik.dk/en/business/nyheder/new-digital-fine-toothed-comb-denmark-about-make-more-300-million-european-consumers-safer.

# Refining validation of risk criteria
Effective regulatory delivery depends on an accurate understanding of risks. Public authorities should base
their inspection and enforcement activities on risk criteria. Therefore, it is critical to monitor how risks evolve
in real life, enable adaptive responses to possible changes and regularly update risk criteria.

ML techniques can calculate the accuracy of risks assessments and refine parameters (Box 5.15). Recent
ML applications are promising in identifying key risk predictors, considerably improving the effectiveness
of risk-based targeting (OECD, 2021[28]). As ML algorithms evolve with new data, they need to be updated
regularly to remain reliable (Cary Coglianese, 2024[39]). While these tools have considerable potential,
regulators need to use discretion when using Al applications to predict compliance to ensure accuracy and
avoid biases.

# Box 5.15. Risk criteria for agricultural contributions in the Autonomous Province of Trento
In Italy, the Autonomous Province of Trento worked with the OECD to analyse the risk parameters used
by the Agricultural Payments Agency (APPAG, Agenzia Provinciale per i Pagamenti), propose revisions
and introduce robust ML standard practices. The APPAG pays agricultural contributions related to the
management of agricultural land, such as manual mowing or limited use of pesticides. The contributions
are proportional to the land's surface area according to the application presented by the farmer.
Because supervision resources are limited, the selection of sites to inspect with the highest possible
precision is particularly important. The APPAG's risk criteria to plan relevant inspections were validated
by applying ML techniques. An algorithm capable of predicting the most at-risk agricultural contribution
requests allowed the revision of existing parameters, making them significantly more effective in
targeting risks (high risk requests) and identifying non-compliance situations.

Source: (OECD/EU, 2024[40]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
190 |

# Enhancing risk modelling to improve targeting of inspections
Regulators can use Al to improve risk modelling to better target inspections. Through a risk-based
approach, regulators direct their resources towards activities that pose a threat to public goods and, more
broadly, to the achievement of desired objectives. Improving inspection efficiency and regulatory
enforcement depends on a precise understanding of risks to the public interest (OECD, 2014[41]).
Establishing and evaluating risk criteria is necessary to gauge the level of risk posed by private operators
and to target enforcement efforts. This better protects the public good, ensuring the efficient use of
resources and fostering a trust-based relationship with businesses (OECD, 2018[42]; Blanc, 2018[43]). See
Box 5.16 for an example of this approach.

# Box 5.16. Tuscany and the OECD develop risk criteria for grant applications
Regulators' application of Al techniques help enhance the understanding of which characteristics of
businesses may be effective predictors of risk. This could considerably improve risk-based targeting.
Using Al techniques tools and advanced data analytics, regulatory delivery authorities can tailor their
oversight strategies, focusing resources on the most critical areas, minimising risks while ensuring that
their actions are both efficient and impactful.

Italy's Tuscany region applied a risk-based methodology to documentary checks on funding requests
for economic activities operating in the region, particularly for European grants to incentivise innovation.
The OECD helped to develop risk parameters guiding the control of these incentive requests. By
analysing the relation between characteristics of small and medium-sized enterprises (SMEs). applying
for public funding and a suitable potential-risk estimation, predictive ML systems were constructed.
Depending on the type of requests, public administrations could use these multiple systems to guide,
enhance and accelerate decision-making regarding grants and funding applications.

Such tools and algorithms could serve as a basis for classification of future applications after updating
the systems with the relevant data, as the data sets grow over the years. The use of these tools over
multiple years could highlight the relapse associated with malicious non-compliance or the improved
behaviour of establishments as they become better at preparing their applications.

Source: (OECD/EU, 2024[40]).

Al-enabled risk modelling can also be enhanced through data gathered from social media. Historical
inspection results and databases already serve to better target future inspections and preventive
strategies. Regulatory delivery authorities have also started to acquire and use data available on social
media platforms to identify potential non-compliances. Whereas traditional sources of information rely on
authorities and inspectors, social media allow direct access to citizens exposed to risks. This helps further
inform risk-based approaches and ensure decisions are result-oriented.

Inspections should be guided by risk assessment, and public complaints often highlight emerging risks.
Better inspections begin with informed and cohesive decisions. Complaints need to be used to improve
risk-based inspection planning, and should, only in a few cases, lead to impromptu inspections. A risk-
based complaint management system is therefore essential to ensure the right balance between proactive
inspections — which occur after careful risk-based planning — and reactive inspections — which are
unplanned and occur ad hoc in response to complaints deemed serious.

Official complaints are frequently lodged through dedicated apps. However, the public might be reluctant
to use these initiatives or simply ignore that this can help track health and safety issues. Regulatory
authorities could therefore use social media platforms and ML techniques to support risk analysis and gain

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 191

broader and timelier insights than through traditional methods (OECD, 2021[28]). The OECD supported an
initiative in Italy's Lazio region to test complaints on social media as a source of the CMS inspired by
international initiatives (Box 5.17).

# Box 5.17. Enhancing risk criteria through customer complaints in the Lazio region
Regulatory authorities need to use risk assessment to target their enforcement strategies to avoid or
address the most likely or most severe potential negative impacts of non-compliance. Citizens'
complaints available on the internet could be an essential source of information and play a crucial role
in enforcing compliance with existing regulations. By improving their tools for collecting and analysing
public feedback, authorities can enhance risk identification and inspection planning.

When citizens do not use the official channels to provide their feedback, including hazard complaints,
they are likely to do it through social networks and other websites. Two million TripAdvisor restaurant
reviews were collected, and a sample of 5 000 comments was selected. Each review of this sample
was manually categorised based on the presence of hygiene issues or food poisoning. This pre-
classified dataset was used to train a ML algorithm, an approach based upon a bidirectional long short-
term memory (LSTM). This LSTM algorithm was then applied to parse new reviews on the website and
classify them, identifying negative reviews (with hygiene issues). Even with the limited pre-classified
data used to train the algorithm, the system's performance ranged between 81% and 83%, showcasing
its efficiency.

Source: (OECD/EU, 2024[40]).

# Improving non-compliance identification
Smarter compliance monitoring and targeting of non-compliance situations should be underpinned by
accurate data repository. When inspectors are challenged by the increase of potentially suspect data, ML
solutions can help identify non-reliable data and spot non-compliance.

Innovative tools streamline data submission, detect anomalies and analyse compliance pattens (Box 5.18),
that enhance oversight efficiency for regulatory delivery authorities.

# Box 5.18. Good standing approvals and compliance in Israel
In 2024, the Registrar of Charitable Trust Unit at Israel Corporations Authority's Ministry of Justice
introduced an Al-based automated process to its core regulatory approval system for issuing "Good
Standing" (proper management) approvals. This approval is vital for over 23 000 non-profit
organizations annually, as it serves as a prerequisite for donor tax refunds and eligibility criteria for
public benefits and procurement opportunities.

The new automated Al-based system overcame significant optical character recognition (OCR) and
object detection challenges to identify compliance with proper management standards while flagging
suspicious signs of corruption or improper management. Supervisors can now focus on flagged cases,
while average response times have been reduced from 45 days to one hour — delivering a new level
of government service.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
192 |

The project was one of nine winning initiatives in an Al implementation open call that was announced
by the Ministry of Innovation, Science and Technology, in collaboration with the Israel National Digital
Agency.

Source: Government of Israel officials, https://www.gov.il/en/pages/most_ai_government_agencies_open_call_winners.

# Managing risks and challenges
## Associated risks
*   Inadequate or skewed data in Al systems
*   Lack of transparency and explainability

If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for
some individuals or groups. With regard to PFM, this could result in, for example, adverse regulatory
outcomes where some individuals or groups are improperly targeted for enforcement action.

Advanced Al systems often make decisions within a black box, often without even the system operators
understanding how it arrived at the decision (Valderrama, Hermosilla and Garrido, 2023[44]; OECD,
2024[29]). This risk of limited explainability, necessitates human oversight and evaluation of the Al
system and its outputs to ensure transparent and accountable regulatory decision-making. If Al is used for
regulatory design or delivery — such as drafting texts, conducting assessments and engaging with
stakeholders — careful attention should be given to: the inputs and outputs of such an application; the
quality of data used; the accuracy and reliability of Al outputs; the explainability of such outputs;
transparency of Al's use in decision-making; and accountability for the associated impacts on regulatory
design and delivery.

This risk can make it difficult to promote accountability and build trust in governments' ability to use
Al to improve rulemaking. Government Al systems should generally be answerable and auditable, which
helps to reinforce the OECD Al principle on accountability. As practicable and appropriate, governments
should prioritise making Al systems open and transparent to foster public trust and enable external scrutiny
and validation. This can include making data public, open-sourcing algorithms and ensuring transparent
decision-making processes to boost confidence in Al-assisted decisions. Additionally, clear structures
need to be in place to ensure appropriate accountability and oversight mechanisms — considering who is
responsible for each element of the Al system's output and who is accountable to the quality or review of
outputs across the Al initiative.

## Implementation challenges
*   Inflexible or outdated legal and regulatory environments
*   Lack of high-quality data and the ability to share it
*   Skills gaps

While Al offers many opportunities for adaptive regulatory governance, frequent changes to regulatory
design can disrupt both business and the public. Adjustments based on continuous data analysis may
lead to a volatile regulatory environment, making it difficult for businesses to plan long-term strategies
and for the public to stay informed about current laws. Further, policymakers and regulators can face
challenges in data access, collection and processing — which limits the extent to which Al systems
will conduct reliable analysis and valid recommendations. For example, Australia has a Data Availability
and Transparency Act that provides a legal basis for sharing of Australian Government data. However, in

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 193

many instances data-sharing is stifled by a lack of protocols or incompatible systems (Productivity
Committee, 2024[45]). Improving data management capabilities is foundational to any use of Al that is
assessing and informing the evidence-base for regulatory design or delivery.

As Al in regulatory governance still requires human intervention, a lack of expertise can lead to poor
outcomes and misuse of Al. Data collected by the OECD through discussion with its members shows that
regulators struggle to match the expertise of technology companies due to the high cost and scarcity of
digital skills. To bridge this gap and enhance regulatory effectiveness, governments need to invest in
building digital skills and promote collaboration with the technology sector, including through
partnerships and public procurement to acquire skills and capacities if they are not already present.

# Untapped potential and way forward
Al in the design and delivery of regulatory governance is still in its early stages compared to commercial
applications. However, there is greater scope for Al to be used in regulatory policy—with a number of key
themes emerging from case studies that governments can consider—to advance Al maturity in regulatory
design and delivery. With regards to regulatory design:
*   Al can be further leveraged for the design of regulations, with the extent of its potential
    application currently under invested. While Al is already being used by governments, many of these
    applications focus on operational decision-making, compliance measures, general internal
    processes and delivery of public services or products. Yet these Al applications can be easily
    adapted to regulatory design. For example, chatbots used in public service delivery or application
    and grant reviews can be repurposed to gather stakeholder feedback and analyse legislation for
    regulatory review. Al used for service delivery and tracking market activities can also be used to
    continuously monitor the impacts of existing regulations, providing real-time feedback and allowing
    for timely adjustments by regulators.
*   Making legislations more digital ready allows broader Al application throughout the policy
    cycle. Al can be used to simplify legislation, make language tech-neutral and improve design for
    automated case processing. If legislation can be partially, or fully administered digitally, then Al
    can be used to support delivery, compliance and ex-post review as well as generating data to better
    inform regulatory policy design and experimentation.
*   Using Al to anticipate future scenarios and risks for more informed regulatory design. Al
    can offer valuable forecasting insights, offering governments an ability to see emerging trends and
    shifts in various industries to proactively plan regulatory responses. For example, Al can forecast
    how technologies or technological applications grow in the healthcare industry, allowing regulators
    to test existing frameworks or develop new ones to ensure safety and efficacy before widespread
    adoption. This can help increase trust in government, as governments take a proactive, rather than
    reactive, role in citizen protections (OECD, 2024[46]).

As for other policy areas to advance the use of Al for regulatory design, governments need to address
legal and governance uncertainties. Many governments may not have the appropriate legal structures and
frameworks in place to confidently deploy Al for regulatory governance. This may be due to, for example,
ambiguities in legal text about compliance and accountability, which require legal judgement. While
countries are taking steps to clarify Al use in government, more mature guidance is needed on the use of
Al in regulatory design. Stronger Al governance is crucial, not just for regulatory systems but all
government applications to ensure responsible and trusted Al deployment.

Public authorities also need to adapt regulatory delivery mechanisms to provide good protection to public
goods and citizens effectively in the context of globalisation and technology, harnessing these changes to
achieve better results. Steps forward include ensuring that regulators have the necessary mandates,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

194 |
powers, functions and accountability mechanisms to use Al; and providing access to high-quality, accurate
and secure data to protect against cyber threats. Three main areas of attention lie ahead when deploying
Al for regulatory delivery:

*   **Empowering regulators with appropriate data collection powers.** To effectively gather and
    make sense of data from a variety of sources, regulators need sound legislation. Regulating data-
    driven markets requires an appropriate toolbox, so that regulators can request and receive
    sufficient information in real time and in relevant shape (OECD, 2020[36]). As Al applications often
    rely on mass data collection, regulators should be legally empowered to collect, process and
    publish data when appropriate, while upholding principles of privacy and data protection, and
    ensuring that legal and institutional conditions support data access and sharing in ways that
    advance the public interest (OECD, 2021[47]). Regulators need to collaborate with national
    governments and parliaments to ensure the appropriate legal framework that defines their remit
    and powers.
*   **Enhancing regulators' skills and knowledge on AI.** To unlock the potential of ML techniques
    and big data analytics, regulators need to boost their Al expertise by recruiting data scientists and
    cyber risk experts. Attracting and retaining data talent amidst private sector competition is a
    challenge for regulators and the broader public administration. Further, there should be investment
    in capacity building for every policymaker and regulatory to boost policymakers' confidence in Al
    applications. These efforts are at both the national level and international level. For example, new
    fora for international exchange and co-operation can be developed for officials to share their
    knowledge and experience — such as the International Network for Digital Regulation Co-operation
    (INDRC) established to foster discussion between regulators (DRCF, 2023[48]).
*   **Ensuring robust data governance and strategies to underpin AI use.** The digital transition
    offers benefits but also poses new challenges for data governance (see Chapter 4, section on
    "Creating a strong data foundation", for a detailed discussion on managing, collecting, providing
    and using data for Al). Robust strategies are essential to mitigate potential risks. Developing a data
    strategy is a holistic way to address data governance. A poll among members of the OECD Network
    of Economic Regulators (NER) in 2024 found that 55% of respondents were in the process of
    developing a data strategy, while 29% already had one in operation.15 These findings highlight the
    necessity of robust governance and data strategies to support an effective use of data and Al.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 195

# Key government processes
Key government processes — such as civil service reform, public procurement, anti-corruption efforts,
policy evaluation and civic participation — are vital to building efficient, transparent and accountable
institutions. These processes strengthen public trust, improve service delivery and foster evidence-
based governance. Governments are using Al to ensure integrity in how taxpayer funds are managed
and spent, as well as bolstering public sector talent for the future.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

196

# Al in civil service reform
Al has the potential to significantly transform the way civil servants are organised and managed. Like in
other policy areas, Al tools could be used to better target and personalise human resources (HR) services,
accelerate and improve HR processes to reduce administrative burdens, and boost employee productivity.
Some governments are already experimenting with applying Al to discrete HR functions, including
recruitment, learning and employee development processes (e.g. training). This kind of application is
generally focused on process automation with the objective of ensuring faster and more accurate HR
processes. Al's potential in this field could be much greater. Given the right data, Al systems could eventually
help better match people to jobs, and predict performance based on job requirements and individuals'
characteristics and backgrounds. However, many elements need to be in place for this to work. For example,
public administrations would need to have strong data in at least three areas: the characteristics of their
workforce, the demands of specific jobs, and indicators of individual performance. Unfortunately, most public
administrations lack strong data in all three areas. To unlock this potential, governments will need to invest
in more and better HR data, as well as associated skill sets in the human resource management (HRM)
function.

## Current state of play
Al could be applied to a wide range of strategic HRM processes and activities, finding patterns in civil
service data to inform more strategic workforce planning, better target HR policies or even identify needed
skills during emergencies and crises. Available data and use cases indicate two areas of civil service
reform where some countries were actively experimenting with Al applications: recruitment; and learning
and development. These are explored and discussed further in this section.

So far, initiatives have often been fragmented pilots without a strategic approach for systemic adoption.
However, governments like France are taking a coherent and strategic approach to explore the benefits of
Al in civil service reform, while also recognising the potential negative impacts and setting up safety
measures to address them (Box 5.19).

**Box 5.19. France's strategy for using Al in government human resource management**

French has developed a structured strategy to integrate Al into human resource management (HRM)
across its public administration. This strategy focuses on three key areas: Al integration, workforce
planning and training for civil servants. It aims to ensure that Al is used responsibly, ethically and
effectively, enhances productivity and supports complex decision-making processes.

The strategy first focuses on identifying the right stakeholders, tasks and tools for Al adoption within
HR activities. It includes defining clear objectives for Al use, selecting reliable Al tools and establishing
methodologies to ensure transparency and accountability in Al-driven processes. The plan also
incorporates risk mapping and internal audits to monitor Al's impact and help ensure its ethical use.

The strategy highlights the need for a strategic workforce planning approach specifically tailored to
integrating Al in HR processes. The adoption of Al tools to perform tasks traditionally carried out by

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 197
public servants has significant and multifaceted implications for HRM. To ensure a smooth transition
and sustainable workforce planning, it is essential to anticipate and assess these impacts effectively.
This approach involves embedding Al-related workforce considerations within existing HR planning
frameworks, with a focus on:

*   Defining the tasks delegated to Al, ensuring alignment with operational and strategic objectives;
*   Assessing current and future skill requirements, including Al-specific competencies and
    complementary expertise;
*   Evaluating the impact of Al on HR professions and job roles, identifying areas for upskilling and
    role transformation; and
*   Attracting and recruiting Al-literate professionals to support, guide and oversee the responsible
    use of Al in HR management.

To support this integration, the French government is emphasising Al training for public servants,
particularly managers and HR professionals. It has created comprehensive training programmes to
upskill employees and developed ethical guidelines that merge HR and digital ethics. This approach
helps ensure that Al is applied in a way that balances technology with human oversight, while preparing
the workforce for the future of Al in public administration.

Source: (French Public Finances General Directorate (DGFIP), 2024[12]).

## Improving recruitment processes
Al can support civil service reform throughout the recruitment process, making it faster and more efficient.
Al tools can automate transactional tasks such as writing job descriptions, designing tailored assessment
methodologies, checking candidate background documents (e.g. university diplomas), and responding to
candidate queries. In Singapore, for example, 10 government agencies introduced an Al recruitment
service to automate repetitive tasks in the pre-screening process, such as reviewing and screening
applications. A custom-designed chatbot also proceeds with a written test, reviewing and scoring the
candidates' written component. The service significantly reduced the agencies' workload, making the
process more efficient and effective.16 The United Kingdom has developed particularly solid efforts in this
area (Box 5.20).

**Box 5.20. Al-enabled recruitment automation in the United Kingdom**

The UK Revenue and Customs Agency (HMRC) uses an Al-enabled platform called Outmatch to
automate the recruitment process from end-to-end for some junior roles. Candidates are asked to
record their answers to six questions linked to a competency framework. The Al tool then analyses their
responses and scores them. The tool is designed to deal with high candidate volumes by automating
the assessment and interview stage.

One area of keen interest is the use of Al tools to assess, simplify and redefine job descriptions to
attract the best candidates. HMRC is also exploring how to assist hiring managers with an Al tool
capable of generating job descriptions, interview questions and social media posts, whilst another
prototype enables analysis of regional employment markets to support tailored recruitment campaigns.
The Cabinet Office has developed a proof of concept, Job Advert Optimiser (JAO), that translates
outcomes from previously successful job descriptions with similar aims into advice. This will allow hiring
managers to tailor their job descriptions to target high quality candidates with the right skills and
experience. Consideration is also being made to where Al may fit into other aspects of recruitment such

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

198 |
as supporting candidates — from when they identify a role through to job acceptance — sifting large
numbers of applications, scheduling and planning interviews, and matching candidates on reserve lists
to other available roles.

Source: https://www.thetimes.com/uk/society/article/inside-hmrc-job-without-speaking-human-ai-tmrljvv2r.

In addition, Al applied to public service recruitment holds great potential to broaden candidate pools and
improve candidate screening. Public administrations often struggle to be more proactive at recruitment, to
address skills gaps in their administrations and proactively market job opportunities (OECD, 2021[49]).
Examples here include one from Canada in Box 5.21. In addition, in Sweden, Upplands-Bro municipal
government developed a tailored Al interview robot with a private Al-consulting company to ensure a more
accurate recruitment process while enhancing efficiency. While excluding data regarding age, sex, clothing
and looks, the Al bot performs blind interviews and evaluates the first-round candidates.17

**Box 5.21. Increasing representation of visible monitories in Canadian defence leadership**

In September 2020, Canada's Department of National Defence (DND) launched an external EX-01 pilot
recruitment campaign aimed at increasing the representation of visible minorities at the senior level.
This initiative piloted new approaches while embracing inclusivity, innovative methods and technology
in order to make fundamental and long-lasting change that helped increase representation and Diversity
and Inclusion (D&I) at the DND. Key objectives of the pilot were to:

*   identify opportunities for members of visible minority groups;
*   introduce novel tools and technology to support barrier and bias-free assessments; and
*   assess the pilot process against traditional approaches to identify systemic barriers and biases
    and identify recommendations for future recruitment processes.

In partnership with various stakeholders, proper guardrails were implemented to ensure privacy and
quality assurance. The process achieved key outcomes by facilitating an objective and fair assessment
of candidates, while removing biases and barriers at the various stages. As a result, this pilot created
career advancement opportunities and improved traditional approaches and processes to achieve
better outcomes.

Source: https://www.canada.ca/en/department-national-defence/corporate/reports-publications/ex-01-report-visible-minorities-recruitment-
campaign.

## Facilitating learning and development
Civil service reform can use generative Al to create learning content, such as learning modules and course
material based on source documents and information. Efforts are already taking root around the world. Al
can also be used to make personalised recommendations, and pathfinding for learning and professional
development through a complex and large amount of information and data (Johnson, Coggburn and
Llorens, 2022[50]). Examples in these areas include:

*   The Australian Public Service Commission (APSC) recently collaborated with IBM in 2023 to
    design, structure and deploy a system that generated course content based on documents inserted
    from users (Box 5.22).
*   Spain's National Institute for Public Administration (INAP) is incorporating Al into the organisation,
    cataloguing and search functions for its digital platforms, learning offerings and broader library.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 199

*   The resulting "knowledge graph" makes a large portion of the resources easily findable, searchable and shareable with Spanish civil servants, partner countries and the broader public.
*   Korea's Ministry of Personnel Management's learning and development platform incorporates Al-enabled functionality to help sort, organise and recommend content. The Al system being implemented is intended to analyse the user's role and learning history to recommend training and material to develop certain skills from the platforms vast catalogue of 1.4 million pieces of content (OECD, 2023[51]).

Box 5.22. Generating learning content in Australia

The Australian Public Service Commission (APSC) ran a six-week pilot project to use Al to design, structure and deploy an online learning course on digital skills for leadership. The pilot system allowed practitioners to "feed" Al a variety of information materials such as articles, books and speech transcripts into a closed system of information that was used to create the course content. The system created a course outline, objectives, modules and content, followed by a quiz. Pilot findings showed that around 60-70% of what the system produced was usable, relevant, well-structured and accurate. In a survey of users, 91% found the pilot output valuable. To increase these figures, the practitioner creating the content could give feedback to the Al system to adjust it.

There were several benefits to this initiative. Firstly, the drafting was very, very quick. Secondly, the information was drawn from a closed system, which eliminated the uncertainty around where information was coming from and if it was correct. The technology highlighted areas of the modules and pointed to where the information was sourced. Thirdly, the system also had programmatic “checkers” built-in to review the material for issues of concern, such as discriminatory language.

While the pilot system could draft course content very quickly, it did not create production-deployment ready content. Issues identified from the pilot were:

*   Al can synthesize existing content well but cannot create content that does not exist. For example, it could not write a course on the use of Al in the civil service at that stage as no content existed.
*   The reliability of the content still required expert review, and this is typically where bottlenecks in content production already exist.
*   The closed system provided more accurate results; however, it is an expensive option if only used for course production.

Post- pilot, the APSC recognises there is value in on-premises, closed Al systems to assist with content creation. It has however referred further investigation of on-premises Al to another Australian government agency, Services Australia. Further observations on Australian government agencies' use of Al can be found on their Al statements.

Source: Information provided to the OECD by the Australian Public Service Commission, https://www.apsacademy.gov.au/news/piloting-generative-ai-address-aps-skills-gap. APSC's Al statement (https://www.apsc.gov.au/initiatives-and-programs/workforce-information/research-analysis-and-publications/state-service/state-service-report-2023-24/fit-future/supporting-safe-and-responsible-use-artificial-intelligence), Services Australia's Al statement (https://www.servicesaustralia.gov.au/automation-and-artificial-intelligence-ai-use).

# Evidence of impact
Given the very nascent nature of the applications described above, it is still too early to provide empirical evidence of impact. Early experiments like those discussed above show significant potential to reduce time and effort required to handle large volumes (e.g. number of applicants, amount of existing learning

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

200

material), broaden candidate pools, and reduce human error in decision-making. However, in most cases, there is a notable lack of rigorous, empirical evidence demonstrating their effectiveness and impact. Many Al implementations are based on theoretical potential or anecdotal success stories rather than robust, scientific evaluations. Addressing this limitation requires a concerted effort to design and conduct rigorous evaluations of Al applications in government HRM. Future implementations should be grounded in empirical evidence and tailored to the specific needs and constraints of government organisations.

Furthermore, there are many unanswered questions regarding potential negative impacts. For example, Al hiring tools may help to reduce human error, depending on how they are used. Yet they may also limit the autonomy of hiring managers in ways that impact the quality of hire related to culture, fit in team, or other hiring decisions. They may also further limit managers' abilities to build their own teams to achieve the results they need to achieve. The real quality of decisions made through Al systems are difficult to assess since it requires a longer-term view on performance and job fitness. Furthermore, there are limited baselines to measure against. Traditional (i.e. pre-Al) systems and processes face challenges in measuring and assessing this, and there are no agreed standard indicators, especially in systems without objective performance measures as can often be the case in public administrations.

As such, it may take a long time before governments can adequately measure the real longer-term impact of Al-driven decision quality versus those made by traditional systems or humans. It will also be very hard to quantify Al's impact on productivity of HR systems, as very few standard comparable measures and benchmarks exist. The OECD is currently working with a core set of member countries to try to establish these kinds of indicators, which may help to track improvements driven by Al in the future.

# Managing risks and challenges

## Associated risks

*   "Automation bias"
*   Inadequate or skewed data in Al systems
*   Misuse or questionable use of Al, resulting in surveillance and privacy concerns
*   Lack of transparency an explainability

In the domain of civil service reform there is a documented risk of so-called automation bias, whereby humans prefer not to second guess the results of automated decision aides, even when they have the ultimate responsibility and accountability to take the final decision. Making best use of Al for civil service reform will require upskilling strategic analytical capabilities in many HR activities and among hiring managers (Broecke, 2023[52]).

Another well-documented challenge relates to avoiding, detecting and addressing partiality in the Al systems themselves, particularly if Al is being used to inform decision-making related to job selection and career advancement. The problem is that any organisation's historical data is based on past decisions made by humans, and there is a significant risk that Al systems will hard code these outlooks into their algorithms. Add to this the general lack of good employee data and performance indicators, and it becomes difficult to see how quality tailored advice could be given through such Al systems. Introducing any system in this area will require careful monitoring and evaluation mechanisms to detect and correct for bias (Johnson, Coggburn and Llorens, 2022[50]).

The data and privacy rights of public servants require particular attention in a public service context, where values such as merit and fairness guide recruiting, inherently limiting the types of data that can be used in Al systems. For example, some private sector recruitment tools regularly check applicants' social media accounts and use this data to assess candidates. There is little empirical evidence that social media posts or physical features that may be assessed in video interviews have any real bearing on job

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 201

performance. This raises both ethical and effectiveness questions about many Al-driven assessment tools currently available on the market (Broecke, 2023[52]).

The use of "algorithmic management" tools — software to automate aspects of management in, for example, the allocation of work schedules, the monitoring of work activities or the setting of worker targets — is increasing significantly, reaching an adoption rate of 90% in US firms and 79% in the European Union (Milanez, Lemmens and Ruggiu, 2025[53]). Up to now, government-specific studies have not been conducted. While some of these tools may help raise productivity when applied effectively, tangible concerns have been raised about existing negative impacts of Al and algorithmic tools on job quality, including work intensification, increased stress and perceived reduction in fairness (OECD, 2023[54]). Al could make jobs less fulfilling by incentivising new types of surveillance in the workplace that could harm mental health (APA, 2023[55]), or new forms of hyper-efficient yet exhausting "digital Taylorism" in which work is subject to increased surveillance and regulation (UC Berkeley, 2021[56]). Al task management may also have the potential to erode the autonomy and voice of workers, reducing human insights into how work is managed (Gmyrek, Berg and Bescond, 2023[57]). Many existing HR Al tools are designed to "optimise" workforce management (e.g. monitor, control, reduce autonomy in decision-making and problem solving), going against decades of science that shows how employee empowerment builds engagement, performance and trust. Some research suggests that framing Al as a tool used to support employees, rather than replacing them or limiting their autonomy, is critical for fostering positive perceptions of Al in the workplace (Brougham and Haar, 2017 [58]).

The more complex Al systems and predictions become, the less they can be understood and explained. This reduces accountability if employers cannot explain their choices and it impedes the ability of employees to understand how to develop themselves to advance in their careers. Merit based recruitment systems are a bedrock of well-functioning public employment systems, and these require transparency and accountability to function appropriately. Employees and their employers need to clearly understand why appointment decisions are taken, and how the skills and performance of individuals are analysed (Cappelli and Rogovsky, 2023[59]).

# Implementation challenges

*   Lack of high-quality data and the ability to share it
*   Explainability
*   Skills gaps

Quality data is essential to implementing Al in civil service reform. Unfortunately, OECD countries lack large amounts of data in most of relevant areas, and it is often not standardised systematically across organisations to allow for more rigorous and predictive analysis. Descriptive data is often limited to age, sex, education level and career path. Performance is very hard to assess objectively and consistently across teams and organisations. Job roles are also often categorised broadly. If Al is based on bad or incomplete data, it will make bad predictions.

Implementing Al in civil service management systems requires HR professionals with the right skills and mindsets. While Al technical skills may not be required, HR leaders would need to understand the potential application of Al to their systems and have the right skills to be smart buyers of tools on the market. HR professionals working with Al tools often need analytical capabilities to understand the principles of the tools and their use of data analytics, to interpret and challenge results. While abundant in public administrations, needed Al skills are often lacking in HR departments.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

202 |

# Untapped potential and way forward

## Strengthened analytics for the present and future

Government organisations could gather a great deal of data and information on their employees that could be analysed to improve performance and employee experience; however, Al is generally under-used in the field of HRM due to several challenges. Al capabilities could allow HR practitioners and management to examine current workforce trends (ageing, skills and performance, compensation) to provide key insights into the main challenges and questions of the day: attractiveness or competitiveness of government as an employer; reskilling and upskilling needs; better targeted learning and development opportunities; or the drivers of employee and team performance and satisfaction.

Al algorithms can use time series data for predictive analytics to identify trends and make predictions on the civil service about the future. While simple regression analysis can be achieved without Al, more sophisticated operations could be developed with more complex modelling and scenario building. For example, organisations could potentially reduce employee turnover by predicting high-risk employees for attrition based on their tenure in a position, their levels of team engagement, and other factors. Through the analysis of big datasets, Al can identify factors and patterns that lead to excessive turnover — which is costly to organisations and a detriment to performance — and allow practitioners to take anticipatory steps for improvement. Aside from turnover, predictive analytics can assist workforce planning by anticipating skills or personnel shortages, predicting top performers for specific kinds of roles, supporting diversity and inclusion, or boosting engagement and well-being.

Currently such applications are extremely nascent in government workforces; the OECD was unable to identify many concrete use cases yet in this area. This is likely due to a variety of challenges, such as those listed above, as well as valid ethical and privacy concerns, which are further detailed below.

## Way forward

Al tools can provide leaders with a new opportunity to develop a strategic vision and direction for their public service and the HR activities needed to achieve it. Al has the potential to reshape the workforce and augment its skills in many areas. In the field of HRM, AI can speed up HR processes, better target services, knowledge and recruitment/branding campaigns, and generate valuable insights for HR managers and senior leaders on a range of issues from future skills gaps to hiring effectiveness. Al can be a transformative tool in learning and development, bringing knowledge to public servants while building their essential skills and capabilities. This all depends on a clear vision for what the future public service should look like, backed by resources and capable HR teams. This implies a joined-up strategy for workforce development in which Al has a key role to play.

Enhance transparency and give employees an explanation and the ability to contest automated decisions. Studies suggest that many candidates and employees may perceive automated assessment processes as fairer than those conducted by humans if they understand how they work and why they are being used, so long as they are confident that a human will be accountable for the final decision (Broecke, 2023[52]). This transparency should include the inputs to the decision, ensuring care is taken to obtain informed consent and manage employee privacy issues. Governments should have a clear empirical basis for the input data they choose to use.

Include HR professionals and other employees in the design, implementation and evaluation of HR AI tools. Governments should be especially careful when introducing Al tools that may reduce employee autonomy. In some cases, Al-driven automation could reduce autonomy of workers and de-value their expertise, resulting in lower motivation, engagement and commitment. This is especially true when Al tools are directly applied to optimising their productivity, directing them in how to use their time and monitoring their work activities. This can have unintended adverse consequences; it may increase stress and anxiety,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 203

which could increase work absence and turn-over, thus reducing productivity in the longer run. These consequences can be avoided by including HR professionals and other employees in the design, implementation and evaluation of HR tools.

Upskill and reskill HR professionals for the age of Al. Automation stands to hold many advantages and reduce administrative burden for HR professionals and the employees they support. They can take over many of the repetitive and dull tasks leaving HR professionals to focus on more complex and higher value-adding tasks. Those can include dealing with complex cases, recruiting more specialised workers and developing strategy (OECD, 2024[60]). But this will require upskilling and reskilling within the HR profession in many cases. For some types of employees, governments will need to invest in upskilling in more technical areas, like data science and programming, help HR professionals understand and use Al systems effectively.

If Al systems are used as an input into candidate assessments, governments should have well-qualified humans interpreting the results and making the final decisions. Governments should take care to design the process in a way to minimise “automation bias”. This may include conducting traditional assessments first, and then adding Al information after, to provide additional insights on a short list of candidates. In this way, Al can help to audit recruitment practices and improve human decision-making without replacing it. This is essential to ensuring the right level of accountability necessary for merit-driven decision-making in public services.

While incorporating Al into the field of people analytics, governments should pursue the benefits of Al while accounting for costs and risks. They need to also have certain prerequisites in place, such as rigorous, trustworthy data, statistical capabilities for understanding and verifying Al-generated outputs and analysis and their weaknesses, and measures to protect employee privacy and avoid bias.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

204 |
# Al in public procurement
With public procurement representing about 13% of GDP in OECD countries (OECD, 2024[61]), adoption of
Al in public procurement is often driven by the need to enhance efficiency and operational decision-making
and reduce costs (Friton et al., 2024[62]; Hickok, 2022[63]). It is also used to help address challenges such as
workforce constraints. With Al, public procurement can become more dynamic and responsive, capable of
meeting the demands of a rapidly changing environment throughout the procurement lifecycle (Hickok,
2022[63]; Gastaldi et al., 2024[64]) (Figure 5.3). This digital transformation also presents an opportunity to
fundamentally rethink public procurement and administration, improve connections between public entities
and suppliers, and enable more dynamic collaboration (Glas and Kleeman, 2016[65]). Yet realising Al's full
potential requires effective implementation, robust data governance and a user-centric approach.

## Figure 5.3. Potential use of Al and data analytics throughout the public procurement cycle

| Phase | | Pre-tendering phase | | | | Tendering phase | | | Post-award phase | | |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Category** | **Needs assessment and market analysis** | **Planning and budgeting** | **Develop-ment of procedure require-ments** | **Choosing the right procedure** | **Request for proposal / bid** | **Bid sub-mission** | **Bid evaluation** | **Contract award** | **Contract manage-ment** | **Order and payment** | **Reporting / perfor-mance evaluation** |
| **AI** | Forecasting, automated data analy-sis, identifi-cation of risks and opportuni-ties. | Optimising budgeting, predicting costs, analysing budget scenarios. | Automa-tion of specifica-tion deve-lopment by docu-ment analysis and infor-mation extraction. | Optimised selection process, reduced decision-making time. | Automating the drafting of RFPs by analysing past docu-ments and current require-ments. | | Automating the evalua-tion pro-cess. | | Reduced manual oversight, automated monitoring/ compliance checking. | Automated order processing and pay-ment verifi-cation. | Accurate reporting on supplier perfor-mance and procure-ment outcomes. |
| **Big Data and analytics** | Analysing large data-sets for market trends, demand assess-ment, mapping supplier capabilities. | Data-driven budget decisions, identifica-tion of cost-saving opportuni-ties. | Determina-tion of most effective specifica-tions based on past procure-ments and market analysis. | Analysing previous procure-ment outcomes to identify the most effective procedure. | | | Data-driven decision making, identifica-tion of patterns and anomalies. | | | | Generating insights into supplier perfor-mance, contract compli-ance, pro-curement efficiency. |
| **Lifecycle Marker** | | | | **Call for tender** | | | **Signing of contract** | | | **End of contract** | | |

Note: RFP = Request for Proposal
Source: OECD's illustration based on desk research and (EC, 2020[66]).

## Current state of play
Public entities are integrating Al and algorithmic decision-making into their processes, using these
technologies to improve services, streamline operations and enhance decision-making, as well as
strengthen risk management, oversight and accountability. A recent study mapped Al-based functionalities
offered by public procurement platforms, revealing that 54% of solutions support pre-tendering and
planning, 31% focus on tendering activities, and only 4% address the more operational activities of the
supply phase (Guida et al., 2023 [67]). Additionally, 11% of solutions, including digital assistants and
automation of non-value-added activities, support the entire procurement lifecycle. Common functionalities

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 205
include spend analysis, risk management, supply chain finance, supplier scouting and negotiation
optimisation.

## Streamlining operational tasks
Al can help to classify spending to standardise reporting. Classifying spend data into standard taxonomies
in public procurement means organising spending into predefined categories, which helps in tracking and
analysing expenditures more effectively. Its importance lies in the ability to better make decisions, enhance
transparency and identify opportunities for cost savings. For example, Ukraine's ProZorro e-Procurement
system uses a ML solution to predict the correct Common Procurement Vocabulary (CPV) code for
products and services (Box 5.23). These codes establish a single classification system for public
procurement; aimed at standardising the references used to describe procurement contracts to increase
transparency and make it easier for potential suppliers to identify opportunities (EC, 2020[66]).

### Box 5.23. Ukraine's ProZorro e-Procurement System
Recognising the challenges raised by lack of fair competition and the risks of corruption due to
procurement practices, Ukrainian civil society organisations, expert associations and government
collaborated in 2014 to develop ProZorro. This open-source procurement system uses Al and advanced
analytics to enhance efficiency, transparency and accountability. A decade after its inception, ProZorro
has evolved into a data-driven ecosystem that integrates cutting-edge business intelligence (BI) tools
to support evidence-based decision-making across government, oversight bodies, businesses and civil
society.

The system's BI ProZorro and ProBI analytics modules enable real-time monitoring and deep analysis
of procurement data. The public BI Prozorro module offers 49 dashboards covering all procurement
stages, allowing users to assess price trends, medical procurement, buyer performance and risk
indicators. The ProBI module provides a report-building tool for advanced users to create customised
analytics, facilitating regulatory oversight and strategic procurement planning.

The impact of ProZorro's analytics is substantial. These tools have been widely adopted, with over 30
000 users analysing Ukraine's procurement market annually, covering transactions worth the equivalent
of EUR 21 billion in 2023. More than 80 procurement studies have informed regulatory improvements,
including EUR 250 million in savings since 2021 from policy changes related to tender corrections.
Additionally, Al-driven risk assessments help oversight bodies detect irregularities, while procurement
entities use data-driven insights to optimise purchasing strategies. The system's collaborative
governance model, integrating government, civil society and private sector stakeholders, promotes
continuous innovation and responsiveness to emerging challenges.

Source: https://prozorro.gov.ua.

Al can help governments to enhance processes by simplifying and rapidly streamlining highly rule-driven,
end-to-end workflows. Simplifying and streamlining highly rule-driven, end-to-end workflows in public
procurement involves reducing complexity and automating tasks, such as with the introduction of RPA or
LLMs to enhance efficiency. This can be achieved by integrating digital tools and technologies to minimise
errors and accelerate the procurement process. For example, in Chile, ChileCompra has transformed how
public procurement is performed and has evolved over time to use novel technologies to support
government teams (Box 5.24).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
206 |
### Box 5.24. Chile advances public procurement with ChileCompra
In Chile, public procurement has been transformed through ChileCompra, the country's central
purchasing body established in 2000. ChileCompra operates Mercado Público, an electronic platform
that centralises and streamlines the procurement of goods and services for public entities. The platform
supports framework agreements, which allow multiple suppliers to provide products under standardised
terms, fostering inclusiveness and competition. Over time, ChileCompra has become the largest virtual
store in Chile, promoting transparency and efficiency in public procurement. Additionally, it has
introduced innovative tools like ChileCompra Express, an online marketplace enabling direct purchases
from pre-approved suppliers without additional tendering processes.

ChileCompra has continually evolved to address challenges, such as uneven supplier participation and
inefficiencies in framework agreements. By 2014, over 850 public entities were using the platform,
generating approximately 810 000 purchase orders worth USD 1.8 billion annually. Between 2010 and
2015, the number of transacting suppliers increased by nearly 180%, creating opportunities for small
and medium-sized enterprises (SMEs). However, the system faced operational challenges, including a
high concentration of revenues among a small number of suppliers and limited second-stage
competition in framework agreements. To address these issues, ChileCompra redesigned its
framework agreements by standardising product categories and introducing competitive mechanisms
that reduced prices by up to 28% compared to market rates.

In recent years, ChileCompra has integrated Al to modernise procurement practices further. It
introduced standardised bidding templates for Al and data science projects as part of its Ethical
Algorithms initiative in collaboration with Universidad Adolfo Ibáñez and BID Lab. These templates
include requirements for transparency, privacy, non-discrimination and explainability to ensure
responsible Al use in government contracts. Additionally, ChileCompra's Public Contracting
Observatory uses Al tools such as LLMs to analyse procurement data for irregularities and improve
compliance monitoring. These advancements have enabled more efficient oversight while promoting
ethical standards in public procurement.

Source: https://www.chilecompra.cl.

Al can help streamline efforts to manage public procurement legal and regulatory frameworks. For
example, in Romania, the National Public Procurement Agency (ANAP) developed a tool to improve its
ability to screen new legislation, including retrieving documents in real time from public institutions'
websites and converting scanned documents into searchable text (The World Bank, 2023[68]).

## Enhancing procurer-supplier relations and public servant capacities
Al provide real-time communication and support through chatbots, which can answer queries, provide
updates and facilitate smoother interactions. This technology helps streamline processes, reduce response
times and improve overall satisfaction for both parties. For instance, in the United States, the El Paso City
Council Purchasing and Strategic Sourcing department (PSS) integrated a chatbot solution, called Ask
Laura, on its webpage. Ask Laura uses open-source algorithms to interpret and deal with questions and
get information about potential suppliers based on business profiles and the questions asked (Collins,
2020[69]).

Al tools can facilitate real-time support and guidance for procurement professionals and suppliers,
streamlining communication, and expediting query resolution. This can help enhance collaboration by
offering timely advice, auto-populating forms, and creating personalised dashboards. For example, in the

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 207
United States, the North Carolina Department of Information Technology (NCDIT) has introduced an Al-
powered chatbot to assist state agency staff with IT procurement processes. Available 24/7, the chatbot
provides instant answers to common queries, such as accessing procurement forms, submitting exception
requests, and understanding procurement timelines, reducing wait times and enhancing efficiency (NCDIT,
2024[70]).

## Improving risk management, oversight and accountability
Automated compliance checks, fraud detection algorithms and anomaly detection mechanisms bolster
accountability by flagging irregularities and deviations from established procurement protocols. Al
functionalities use ML techniques to automatically identify errors and fraud, and to manage risk efficiently
and effectively (Guida et al., 2023[67]).

Al can also be used to identify integrity breaches in procurement. Both administrations and citizens are
investigating Al's potential this regard. As one relevant example, using publicly available procurement
auction data, researchers have been able to use Al algorithms to detect collusion with an accuracy rate of
81-95%. Once the algorithms are trained, they can be automatically updated with the latest auctions, and
with little effort on the user's part to supervise their outcomes (Garcia Rodriguez et al., 2022[71]). In addition,
in Hungary, a study analysed 119 000 government tenders from 2011-2020 to identify subtle, text-based
strategies used by corrupt actors to favour specific bidders. Using ML approaches like Random Forests,
the study found that text data improved system accuracy from 77% to 82%, demonstrating the potential of
text mining to uncover corrupt behaviours and enhance anti-corruption policies (Katona and Fazekas,
2024[72]). Another relevant example is from Spain, where researchers developed an Al system to provide
an "early warning system" predicting public corruption. The tool uses data on economic and political factors
– such as economic growth and the length of a political party's time in power – along with data on
corruption cases to predict the risk of corruption in Spanish provinces (López-Iturriaga and Sanz, 2017[73]).
Anti-corruption beyond public procurement is discussed below in the section on "Al in fighting corruption
and promoting public integrity".

Beyond identifying anomalies in existing data, Al's predictive capacities can flag potential risks and
irregularities and optimise public procurement processes. In Brazil, for example, the Comptroller General's
Office developed Alice, a tool that uses Al to detect possible instances of fraud, enabling real-time risk
management and oversight (Box 5.25).

### Box 5.25. Brazil's Al-powered procurement oversight with Alice
In Brazil, public procurement accounts for a significant portion of government spending, making it a
critical area for ensuring efficiency and transparency. To address vulnerabilities such as fraud,
inefficiencies and errors in the procurement process, the Comptroller General's Office (CGU) developed
Alice, an Al-powered system designed to analyse bids, contracts and public notices. Alice uses artificial
intelligence and RPA to continuously monitor procurement activities across federal agencies, identifying
risks and irregularities in real time. By automating these processes, Alice enables large-scale auditing
and supports public officials in making informed decisions to improve oversight.

Since its implementation, Alice has delivered remarkable results. In 2023 alone, it analysed nearly 191
000 acquisitions and triggered 203 audits involving contracts worth EUR 4.15 billion (equivalent).
Between 2019 and 2022, its alerts led to the suspension or cancellation of bids totalling around EUR
1.5 billion (equivalent). Additionally, the system has significantly accelerated audit processes, reducing
the average time required from 400 days to just eight days. Alice leverages tailored natural language

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
208 |
processing (NLP) algorithms capable of handling the unique complexities of Brazilian procurement data,
further enhancing its effectiveness in identifying risks across approximately 40 predefined typologies.

By combining advanced technology with robust institutional frameworks, Brazil improved oversight,
achieved substantial financial savings and enhanced accountability in public spending.

Source: https://oecd-opsi.org/innovations/robot-alice-bid-contract-and-notice-analyser.

Oversight bodies including supreme audit institutions are key actors ensuring the legality, efficiency and
integrity of procurement processes. (OECD, 2015[74]). Every year, Portugal's court of audit (Tribunal de
Contas, or TdC) conducts a significant number of reviews and audits related to public procurement
processes (before, during and after), requiring extensive human and financial resources. TdC is working
with the OECD to develop stronger control capabilities and more efficient allocation of resources. This
includes the development and testing of data pipelines and ML systems to identify red flags, focusing on
risks of irregularities in public procurement processes (OECD, 2024[75]).

## Empowering external actors and strengthening trust in government
Al can also empower external actors, such as citizens and civil society organisations, to conduct third-
party assessments of public procurement programmes and government spending (Santiso, 2022[76]).
Governments have developed platforms that enable stakeholders to access open public procurement data,
facilitating a transparent exchange of information (Attard et al., 2015[77]). These portals publish both
structured and unstructured data covering various phases of the contracting processes. To enhance the
presentation of this data, some government agencies have integrated Al-driven dashboards into these
platforms that display statistics and indicators relevant to the contracting processes (Ansari, Barati and
Martin, 2022[78]). Countries including Colombia (2024 [79]), Chile (2024[80]) and Mexico (2024 [81]) have
adopted such initiatives.

Al technologies can enable stakeholders to monitor procurement activities and manage risks with
unprecedented granularity by providing real-time access to procurement data, audit trails and performance
metrics. Moreover, Al-powered transparency initiatives can promote greater public trust and confidence in
government procurement practices, fostering a culture of integrity and accountability. Al tools can help
governments to anticipate demand, identify potential risks and optimise their procurement processes. In
Brazil, for example, the Labcontas project (GLOBO, 2018[82]), which brought together 96 databases with
information relevant to the work of the Brazilian Federal Court of Audit (TCU), has enabled automated
checks of public tenders posing a risk of potential corruption (EC, 2020[66]).

## Managing risks and challenges
A variety of potential risks and challenges are areas of concern for the use of Al in government (Andersson,
Arbin and Rosenqvist, 2025[83]; Shark, 2024[84]). The issues most seen in OECD work and the evaluation
of Al used cases are discussed below.

## Associated risks
*   Inadequate or skewed data in Al systems
*   Lack of transparency and explainability

Al systems with inadequate or skewed training data can present concerns, as systems used to
evaluate bids might favour certain bidders due to skewed training data, leading to unfair procurement

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 209
decisions. Moreover, the ability of public procurement teams to understand the accurate functioning of algorithmic systems is constrained by human biases in perception, multi-layered complexities and other factors (Hickok, 2022[63]). These types of Al systems can have harmful outcomes that might impact a larger portion of society. In procurement, a human public employee reviews bids and decides one by one, whereas an Al system can review many bids and make decisions in a matter of seconds and minutes. Therefore, if bias exists in the Al system, the speed and scale of harm will also exceed that of a human review (Hickok, 2022[63]). Τo prevent these outcomes, procurers need to ensure that the Al has been trained on representative datasets. In addition, the Al systems should be designed with fairness in mind, considering factors beyond cost and efficiency. Finally, Al performance should be monitored in real-world scenarios to detect and address any emerging harms.

Concerns also arise regarding Al's lack of algorithmic transparency. When an Al system is deployed within the public administration, governments should make and honour commitments to principles of fairness, accountability and transparency. The system should be sufficiently explainable; the contracting authority should obtain sufficient information on how the system works and the data it has been trained on to derive its conclusions. Otherwise, public actors will have embedded systems without an independent capability to maintain and monitor these systems. Without these capabilities, alternative oversight and accountability mechanisms will also not be available due to the initial lack of transparency or subcontracting arrangements (Hickok, 2022[63]). In the United Kingdom, the Office for Al (OAI) and the Government Digital Service (GDS) produced a guidance in partnership with The Alan Turing Institute to safeguard public trust in the use of Al in procurement through the use of the FAST Track Principles: fairness, accountability, sustainability and transparency (GOV.UK, 2019[85]).

# Implementation challenges

*   Inflexible or outdated legal and regulatory environments
*   Lack of high-quality data and the ability to share it
*   Skills gaps
*   Risk aversion
*   Data and vendor lock-in

Many jurisdictions lack regulations and formal guidance on Al use, leading to legal ambiguities and potential challenges from unsuccessful bidders questioning the fairness of the process. Given these regulatory gaps, there is a growing need for regulatory frameworks and guidelines to ensure clear guidance for Al in public procurement, promoting transparency and fairness, reducing legal ambiguities and minimising challenges from unsuccessful bidders. Box 5.26 illustrates how some governments are coming together to overcome this challenge.

---
**Box 5.26. GovAl Coalition for responsible Al procurement and deployment in the United States**

The GovAl Coalition is a multi-agency initiative dedicated to promoting the responsible and ethical use of Al in government. Founded in 2023 by the City of San José, the coalition has since expanded to include local, state and federal agencies across the United States. It serves as a platform for cross-agency collaboration, knowledge sharing and Al governance best practices, helping governments simultaneously promote innovation while ensuring accountability.

GovAl Coalition members have collaborated to create a suite of public procurement templates and knowledge-sharing tools that any public agency can use to jumpstart its own Al governance programme. Among these resources, the GovAl Coalition developed the Al Contract Hub, launched in February 2025 in partnership with Pavilion. This platform streamlines Al procurement by offering a shared
---

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
210 |
repository of contract templates, cooperative agreements and best practices. The hub aims to reduce procurement costs and timelines, improve contract transparency and expand access to Al vendors. As Al adoption in government grows — reaching USD 3.3 billion in federal Al-related contracts in 2022 — the GovAl Coalition helps ensure that public agencies have the tools to procure Al solutions efficiently while upholding public values.

Source: https://www.sanjoseca.gov/your-government/departments-offices/information-technology/ai-reviews-algorithm-register/govai-coalition.

---
Al can significantly enhance the entire public procurement cycle. However, its impact is limited without standardised and accessible data, which necessitates a coherent, government-wide data governance strategy. Moreover, government agencies often implement various Al systems without unified standards, resulting in incompatible systems, fragmented data and inefficiencies in aggregating procurement information. Restrictions on data sharing contribute to these challenges and make it challenging to get the most out of Al systems by broadening the scope of system training and analysis (Andersson, Arbin and Rosenqvist, 2025[83]). Although OECD countries have made considerable progress, data containing all relevant public procurement information is still largely unavailable, and very little exists as open data (defined as data reusable in an accessible format) in most evaluated countries (da Rosa, 2023[86]).

Digital skills gaps — as well as a lack of understanding of Al's potential — are relevant hurdles to the successful deployment of Al in procurement processes (Guida et al., 2023[67]). The power of Al alone is not enough for its successful adoption of advanced procurement platforms. Data management, cultural change and skills development are fundamental (Handfield, Jeong and Choi, 2019[87]). If such gaps and limited understanding persist, public entities may struggle to effectively implement and manage Al systems or mitigate their risks, leading to inefficient and potentially improper procurement processes.

Another interesting finding is that procurement managers are mostly sceptical of Al, believing that the typical skills of the human buyer are strictly related to negotiation and that this knowledge, often tacit and not formalised, cannot be transferred to autonomous agents or systems (Guida et al., 2023[67]). Consequently, they feel that this knowledge cannot be effectively transferred to autonomous agents or systems. This risk aversion highlights the importance of digital readiness and the level of digital skills possessed by public officers, as these factors are crucial for the successful integration of Al in procurement processes.

Poorly designed or restrictive data licensing agreements can create data lock-in, preventing the contracting authority from sharing the necessary data with the Al developer, thus limiting the Al system's effectiveness. And there is a risk of vendor lock-in, which makes the contracting authority heavily reliant on the Al vendor's proprietary technology and data formats.

# Untapped potential and way forward

OECD findings and external research identify little dedicated research on Al for public procurement, and a fairly low level of Al maturity in public procurement entities (Andersson, Arbin and Rosenqvist, 2025[83]). To help public procurement organisations assess their own maturity and identify factors needed for growth, the IBM Centre for The Business of Government has developed an Al maturity model for public procurement that may be a useful reference (2023[88]).

If successfully adopted in the field, Al's potential in public procurement includes automated supplier evaluation, predictive systems to anticipate events — like product shortages and optimal timing for securing best pricing — detection of potential influences from broader economic and geopolitical issues, and the creation of smart bidding platforms that automatically match procurement needs with the most

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 211
appropriate bidders (Shark, 2024[84]). LLMs could be used promote integrity in public spending. For instance, models such as those that power ChatGPT can support public procurement officials in analysing large amounts of data on a company and potential contractor to screen for fraud or corruption risks (Ugale and Hall, 2024[89]).

Al could also make an impact in setting requirements and specifications needed by a purchasing official, assessing bids and ensuring fair and reasonable pricing, optimising supplier selection and ensuring regulatory compliance (IBM, 2023[88]). Al could help public procurement officials to determine specifications for a purchase by presenting information about previous procurement exercises, or by dynamically identifying and presenting relevant products services on the market (IBM, 2023[88]). Improving market knowledge through Al-gathered and synthesised content could also assist procurement officials in identifying reasonable and fair prices for various products and services to help serve as a baseline for direct purchase or in considering competitive bids. Moreover, Al could help to synthesise suppliers' information for procurement decision-making. Information about suppliers can be analysed using NLP methods from a variety of sources, such as business profiles, financial data and internet reviews (Burger, Nitsche and Arlinghaus, 2023[90]).

Other potential applications can be found in the private sector's use of Al tools. Private procurement has been the subject of significantly more research, even though companies are slow to adopt Al relative to other business functions (Andersson, Arbin and Rosenqvist, 2025[83]). These approaches may serve as inspiration for public procurement offices, which may not be able to directly replicate private sector solutions due to legal and regulatory frameworks. Examples include:

*   Walmart has implemented Pactum Al, a negotiation chatbot for suppliers providing "goods not for resale", which aimed to enhance payment terms, secure discounts and offer flexible contract termination notices.18
*   AutogenAl has developed an Al tool designed to expedite the bid-writing process for procurement. This tool assists businesses in crafting proposals more efficiently, reducing the time and effort required in responding to procurement opportunities.19
*   Sievo, a procurement analytics company, offers a platform to enhance procurement processes that uses Al to analyse spend data, forecast demand and optimise supplier selection, thereby improving decision-making and operational efficiency.20
*   DocuSign developed an Al-powered contract management tool that uses NLP to scan and interpret legal documents, identifying cost-saving opportunities and ensuring compliance.21

Contracting authorities in government need to take steps to ensure they are taking informed actions and decisions when incorporating Al into their procurement processes. They should focus on reducing both risks and risk aversion, improving skills and capacity, encouraging procurement officials to engage in dialogue with suppliers, and enhancing data collection and monitoring of results. The OECD Recommendation on Public Procurement (2015[74]) and the OECD Al Principles (2024[91]) — among other OECD and international standards — help contracting authorities navigate their efforts to implement trustworthy Al in their respective processes. Without an informed and trustworthy approach, public actors could fail to seize the benefits of Al systems. They could also end up with highly integrated yet flawed systems without an independent capability to maintain these systems, or skills to monitor their performance (Hickok, 2022[63]).

The success of Al in procurement processes hinges on both the effective implementation by the buying entity and the commitment of key stakeholders. A user-focused approach is essential for digital transformation in public procurement. Success also depends on robust data governance and infrastructure, including the standardisation, sharing and use of procurement data, as well as modern computing systems needed to efficiently host and transfer data and run Al systems.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
212 |
Governance mechanisms and accountability structures remain essential. Policymakers and intergovernmental organisations are establishing regulations to govern Al use in public procurement. To ensure solid governance and accountability, Al-specific procurement obligations and documentation should apply equally to both external and in-house development (Heikkila, 2022[92]).

Governments should also invest in capacity development programmes, training initiatives and knowledge-sharing platforms to support Al adoption in public procurement. By investing in capacity building and training programmes, procurement professionals can be equipped with the necessary skills and knowledge to effectively use Al technologies.

Furthermore, collaboration between public and private sectors, academia, civil society and, in some cases, the public is essential for encouraging innovation and disseminating best practices in Al-enabled procurement systems. By promoting knowledge sharing and collaboration, governments can accelerate the adoption of Al technologies and maximise the potential benefits for society. This collaboration also helps to determine whether Al is the best solution for a given challenge relative to other approaches or technologies – an important but often overlooked step (Hickok, 2022[63]).

Public purchasing bodies should prioritise the ongoing evaluation and iteration of Al systems used in public procurement, such as monitoring the performance of Al algorithms. They should assess their impact on procurement outcomes and people and solicit feedback from stakeholders.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 213
# Al in fighting corruption and promoting public integrity

Integrity actors — such as anti-corruption agencies (ACAs), supreme audit institutions (SAIs), internal audit and other oversight bodies — are reaping the benefits of adopting Al to enhance their operations, audits and investigations. As data availability intensifies and digital complexity increases, these institutions are forced to adapt to remain relevant. Faced with the increased use of technology by all actors, including those meaning to evade scrutiny and oversight, it is a matter of legitimacy for integrity institutions to keep up with the digital evolution.

Al has been a particular focus for integrity actors in recent years. This is due to rapid technical improvements making these technologies more available and affordable, as well as to the possibilities afforded by Al to process all types of data efficiently, uncover complex patterns and relationships, enhance analytical accuracy and precision, and generally augment current integrity activities (OECD, 2024[93]). As in other policy areas, Al is mostly valuable for the analysis of vast and complex sets of data, where computers can be more accurate or faster than humans.

## Current state of play

Across integrity actors, Al has numerous potential applications, which are currently being used, tested or are anticipated to emerge in the coming years. The primary activities have been categorised into three categories based on their potential impact: detecting fraudulent activity; achieving efficiency gains in knowledge management and synthesis; and enhancing predictive analytics and forecasting.

## Detecting fraudulent activities

One of the earliest and still most profound applications of Al by integrity actors lies in detecting fraudulent activities, transforming traditional analytical methods into sophisticated, data-driven approaches. Al algorithms excel at applying statistical techniques to identify outliers, patterns, transactions and behaviours that deviate from established norms that warrant further human investigation (OECD, 2024[93]; Taşdöken, 2024[94]). These tools are able to analyse numerical data across entire populations, a significant shift from traditional sample-based analytics, which enables the identification of misallocations or misreporting of funds, among other irregularities (Köbis, Starke and Rahwan, 2021 [95]) (Box 5.27). In other examples:

*   The OECD recently worked with the Spanish General Comptroller of the State Administration (IGAE) on an initiative proof of concept that employed advanced analytics and ML to detect anomalies and patterns indicative of potential corruption or fraud risks (OECD, 2021[96]).
*   The European Court of Auditors (ECA), as part of an audit on EU lobbying activities, has used ML algorithms to check the transparency register of the European Commission and identify outliers with the objective of isolating a more interesting, risk-based sample for analysis by auditors (ECA, 2024[97]).
*   In Brazil, the Alice tool analyses daily purchasing and procurement processes to uncover risk areas and inconsistencies. Unusual patterns trigger an alert that suspends the purchase, which is flagged for further inquiry (Box 5.25).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

214 |
• In the United Kingdom, the Department of Work and Pensions is using Al to identify patterns in claims that could suggest fraud or error so that these claims can be reviewed by relevant teams within the department (Box 5.28).

# Box 5.27. Europe's DATACROS tool for detecting corporate ownership anomalies
In the European Union, Project DATACROS has developed an innovative Al-powered tool to detect anomalies in corporate ownership structures that may indicate risks of corruption, money laundering, and other financial crimes. Funded by the EU Internal Security Fund - Police and coordinated by Transcrime at Università Cattolica del Sacro Cuore, the project addresses the critical need for advanced analytical tools in public oversight and integrity efforts.

The DATACROS prototype tool consists of two main components: the Restricted Area for authorised users such as law enforcement and anti-corruption agencies; and the Public Area, accessible to all citizens. The Restricted Area employs Al algorithms to analyse the ownership structures of over 70 million companies across 44 European countries, identifying red flags and hidden patterns that may indicate illicit activities. It incorporates cross-border data and leverages extensive knowledge of criminal schemes, while adhering to privacy and data protection regulations.

Testing activity of the DATACROS tool in 2021 has shown promising results. The predictive systems correctly identified 83% of companies targeted by sanctions and 88% of companies with sanctioned owners. Partner agencies reported high satisfaction (4.3/5) and likelihood of future adoption (4.3/5). By providing both investigative capabilities for authorities and transparent aggregate data for public oversight, DATACROS represents a notable example of how using Al can help enhance public integrity and combat financial crime.

Source: https://www.transcrime.it/wp-content/uploads/2021/10/Datacros_report.pdf.

# Box 5.28. Using Al to tackle benefit fraud in the United Kingdom
The United Kingdom's Department for Work & Pensions (DWP) has been using Al systems since 2021-2022 to analyse historical data and identify patterns linked to fraudulent Universal Credit claims. It is investing GBP 70 million in advanced analytics between 2022 and 2025 to reduce fraud and error in benefit claims, with projected savings of GBP 1.6 billion by 2030. The systems adopted assess risk based on inconsistencies in reported income, unusual claim frequencies and mismatches with external records. High-risk claims are flagged for manual review, where payments may be paused until further verification is completed. Key areas of focus include self-employment claims, housing benefit fraud and undeclared capital, where fraud detection has historically been more challenging.

While these systems improve efficiency, DWP recognises that ensuring fairness and transparency remains a challenge. To mitigate bias, it conducts fairness analysis before deployment and continuously monitors flagged claims. However, gaps in demographic data make it difficult to fully assess whether certain groups are disproportionately affected. Caseworkers retain full decision-making authority and are not informed of why a claim was flagged to prevent confirmation bias. Random claim selection is also used to test the accuracy of the system and avoid overreliance on automation.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 215

To strengthen public confidence, DWP has committed to publishing annual reports on the impact of Al in fraud detection, particularly concerning vulnerable groups. Efforts are underway to refine fairness analysis by improving data collection and adjusting risk-scoring methods where needed.

Source: (UK National Audit Office, 2023[98]).

Network analysis is another valuable technique for detecting potential fraud or similarly risky scenarios. It involves examining the interactions among entities within a system – such as public officials, contractors and suppliers – to unearth and visually represent potentially hidden relationships. This method is especially useful in identifying conflicts of interest, as well as in detecting corruption activities that were previously hard or impossible to detect (due to the volume and complexity of the data), providing crucial insights that help maintain the integrity of public operations. For instance, in procurement, pattern recognition can help identify sequences of transactions that may indicate collusion or kickbacks. 22 Anti-corruption in this area is further discussed above, in the section on "Al in public procurement".

# Improving knowledge management and synthesis
For integrity actors, who dedicate a large portion of their workday to reading, processing and extracting meaning from text-based documentation, Al can assist knowledge management and text analysis. This can include, for instance, extracting meaning and automating fact retrieval from documents.

Within the realm of NLP, named entity recognition allows the rapid detection and classification of essential information in texts and other unstructured data formats — such as names of individuals, places, dates and organisations — at a speed and scale that would have been impossible to retrieve manually. Named entity recognition is used in chatbots, sentiment analysis, information extraction and fraud detection. Brazil, for example, integrated it into the Federal Court of Accounts (TCU) (Odilla, 2023[99]). Machine translation is also facilitating access to better textual information more quickly, thereby enhancing the effectiveness of audits and investigations.

The rapid development of GenAl is also being used to improve efficiency. LLMs can be of great assistance by allowing the reading, interpretation, summarisation and categorisation of vast quantities of textual information with a high degree of accuracy and in a fraction of the time of a human. Integrity actors are expanding their use of LLMs for internal and public-facing applications, making not only their work more efficient but also the public more engaged and aware of their efforts. Brazil's creation of ChatTCU is one example (Box 5.29). Others include:

*   Integrity actors in Finland, France, Greece, Lithuania, the United Kingdom and at EU institutions are using LLMs to support in the drafting of documents, analysing spreadsheets, summarising texts, processing of corruption reports, analysing case law or jurisprudence, and for discovery in performance audit (Ugale and Hall, 2024[89]).
*   The Netherland's Court of Audit is piloting a GenAl system to allow citizens and other stakeholders to roam through public reports and to find answers and sources to their questions on public audit work.23
*   The ECA is piloting a project with three other SAIs (Netherlands, Germany and Sweden) to enhance interinstitutional relations and knowledge sharing by using LLMs to parse through existing national audit reports (across all European languages), automate translation and create English-language factsheets and guided summarisation.24

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

216 |

# Box 5.29. Brazil enhances audit processes through generative Al with ChatTCU
The Brazilian Federal Court of Accounts (TCU) has pioneered the use of generative Al in audit and oversight activities through ChatTCU, an Al-powered assistant launched in February 2023. Developed as an institutional initiative, ChatTCU integrates with TCU's internal systems, providing auditors with real-time access to case summaries, regulatory guidance and administrative support. As of December 2023, the tool had over 1 400 users, demonstrating its rapid adoption across the institution.

ChatTCU, currently operating on GPT-4 32k, enhances efficiency by allowing auditors to retrieve and synthesise information quickly, reducing manual workload while maintaining accuracy and security. Hosted on Microsoft Azure, the platform ensures data protection and prevents unauthorised sharing of sensitive information with external Al providers. Future developments include deeper system integration and workflow automation, further embedding Al into audit processes.

Beyond its internal application, ChatTCU is now part of an international technology transfer effort. In October 2024, TCU signed an agreement with the Supreme Audit Institution (SAI) of Honduras, making it the first international recipient of ChatTCU's source code. This partnership, established through OLACEFS, reflects a broader strategy to strengthen Al adoption in audit institutions across Latin America and the Caribbean. Since its launch, 33 Brazilian institutions have also begun adapting ChatTCU for their specific needs, highlighting its scalability and adaptability.

Source: (Ugale and Hall, 2024[89]).

With GenAl just entering popular discourse in late 2022, integrity actors have had little time to comprehend the opportunity generative Al presents for their work, let alone to fully integrate it into activities. When the OECD (2024[89]) surveyed integrity actors last year, respondents generally described their organisations as being in the early stages of maturity concerning the use of generative Al and LLMs, if at all, though it is becoming a primary area of focus.

# Preventive and predictive analytics, forecasting, foresight
Predictive Al systems can help anticipate potential corruption and fraud risks and other issues, enabling the prioritisation of cases for further human examination. While many integrity bodies lack the mandate for ex ante actions, identifying rising risks early can help mitigate them more effectively. Although ex ante actions are often out of the mandate of many integrity bodies, anticipating a rise in risks associated with corruption and fraud before they manifest can help mitigate these risks. For example, in Colombia, VigIA was developed by the Universidad del Rosario to analyse contracts from Bogotá's Mayor's Office and flag those with a high risk of corruption, anticipating potential illegal conduct. The tool is now adopted by the City of Bogotá (Salazar, Pérez and Gallego, 2024[100]).

Other researchers demonstrated how Al and data science techniques can be adopted to predict corruption. For instance, focusing on Brazil, researchers demonstrated that, in comparison to random audits, an Al system using budget data as predictors could detect almost twice as many corrupt municipalities for the same audit rate (Ash, Galletta and Giommoni, 2020[101]). Focusing on Italy, researchers used police archives and applied Al algorithms to predict white collar crimes demonstrating how algorithmic forecasts could support anti-corruption policy targeting (de Blasio, D'Ignazio and Letta, 2022[102]). In Spain, a research team also developed an Al system that serves as an early warning system to predict public corruption based on economic and political factors across Spanish provinces (López-Iturriaga and Sanz, 2017[73]). The transfer of these approaches from research to governments is still limited but growing. For

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 217

instance, in Lithuania, the Special Investigation Service (STT) is developing an Al-based tool to assist corruption prevention officers with their legislative analyses (Box 5.30).

# Box 5.30. Corruption prevention through the analysis of legal drafts in Lithuania
The Special Investigation Service of the Republic of Lithuania (STT), the country's main anti-corruption body, is currently developing and testing a tool to help corruption prevention officers evaluate both enacted and draft legal acts for anti-corruption purposes.

The tool uses LLMs specifically trained on corruption risk data and risk assessment methodologies. Through the identification of potential legal corruption risk factors (e.g. loopholes, insufficient or weak procedures and measures), it helps officers rapidly and efficiently analyse large volumes of legislation in order to identify potential shortcomings or vulnerabilities with the legal acts.

By using this tool, STT seeks to strengthen legislative safeguards and ensure that when a draft legal act is adopted, the possible consequences of its implementation are carefully considered.

Source: Ongoing work with the OECD and STT (report forthcoming).

# Evidence of impact
Al holds much promise for integrity actors, yet its empirical impact is still difficult to measure at this stage. Anecdotal evidence shows that Al enhances operational efficiency by saving time, allowing smart automations and increasing the accuracy of analyses. Use cases in which NLP, including LLMs, summarise, translate or extract information from text-based sources are among those where Al's added value for integrity-related activities is the easiest to see and assess. However, quantifying the broader impact of Al in the field is complex. First, maturity in the field is generally low; many Al initiatives by integrity bodies are still at the exploratory phase (proof of concepts, pilot projects) and have not yet reached scale.

Additionally, assessing the current state of Al in this field is hindered by a lack of transparency and sharing of information and lessons learned between institutions and across borders. Information remains highly fragmented, and the sharing of use cases, best practices and knowledge about Al tools in integrity remains challenging. The challenges stem from a combination of factors, including trust issues around confidentiality and sensitivity of oversight activities and investigations, and cultural differences as well as varying levels of institutional maturity in adopting Al. Additionally, the rapid pace of technological evolution, coupled with limited resources in terms of both time and expertise, further complicates efforts to share information and learn from diverse use cases. This lack of openness hinders the ability to evaluate and understand the effectiveness of Al applications and learn from different institutions and contexts.

# Managing risks and challenges
## Associated risks
*   Inadequate or skewed data in Al systems
*   Lack of transparency and explainability
*   Misuse or questionable use of Al

When deploying Al in public integrity and anti-corruption efforts, it is crucial to address the potential errors that can be embedded in Al systems, such as those caused by inadequate or skewed data (Köbis,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

218 |

Starke and Rahwan, 2022[103]). This is particularly critical in areas like fraud detection and conflict of interest analysis, where fairness and accuracy are paramount. Efforts continue to identify objective indicators that could serve as proxies for corruption, a phenomenon that – by definition – is hidden. While the most practical, the reliance on historical data (past cases or decisions) to train algorithms can perpetuate errors. This could result in skewed insights and limit the potential to uncover new and evolving dynamics of corrupt behaviour, potentially leading to unfair targeting or oversight practices, undermining the credibility of integrity efforts. To counter bias, Al systems should be developed with robust checks and balances, including rigorous testing, continuous monitoring and feedback mechanisms that allow for the identification and rectification of unintended errors and resulting harms.

The opaque nature of many advanced Al systems also poses significant challenges for integrity actors. If the public perceives government actions and decisions as opaque and perceive that they are relying on “black box” algorithms — where Al-generated outcomes lack explainability and transparency — citizens are likely to resist or distrust the use of AI (OECD, 2024[93]). In the audit profession in particular, its use to generate insights to be used as audit evidence is still a contended issue (Mpofu, 2023[104]). It raises question about their reasonableness, reliability and compliance with professional and regulatory standards (such as International Standards on Auditing, or ISAs) that have not yet been updated to account for recent technological changes.

The integration of Al technologies in integrity bodies raises significant concerns about responsibility, ethics and data protection, especially regarding personal data. The potential misuse of data, including inappropriate data merging or public disclosure of confidential information, poses serious ethical and legal challenges. Ensuring the protection of sensitive information, such as interest declarations, is paramount. Institutions should therefore navigate data protection, and ethical standards and regulations while implementing Al. Moreover, integrity bodies should adopt robust data governance frameworks and implement comprehensive data protection measures to mitigate privacy risks, including conducting regular audits, employing advanced encryption techniques, and fostering a culture of ethical data usage within their organisations (see Chapter 4, section on "Creating a strong data foundation").

# Implementation challenges
*   Skills gaps
*   Lack of high-quality data and the ability to share it
*   Lack of comprehensive guidance and practical frameworks
*   Risk aversion
*   High costs of Al adoption and scaling

OECD (2024[89]) work has found that a shortage of relevant skills and experience is one of the biggest challenges in the adoption of Al in public integrity and oversight. This encompasses technical skills (both advanced digital expertise and the upskilling of general staff), as well as change management, data governance and leadership skills.

Access to comprehensive, high-quality data is a pre-requisite for the effective use of Al by any institution, yet integrity actors often lack data autonomy. While some integrity actors "own” the data they use (for example, interest declaration databases), many — including ACAs and SAIs — often rely on externally generated data over which they have little or no control. They depend on government rules and regulations, historical practices and memorandums of understanding (MoUs) with other institutions to acquire the data necessary for their activities. This means that integrity bodies often face delays in accessing the necessary data, hindering real-time analysis and timely decision-making.

Inconsistent and low-quality data can also severely impede the development and effectiveness of Al tools, making it challenging to create reliable and robust systems. Integrity bodies often rely on data from

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 219

external sources, making the availability and accuracy of this data critical for successful implementation.
The quality of externally sourced data is frequently unknown or uncontrolled until it is received, potentially
leading to inaccuracies and inconsistencies that can limit or complicate Al development and system
training. As quality data are foundational the effective development and use of Al, regulatory frameworks
need to facilitate data sharing and collaboration between government agencies and across sectors, as
appropriate and consistent with data protection and privacy rules, and strategies and systems should place
to ensure data quality and completeness.

Data interoperability is also a barrier when it comes to sharing or combining data. The ability to
cross-reference and analyse relationships within data is central to uncovering issues such as conflicts of
interests. Yet currently, the maturity of most governments' data platforms means that cross checking
information is extremely difficult, if not impossible. Regulatory constraints for security or protection
reasons – may further impede the ability to integrate different data sources, thus limiting the potential for
effective and comprehensive oversight.

Perhaps because of the nature of the work, integrity institutions are often risk averse. Many integrity actors
want to integrate advanced technologies but are unsure where to begin or how to proceed. This
apprehension is made stronger by the fear of making mistakes in the adoption process. Government
guidelines frequently focus on cautionary advice, emphasising what not to do, rather than providing
concrete, actionable steps for effective Al implementation. This lack of practical, implementable advice
leaves many integrity bodies without a clear path forward, stalling progress and innovation. Comprehensive
guidance and practical frameworks on the trustworthy use of Al for integrity actors, which are often
lacking, actors could help.

Finally, the cost of implementing and maintaining Al tools poses a significant challenge, particularly
for institutions with limited budgets and technical expertise. The complexity of ensuring robust cyber risk
mitigation measures further complicates this landscape. In response, collaboration across institutions
becomes essential. By using centralised resources, such as government-led Al sandboxes or shared tools,
integrity bodies can reduce costs while accessing advanced technologies.

# Untapped potential and way forward

Looking ahead, adaptive learning systems could continually refine their predictions based on new data
they can play a significant role in updating risk assessments dynamically, which will allow integrity bodies
to stay ahead of potential evolving threats. Al — particularly its ability to analyse and recognise patterns in
non-numeric data — can also be the source of future improvements in anti-corruption. By combining it with
sensor and image technology (satellites, drones, aircrafts capturing images or other data such as thermal
readings or radar signals), Al creates new opportunities to monitor and analyse patterns on a large-scale
to understand corruption-related activities and dynamics (Zinnbauer, 2025[105]).

Further down the line, agent-based modelling (ABM) by modelling entities (officials, businesses, etc.) and
their interactions, could simulate how corruption and influence evolve in different conditions (U4, 2025[106]).
Doing so could help test the impact of anti-corruption or integrity policies, laws and strategies before
implementation.

Al-driven network analysis could also help more efficiently and comprehensively map the relationships
between lobbyist, politicians, corporations and other actors, revealing influence patterns, conflicts of
interest and revolving-doors dynamics. While integrating Al technologies into public integrity and anti-
corruption efforts offers great potential, ensuring their effective and ethical use requires careful attention
to key policy considerations that promote trustworthy adoption. Recent OECD (2024[89]) work provided
three pieces of advice for integrity actors in exploring the use of Al:

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

220

*   Start by incorporating generative Al into low-risk areas and processes. This approach can help
    build capacity in areas where mistakes are less costly — either financially or from a compliance
    perspective — before they scale to riskier and more analytical tasks, including those that require
    more financial resources.
*   Consider the IT requirements for both piloting and scaling. Consider what computational and
    storage resources, data storage and data management capabilities may be needed and make sure
    early decisions do not overly complicate future plans.
*   Consider internally generated or open data to demonstrate value and establish quick wins. This
    approach is low-cost and helps demonstrate use cases faster.

As government continue their exploration of Al, they should establish robust transparency and
accountability mechanisms to ensure Al-driven decisions are not only accurate but also appropriately
interpreted and documented. For instance, while Al systems can provide valuable insights by processing
vast amounts of data, and future systems could be increasingly autonomous, the ultimate authority over
sensitive decisions need to remain with human operators to preserve fairness, professional judgement (or
scepticism) and ultimately maintain public trust. Public integrity bodies should seek to ensure that: the
reasoning behind decisions is understandable both to experts and lay audiences; there are recourse and
challenge mechanisms in place; and, to the extent possible, Al processes are explainable. Al-generated
evidence needs to meet documentation requirements to provide an appropriate audit trail, including
complying with current standards to demonstrate how evidence was obtained and assessed.

Knowledge exchange is also crucial for the successful implementation and scaling of Al technologies in
public integrity roles. Institutions should participate in and create platforms that enable the sharing of best
practices, strategies, lessons learned and even models, code and data. Sharing will help build a more
comprehensive understanding of Al's effectiveness in integrity roles and drive the development of best
practices that can be widely adopted. Initiatives like the OECD Anti-Corruption in Government division's
Tech and Analytics Community of Practice or the Tech Connect for Integrity initiative serve as examples.²⁵
These forums bring together public and private sector practitioners to discuss challenges, explore
innovative solutions, and develop collective strategies to enhance the adoption of Al and other
technologies. This can allow for better flow of information, pooling of resources, rapid learning and faster
development and implementation of methodologies and solutions.

Building on existing guidance on the ethical and responsible use of Al, governments should go beyond
broad directives and provide more detailed, actionable guidance and frameworks for implementing Al
technologies. This may include comprehensive step-by-step instructions, case studies and templates that
institutions can tailor to their specific needs. Such guidance could also provide advice on identifying and
mitigating bias in data, utilising explainable Al techniques, building transparency into decision-making
processes and how to incorporate redress mechanisms.

A unified and interoperable data foundation is essential for the effective use of Al. Governments need to
streamline their data operations to ensure that databases and systems can seamlessly communicate and
integrate. This involves creating standardised data formats, establishing robust data governance
frameworks and investing in infrastructure that supports data interoperability. By promoting data
standardisation and integration, as well as policies for safe data sharing and crossing, governments can
enhance the ability of Al systems to analyse data comprehensively, identify patterns and provide actionable
insights to support public integrity.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 221

# Al in policy evaluation

Public policy evaluation provides crucial evidence to help policymakers understand what works, for whom
and under what circumstances (OECD, 2025[107]; 2020[108]). Al can play a significant role in supporting policy
evaluation. The exponential rise in globally generated data coupled with the rapid development of new
technologies lowering storage and computational costs, is driving innovation in techniques that can instantly
capture, analyse and visualise these vast data repositories, enriching evaluations (Petersson et al., 2017[109])
(Rinaldi, Giuffrida and Negrete, 2017[110]). This can have important consequences on what and how
evaluators evaluate.

Al has the potential to accelerate and automatise essential tasks, such as data collection and analysis, and
support evaluators in different managerial tasks, by accessing a broad set of internal and external data, or
synthesising results. Al can also support ex ante evaluations by building predictive systems and simulations
that help policymakers anticipate potential impacts before implementation (Bénassy-Quéré, 2022[111]).
However, its use within government for policy evaluation has been limited and has progressed slower than
in other functions discussed in this chapter.

## Current state of play

## Supporting evaluation design and implementation

Al can help policy evaluators to process a large amount of content that can be useful to design and
implement evaluations, whether ex ante or ex post. This ranges from more sophisticated and structured
approaches, such as supporting synthesis of existing evidence, to more basic functions, such as providing
plain summaries of previous evaluations.

Evidence synthesis is particularly useful to inform the development of ex ante or ex post evaluation. These
methods typically involve combining results from different studies that investigate the same topic to have
a comprehensive understanding of the subject. In the field of evidence synthesis, text mining and other
types of Al tools have been applied to literature searching, screening full text, data extraction and analysis
for more than 10 years. Researchers in the field have mapped a variety of tools that can support the
different stages of evidence synthesis, particularly for systematic reviews and make them more effective.
Examples of tools include Rayyan, for screening titles and abstracts, and Robot Reviewer, for assessment
of certain risks (Khalil, Ameen and Zarnegar, 2022[112]). Guidance and recommendations were developed
to ensure the responsible use of Al in Evidence Synthesis (RAISE), showing the growing interest of
applying these tools in the field (Thomas et al., 2024[113]). The benefits of using Al for evidence synthesis
rely on the ability to access a vast amount of literature and to process the information faster than alternative
approaches. Indeed, the average time to conduct an evidence synthesis is 15 months, but the use of Al
can radically reduce some of the steps (Blaizot et al., 2022[114]). For example, a risk of skewed data
assessment of 30 randomised control trial (RCT) articles can be accurately conducted using an LLM in an
average of 53 seconds. That would have taken orders of magnitude more time for human; a recent study
provided an estimate of around 28 minutes for each study in the systematic review using a tool for
randomised trials (RoB 2), which is now considered the gold standard (Minozzi et al., 2020[115]; Lai et al.,
2024[116]; Odell, 2024[117]). Similarly, World Bank evaluators, using text mining and Al, have been able to
double the size of the evidence base they use to make certain programme decisions. That likely would

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

222 |

have been impossible using traditional portfolio identification approaches, laying the groundwork for the
relevance and effectiveness assessments in the portfolio analysis they conducted (Bohni Nielsen, Mazzeo
Rinaldi and Petersson, 2024[118]).

## Supporting analytics

Al can support processing large quantities of data and long texts, such as documentation reports and
interviews, to identify patterns, which can be particularly useful for evaluations. By using NLP-enabled text
mining, Al can help evaluators comprehend conclusions and provide fine-grained assessments that would
otherwise be time-demanding (Næss et al., 2025[119]).

Quantitative text analysis applications for programme evaluation are promising, with Al enabling faster
analysis of a large number of documents compared to classical text analysis tools (Gatto and Bundi,
2025[120]). For instance, analysing responses to open-ended questions required to reconstruct a
programme theory could involve different time-consuming methods, such as identifying statements that
have a specific form and reformulating such statements into conditional “if-then” propositions (Leeuw,
2003[121]), which can be facilitated by novel techniques, such as topic models (Gatto and Bundi, 2025[120]).
While conventional text analysis can contribute to evaluation in several empirical and conceptual ways —
such as by measuring stakeholder preferences or identifying underlying programme theories — Al-enabled
quantitative text analysis can create even more opportunities. For example, the World Bank used
unsupervised ML to analyse 392 project reports across 64 aid-receiving countries, successfully identifying
novel and insightful factors influencing project success and failure (Franzen et al., 2022[122]). Al text
analysis is particularly helpful in identifying underlying themes in existing policy programmes or reports by
mapping key concepts embedded in relevant documentation, a technique known as a topic modelling
(Cintron and Montrosse-Moorhead, 2021[123]). Some of these methods can be used to understand positions
of different stakeholders providing interesting insights for policy evaluation. In some countries, relevant
actors, such as SAls, are adopting quantitative text analysis techniques to conduct performance audits
that share several characteristics with policy evaluations. In Norway, for example, text mining and ML
applications were used to perform a performance audit on police handling of cybercrime (Box 5.31). In the
domain of environmental policy, the OECD partnered with leading research institutions to use Al to conduct
the first comprehensive global evaluation of environmental policy measures, analysing over 1 500 policy
interventions across four sectors from 1998 to 2022 in 41 countries across six continents (Box 5.32).

Beyond text analysis techniques, Al also has potential to enhance causal inference in policy evaluation, to
support quasi experimental designs that rely on probabilistic models, helping to generate some of the
missing data that are needed for sophisticated non-parametric methods and instrumental variables to
simulate various impact scenarios. This can help move the frontiers of research and enable way more
powerful evaluations without the need for costly randomised control trials approaches (Miller, 2020[124]).

---
### Box 5.31. Norway uses text mining and ML in police audits

In 2018, Norway's Office of the Auditor General established an Innovation Lab aimed at integrating data
science into auditing. The lab included data scientists with expertise in areas like performance
evaluation/auditing, coding and ML, to support auditors by automating tasks, assisting with data
acquisition (such as web scraping) and analysis (e.g. text mining), as well as by providing internal
training in coding and analytical tools.

In 2021, the Office of the Auditor General of Norway conducted a performance audit of the Norwegian
national police efforts at combatting cybercrime. The goal of the audit was to examine whether the
Norwegian police has improved its ability to combat cybercrime. During the audit, the collaboration
between data scientists and auditors was key in ensuring a skilful use of novel methods in such audits,
---

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 223

providing contributions in their respective competences. While the auditors dealt with several tasks,
such as research design, data collection and analysis, as well as writing, data scientists played a key
role in applying advanced methods of text mining and ML to classify criminal cases. More specifically,
during the audit, 1 000 coded cases were used to train a ML system that applied text mining techniques
to extract the text from 334 544 cases across different types of crime (e.g. illicit gain/theft, traffic,
violence, financial). The task of classifying criminal cases as cybercrime or non-cybercrime was crucial
for assessing the police's understanding and handling of such crimes. The data previously held by the
Norwegian police was unreliable and lacked insight into the extent of investigations and case
resolutions.

Source: (Næss et al., 2025[119]), https://www.adb.org/sites/default/files/publication/928976/governance-brief-052-digital-transformation-tax-
administration-rok.pdf.

---
### Box 5.32. Evaluating the effectiveness of environmental policies with Al

Understanding which policies effectively reduce emissions is a pressing challenge for governments
worldwide. In partnership with the Potsdam Institute for Climate Impact Research (PIK), the University
of Oxford and the University of Victoria, the OECD has contributed to a study that uses Al to evaluate
the effectiveness of such policies across 41 countries. This research, published in Science, takes stock
of over 1 500 policy interventions spanning 1998 to 2022, offering unprecedented insights into what
works in the fight against climate change.

At the heart of the study is the OECD's Climate Actions and Policies Measurement Framework
(CAPMF). Using Al, the study identified 63 policies that have led to significant emission reductions. This
Al-driven approach not only enhances the ability to detect successful policy measures, but also
uncovers patterns and policy mixes that might otherwise go unnoticed. One key finding highlights that
policy combinations — rather than stand-alone measures — are most effective in reducing emissions,
reinforcing the importance of strategic policy design.

Source: https://www.oecd.org/en/blogs/2025/01/what-works-groundbreaking-evaluation-on-the-effectiveness-of-climate-policies.html.
---

## Supporting management and communication

Evaluation managers can benefit from a variety of Al-based tools developed to facilitate support activities,
such as administrative processes, drafting, translating and searching tools. When looking at planning and
management, government evaluations are often outsourced to external evaluators, increasing their
managerial complexity. The Al-based features of project management tools, such as monday.com or
Asana, help evaluators optimise resources and timelines, for example, by recommending optimal staffing
and scheduling based on prior evaluations, or ensuring resources are allocated where they are most
needed. Both platforms use Al to provide automation and insights, such as workflow automation, predictive
tasking or assistance through Al assistants. In addition, generative Al can also facilitate writing terms of
reference or similar managerial tasks (Jacob, 2025[125]).

Tools using LLMs can help to improve the communication of evaluation results; they quickly summarise
long reports into shorter products that can be shared with decision-makers or the public. The European
Commission, for example, has developed an LLM-driven tool that can produce summaries and policy briefs
from documents produced in different languages (Box 5.33).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

224

Finally, Al tools can be useful to develop digital evaluation repositories and knowledge management tools. Several OECD countries have developed evaluation repositories, which ensure that all conducted evaluations are easy to find, or platforms to describe and align evaluation efforts across government. One example is Norway's Kudos platform.26 While the manual development of such repositories can be time consuming, LLMs can automate much of the work and allow for more precise searches across a large volume of reports. In France, the General inspectorate of Finance (IGF) is currently using LLMs to develop an internal retrieval augmented generation (RAG) (Box 5.34) tool called Fragments, which collects reports by the IGF and French Court of Audit since 2006 and allows for precise searches through these documents.

## Box 5.33. European Commission's eSummary tools to support public administrations
The European Commission's Directorate-General for Translation has developed a series of Al-based services that can support policy analysis including policy evaluation. For example, eSummary is an Al-based service that can perform a quick overview of a submitted text and send a shortened version back; it uses Al algorithms to choose where the emphasis lies in the document and provide a relevant synthesis. eSummary is connected to another Al-based translation tool (eTranslation), allowing it to create text in all the EU languages. The tool is accessible to a variety of actors across the European Union, including public administrations in member States.

Source: https://language-tools.ec.europa.eu.

## Box 5.34. Retrieval-Augmented Generation for LLMs
Retrieval-Augmented Generation (RAG) is a technique developed to improve how LLMs, such as those behind advanced chatbots and virtual assistants, handle information. For different reasons, including reliance on old data, LLMs can provide incorrect answers, and it can be difficult to understand how they arrived at a particular response. RAG allows LLMs to access additional data sources that can keep information current, which is particularly useful when applied to specialised domains or knowledge areas. For government actors, RAG can be an effective means of fencing in their internal data sources, while improving the accuracy, relevancy and trustworthiness of a model's output.

RAG begins with identifying pertinent documentation and extracting vital text from it. Then, it breaks this text down into smaller parts and transforms these parts into a format (i.e. embeddings) that the model can understand and store efficiently. These pieces of information are kept in a special database (i.e. vector databases). When someone asks the model a question, it can look through this database to find up-to-date and accurate information to add to what it already knows before giving an answer.

For situations where it is critical for a model to provide facts that are current and accurate, such as when dealing with confidential information or needing to keep a clear record of data sources, the United Kingdom's Al Playbook for the UK Government (Box 4.2) recommends using RAG. This approach can help to ensure that the model's answers are based on reliable data, making it particularly valuable for organisations focused on maintaining high levels of accuracy and accountability.

Source: (Ugale and Hall, 2024[89]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 225

# Evidence of impact
As the use of Al in policy evaluation is still at early stages, the impact of Al on the practice of policy evaluation is still modest and difficult to measure. A recent study conducted on 758 Boston Consulting Group (BCG) consultants on complex, realistic knowledge-intensive tasks (such as policy evaluation), showed that each one of a set of 18 realistic consulting tasks within Al's known capabilities, consultants using Al were significantly more productive. Compared to a control group, on average, they completed 12% more tasks, 25% faster, with 40% higher quality (Dell'Acqua et al., 2023[126]). However, a different effect was observed for tasks "outside the current capability of Al", showing fewer mistakes from the group not using Al. Other studies on the impact of Al on evidence synthesis show promising results of using LLMs to conduct some elements of systematic reviews, like risk of bias assessments, with agreement in judgment between humans and Al systems ranging from 41% for overall judgement to 71% for outcome measurement (Eisele et al., 2024[127]). At the same time, the study also highlights that Al judgment cannot yet replace human assessment.

# Managing risks and challenges
While there is very little research on the risks and challenges of using Al in policy evaluation (Jacob, 2025[125]), that research — along with OECD work with governments and analysis of individual use cases — have identified several associated risks and implementation challenges for Al use in the field.

## Associated risks
*   Inadequate or skewed data in Al systems
*   Automation bias
*   Lack of transparency and explainability

Al's use during evaluation processes can reinforce some errors that can emerge at multiple points within the Al pipeline. The first risk of using of Al in policy evaluation originates from training algorithms with skewed or incomplete data. This can produce systems that generate erroneous predictions or that reinforce or exacerbate pre-existing outlooks (Jacob, 2025[125]). While this risk is does not only concern policy evaluation — and can apply to other uses of Al in policymaking — its potential risk in the field are significant considering the impact on maintaining or discontinuing potentially positive or harmful interventions (Marcucci and Verhulst, 2025[128]). For this reason, it is essential to mitigate this risk as much as possible by making sure that the data used to train these systems is of good quality and is representative.

Many people perceive Al systems and the decisions they make to be neutral and impartial, leading them to accept results without scrutiny, despite the possibility of inaccuracies. This tendency for human operators to over-rely on automation is known as “automation bias" (Horowitz, 2023[129]; Alon-Barkat and Busuioc, 2022[130]). Over-automation could reduce the role of human judgment and potentially oversimplifying complex social and economic assumptions. This may cause evaluators to accept recommendations proposed by Al without fully scrutinising the underlying assumptions or data.

Furthermore, the lack of transparency of certain Al tools can further complicate policymakers' tasks to understand and justify Al-driven insights. These can be particularly problematic in policymaking, where an objective approach is needed to address proportionately different populations and justify the decisions made.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
226

# Implementation challenges
*   Lack of high-quality data and the ability to share it
*   Skills gaps

Just as governments face a number of challenges in promoting policy evaluation, they also face specific challenges when seeking to use Al in this field (OECD/UNESCO, 2024[131]). Inadequate data governance has long been a challenge for evaluators, limiting the capacity of governments to generate the data that is necessary to produce evidence and evaluation (OECD, 2020[108]). This issue persists even though in adhering to the OECD (2023[132]) Recommendation on Public Policy Evaluation, all member countries committed to ensuring the availability of high quality, timely, accessible, disaggregated and reusable results, performance and administrative data for policy evaluation.

The implementation of Al requires digital and numeracy skills. While not all members of an evaluation team need to be experts, it is important to ensure that all evaluators understand how Al can support policy evaluation. Evaluators should therefore be properly supported by digital and data science teams, which are currently being put in place, such as at France's Inspectorate General of Finance (IGF). Evidence shows that policy evaluators have been slower to adapt to the new developments at a general level, even if some countries have advanced practices. There is often limited development training in big data analytics and Al for evaluators. This is also the case for evaluations inside government, which often suffer from limited internal analytical capacities and technical skills, hindering the development of quality evaluations (OECD, 2020[108]).

The OECD (2025[107]) Implementation Toolkit for the OECD Recommendation on Public Policy Evaluation provides information on how governments can assess their current policy evaluation capacities, identifies best practices and use cases from around the world, and illustrated potential practical solutions and tools for policymakers and evaluators.

# Untapped potential and way forward
In the field of policy evaluation, Al can perform some tasks, allowing government analysts to use a broader range of evidence and process it faster. While some initial applications of Al were identified in evaluation design, analysis, and evaluation communication and management, the use of Al in policy evaluation remains limited. For this reason, there are areas where Al has the potential for significant impact on policy evaluation in the future.

First, to support evaluation design, chatbots could help evaluators build their knowledge in specific fields. Indeed, if well prompted, chatbots can perform several activities that can support learning. As some initial examples of evaluation design show, they can also support creative thinking and be used as useful tools for brainstorming (Ferretti, 2023[133]). Even if these tools do not generate new evidence, they can provide new insights helpful for initial stages of an evaluation process. Recently, for instance, ChatGPT's Deep Research attempts to automate a large part of the process of evidence review and synthesis. Using chain of thought (CoT) reasoning, tools such as Deep Research break complex research questions into smaller, comprehensible sub-questions that it answers in sequence. The approach enables the system to prepare a detailed report based on its review of the available evidence. Such CoT techniques have the potential to automate a large part of the evidence review and synthesis process. This may enable researchers who would previously develop a few reviews from scratch to instead automate, quality assure and build upon dozens of Al-generated research reviews.

Second, from an analytical perspective, there is a strong potential for Al to be further used to conduct more ambitious ex ante and ex post evaluations, using a broader range of data and assessing impact through quasi-experimental methods. For instance, Al-driven behavioural forecasting can analyse large quantities

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 227

of historical data and observed behaviour to identify patterns, anticipate decisions and optimise user experiences by integrating contextual variables and external stimuli. ML tools can be used for counterfactual prediction in cases where a control group is missing. This can be used, for example, in the case of carbon pricing assessments, where policy evaluators lack an ex-post perspective. One study proposes a policy evaluation approach using ML tools and economic theory for counterfactual prediction to analyse the costs and emissions impacts of the UK CPS, “a carbon tax levied on all fossil-fired power plants" (Abrell, Kosch and Rausch, 2022[134]).

Finally, in the longer-term, Al has the potential to change the approach to policymaking from a policy cycle and allow evaluations to feed into decision-making at multiple stages. Because Al makes evaluations quicker and to some extent less costly, academics suggest the possibility of shifting from a system where evaluations often arrive too late for decision-making to an approach where evaluative evidence is available to shape, adjust and redesign policies almost in real time. This is referred as Dynamic Public Policy Cycle (Jacob, 2025[125]). As countries around the world have faced a series of crises in recent years, it is essential that governments have access to evaluative evidence in key decision-making stages. Rapid evaluations are developed to inform urgent decision-making and have been efficiently used for this purpose, for example, in Australia (Better Evaluation Knowledge, 2022[135]). While these rapid evaluations now rely mainly on qualitative data, Al could play an important role in making these evaluations more robust and common in the future.

However, for Al to effectively support evaluation, governments need to invest in civil servants' skills and developing a strong data infrastructure. Stronger international collaboration can also enhance Al's potential in policy evaluation. Evaluators need a good understanding of Al's potential benefits, risks and limitations to make informed decisions on when and how to use it. For this reason, governments need to invest in training courses for evaluators to ensure they understand the different tools available to them. Trainings have been developed across OECD governments (see Chapter 4, section on "Fostering skills and talent"). However, these are mainly on the use of Al in government and are not tailored to the field of evaluation. In addition to trainings, it is important to support experimentation with Al and learn-by-doing. Developing a network across line ministries to exchange relevant Al applications can be a good way to support Al uptake in different evaluation tasks. Some incubators are currently being developed but a stronger focus on evaluation is needed.

As is the case for other policy areas, governments should invest in relevant data infrastructures and data sharing that is safe and secure (see Chapter 4, sections on "Creating a strong data foundation" and "Building out digital infrastructure" for a detailed discussion). Some government organisations, such as the Australian Centre for Evaluation, have developed guides to facilitate data discovery and access to support evaluation activities (ACE, 2025[136]). Some OECD countries have developed ways in which different datasets can be linked and accessed in secure environment to ensure policy analysis. In Denmark, for example, Statistics Denmark (2025[137]) facilitates the use of these micro-level databases for research purposes for approved analysts, universities, research organisations or ministries. In the Netherlands, the government launched the Data Agenda Government, outlining plans to improve the management of personal data, open data and big data, leveraging analysis and integration for informed policymaking and addressing societal challenges (Netherlands Ministry of the Interior and Kingdom Relations, 2019[138]).

Finally, Al has potential in evidence synthesis. There is a broader calling for stronger collaboration on evidence generation across countries, following strategic initiatives supported by countries such as the United Kingdom and Australia (Halpern and Maru, 2024[139]). This agenda recognises a need for faster, reliable synthesis at the international level, given that Al is already helping to reduce timelines for evidence production. This could help to fill some of the existing gaps faster.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
228 |

# Al in civic participation and open government
Stakeholder participation refers to “all the ways in which citizens and stakeholders can be involved in the policy cycle and in service design and delivery” (OECD, 2017[140]). Civic participation, which focuses on engagement with the public, can yield benefits for governments and citizens alike. It not only builds trust in government, but it also reinforces democracy by providing meaningful opportunities for citizens to have a say in how government designs and implements policies and services (OECD, 2023[141]; 2024[142]; 2022[143]).With regard to Al policies and products, engagement early in the technology development cycle enriches the understanding of issues, helps align technological innovation with societal needs, and influences how well potential harms are mitigated (OECD, 2024[144]; UK Government Office for Science, 2023[145]).

Governments are using digital technologies to expand civic participation opportunities by enabling new forms and channels of interaction between citizens and public institutions. This contributes to the growing trend of Civic Tech: the use of digital technologies to reinforce democracy by enabling the public to be informed, participate in decision and policymaking, and increase governments' responsiveness and accountability (OECD, 2024[146]). In particular, Al tools have relevant applications in civic participation and more broadly in open government policies and practices, including access to information, government communication and protection of the civic space.

## Current state of play
## Improving transparency and information access
Al's ability to sort, filter and summarise vast amounts of information could lower barriers to disclosure, making it easier for governments to be transparent to the public (OECD, 2024[29]). For example, the US government is testing an Al-powered tool to review classified documents for future disclosure under the Freedom of Information Act (US FOIA, 2023[147]; MITRE, 2023[148]). Al can also help citizens understand complex governmental processes and create opportunities for broader engagement and scrutiny from citizens and civil society organisations (CSOs) (Araszkiewicz and Rodríguez-Doncel, 2019[149]).

Governments can offer Al-enabled tools to the public directly to help people navigate and make sense of extensive amounts of data and information, thereby providing citizens with tailor-made and accessible access to public information. For example, the District of Columbia (US) has released a beta version of the platform DC Compass,27 which uses Al to respond to users queries and generate maps based on the city's open data. In Greece, the opencouncil.gr platform uses Al to automatically transcribe local council meetings and generate summaries, social media content and personalised neighbourhood updates via messaging apps, making local governance more accessible and understandable for citizens.28 Another example from Greece is the platform DidaktorikaAl launched by the National Documentation Centre (EKT), improves the accessibility of academic and scientific knowledge for policymakers and the broader society through an Al-powered online library gathering more than 50 000 publications (National Documentation Center (EKT), 2025[150]). Furthermore, the European Parliament provides an Al tool to help citizens access its archive by asking questions in natural language (Box 5.35).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 229

# Box 5.35. Democratising access to the European Parliament's archives
The European Parliament Archives have embraced generative Al to transform access to their extensive
historical records. Developed by the Archives Unit, the innovative Archibot platform integrates LLMs
with RAG techniques to enable users to interact directly with digitalised documents. Citizens,
researchers and policymakers can now make natural language queries to retrieve information on
historical events, key figures and institutional developments from an index of over 100 000 documents
dating back to 1952. The tool employs RAG methods to identify relevant documents based on users'
queries and synthesizes the extracted information into concise, easily comprehensible responses.
Accessible via the European Parliament's archive website, the platform supports automated translation,
thereby extending its reach to users in 55 languages despite the predominantly French content.

The project, which reduces document search and analysis time by approximately 80%, significantly
improves the efficiency of historical research and data analysis. In addition to facilitating rapid access
to legislative and policy information, Archibot supports the creation of comprehensive reports and
analytical outputs, serving as a valuable resource for educators, researchers and policymakers. This
digital transformation of archival access not only addresses longstanding challenges in navigating vast
records collections but also enhances transparency and public engagement within the European Union.

Source: https://historicalarchives.europarl.europa.eu/en/sites/historicalarchive/home/cultural-heritage-collections/news/ai-dashboard.html.

Enabled in part by improved transparency and access to information, Al tools present opportunities to
promote civic space (OECD, 2023[151]). Civic space is a cornerstone of functioning democracies. It consists
of the set of legal, policy, institutional and practical conditions non-governmental actors need to access
information, express themselves, associate, organise and participate in public life (OECD, 2022[152]). For
example, in Israel, the platform Kol Zchut (All rights) — a comprehensive repository of residents' rights
developed by the homonymous CSO along with the country's Ministry of Justice and National Digital
Agency — has recently integrated an Al chatbot to allow users to formulate their queries in Hebrew, Arabic
and Russian (OECD OPSI, 2019[153]). Al experts have identified empowered citizens, CSOs and social
partners (e.g. trade unions) as one the most critical potential benefits of Al use, calling on governments to
take more action to empower these actors (OECD, 2024[29]).

Al can also expand access to information by helping people with disabilities that may face barriers to their
access to information. For example, citizens affected by visual or cognitive impairments can benefit from
speech-to-text or image-to-speech conversion applied to government websites and portals, as well as from
Al-powered accessible interfaces with adaptive texts, fonts, colours and contrasts (Welker, 2023[154]). The
United Kingdom built its gov.uk website to be fully compatible with technologies that use Al to improve its
accessibility. Al can also enhance access to information by overcoming the language divide, including on
government websites through automatic translation of content, which has become mainstream. This can
enhance the ability to engage in participatory processes by fostering dialogue among participants speaking
different languages (European Parliament, 2022[155]). India's Bhashini platform, discussed in Chapter 4,
serves as another example of seeking to overcome language divides, including through leveraging
participatory techniques.

## Making participatory processes effective and inclusive
Governments can use Al to help conduct and facilitate public discussions and dialogues. Such dialogues
often face a trade-off between breadth (the number and variety of participants) and depth of discussion
and consensus-building (Landemore, 2022[156]). While the internet has enabled spaces for many-to-many
communication, these spaces are not always designed to foster deliberation and consensus-building

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
230 |

(Weyl, Tang and Plurality, 2022[157]). Al can provide for a welcoming and productive deliberative space by
(Landemore, 2022[156]; Ovadya, 2023[158]):

*   Extracting meaningful insights from the contribution of many participants, which could be provided
    under different formats, such as text and voice.
*   Detecting of harmful content and supporting human moderators in countering hate speech.
*   Facilitating fact-checking by providing data and sourced information in real time.
*   Helping to perform live facilitation to favour multiple opinions and to create bridges towards
    consensus and support deliberation.

Al can also enhance the quality of dialogue. For instance, it can support organisers in drafting accessible
and fact-based learning materials and **simplify complex bureaucratic documents into easy-to-read
language to enable informed debate.** For instance:

*   In the United States, the Al-powered tool MAPLE (Massachusetts Platform for Legislative
    Engagement) allows citizens to better understand the context and objectives of draft legal texts
    through Al-generated summaries submitting their inputs and comments. 29
*   In Spain, the participatory platform Decide Madrid, based on the open-source software Consul,
    experimented with an NLP system to assist citizens in aggregating and developing proposals
    (Arana-Catania et al., 2021[159]).

Research indicates that the use of Al-enabled deliberation tools could have a significant impact on
decreasing polarisation (Tsai et al., 2024[160]; OECD, 2020[161]). The examples in Box 5.36 illustrate that
such tools are not only beneficial for obtaining understandable insights on a specific topic, but can help
bring together the results of the multiple deliberations. They can ensure consistency while preserving the
richness of the debates (Landemore, 2022[156]), as well as strengthen connections between the participants
and the broader society by making the content and results of discussions more accessible to the public.

# Box 5.36. Al as facilitator of deliberative processes
## Mass online deliberation with Polis
Polis is an Al-powered open-source software designed to allow large group of people to discuss,
collaborate and reach consensus on complex issues. Participants share their opinions on a given
question and express their agreement or disagreement on other participants' statements. The algorithm
maps participants' responses and clusters opinions, facilitating the identification of positions that are
supported by the majority of participants. Polis has been used to facilitate discussion and build consensus
in Austria on environmental issues, in Uruguay on a national referendum, in New Zealand to facilitate the
development of government policy, in the Philippines to generate municipal policy, in the United States to
counteract polarisation at the municipal level, and in Germany to develop a political party's platform.

## In Chile, Al helps moderate deliberative processes
In 2020, the Senate of Chile partnered with the Stanford Center for Deliberative Democracy to involve
citizens in the online deliberative process “LXS 400 – Chile Delibera” performed through the Stanford
Online Deliberation Platform. The platform used an Al tool to keep time and distribute speaking rights
equitably, allowing participants to form speaking queues and discuss in small groups with timed
agendas. Over 500 citizens representative of the Chilean society discussed in small groups and
deliberated in plenary sessions on health and pension reforms.

Source: (The Computational Democracy Project, 2024[162]; Fishkin and al, 2021[163]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 231

In addition to facilitating engagement, Al can help governments and citizens analyse and make sense of
the inputs from participatory and deliberative processes. Al features — such as automation and processing
of large amounts of data and text — can facilitate mass, multilingual online deliberation and dialogue.
Governments usually face the challenge of analysing large quantities of qualitative inputs received in public
consultations, which can be remedied with the help of Al. For example, the United Kingdom's Incubator for
Artificial Intelligence (i.Al) has developed the i.Al Consultation Analyser, which aims to expand the
government's capacity to analyse citizens' inputs in legal public consultations. The tool is expected to
reduce the cost of this activity by GBP 80 million (AI.GOV.UK, 2024[164]).30

Al sensemaking tools allow for the identification and evolution of recurrent topics, the automatic clustering
of opinions and ideas, the detection of outliers, and the sentiment analysis of the perception of a given
issue (Arana-Catania et al., 2021[159]; Berditchevskaia and Baeck, 2020[165]; Schneider and Sanders,
2023[166]). Sensemaking tools can help public servants understand and visualise citizens' priorities and
opinions on issues and support them in translating large volumes of inputs into actionable
recommendations that are representative of the participants' views. Citizens can also use these tools to
understand others' perspectives, inform and craft their own inputs, and better understand the results of
participatory and deliberative processes. Examples include France's national *Grand Débat*, or Great
Debate (Box 5.37), as well as:

*   The Cambridge City Council in the United Kingdom used the Al-powered sensemaking tool of the
    Go Vocal platform (formerly CitizenLab), which automatically clusters and prioritises citizen
    opinions to analyse their contributions to its Design Code, saving 50% of the estimated time for
    manual processing (Fillet, 2024[167]).31
*   The French Economic, Social and Environmental Committee (CESE) organised a deliberative
    process (Convention Citoyenne) to inform legislation on the sensitive policy issue of end of life.
    The Al-powered tool Panoramic, developed by Make.org, allows citizens, journalists and CSOs to
    access and navigate the discussions and the results of the deliberative process via an interactive
    interface.32

# Box 5.37. Improving participation in France's Grand Débat National
In France, the Grand Débat National, launched in early 2019, exemplifies a pioneering effort to
democratise public debate through digital innovation. In response to growing social discontent, the
French government established this national consultation to gather citizen input on key issues —
including employment, taxation and democratic reform — using a dedicated online platform. Artificial
intelligence played a central role in managing and interpreting the vast array of contributions.

Al-driven techniques, such as NLP and clustering algorithms, were employed to systematically analyse
millions of submissions. By identifying recurring themes and synthesising diverse viewpoints, these
tools enabled policymakers to highlight consensus points and emerging trends. This automated
analysis transformed raw citizen input into accessible insights, supporting more informed and
transparent decision-making.

Source: https://granddebat.fr.

Finally, Al can facilitate innovation in civic participation activities by **generating simulations and
visualisations on various scenarios and alternatives**, including in combination with other emerging
immersive technologies like augmented or virtual reality (VR).33 Generative Al tools can help governments
to engage with the public on complex projects concerning a physical space (e.g. urban mobility and
redesign). These tools can simulate future and alternative scenarios, allowing citizens to visualise the final
results and provide feedback for government consideration (OECD, 2023[2]). Generative Al can

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
232 |

significantly reduce the costs of creating visual simulations by automating the design process and
generating realistic renderings. For example, the City of Hamburg in Germany, used 3D and Al
technologies in the CityScope platform, developed at MIT Media Lab, to engage relevant stakeholders in
the decision-making process for 161 viable locations to home refugees (Campagnucci et al., 2025[168]).
Similarly, Finland used the tool UrbanistAl to foster discussion on the pedestrianisation of streets
(Box 5.38).

# Box 5.38. Finland uses generative Al for participatory urban planning
In Finland, the City of Helsinki used generative Al to enhance participatory urban planning through
UrbanistAl. This platform integrates Al-powered visualisation tools with co-design features that allow
residents and businesses to collaboratively shape urban spaces. During the 2023 Summer Streets
initiative, Helsinki used the platform in community workshops, where participants translated their ideas
into Al-generated street designs, fostering more inclusive and engaging urban planning processes.

By enabling the real-time visualisation of community proposals, UrbanistAl helped bridge the gap
between citizen input and final design decisions. The tool's ability to align proposals with local policies
also streamlined the planning process, ensuring regulatory compliance while maintaining creative
flexibility. The success of the Helsinki case has inspired broader adoption of the platform, with cities
including Tallinn, Pristina and Berlin integrating it into their participatory urban design initiatives.

Source: https://interoperable-europe.ec.europa.eu/collection/public-sector-tech-watch/reimagining-helsinki-participatory-urban-planning-
generative-ai.

## Supporting effective and tailored public communications
Al-powered analytics software can help public communicators monitor and analyse online debate,
audience perceptions and attitudes on a given issue.34 Al can help them to improve the quality, quantity,
accessibility and relevance of information governments deliver to different segments of the population.
Moreover, Al tools can enhance the efficiency and effectiveness of public communicators by assisting in
brainstorming, automating routine tasks such as media planning, and ensuring consistency in content
across communication channels. These capabilities enable communicators to better engage with their
audiences, tailor messages to diverse groups, and respond promptly to public concerns, thereby fostering
a more informed and engaged citizenry. An example can be found in Box 5.39.

# Box 5.39. Innovating public communications with Al in the United Kingdom
In the United Kingdom, the Government Communication Service (GCS) has been developing and
testing GCS Assist, an Al-powered conversational tool designed to help government communicators
improve the efficiency and effectiveness of their work. The tool integrates professional guidelines,
communication frameworks and proprietary audience insights, ensuring that Al-generated outputs align
with government standards. Because Al is most effective when used as a collaborative assistant, GCS
Assist is tailored to support both experienced and less-experienced professionals by streamlining
routine tasks, enhancing creativity and enabling more time for strategic work.

GCS Assist has undergone an iterative development process, beginning with an initial prototype piloted
within the Cabinet Office in late 2023. The tool was designed to support government communicators by
generating draft texts, plans and strategic ideas while ensuring data security within government

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 233

systems. The alpha assessment in March 2024 rated the tool's progress as Amber, acknowledging its
potential while highlighting areas for further refinement. A phased rollout is now underway, starting with
a limited group of users before expanding access more broadly.

Source: https://gcs.civilservice.gov.uk/wp-content/uploads/2024/04/2024-05-GCS-Innovating-with-Impact-Strategy-interactive.pdf.

The production and dissemination of information materials, as well as the assistance and response to
citizens' queries, is a fundamental yet resource intense function to enable effective participation. Al can
also enhance public communications efforts by curating and tailoring communications materials.
Generative Al can, for example, summarise and synthesise information and create content for different
audiences in different formats (video, image, text, etc.). Moreover, GenAl can support governments in
providing citizens with accessible and evidence-based information, allowing them to better understand the
policy issues at stake as well as the role of the government in regulating them. Examples from the
Netherlands and Brazil in Box 5.40 illustrate how this can be done in government.

# Box 5.40. Practices of Al for information curation in citizen participation
## Helping reporting oral deliberations in the Netherlands
The Netherlands House of Representatives implemented the Speech2Write system, which allows its
Parliamentary Reporting Office (PRO) to convert voice to text, as well as translate voice into written
reports and produce an "almost-ready" report for human finalisation. The system is based on a
parliamentary language model that was developed from scratch based on 2000+ hours of audio of
proceedings and text files.

## Making complex information more accessible in Brazil
The Brazilian Chamber of Deputies is using Al to improve the support given to parliamentarians and to
build a more public-friendly legislative institution. Its Ulysses Al Suite uses an NLP system to classify
and help citizens navigate the vast amount of information produced by the Chamber, including laws,
speeches, data and research documents. Ulysses also helps parliamentarians draft legislative texts
and find similar bills already adopted or rejected.

Source: https://www.ipu.org/innovation-tracker/story/artificial-intelligence-innovation-in-parliaments, (Arana-Catania et al., 2021[159]),
https://www.camara.leg.br/noticias/548730-camara-lanca-ulysses-robo-digital-que-articula-dados-legislativos.

Virtual assistants such as chatbots can support communications efforts by helping citizens to navigate
government information, by responding to their queries in plain language, and by sending personalised
notifications and content based on their interests (Androutsopoulou et al., 2019[169]; van Noordt and
Misuraca, 2019[170]; Cortés-Cediel, 2023[171]). In some cases, chatbots have been used as a channel for
civic participation (see examples in Box 5.41).

# Box 5.41. Chatbots supporting participation in Spain and Colombia
In 2021, the city of Madrid (Spain) embedded Clara, an Al-based virtual assistant into its existing
participatory platform, Decide Madrid, based on the open-source software Consul. Clara responds to
users' questions on the functioning of the platform and of the participatory processes of the city.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

234

In 2022, the city of Bogota (Colombia) deployed Chatico. This virtual assistant supports the interaction between citizens and the local administration by improving the experience of procedures and services and enabling citizen participation. Chatico is available both on the website and via WhatsApp to enhance its accessibility.

Source: https://www.madrid.es/portales/munimadrid/es/Inicio/Actualidad/Noticias/Nace-Clara-el-asistente-virtual-de-Decide-Madrid, https://oecd-opsi.org/innovations/chatico-virtual-agent, https://gobiernoabiertobogota.gov.co.

# Strengthening electoral processes

Policy discussions on Al's potential in the electoral process have focused on protecting electoral processes against the risks of Al, namely by empowering society and building resilience, protecting democratic principles, and promoting information integrity. Yet there are also relevant opportunities for Al to strengthen electoral processes by pre-empting fraud and disenfranchisement, and lowering barriers to entry for underfunded candidates (Eisen et al., 2023[172]; OECD, 2024[29]).

Al tools can be used by electoral management bodies (EBM) throughout the electoral period (Juneja, 2024[173]). Before elections, Al tools can be adopted to support voter list management, voter registration, resource allocation planning, forecasting election costs or targeted advertising. For example, in the United States, the Electronic Registration Information Center (ERIC) (2024[174]) uses ML to analyse voter registration and motor vehicle records. This helps states identify duplicate registrations, deceased voters and eligible but unregistered individuals, which improves voter roll accuracy. During elections, Al tools can contribute to campaign and media monitoring, voter verification, polling place monitoring and ballot counting. Finally, Al can support authorities in post-electoral audits by detecting incidents or frauds (Juneja, 2024[173]).

# Managing risks and challenges

Al offers significant opportunities to empower citizens and civil society and reshape relationships between governments and their people for the better. However, potential risks persist, which can have direct implications on democratic spaces. While technological advancements may progressively address these issues, policymakers should consider them when adopting Al tools in this area.

## Associated risks
*   Inadequate or skewed data in Al systems
*   Overreliance on Al
*   Lack of transparency and explainability
*   Resistance: Lack of public understanding about how government uses Al
*   Misuse or questionable use of Al, resulting in surveillance and privacy concerns
*   Exacerbating social exclusion and digital divides

If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for some individuals or groups. With regard to civic participation and open government, this could result in inaccurate or imprecise consideration of citizen input into Al-enabled participation processes.

Moreover, deliberative processes are meant not only to harness collective intelligence and enable societal dialogue on specific policy issues, but also to enhance the knowledge of participants as well as their mutual

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 235

understanding and empathy (OECD, 2021[175]). Overreliance on Al tools to improve the efficiency of deliberative processes might overlook other fundamental aspects of deliberation.

Al's lack of transparency and explainability, especially in complex systems, can decrease trust in Al tools, and when these are used in democratic spaces, it can in turn affect trust in the participatory process and its outcomes. To address this challenge, some governments have launched algorithm registers that disclose detailed and technical information about algorithms, such as, their purpose, design, data inputs, decision-making processes, potential biases, among others (for details and examples, see Chapter 4, section on "Establishing guardrails to guide strategic and responsible Al”).

In addition, there are still many unknowns about user perceptions regarding Al in participatory processes and the influence it may have on their contributions and their willingness to participate. Experiments are being conducted to assess the reaction of participants to the introduction of Al tools as intermediaries in participatory and deliberative processes (Hadfi et al., 2021[176]; Kim et al., 2021[177]). The use of Al tools to support participants in formulating inputs and contributions should be carefully handled to avoid that these tools compromise the creativity in language and reflection of participants, focusing rather on efficiency and agreement.

Some governments have misused digital technologies for surveillance or even silence populations and digital opposition, thus damaging the civic space (OECD, 2022[152]). The use of Al systems for surveillance purposes, content censorship and improper forms of predictive policing threaten the free exercise of civil freedoms, such as the right to peaceful assembly and freedom of expression. These improper uses risk creating general mistrust among citizens towards the adoption and deployment of Al systems in government functions and public services. The OECD (2022[152]) found that most national Al strategies fail to discuss the impact of Al on the ability to freely exercise rights, although around half propose concrete oversight and redress mechanisms (OECD, 2022[152]).

Finally, many languages are insufficiently represented in Al systems, which are mainly trained in English, Spanish, and Mandarin (Peixoto, Canuto and Jordan, 2024[178]) (see Chapter 1, section on “Exacerbating digital divides” for a detailed discussion of the issue). In the context of citizen participation, this means that inputs submitted in other languages might not be processed and valued in the same way, creating new democratic imbalances (Romberg and Escher, 2024 [179]). For example, to address the language divide and to preserve the Icelandic language, the government of Iceland partnered with OpenAl to train the LLM GPT-4 in Icelandic (Government of Iceland, 2023[180]). Similarly, the University of Turku (Finland) partnered in 2023 with the company SiloAl to build the Poro suit of systems, a family of multilingual open-source LLMs for all European official languages (University of Turku, 2023[181]). Similar efforts exist in for other languages, including Indigenous and endangered ones (OECD, 2023[182]).

## Implementation challenges
*   Skills gaps
*   High costs of Al adoption and scaling

The adoption of Al tools by civil servants in charge of participatory and deliberative processes, as well as by citizen participation practitioners, requires adequate skills. This skillset spans from the identification of relevant uses of Al tools to support participatory and deliberative practices (OECD, 2025[183]), to the selection and purchase or development of Al solutions that meet the defined objectives, to the use of Al tools in the context of participatory and deliberative processes, to the evaluation of the quality of their outputs.

The adoption, either through in-house development or through public procurement, and the use of Al tools to support citizen participation requires a flexible approach including pilot initiatives, testing, and iterative adjustments. Such approach entails significant costs and require an elevated high tolerance to risk.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
236

Challenges related to costs and scaling of Al tools are particularly relevant for citizen participation, ss participatory processes are often organised and implemented by local governments (OECD, 2022[184]).

# Untapped potential and way forward

Given the novelty of the use of Al in civil participation and enablement, it is difficult to assess evidence of impact and general lessons learned beyond individual case studies. The use cases showcased in this chapter suggest that Al has the potential to improve the efficiency, reduce the costs and enlarge the scope of participation, ultimately lowering barriers for citizens and CSOs to voice their opinions and provide feedback at various stages of policymaking. The use of Al tools to process citizens' inputs, automate tasks, support the creation of information and communication materials, and provide citizens with 24/7 virtual assistance could significantly reduce some of the costs associated with the design and implementation of relevant processes. These savings, coupled with the growing availability of open-source tools, could enable citizen participation opportunities in contexts with limited resources, such as in smaller cities and less developed regions.

Digital technologies have enabled asynchronous participation and significantly reduced the burden of geographical barriers, allowing for broader collaboration (OECD, 2022[184]). Al has the potential to lower other barriers, namely the language divide, allowing higher levels of citizen participation. Moreover, virtual assistants and chatbots can further improve the accessibility of participatory and deliberative processes by helping participants navigate complex information. Finally, Al tools for moderation, facilitation and sense-making could become essential to addressing the challenge of scale in deliberative processes (Landemore, 2022[156]).

Early efforts could lead to longer-term conceptions of transparency and responsiveness. Digital technologies have long affected how individuals engage with notions such as their so-called "right to know,” and voice opinions about complex operations and their outcomes (Margetts, 2011 [185]; Song and Lee, 2015[186]). Al technologies also offer novel ways of enhancing service design, delivery and transparency. Individuals may begin to find current operational systems antiquated and difficult to use, and therefore they may voice their opinions about how services should integrate technologies that can enhance access to information (Carrasco et al., 2019[187]). This could help accelerate institutional reforms that aim to improve transparency and accessibility. These may be driven not only by the adoption of Al technologies but also by their capacity to shift public perceptions and expectations of institutional capacity.

Moving forward, governments should explore Al's potential to enhance existing civic participation processes by expanding government capacities of analysing citizens' contributions, enabling mass-deliberation and reducing barriers to participation. Governments should carefully consider the challenges associated with the use of Al in civic participation, namely issues related to increased technological intermediation of interactions between citizens and government, and its impact on public discourse and trust. The adoption and deployment of Al tools for civic participation should follow clear strategies that include transparency and accountability as fundamental principles. Citizens and civil society should be actively involved in the elaboration of such strategies to ensure alignment with democratic principles and enhance trust and acceptability of the process (see Chapter 4, section on “Engagement to shape strategic and responsible Al").

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 237

# Government services and justice functions

Government services and justice functions are essential to meeting citizens' needs and upholding the rule of law. This includes the design and delivery of public services that are accessible, efficient and responsive, as well as effective law enforcement and disaster risk management to ensure safety and resilience. Justice administration and access to justice are equally critical, providing fair and timely legal processes that protect rights and promote public trust. These areas have the most impact with the public. Governments are using Al in a variety of ways to ensure that they are efficient and effective, and that citizens and residents are safe and treated fairly.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
238

# Al in public service design and delivery

The development and use of Al has permeated public service design and delivery in recent years, with 67% of OECD countries using Al to improve this function (OECD, 2024[188]). Public servants are increasingly taking it upon themselves to experiment with Al in their job duties (Bright et al., 2025[189]). In general, the aim is to make them more efficient, effective and responsive to the public's needs. Al can help achieve this thorough the automation of processes, more efficient allocation of resources (e.g. optimising staff levels), supporting decision-making, improving citizen participation, and tailoring and personalising content and service pathways for citizens (2024[60]; 2023[190]; 2019[191]; OECD, 2025[192]). Al can also increase governments' understanding of socio-economic challenges service users are facing —by picking up on trends and causal relations that are not detectable by humans — thus, improving the responsiveness and personalisation of public services (Anshari et al., 2024[193]). This can allow governments to design novel public services that are more proactive in anticipating and responding to user needs (Madan and Ashok, 2023[194]).

In certain circumstances, automated decision-making in public services may also be perceived as fairer and less prone to human error or corruption (Miller and Keiser, 2020[195]; Leyer and Schneider, 2021 [196]). However, a variety of human behaviour factors how people perceive, trust and interact with Al-driven decisions — will determine its effectiveness and legitimacy. Better service delivery and service effectiveness can boost citizens' satisfaction and their trust in government (Sun and Medaglia, 2019[197]; OECD, 2024[46]). Some argue that this moment requires a broad rethinking of how impacts Al impacts public administration structures underlying public service delivery, beyond focusing on efficiency gains (Babšek et al., 2025[198]).

## Current state of play

## Automating and optimising tasks

The most common tasks in public services are routine recording, preparing, sorting, classifying, filing and verifying the accuracy of information and have a high potential to be automated (Straub et al., 2024[199]). Al can streamline bureaucratic tasks, freeing time for public servants to focus on those tasks requiring human judgement, creativity, discretion and decision-making. Real-world use cases highlight the importance of cost efficiency in integrating Al applications to service delivery. For example, Brazil employs a RPA solution to detect and dismiss predatory and repetitive legal claims -claims engineered by wealthier entities to burden smaller defendants with exorbitant, extraneous data requests and costs thereby streamlining court procedures and conserving valuable time.35 In Spain, RPA technology automates or accelerates low-value repetitive tasks in public services, ensuring an efficient distribution of non-contributory disability and retirement pensions.36 Additional examples in Austria and Spain can be seen in Box 5.42.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 239

# Box 5.42. Al solutions in planning processes

## Vienna's digital building permit reviews (Austria)

The Building Regulations Information for Submission Envolvement (BRISE-Vienna) in Austria introduces a digital innovation in building permit reviews, transforming traditional, paper-based processes into a comprehensive digital workflow. In the BRISE project, Al-based verification routines automatically compare the digital 3D Building Information Models submitted by planners with a municipal digital reference model that encapsulates regulatory requirements. This automated process not only quickly identifies any deviations from established standards but also provides immediate feedback, significantly reducing the traditionally lengthy review period.

## Automating the energy poverty report in Catalunya (Spain)

The Automating Energy Poverty Report in Catalunya, in Spain, is an initiative by the Open Administration Consortium of Catalonia (AOC) to develop an Al-driven platform for automating the generation of energy poverty reports. This platform targets the manual and bureaucratically expensive process of determining social vulnerability and producing energy poverty reports for municipalities. The innovation lies in automating the energy poverty report generation process, which traditionally involved manual, time-consuming and error-prone methods. The initiative addresses the problem of social vulnerability determination by using robotic process automation (RPA), business process modelling (BPM), and Al technologies to streamline the process. Previously, municipalities handled this task independently, leading to inconsistent results and uneven resource allocation. The automation of energy poverty reports leads to several benefits, including centralised Al-powered support, seamless integration with diverse information systems, and enhanced interoperability among companies, municipalities and other administrations. Overall, the platform enables more efficient and accurate social vulnerability determinations, streamlined administrative processes, and equitable resource allocation for energy poverty mitigation.

## Automating property records in Greece

The Hellenic Cadastre, previously hindered by manual paper processing that delayed property transactions for months or even years, has introduced an Al-driven system to automate the reading, categorization, and legal assessment of property contracts. This innovation has cut assessment times from several hours to under 10 minutes and reduced costs from EUR 15 to just EUR 0.11 per case. It has also enhanced legal security for property owners and boosted economic activity by accelerating transaction completion.

Source: https://oecd-opsi.org/innovations/brise-vienna-building-regulations-information-for-submission-envolvement, https://uia-initiative.eu/en/news/piloting-brisevienna-results-journal-ndeg-3, https://www.aoc.cat/blog/2023/pilot-pobresa-energetica., https://www.ekathimerini.com/economy/1245436/smart-solutions-for-land-register, https://www.microsoft.com/en/customers/story/20308-hellenic-cadastre-azure-open-ai-service, Government of Greece officials.

Automation is relatively easy with Al when dealing with repetitive and low discretionary tasks if the data quality is assured. Automation becomes more difficult when higher discretionary tasks are involved but used to uncover new options, detect anomalies and risks and better plan services. However, potential challenges for ensuring systems are trustworthy need to be considered, as seen in Box 5.43.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

240 |

# Box 5.43. Automation for smoother delivery of services in Sweden

The Public Employment Service in Sweden rolled out Prepare and Match across the country in 2021 to improve consistency and accuracy of labour-market related assessments, and thereby improve the efficiency of resource allocation. Enrolled jobseekers get support in the form of training or guidance from a chosen provider. Decisions about whether jobseekers should be approved to participate in Prepare and Match are assisted by a decision-support tool called BÄR.

BÄR is a ML system trained on historical data consisting of 1.1 million profiles collected over a period of 10 years. It gives different recommendations for action based on the jobseeker's probability of finding a job within six months. Factors considered by the system include age, sex, education, residential location (and associated demographic information), and previous (un)employment activities.

Decisions concerning Prepare and Match are formally made by caseworkers, who are instructed in guidelines to primarily adhere to the automated recommendation. Overriding a negative recommendation from the system is difficult and requires contacting a special working group within the agency. The role given to the Al in the decision-making process highlights the potential impact of Al for jobseekers while underscoring challenges with partially or fully removing them from decisions that affect them. Jobseeker's own judgment concerning their need for support is not considered by the decision-support system

Source: (Berman, de Fine Licht and Carlsson, 2024[200]; OECD, 2024[201]).

# Offering new sources of information for advanced insights

Al can help to maximise the quality and utility of data, as well as humans' and machines' ability to process and analyse it (Jarrahi et al., 2023[202]). This can contribute to Al being used for more advanced and real-time impact analysis of public services. Able to recognise patterns that may be undetectable by humans, Al applications can quickly identify problems that may have gone unnoticed (Gesk and Leyer, 2022[203]). They can also process data from a variety of structured and unstructured sources (e.g. images, text, meta-data), making information management much easier (Cockx, Lechner and Bollens, 2023[204]). In Finland, the city of Tampere collects data from traffic cameras to feed a predictive algorithm to predict visitor flows in the city centre, helping businesses and public servants make informed decisions, representing an entirely new public service (Box 5.44).

# Box 5.44. Al-powered visitor flow forecasting with Tampere Pulse in Finland

Tampere Pulse is an Al-driven predictive analytics service that forecasts visitor flows in the city centre of Tampere, Finland. Developed in response to challenges faced by local businesses in predicting customer traffic, the service uses data from the city's Internet of Things (IoT) platform, including machine vision-equipped traffic cameras, weather conditions and event schedules. The result is a month-long visitor flow forecast, accessible on both mobile and desktop devices through an intuitive map-based interface.

The service has demonstrated significant impact, with a prediction accuracy of 79.33% for the exact visitor flow category and 97.55% for the correct or adjacent category up to three weeks in advance. This precision allows businesses to optimise workforce planning, inventory management and operating

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 241

hours, leading to cost savings and improved customer service. User feedback has been highly positive, with an ease-of-use rating of 4.47 out of 5 and a recommendation likelihood of 7.16 out of 10.

Beyond business benefits, Tampere Pulse helps city residents and visitors plan their movements and assists maintenance and security teams in resource allocation. Future enhancements aim to expand coverage, integrate purchasing behaviour insights and link with enterprise resource planning (ERP) systems. The initiative showcases the potential of Al and IoT in fostering a data-driven, smart urban environment while serving as a model for replication in other cities worldwide.

Source: https://oecd-opsi.org/innovations/tampere-pulse.

These new advanced insights often result from a combination of information from variety of sources and technologies. In Portugal, the Land Cover Monitoring System uses Al to integrate stakeholder needs with satellite technology to create an open cartography, promoting efficient, accessible and transparent insights into land cover (Box 5.45). The Saudi Data and Artificial Intelligence Authority (SDAIA) developed Smart C to support data-driven urban planning and real-time decision-making, enabling tools such as traffic simulation, environmental monitoring, and Al-based visual pollution detection (SDAIA, 2024[205]).

# Box 5.45. Portugal's Land Cover Monitoring System (SMOS)

The Portuguese Land Cover Monitoring System (SMOS) is a public service that provides open-access, Al-powered land use and land cover maps to support evidence-based decision-making. Developed by the Directorate-General for Territory (DGT), SMOS ensures that policymakers, researchers and the public have reliable data on land changes, enhancing transparency and sustainable land management.

SMOS analyses Sentinel-2 satellite images, high-resolution orthophotos and official geographic data using Al to produce accurate cartographic products, such as Land Use and Land Cover Maps (COS), dynamic Conjunctural Land Cover Maps (COSC), and specialised monitoring products such as the Annual Map of Temporary Agricultural Crops (MACAT). These products are based on automated classification of satellite imagery into thematic land cover categories, using Al to distinguish features such as urban areas, forests, water bodies and agricultural fields.

SMOS has progressed through three phases: initial research and development; engagement with users to align products with public needs; and now full operational deployment. Since 2022, SMOS has delivered annual Land Use and Land Cover Maps (COS), dynamic Conjunctural Land Cover Maps (COSC), and specialised monitoring products, all accessible via Portugal's National Spatial Data Infrastructure (SNIG).

Source: https://smos.dgterritorio.gov.pt.

# Providing constantly accessible information and services

Virtual assistants and chatbots are among the most common uses of Al in public services (Ramires Hernández, Valle-Cruz and Mendoza Méndez, 2022[206]; Chen, Gascó-Hernandez and Esteve, 2023[207]). These tools give public service users access to information quickly, 24 hours a day. Currently, chatbots range from basic (information retrieval-based algorithms) to more advanced chatbots that use generative Al systems, such as LLMs, and tap into real-time service-related data. The latter can respond to queries with personalised messages, diverging from scripted conversations to tailor information and recommendations to users' specific needs, including plain language or sign language based on text or

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

242

speech input. In addition to being convenient for users, chatbots can make public services more accessible, increase the uptake of services and boost engagement.

Efforts in Portugal serve as an example of how governments can integrate the latest foundation models into public services (Box 5.46). In the United States, the Department of Homeland Security's Emma chatbot provides users with information on immigration services, green cards and passports (Chen, Gascó-Hernandez and Esteve, 2023[207]). In Singapore, the chatbot Gov.sg allows users to file and track the status of complaints about public services. In Brazil, the municipality of Recife allows for over 700 public services in the "Conecta Recife" platform to be automatically distributed and delivered to its citizens, with a chatbot leveraging Al systems to immediately provide information to users. In Chile, a chatbot was piloted on ChileAtiende to respond to citizen queries about public services, demonstrating the potential to provide personalised assistance and reduce response times across millions of requests.³⁷

Beyond direct interactions with citizens, Al-powered chatbots are also being used within public administrations to support staff in delivering services more efficiently. For example, Caddy, developed by the United Kingdom's i.Al, acts as a copilot for customer service agents, helping them quickly retrieve reliable information from government resources while ensuring accuracy through a human-in-the-loop validation system.³⁸ Similarly, Singapore's AlBots platform allows government teams to customize Al assistants for internal processes, streamlining workflows and improving decision-making.³⁹ In France, a chatbot was developed to support public servants to ensure better delivery of services across different fields (Box 5.46). The government of the United Arab Emirates has sought to innovate the virtual assistant concept by representing both virtual and human assistants in the form of a hologram (Box 5.47). In focusing on a specific area, the Israel Planning Authority — the national body responsible for overseeing spatial planning, infrastructure and housing developments — in May 2025 commenced proof of concept for a chatbot designed to help planning professionals in reviewing plans against national requirements, streamlining lengthy review processes, which often take years, ensuring compliance with legal and professional standards.

# Box 5.46. Chatbots that streamline access to information

## Portugal's chatbot provides information to citizens

In May 2023, Portugal's Administrative Modernisation Agency (AMA) launched a chatbot with a realistic avatar to assist citizens with questions about the Mobile Digital Key (MDK). Developed in partnership with Microsoft, DareData Engineering and Defined.ai, the chatbot is based on Azure OpenAl's GPT-3.5 turbo model and can recognise and reproduce both text and voice in Portuguese. From May to December 2023, it facilitated 23 780 conversations (averaging 101 per day) and contributed to a 10% increase in MDK activations.

In January 2025, AMA expanded the chatbot into a full-fledged virtual assistant on the gov.pt portal, reinforcing Portugal's commitment to digital inclusion and public service transformation. Now powered by ChatGPT with a specialised knowledge base, it provides information on over 2 300 public services and offers support in 12 languages, eliminating language barriers for citizens of diverse nationalities. Integrated into over 5 000 pages of gov.pt, the virtual assistant is set to introduce new transactional features in 2025, including process tracking and appointment scheduling, further enhancing its role as a key public service tool.

## France's Albert supports public services employees

In April 2024, the French government introduced Albert, a sovereign generative Al developed by the DataLab of the Direction Interministérielle du Numérique (DINUM) to assist public administration agents in responding to citizens' requests more efficiently. Trained on open-source models and enriched with

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 243

practical guides from service-public.fr, Albert helps government employees search regulations, draft summaries, and provide accurate information to citizens. Albert is based on open-source models from Meta (Llama) and Mistral. As a digital common, the Albert application programming interface (API) provides open, reusable generative Al models, lowering the adoption threshold for public agencies and contributing to a national digital public infrastructure for Al.

In early 2024, Albert had been tested by 60 agents across 30 France Services centres, offering suggested responses, verified sources and useful references — while keeping human agents in control of final interactions. Officially launched nationwide in April 2024, Albert is set to expand across public administration, aiding tax services, environmental project reviews, judicial transcriptions and more.

## France's Sofia improves public access to information

In 2025, the French Ministry of Ecological transition released Sofia, a conversational agent that facilitates access to the organisation's scientific and technical knowledge. Sofia enables users to query a specialised, pooled documentary database, making information searches quicker and more efficient. The system is based on a LLM developed by Mistral and can provide relevant answers based on users' needs. Sofia has been developed with attention towards the ecological impacts. For this reason, it was decided to show users the carbon footprint of each search.

## Greece's Al assistants help users navigate and find information

Greece's mAigov is an Al-powered assistant on the gov.gr portal that helps users navigate over 1 300 digital services and over 3 200 administrative procedures by answering questions in natural Greek via text or voice. mAigov can understand and respond to queries submitted in natural language, providing an intuitive way for users to locate the services they need. The chatbot incorporates reasoning capabilities and maintains the context of conversations to provide optimal user experience. Accessible via both mobile phones and computers, mAigov was initially launched in a pilot mode in December 2023 and can handle up to 240 concurrent conversations in Greek. Its functionality has since been expanded to support 25 languages, catering to a broader range of users, including Greek citizens abroad. With over 1.6 million queries answered, mAigov has proven to be a valuable tool in enhancing citizen interaction with the state. Future developments for mAigov include the ability to issue certificates and schedule appointments on behalf of citizens, further streamlining public service delivery. In addition, the Hellenic Ministry of Tourism, in collaboration with the Ministry of Digital Governance, has developed mAiGreece, a digital Al assistant to enhance travel experience in Greece. The app provides administrative and health & safety information, and recommendations for exploring Greece.

Source: https://oecd-opsi.org/innovations/virtual-assistant-for-public-services; https://digital.gov.pt/noticias/assistente-virtual-do-gov-pt-facilita-a-interacao-em-12-idiomas, https://www.info.gouv.fr/actualite/ia-connaissez-vous-albert, https://www.lefigaro.fr/secteur/high-tech/albert-l-ia-generative-de-l-etat-desormais-deploye-a-grande-echelle-20250212, https://digital-skills-jobs.europa.eu/en/latest/news/maigov-new-ia-digital-assistant-govgr-service-citizens, Government of Greece officials.

# Box 5.47. United Arab Emirates Smart Mission for consular services

Implemented in line with the UAE Strategy for Government Services and the National Al Strategy 2031, the Smart Mission is designed to streamline and digitalise consular services, significantly reducing processing times, improving service delivery and enhancing user experience. At the core of this transformation is the Al-powered Document Attestation Service, which uses an Al-driven attestation verification system to authenticate official documents by recognising official stamps of personal and

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

244 |
commercial documents. This ensures higher accuracy in attestation processes and enhances security
measures to protect against fraud and misuse.
Complementing this is the Al-Driven Holographic Assistance, an interactive Al virtual assistant that can
engage with users directly through a hologram. These Al agents support users throughout the user
journey, answering queries instantly in multiple languages and assisting with services. If further
assistance is required, the Al assistant can transfer the conversation to a human consular officer in
holographic form. Predictive Al systems analyse user behaviour, historical data and interaction patterns
to provide proactive consular support. This allows the system to anticipate frequent requests, suggest
relevant services and notify users of required actions ahead of time.
Finally, an Al-Powered Facial Recognition is also provided as an optional service for seamless access
and proactive services, where users can authenticate their identity using facial recognition. This
eliminates the need for physical documents and allows for tailored assistance without manual input,
such as for the issuance of Return Documents for UAE nationals with lost or damaged passports,
without any documentation needed.
Source: Government of UAE officials, https://u.ae/en/about-the-uae/digital-uae/digital-transformation/platforms-and-apps/smart-mission.

Recent research also explored the role of chatbots in behavioural interventions (e.g. during public health
and risk communications during the COVID-19 crisis), such as increasing the willingness to socially
distance. For example, a randomised controlled study found that an Al chatbot, designed with behavioural
science, improved understanding of COVID-19 guidelines and increased intentions to seek testing services
by reducing uncertainty around protective behaviours. By using animations and engaging messaging, the
chatbot effectively addressed users' informational and emotional needs, demonstrating how Al can shape
decision-making and promote public health behaviours (van Baal, 2024[208]).
Chatbots are often designed primarily to streamline operations, rather than to optimise user experience for
citizens. However, research shows that users engage more positively with Al-driven services when
chatbots maintain continuity in identity and retain user information across interactions. Migratable Al
systems, which preserve both an agent's identity and user history across different interactions, have been
found to increase trust, competence and social presence (Tejwani et al., 2020[209]). This suggests that
designing chatbots with a stronger emphasis on familiarity and user continuity - not just efficiency - can
significantly improve engagement. Applying behavioural insights can further enhance their effectiveness
by ensuring chatbots detect when users need human support, rather than frustrating them with prolonged
automated interactions. By recognising signals of confusion or urgency, Al chatbots can seamlessly
escalate complex issues to human agents, reducing friction and improving service accessibility. Prioritising
continuity and user-centric design in chatbots not only improves efficiency but also fosters trust,
accessibility and engagement in public services.
# Improving personalisation and tailoring of services
Al use for public service delivery also enables a shift from top-down implementation of public services to
approaching design and delivery based on user needs. By enabling the customisation of services, Al
enhances the relevance and responsiveness of interactions with each citizen, making services more
accessible and significantly boosting public engagement (OECD/UNESCO, 2024[131]). For instance,
France is using Al to enhance public service delivery, ensuring a smoother relationship between users,
their individual needs and public servants (Box 5.48).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 245
## Box 5.48. France's Al-assistance for personalised public service delivery
In France, the Direction Interministérielle de la Transformation Publique (Interministerial Directorate of
Public Transformation DITP) has launched an innovative Al-powered platform called Services
Publics+ to improve the quality and efficiency of public services nationwide. The platform, which
involves 45 million citizens and 2.5 million public servants, incorporates three main Al components:
speech-to-text functionality for improved accessibility; automated assistance for civil servants in drafting
responses; and real-time analysis of user feedback to identify trends and pain points.
The system's implementation maintains a careful balance between automation and human oversight.
Public servants retain full control over the Al-generated responses, with the ability to modify or reject
suggestions before sending them to citizens. In line with EU Al Act principles, citizens are notified when
responses have been assisted by Al, and all Al-generated answers are published as open data to
ensure transparency. The system has been deployed across 12 ministries and 40 public services, with
more than 4 000 civil servants using it regularly.
The impact of this innovation has been significant, with average response times dropping from 19 days
to three days. The system has achieved high satisfaction rates, with 78% of public servants finding the
Al suggestions useful, and 70% of Al-suggested elements being validated by public servants. Most
importantly, citizen satisfaction with responses has increased, with 68% of users finding Al-assisted
answers useful, compared to 57% for traditional responses. This demonstrates how Al can be
effectively integrated into public services while maintaining human expertise and improving both
efficiency and user satisfaction.
Source: https://www.plus.transformation.gouv.fr, presentation by France officials at Al Action Summit (February 2025).

Beyond their use in chatbots, generative Al systems (such as text, image, video, code or audio generators)
can further personalise services for citizens. Capable of building user profiles and micro-sorting citizens
into specific types of user groups, Al can tailor information and the services themselves to the complex
needs of users and groups of users, including those in vulnerable and disadvantaged conditions. This can,
for instance, be used to ensure eligible individuals are aware of social programmes and benefits available,
event potentially pre-emptively providing them (OECD, 2024[210]) (Box 5.49). It can also tailor services
around life-events by anticipating context-dependent service needs in a range of fields, including
education, transportation and employment (Kopponen et al., 2024[211]). It can also assist in public
employment services, such as by matching employers and job seekers (Box 5.50).

## Box 5.49. How social protection systems are embracing Al
Advances in data and technology are helping to improve the accessibility, coverage and delivery of
social benefits and services, though non-take-up remains a significant issue. Recent advances centre
around linking administrative data from different sources to improve enrolment in social programmes.
By linking datasets, governments can streamline application and renewal processes, inform potential
beneficiaries of their eligibility for benefits, and (in limited cases) automatically enrol eligible users.
Despite its potential, advanced uses of Al have been little used by social affairs ministries, including for
programme take-up. The most common uses of Al in social programmes in OECD countries have been
automated client support (e.g. chatbots and digital assistants), automation of internal processes (e.g.
data entry and document processing) and fraud detection and finding anomalies in benefit claims.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

246 |
Despite this limited usage, Al offers significant promise in social protection, including through the
identification and enrolment of service users, enhancement of user support, and improving the efficiency
and timeliness of benefit and service delivery in response to changing needs. Emerging uses include:
- advancing current uses of chatbots, automation of routine tasks and fraud detection
- improving client service by accompanying human service providers in sensitive situations
- better automating benefit decisions based on statutory eligibility rules
- new types of predictive analytics, such as identifying recurring risks and vulnerabilities to target social programme interventions to at-risk individuals and groups.

Perhaps the most rewarding potential use case for Al in social protection is identifying high-risk
beneficiaries and proactively reaching out to them — or automatically enrolling them — to improve
social protection coverage. This is starting to be employed in the areas of homelessness prevention
and alleviation and of risk assessments for survivors of domestic violence. In the latter, survivors are
connected with case workers and other relevant service providers with the goal of preventing a
recurrence of violence.
These opportunities come with risks, and governments (e.g. Germany) are putting in place a range of
measures to ensure they are mitigated, including the appropriate legal, regulatory and accountability
frameworks to protect people's privacy and govern the use of automated systems.
Source: (OECD, 2024[210]; 2025[212]), responses to the questionnaire Harnessing Technology and Data to Improve Social Protection
Coverage and Social Service Delivery, administered by the OECD Social Policy Division; (OECD/UNESCO, 2024[131]); (Policy Lab Digital,
Work & Society within the German Federal Ministry of Labour and Social Affairs, 2024[213]).

## Box 5.50. PES in OECD countries are increasingly turning to Al for service provision
Half of Public Employment Services (PES) in OECD countries have deployed Al-powered solutions,
including generative Al solutions using LLMs, to aid their activities and services to jobseekers, people
at risk of job loss and employers. As present, they are most used to:
- profile jobseekers and predict a jobseeker's likelihood of remaining in unemployment
- match jobseekers with suitable vacancies
- aid the design of vacancy postings, including occupational classification
- provide information to clients via chatbots or virtual assistants
- aid the career management and job-search orientation of jobseekers.

For example, since 2024, the Israeli Employment Service has integrated Al engines into its core
systems to streamline job matching processes for job seekers. Al solutions offer numerous opportunities
for PES, such as improving the targeting of measures and services, optimising data usage, reducing
administrative burdens, and enabling more dynamic digital systems. However, PES need to also
consider several challenges and risks, including the need to define clear accountability for Al systems,
address concerns about transparency and explainability, ensure data quality and privacy and manage
potential resistance or skills gaps among both staff and clients. For example, the Austrian PES
implemented a ChatGPT-enabled chatbot in early 2024 to provide information on training and career
orientation to jobseekers. However, this innovation came under criticism soon after launch, notably due
to reports that the chatbot's recommendations perpetuated differences between men and women.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 247
To address these challenges, a few OECD countries are pioneering innovative steps to promote better
governance of Al within their PES. This includes the establishment of multi-disciplinary ethics
committees by PES in France and Belgium, and the development of a dedicated strategy by Norway's
PES to set out the ambitions, enablers and principles for Al use.
Source: (Brioscú et al., 2024[214]), https://www.maariv.co.il/business/carrier/article-1122739.

Health services represent a particularly promising field, with Al experts considering it to be one of the areas
of the greatest potential for Al (OECD, 2024[29]). Al systems can suggest diagnoses and predict risk factors
to help introduce preventative measures (Khalifa and Albadawy, 2024[215]; Alowais et al., 2023[216]). This
was particularly helpful during the COVID-19 pandemic. For example, Greece developed and used an ML
to optimise border testing by targeting asymptomatic travellers based on demographic data and previous
test results (Bastani et al., 2021 [217]). In some contexts, Al can also be used to predict the likelihood of
illness or injury. For example, in Portugal, the application PrevOcupAl is applied to predict work-related
illnesses and connected risk factors in public administration (EC JRC, 2021[218]). In Saudi Arabia, Al is
being deployed to predict and reduce patient no-shows at outpatient clinics, significantly improving
resource utilisation.40 In Korea, the city of Incheon is using Al technology to improve healthcare
accessibility for foreign residents and visitors (Box 5.51).
Combined with the knowledge of doctors and other medical experts, Al can lead to better accuracy, higher
efficiency and more positive outcomes for people. The benefits can go beyond citizen well-being; in the
United Kingdom, savings to the public budget through expansion of Al-enabled preventive health care are
estimated to be worth GBP 6 billion per year by 2040 (TBI, 2024[219]).

## Box 5.51. Korea's Al-powered multilingual healthcare communication
In Korea, the city of Incheon has implemented SIMTOMI, an Al-based medical support service that
bridges the language gap between foreign patients and healthcare providers. This service combines a
multilingual Al symptom checker with advanced language translation capabilities, allowing foreigners
and tourists to accurately communicate their health concerns to local medical professionals and
pharmacists. The system generates anonymised symptom summary reports that can be shared via QR
codes during in-person hospital or pharmacy visits. The impact of this innovation has been significant,
with the service achieving a high satisfaction score of 84.4 points and a 95.0% intention to reuse rate,
exceeding initial targets.
Source: https://oecd-opsi.org/innovations/simtomi-ai-powered-multilingual-medical-support.

# Forecasting future public service needs
Al also has wide potential uses in conducting predictive analytics to forecast future service needs as well
as to prepare and adjust the response capacity accordingly. This can complement the profiling of service
users and their needs, helping to better target and propose public services to users. The potential of
predictive analytics is well known in the field of policing and justice (Macnish, Wright and Jiya, 2021[220]),
as discussed in the "Al in law enforcement and disaster risk management" and "Al in justice administration
and access to justice" sections of this chapter. For optimising large-scale systems, Al predictive systems
have demonstrated concrete service quality improvements, such as optimising traffic, decreasing road
accidents and increasing fuel efficiency in public transportation systems (Jevinger et al., 2023[221]). In
Belgium, the Agency for Roads and Traffic used Al is used to predict slippery road conditions and help

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

248 |
allocating resources for keeping roads ice free. In the Netherlands, Al is used to experiment with traffic
predictions and forecasting road accident. In Portugal, the application PrevOcupAl is used to predict work-
related illnesses and connected risk factors in public administration (EC JRC, 2021[218]).
A step further is the emerging trend of proactive service delivery, where Al can help to anticipate people's
needs beyond the current public service context and rapidly respond to them (Pawlowski and Scholta,
2023[222]).41 For example, this may involve citizen digital twin (CDT) systems, which collect data about a
person's overall situation and then helps to structure scaffolding service responses to their life events
(Kopponen et al., 2024[211]). In this way, tailored service combinations can be created proactively to meet
individuals' specific needs depending on their current situation or predicted future life event (e.g. finishing
school and entering the labour market). In Singapore, the "Moments of Life" application uses Al algorithms
to analyse user information and send personalised notifications (e.g. for upcoming vaccinations or school
enrolment deadlines) (Aldemir and Uçma Uysal, 2025[223]).

## Box 5.52. How cities are using Al tools to provide services
Al is starting to play a critical role in public service provision and tackling urban development challenges.
For example:
- Cities are using Al to optimise traffic and mapping transportation gaps and needs. Los Angeles
(United States) uses Al to detect and respond to traffic incidents, such as accidents or road
closures, minimising their impact on traffic flow. Al-driven systems analyse data from traffic
cameras, sensors and social media to provide real-time alerts and suggest optimal routes to
drivers, reducing overall congestion. Sydney (Australia) is using Al to optimise traffic flow and
test driverless buses, setting the stage for wider adoption.
- Cities use Al to provide public services and information. Buenos Aires (Argentina) created a
chatbot called Boti, first as the official government channel for COVID-19 vaccinations, and now
as a channel to provide information on topics such as bike sharing and social care. Yokosuka
(Japan) is developing a dementia prevention service using conversational generative Al to
strengthen elderly citizens' mental health.
- Greece's Ellinikon Project aims to transform the former Athens International Airport into a
cutting-edge smart district. Advanced technologies, including IoT, Al analytics, 5G connectivity
and ultra-high-speed fibre optics, will be seamlessly woven into the fabric of the city. Smart
sensors and sophisticated Al algorithms will be deployed to manage infrastructure efficiently,
enhancing resource allocation and service delivery. Smart mobility solutions, such as intelligent
parking assistance and shared transportation options, will further streamline urban movement.
Additionally, Al will play a pivotal role in optimising water and waste management, ensuring
environmental sustainability. A Digital Twin of the city will be created to monitor and optimise
resource consumption and environmental conditions in real-time.

Generative Al in particular has the potential transform the way cities work; it can predict demand and
streamline public services, improve local governments' capacity to innovate, enhance data-driven
decision-making, optimise resource allocation, and streamline administrative processes. This is
possible as some cities collect data continuously from vehicles, buildings, infrastructure and individuals
via sensors, drones and mobile devices to present an up-to-the-second picture. For example:
- Amsterdam (Netherlands), Eslöv (Sweden), Helsinki (Finland), and Munich (Germany) use
digital twins to improve city planning and management and build more resilient cities to future
threats. The digital replica, constantly updated with data from its physical twin, enables cities to
analyse data, monitor systems and run simulations and build scenarios each evaluated against

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

249

*   key criteria such as social accessibility, environmental sustainability and financial return, facilitating decision-making on housing, land use, density, green infrastructure and transport.
*   Shanghai (China) uses GenAl-powered digital twins and loT to manage its complex city infrastructure by combining real-time data from IoT devices with sophisticated analytics. This helps the city to ease traffic, boost the effectiveness of public transport, optimise energy use, enhance disaster preparedness and plan infrastructure.

Despite its potential, cities are at an early stage of GenAl use. A 2023 Bloomberg Philanthropies survey of 100 cities around the world found that only 2% were actively implementing GenAl in their activities, while 69% were exploring or testing the technology but not yet developing capabilities and policies. Barriers include lack of awareness, budget constraints, a lack of relevant guidelines and data governance, skills gaps, data privacy and security concerns, and administrative and technical challenges in integrating Al technologies such as geospatial Al (GeoAl) in planning and service design processes.

Going forward, to harness the potential and uptake of Al, cities should:

*   close digital divides, in coordination with the national government, to ensure access to internet services for the entire population
*   consider and proactively address the future challenges, risks and potential drawbacks of Al (e.g. data privacy issues and data quality and availability that limit decision-making)
*   develop, with the support of national governments, the regulatory systems to ensure that Al systems used are safe, transparent, traceable, and non-discriminatory to preserve the privacy, ethical values, and individual's rights
*   explore regulatory sandboxes to foster public-private partnerships in a controlled and innovative environment and test ideas safely
*   invest in Al literacy for local public employees, develop specialised Al expertise within their legal departments.
*   build partnerships with academic institutions and tech companies for knowledge sharing.

Source: (OECD, 2024[224]; 2023[225]; Bloomberg Philanthropies, 2023[226]), https://theellinikon.com.gr/en/smart-and-sustainable/smart-city.

# Evidence of impact

In a recent study on the potential automation of UK public services, the Alan Turing Institute found that Al could help automate 84% of service-related transaction and save an equivalent of approximately 1 200 person-years of work every year (Straub et al., 2024[199]). In addition, reduction in red tape and improvements in regulation around public services' design and delivery could greatly benefit users in terms of saving time, effort and resources, or in accelerating response time from government.

While the promise is great, there is so far little empirical evidence that Al has or will deliver on these benefits. Current knowledge about Al's adoption in public service is based on case studies that synthesise early evidence from implemented practices.42 Use cases now are multiplying rapidly, and the following sections will give an overview of the emerging innovation trends.

Most of the evidence of impact of the newest Al innovations in public services is based on individual projects and cases and is most often self-reported. Case review in literature indicates a general positive indication of the benefits of Al. However, it is not very common for Al projects to disclose their potential negative impacts in advance (Birhane et al., 2022[227]). This is expected, as the applications are still relatively new, issues are still emerging, and evaluations are often not carried out.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

250 |

As Al continues to reshape public services, rigorous testing of behavioural interventions is essential to ensure these technologies are not only efficient but also effective in influencing citizen engagement and decision-making (Soman, 2024[228]). Some government teams are already prototyping and rapidly testing Al-driven solutions. However, more structured evaluation methods — such as RCTs, difference-in-differences analysis, and A/B testing — can help determine which Al applications work best, for whom, and in which contexts. Partnering with academics to make these experimental approaches part of Al implementation can provide stronger empirical evidence on Al's real-world impact, ensuring public services are designed and adapted based on behavioural insights rather than assumptions.

# Managing risks and challenges

While Al has tremendous potential to improve the efficiency, effectiveness and responsiveness, there are risks and challenges that can limit adoption and lead to real-world harms. A 2022 study on deriving lessons learned from 61 cancelled public service automation initiatives across various countries finds that many have failed due to lack of effectiveness, civil society protect, critical media investigation and legal action, among other issues (Redden et al., 2022[229]). The top risks and challenges identified are discussed below.

## Associated risks

*   Misuse or questionable use of Al, resulting in surveillance and privacy concerns
*   Inadequate or skewed data in Al systems
*   Lack of transparency and explainability
*   Exacerbating social exclusion and digital divides

Using Al in public service innovations requires increased access to users' personal information, especially when connected to proactive and personalised service delivery. Often this also requires having access to a variety of public organisation databases and service information to identify to best service approach. Proactive service delivery, for example, often requires algorithmic processing of data scattered across multiple publics and sometimes private data sources (Nikiforova et al., 2023[230]). The use of Al raises concerns about privacy and the purposeful and responsible use of data and can make these services more contestable (see Chapter 1, section on “To seize the benefits of Al, its risks need to be managed"). A commonly held assumption is that intelligent and data-trained tailored Al tools face inescapable trade-offs between (predictive) capability and privacy. However, there has been much recent research interest in getting around this general hypothesis thanks to privacy preserving technologies (PPTs) or privacy enhancing technologies (PETs), which use anonymised or encrypted data (OECD, 2023[231]).43

If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for some individuals or groups. With regard to public service design and delivery, this could result in, for instance, undue preferential treatment for some individuals or groups or reinforcing inaccurate stereotypes. Related in part to inadequate or skewed data, digital data divides — where some groups are more represented in data than others — limit the potential for personalised Al services, leaving them only useful and accurate for data-rich populations and potentially leaving some groups less represented (UNESCO, 2019[232]; Perry and Lee, 2019[233]; Dieterle, Dede and Walker, 2024[234]).

Given the nature of public services, ensuring the accountability, transparency and explainability for decision-making and results from Al systems and tools is crucial. This requires the creation and implementation of public service frameworks that define clear lines of responsibility for Al systems along their entire lifecycle within public services. The more transparency there is in the use of Al in public services, the easier it will be to monitor for adverse effects and create a greater sense of explainability and trust in Al outcomes (Sun and Medaglia, 2019[197]; Thiebes, Lins and Sunyaev, 2020[235]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 251

## Implementation challenges

*   High costs of Al adoption and scaling
*   Lack of actionable frameworks and guidance on Al usage
*   Difficulty in establishing continuous monitoring for track progress and surface risks
*   Lack of high-quality data and the ability to share it
*   Skills gaps

The cost associated with building and maintaining Al systems for public services (from infrastructure, monitoring, staff training and education) cannot be ignored. For instance, the cost of commercial Al subscription options could increase when companies seek to become profitable and cover large overhead and operating expenses to satisfy investor expectations (Shark, 2025[236]).

The trustworthy adoption of Al systems in the design and delivery of public services requires continuous monitoring to track progress and help identify emerging risks, but governments generally lack this function. Fully autonomous Al systems that have an impact on citizens' lives can present legal issues and further contribute to distrust and resistance in adoption. As a result, human determination and oversight is often required or otherwise prioritised in public policy. For instance, the EU AI Act imposes human oversight requirements on “high-risk” use cases, which many government uses are considered. However, relying on human intervention alone may create a false sense of security in adopting algorithms (Green, 2022[237]). Having humans in the loop does not negate the need to carry out cost-benefit and benefit-risk analyses to weigh trade-offs, nor for evaluation throughout the Al lifecycle. Consequently, the adoption of Al in public service provision needs granular and technical evaluation from a public value perspective in a where adverse effects may manifest during Al system implementation (Medaglia, Gil-Garcia and Pardo, 2021[238]; Madan and Ashok, 2023[194]).

Some of the early failures in Al use in public services and instances of errors have been connected to data quality issues. OECD (2019[191]) research has identified to the need to continually verify the accuracy, reliability and appropriateness of data inputs to Al systems, which helps service providers to identify and address errors present in the data.

Lastly, varying levels of Al competences and associated skillsets in government are problematic (Medaglia, Mikalef and Tangi, 2025[239]). While generative Al tools have become widely accessible for bottom-up adaption, there has not been sufficient training in Al in government and clear guidelines for its use in public organisations for developing and informing public services. Furthermore, given the rapid development of Al systems continuous learning is a must to keep current. Necessary skills for adapting Al systems are not only technological but also ethical, legal, managerial and sociotechnical; public administrators need to understand how the Al systems interact with both the organisation and the public at large (Trajkovski, 2024[240]). So, for example, creativity and design thinking skills are necessary to implemented human-centric services tailored to public needs. This also requires high levels of interpersonal skills, as administrators need to effectively collaborate with data scientists, lawyers, ethicists and external partners. A lack of these skillsets may cause delays in Al adoption or worse negative impacts, such as biased or opaque algorithmic systems. Systemic approaches to developing such skillsets across governments are currently largely lacking. Some have proposed a new profession of Al functional professionals who act as intermediaries between the technical and public policy side and help train public officials accordingly (Labanava et al., 2022[241]).

## Untapped potential and way forward

There is significant potential to using Al in additional service areas and in novel use cases. For instance, in healthcare, Al could enable tailored and preventative interventions and informed behavioural “nudges”

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

252

leading to better outcomes and allowing health professionals more time for care. It could also yield new techniques to unlock value from vast health data assets, 97% of which remain untapped in OECD countries (Sumner et al., 2023[242]; Bennett Institute, 2024[243]; OECD, 2024[244]). In this area, the OECD (2017[245]) standard for promoting the use of health data in the public interest guides governments in making this data more available for innovation in health care. Exploration of challenges for the implementation of the principles of this recommendation may be found in (OECD, 2022[246]) and in a forthcoming OECD report: "Facilitating the Secondary Use of Health Data for public Interest Purposes Across Borders". Al advances could also help ease projected healthcare workforce shortages of 3.5 million by 2030 in OECD countries (OECD, 2024[244]).

Al use in public service design and delivery is still in an experimental phase. While there are examples of automation, streamlining and even new types of services emerging, government organisations are still far from broad adoption and operational use. Al hype and demands for cost efficiency may push governments towards a rapid automation. Yet evaluations and critiques of early practices, as discussed in this section, suggest that a more gradual approach taken together with public servants may be more likely to succeed. Governments need strategies on how to use hybrid models where Al augments human decision-making, and on how to deal with the evolving role of public officials in this new format of algorithmic bureaucracy (Vogl et al., 2019[247]). While the promise of Al may be to free up public servants' time to higher-value tasks — such as engaging with citizens to tackle complex social issues — it can also have the opposite effect, distancing public servants from society as their role in direct data collection/interaction with service users diminishes (Bullock, Young and Wang, 2020[248]; Madan and Ashok, 2023[194]) (see also the discussion on "Al in civil service reform” in this chapter).

Another emerging approach to automation in public services is rules as code (RaC), which involves encoding government rules into machine-consumable formats alongside traditional legal text (Mohun and Roberts, 2020[4]). As services increasingly rely on Al to support decision-making, RaC provides a foundation for more accurate, transparent and scalable Al applications in government. By embedding rules in digital formats, RaC could enhance the consistency of Al-powered service delivery, ensuring that automated systems interpret and apply regulations correctly across different contexts. Several governments have begun using RaC to streamline regulatory compliance and enhance Al-driven service delivery. For example, the United Arab Emirates has launched a nationwide Rules as Code platform that aims to develop Al-based laws and regulations, transforming the financial ecosystem.44

Unlike conventional task-based approaches — where service delivery is segmented into distinct sequential operations — Al-enabled approaches can integrate functions and decision-making processes simultaneously. This represents a potentially transformative shift in how public services are organised.

When it comes to the broader acceptance of Al-based public services by citizens and residents, a few clear insights emerge from existing research. It is generally accepted that Al is better at processing large amounts of data and identifying patterns (Rane, Choudhary and Rane, 2024[249]). However, a combination of factors including perceived usefulness of Al systems, performance expectancy, attitudes, trust and effort expectancy tend to influence the willingness to use of Al across sectors (Kelly, Kaye and Oviedo-Trespalacios, 2023[250]). Perception of risk and trust in Al systems differs when dealing with general public services (i.e. provided by the government without specific request, and concern all or the majority of citizens, such as basic education and public safety) versus specific public services (i.e. explicitly requested by citizens and impact only one or a few citizens, such as elderly care programmes or housing assistance for low-income populations). General services are more abstract and the users have lower levels of situational awareness meaning that they may also accept Al more easily.45 In specific services, the opportunity to decide becomes relevant; users general want to have a choice whether an Al application has been used in their service decision (Gesk and Leyer, 2022[203]).

Early research also indicates that trust in Al applications is higher if they are integrated into already existing services rather than services that are completely new (Aoki, 2020[251]). This means that more proactive

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

253

service innovations may have to prove themselves to users and may face more scrutiny. In all cases, participation of users in co-creating public services is correlated to a positive perception of Al decisions and could drive higher adoption (Gesk and Leyer, 2022[203]). This is very important, as people's experiences with services can influence how they perceive their governments overall, and public satisfaction with administrative and social services is an important driver of trust (OECD, 2024[46]). Public organisations can risk their democratic legitimacy if the public does not trust the services government intend to provide with Al (Aoki, Tay and Yarime, 2024[252]; Aoki, 2020[251]).

Governments also need to better understand and consider user needs to design Al-enabled services they are likely to want to use. This will involve ensuring that policies and services are designed for how people actually behave, rather than how they are assumed to behave. Even well-intended policies can fail when they introduce unnecessary friction ("sludge"), making it harder for people to access services, complete applications or make informed decisions. Further use of behavioural science can assist this by offering practical levers to reduce sludge, improve accessibility and ensure services are user-centred and trusted by citizens. By addressing cognitive barriers — such as complexity, decision fatigue and inertia — governments can design services that are simpler, more intuitive and easier to navigate. Al-powered tools can identify services that need sludge audits, assess intervention effectiveness and improve service design. NLP and sentiment analysis can analyse public feedback in real time, indicating pain points across online platforms and customer service channels. Al can also quantify user interactions and tailor interventions to different demographics, ensuring policies are better targeted and more inclusive. As governments move towards digital-by-design and data-driven governance, integrating behavioural insights with Al will be key to making public services more user-friendly, efficient and responsive (OECD, 2024[253]).

Finally, there is a considerable gap between the speed at which Al is being introduced to public services and the extent to which robust evaluations are carried out. The more thorough analyses already point to many unforeseen and sometimes adverse effects that may appear next to general efficiency gains. This area needs further investment.

In all of these areas, international cooperation in building public sector Al capacity, is crucial. The more government share Al practices across governments in public service development (including sharing open algorithms, infrastructure, intergovernmental datasets, and joint efforts for the responsible development of emerging technologies), the more likely that quality across the board can be assured. Multilateral initiatives such as the Global Partnership on Artificial Intelligence (GPAI) can play a crucial role in this regard.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

254 |

# Al in law enforcement and disaster risk management

Al tools are used across various public bodies with a role in governance of critical risks, including disaster management, law enforcement and intersecting areas such as counterterrorism, customs and border management. Relevant agencies use Al technologies to enhance the scale, speed and accuracy of capabilities for anticipatory analysis, real-time surveillance and monitoring and administrative processes while lowering operational costs. This can enhance investigation and crisis management capabilities, optimise resource allocation and improve response times.

Because Al use has high-impact potential in this space, especially with regard to law enforcement, these entities are considered high-risk Al end users (OECD, 2020[254]) and face additional considerations when tapping into Al for public good and safety. Above all other types of public institutions, citizens place the highest levels of trust in police (OECD, 2024[46]). Relevant agencies need to uphold this trust by ensuring Al is adopted in a trustworthy manner that mitigates ethical challenges and risks to the protection of personal rights, including through vigilance regarding how underlying data are sourced, maintained and applied (OECD, 2020[255]; 2019[191]; 2022[256]). Lessons can be derived from existing use cases, and as discussed below, some governments have put in place heightened accountability expectations for Al use by these actors.

## Current state of play

## Identifying criminal suspects and missing persons

Al-powered facial recognition technology enhances capability to match real-time or recorded images from surveillance footage, social media and other sources against a stock of image databases. This may be used to assist in identifying criminal suspects, persons of interest and missing persons. This has also shown to have some deterrent effect on persons who might otherwise attempt to enter areas where access is prohibited to them. For example, in many countries closed circuit television (CCTV) footage is combined with facial recognition technology to enable real-time checking of spectators entering or leaving major sports venues without stopping the activities inside the facility (Hutchins and Andrejevic, 2021[257]). In the United States, the Next Generation Identification system, operated by the Federal Bureau of Investigations (FBI), has implemented Al-powered systems to deliver more accurate biometrics capabilities, including name matching, fingerprint matching, facial recognition, iris recognition and latent print matching. The system generates ranked lists of potential matches, which are then manually reviewed by biometric analysts to ensure accuracy. This process has proven effective in aiding investigations, providing leads in cases where other identifiers are either degraded or missing (US GAO, 2024[258]).

Also with regard to biometrics, the use of facial recognition technologies has raised concerns over infringement of privacy in many jurisdictions (OECD, 2024[259]) The need for a robust legal and policy framework that places limitations on interventions based on such analysis is discussed further below under "Managing risks and challenges".

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 255

In addition to biometric identification, Al algorithms help analysts sift through vast amounts of data to identify patterns and anomalies that may indicate a higher or lower likelihood of a specific person's involvement, or to uncover criminal activity that otherwise would have gone unnoticed. This includes analysing social media posts, financial transactions and signals intelligence for evidence of illicit behaviour that has already occurred.

## Anticipating criminal behaviour and identifying risk factors

By analysing the psychological profiles, behaviour and past actions of individuals, Al systems can anticipate potential future criminal behaviour and offenses (Hung and Yen, 2020[260]). Sources of information to derive these predictions include social networks, online transactions, public records, existing law enforcement documentation and CCTV footage, among others. Such applications have been used for monitoring known offenders or identifying previously unknown individuals who may be planning terrorist attacks or other violent crimes (McKendrick, 2019[261]). They are also deployed for high frequency non-violent offenses, and identifying suspicious behaviour that stands out as a statistical anomaly (Wastupranata, Kong and Wang, 2024[262]).

Al-powered systems have also been used in border management. For example, the US Customs and Border Protection (CBP) has deployed a Passenger Security Assessment Model that to identify potential risks in passenger crossings, focusing on various indicators of concern. This model is designed to support CBP personnel in quickly recognising crossings that may warrant additional scrutiny. (US DHS, 2024[263]) A further example is CBP's use of a ML system to identify potentially suspicious patterns in a border-crossing histories of vehicles, which has led to 240 seizures of thousands of kilograms of illicit drugs (US DHS, 2024[264]).

Al tools can be used to analyse social networks and relationships to identify individuals who may be at higher risk of becoming involved in criminal activity, as a perpetrator or a victim. This can help in targeting interventions and community policing efforts. Al technologies are designed to provide investigative assistance, for example, by alerting police regarding whom to watch before crimes are committed.

There are many relevant examples around the world. This can be seen in small-scale uses. For instance, in Japan, Al shoplifting detection software detects potentially suspicious body language on security camera footage and alerts authorities about potential thieves through a smartphone application (Belova, 2020[265]). They can also take the form of larger-scale operations, such as the UK Durham Constabulary's Harm Assessment Risk Tool (HART). Predictive policing has raised controversy, as discussed below.

## Box 5.53. Germany's risk assessment tool for Islamist terrorism

The Risk Assessment for Islamist Terrorism (RADAR-iTE) is a standardised algorithmic risk assessment tool introduced by the German police throughout the country in 2017. The tool is specifically designed for use in state protection (Staatsschutz) contexts to evaluate the risk of politically motivated serious violent religiously motivated terrorist acts committed by individuals already known to law enforcement.

RADAR-iTE involves a standardised case preparation process in which risk and protective factors of an individual are assessed, assigning them to a two-tiered risk category (moderate or high). This enables prioritisation of individuals and supports the efficient allocation of police resources. The assessment relies on observable behaviours and information already available to or legally obtainable by police officers, rather than on attributes such as ideology or religiosity. The tool uses a risk assessment form with standardised questions and answer categories, but it is not automated; the evaluation of the features always requires the professional assessment of trained specialists.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

256

RADAR-iTE facilitates prioritisation decisions by identifying the presence of risk and protective factors. Individuals assessed as high-risk are then discussed in case conferences managed by the Federal Criminal Police Office (Bundeskriminalamt, or BKA) within the Joint Counter-Terrorism Centre's (GTAZ) Risk Management Working Group (AG RIMA). The tool is designed to enhance the structuring and documentation of biographical histories of known individuals within the militant-Salafist spectrum, improving risk assessment transparency and comparability across Germany. It serves as a tool to assist, but not replace, individual case assessments, complementing standard measures applied to potential threats and relevant individuals in police state protection.

Source: https://www.bka.de/DE/UnsereAufgaben/Deliktsbereiche/PMK/Radar/radar_node.html, https://penal.org/sites/default/files/files/A-02-23.pdf.

## Predicting times and locations at risk of criminal activity

In addition to predicting who may be at risk of committing or being a victim of crime, predictive policing algorithms analyse historical crime data to help predict when and where crime may be more likely to occur. These algorithms take into account various factors, such as time of day, weather conditions and socioeconomic data. Some police departments use these analyses to focus patrols in identified hotspots, helping agencies to determine patrol routes and deploy resources more strategically.

Some anticipatory policing systems use real-time data to adjust predictions and recommendations dynamically both in law enforcement and emergency management contexts. Several countries use CCTV surveillance, live incident reports and sensor data to refine predictions in real time. In Korea, for example, the Internet and Security Agency (KISA) and the National Police Agency (NPA) collaborated to develop technology aimed at helping potential stalking victims recognise and avoid danger. This system detects precursors of stalking crimes, issuing warnings to potential victims and alerting the police. Its goal is to apprehend offenders before any harm is done. This application uses Al technology to analyse information from surveillance cameras in real time (which were previously available only for post-crime apprehension of the offenders), making it possible to identify signs of stalking crimes in advance and inform the victims, thereby preventing any harm. (OECD, 2025[266])

## Enhancing disaster risk identification and anticipation

Al is transforming how countries identify and anticipate risks across sectors. ML algorithms are being applied to vast datasets to detect early warning signals for a wide range of critical risks, from natural hazards to public health threats. Box 5.54 highlights how Al is used in a Canadian province to anticipate wildfire risks and pre-position assets. Greece is also using Al for early fire detection in forests and groves, as well as for flood prevention.46

## Box 5.54. Anticipating wildfire risks in Canada

The Province of Alberta in Canada uses artificial intelligence to its support decisions on allocating resources and pre-positioning assets to combat wildfires. The innovative system predicts the likelihood of wildfires breaking out the following day across protected forests, which cover more than half of the province.

Trained on a decade's worth of fire, weather and ecological data, the Al system incorporates daily weather forecasts and factors such as increased human activity during long weekends. The system has

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 257

a 50% success rate in predicting wildfires and is accurate 80% of the time when it indicates a fire is likely. Crucially, the tool does not replace human decision-making but supports staff.

Developed through collaboration between the public and private sectors, the Al system continues to improve each year as new wildfire data is integrated.

Source: https://www.oafc.on.ca/about/announcements/fire-news-headlines/how-alberta-uses-artificial-intelligence-wildland.

In Guatemala, Al analytical techniques applied to earth observation and street-level imagery have been used to identify structures susceptible to collapse in the event of an earthquake. The approach was able to identify approximately 85% of the buildings identified as vulnerable based on traditional civil engineering assessments using Al to identify damaged areas (GFDRR, 2018[267]; Tilon et al., 2020[268]).

Earth observation, connected devices and Al tools are also being used to improve the forecasting of wildfire risk (Nelson, He and Moore, 2024[269]). Earth observation imagery provides regular information on vegetation growth to ascertain fuel loads that drive wildfire potential. In Australia, a satellite with infrared technologies that is specifically calibrated to monitor the dominant local vegetation (eucalyptus and shrub) is under development to provide improved wildfire forecasting accuracy (Amos, 2020[270]).

Brazil created the Geospatial Transmission Management System (GGT System), which uses Al and satellite image processing to inspect transmission lines and therefore avoid wildfires (Box 5.55).

## Box 5.55. Al and satellite images processing to protect against wildfires in Brazil

Wildfires are one of the main causes of blackouts in Brazil. To monitor the thousands of Brazilian Transmission Lines (TLs), Brazilian Electricity Regulatory Agency (ANEEL) created the Geospatial Transmission Management System (GGT System), which consists of a tool that uses Al and satellite images processing, to preventively inspect the maintenance of TLs against wildfires. The GGT System uses Al to process satellite images and identify all spans of transmission lines affected by fires. It automatically detects variations in the amounts of vegetation and can detect vegetation suppression activities carried out in the field by the transmission companies without the need for displacement by ANEEL's inspection teams.

The system also automatically generates monitoring reports containing diagnostics on the adjustments of maintenance performed by the transmission companies in the safety lanes of transmission lines. This allows ANEEL's inspection teams to act preventively and with enough assertiveness to mitigate the risks of blackouts caused by wildfires throughout Brazil. The transmission companies use the information generated by GGT and the alerts issued by ANEEL to improve their transmission line maintenance processes and reduce the risks of blackouts caused by wildfires. From its launch in 2017 to 2022, there was an 89% decrease in shutdowns caused by wildfires on the monitored transmission lines, although the number of annual wildfires has increased throughout the country.

Source: https://oecd-opsi.org/innovations/ai-and-geospatial-data-to-protect-against-wildfires.

In the United States, for example, a major energy services provider for the states of North and South Carolina used Al techniques ahead of Hurricane Florence in 2018 to determine where to pre-position the technicians needed to quickly restore power if transmission lines were damaged (Seto, 2018[271]).

Al can process vast amounts of data from diverse sources, such as medical records, social media and environmental monitoring devices, to detect patterns and anomalies that may indicate the onset of a disease, enabling authorities to take proactive measures. (El Morr et al., 2024[272]) Al is also being deployed

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

258

in applications that address human-induced risks, not only those arising from natural hazards. Box 5.56 illustrates how Al can be used to advance risk anticipation and law enforcement.

## Box 5.56. Korea's Al-powered CCTV to protect against crime and emergencies

In Korea, as urban areas face increasing surveillance demands, cities are deploying Al-based selective monitoring systems to enhance safety, emergency response and crime prevention. These systems use existing CCTV infrastructure and advanced deep learning algorithms to automatically detect and classify objects, people and events, including accidents, fires and unusual pedestrian behaviour (e.g. loitering, fighting unauthorised access).

By prioritising relevant footage, Al-powered CCTV monitoring reduces reliance on manual surveillance, enabling real-time incident detection and rapid response. Key capabilities include multi-keyword trajectory analysis for object tracking, high-speed video search and intelligent event recognition to support law enforcement and disaster management. To ensure privacy, the system anonymises sensitive information, such as faces and license plates, and restricts video export through encryption.

Source: https://smartcity.go.kr/wp-content/uploads/2024/09/EN02.Al-Based-Selective-Monitoring-System.pdf.

## Improving risk assessment and predictive modelling

Advanced Al systems are enabling more precise risk assessments by integrating varied and complex datasets. Predictive modelling powered by Al can simulate various risk scenarios, allowing decision-makers to assess potential impacts and plan mitigation strategies. These systems use data from multiple sources, such as climate records, socioeconomic indicators and infrastructure networks, to generate more comprehensive risk profiles. Al's ability to process large volumes of data enhances the accuracy of risk models, particularly in highly dynamic environments such as disasters. By identifying correlations and causal relationships between different variables, Al systems can provide more nuanced insights into the likelihood and severity of future risks. This improved understanding supports evidence-based decision-making and resource allocation. Al can also help modellers to run faster, less resource intensive and more accurate models. For example, the European Centre for Medium-Range Weather Forecasts (ECMWF) uses the Artificial Intelligence Forecasting System (AIFS) to enhance numerical weather prediction. The AIFS delivers up to 20% greater accuracy than leading physics-based models in several areas, including the tracking of tropical cyclones (ECMWF, 2025[273]). Al systems can be continuously refined as new data becomes available, ensuring that risk assessments remain up to date. This adaptability is particularly valuable in addressing emerging risks, such as those associated with cyberattacks.

## Box 5.57. Singapore's data-driven virtual twin

Singapore developed Virtual Singapore, the world's first digital twin of a country, to support data-driven urban planning and enhance disaster management. Led by the Singapore Land Authority (SLA), this initiative uses advanced 3D modelling and real-time data integration to create a highly detailed digital replica of the city-state. Laser-scanning technology, deployed through aircraft and vehicles, captures precise terrain and surface information, mapping above-ground structures, underground utilities, environmental conditions and population movements. As a key part of Singapore's Smart Nation strategy, Virtual Singapore provides policymakers and researchers with an interactive platform to test scenarios, anticipate risks, optimise services and enhance resilience to future emergencies.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 259
The platform enables users to simulate the impact of new projects, assess transportation flows and model environmental factors (such as urban heat islands) and risks (such as floods). By facilitating cross-sector collaboration, Virtual Singapore supports better resource allocation, enhances decision-making, and fosters innovation in both the public and private sectors. Government agencies can use the platform to improve infrastructure resilience, while businesses and researchers use its data to develop smart city solutions. Additionally, the model plays a crucial role in emergency and disaster management, helping authorities plan responses to extreme weather events and optimise crisis coordination. With ongoing updates incorporating new Al approaches, IoT and new data sources, Virtual Singapore continues to evolve as a dynamic tool for shaping the future of urban living.
Source: https://oecd-opsi.org/innovations/virtual-twin-singapore.

# Enhancing risk communication
Al tools are enhancing how risk information is communicated and understood by decision-makers and the public. By translating complex data into visual formats and accessible language, Al makes risk assessments more comprehensible. Interactive dashboards, chatbots and virtual assistants provide tailored information to different audiences, fostering better risk awareness and preparedness. (UNU Institute for Environment and Human Security, 2024[274])
Al can also personalise risk communication, delivering targeted messages to individuals based on their location, vulnerability and preferences. This approach helps ensure that information reaches those who need it most, especially during emergencies (Zhao et al., 2025[275]). Moreover, Al-powered sentiment analysis tools can gauge public perceptions of risks, enabling authorities to adjust their communication strategies accordingly. Real-time risk communication platforms improve crisis management by providing updates on evolving situations and guidance on protective measures. This dynamic information flow enhances public trust and encourages more proactive risk mitigation behaviour (Box 5.58).

Box 5.58. The United States' hazard mitigation planning assistant
In the United States, the Federal Emergency Management Agency (FEMA) is currently exploring the use of a generative Al solution, called the Planning Assistant for Resilient Communities (PARC). This new system creates efficiencies for the hazard mitigation planning process for local governments, including underserved communities. Hazard mitigation plans are a foundational step that communities can take to build their resilience; however, they can be lengthy to produce and challenging for communities that lack resources to do so. PARC will specifically support State, Local, Tribal, and Territorial (SLTT) governments' understanding of how to craft a plan that identifies risks and mitigation strategies as well as generate draft plan elements from publicly available, well researched sources that governments could customise to meet their needs. This could lead to more communities being able to submit grant applications for funding, making them more resilient and reducing disaster risks.
Source: https://www.dhs.gov/ai/use-case-inventory/fema.

# Improving disaster and crisis response
Al is improving situational awareness during disasters by processing satellite imagery, sensor data and social media updates in real time. This information helps emergency services map affected areas, prioritise resource allocation and coordinate response efforts. Al-powered decision support systems can

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
260 |
recommend optimal evacuation routes, identify critical infrastructure at risk and predict the spread of hazards. Al can also monitor changes in a disaster response operating environment. By analysing live data feeds, Al tools can provide updates on road closures, power outages, and transport disruptions. These insights help authorities and communities adapt to changing conditions and maintain continuity of essential services.
Al can help with complex data gathering directly from affected populations. In Indonesia, residents of Jakarta have used social media to share flood updates, prompted by Bencana Bot, a chatbot from the Indonesian Disaster Mapping Foundation (PetaBencana.id). The chatbot invites users to report flood details, which are then mapped in real time and accessible online for free. The Jakarta Disaster Mitigation Agency also updates the map with official data. Immediately following large-scale flooding in the city, the platform has seen 2000% surge in activity within 12 hours, helping residents avoid dangerous areas and make informed safety decisions. (PetaBencana.id, 2021 [276])
Response agencies are also using change detection algorithms. These can be applied to earth observation imagery to quickly identify impacted geographic regions as well as damage to individual buildings and infrastructure.

# Enhancing post-disaster needs assessment and recovery/reconstruction
Al is enhancing post-disaster needs assessment by integrating data from satellite imagery, social media and administrative records to produce more rapid and comprehensive damage and needs assessments. These systems can automatically identify damaged infrastructure, assess the number of displaced individuals and estimate recovery costs. This automation accelerates the assessment process, allowing recovery efforts to begin sooner.
Al-powered decision support systems help authorities prioritise recovery projects by identifying the most urgent needs and optimising resource allocation. These systems can model different recovery scenarios, enabling decision-makers to evaluate trade-offs between rebuilding infrastructure, restoring livelihoods and enhancing resilience.
Al supports transparent and accountable reconstruction by tracking the progress of recovery projects and identifying delays or irregularities. This oversight helps ensure that resources are used efficiently and that vulnerable communities receive timely assistance. Al can also help to optimise the deployment of resources, such as assigning officials to specific areas or tasks based on predicted needs. These technologies may also be used for public safety purposes that fall outside predictive contexts, such as how to improve response times and overall efficient use of limited resources. A notable example from the US Federal Emergency Management Agency (FEMA) can be found in Box 5.59.

Box 5.59. Accelerating post-hurricane recovery with Al in the United States
In the aftermath of Hurricane lan, which struck the state of Florida in 2022, the U.S. Federal Emergency Management Agency (FEMA) deployed an Al tool known as the Geospatial Damage Assessments (GDA) model. Traditionally, post-disaster damage assessments relied on manual inspections, a process that could take weeks and often delayed the delivery of financial aid to victims. The GDA model transformed this approach by automating damage classification.
This innovation used aerial imagery, satellite data and ML to rapidly assess structural damage across affected areas, significantly improving the speed and accuracy of disaster response efforts. It identified and categorised structural damage levels across over 1 million structures impacted. By integrating additional data such as wind speeds, building characteristics and proximity to the hurricane's path the model provided a more comprehensive understanding of damage severity. It reduced the number

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 261
of structures requiring human review from over 1 million to just 77 000, cutting assessment times from weeks to days. Within 72 hours of Hurricane lan's landfall, FEMA had insights into the extent of damage across affected regions, enabling faster resource allocation and recovery planning.
Source: https://gis-fema.hub.arcgis.com/pages/geospatial-da-training.

# Managing risks and challenges
Al tools can enhance government capabilities related to law enforcement, disaster risk and crisis management presents clear benefits; however, their deployment should take into account several risks and challenges. An analysis of 61 cancelled public service automation initiatives across various countries found that half of the cancelled systems were related to policing and law enforcement (in part due to discontinuation of facial recognition), often as a result of critical reviews by government agencies, media or civil society (Redden et al.[229]). The top risks and challenges identified are discussed below, which governments should consider in their development and deployment of Al tools.

## Associated risks
*   Inadequate or skewed data in Al systems
*   Misuse or questionable use of Al, resulting in surveillance and privacy concerns
*   Lack of transparency and explainability
*   Impact in public trust if perceived as unfair or invasive
*   Over-reliance on Al
While the use of Al for certain productivity gains, such as automated completion of routine tasks and paperwork, are generally low risk and non-controversial, the use of Al in predictive policing raises several significant public policy considerations. These should be considered and addressed to ensure such uses provide credible analysis and include safeguards to ensure responsible use of their capabilities.
If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for some individuals or groups. With regard to law enforcement and disaster risk management, this could, for instance, result in unlawful discrimination (to the extent a country has such laws). Policymakers should seek to ensure that these systems are rigorously tested and validated before deployment. They should require rates of true and false positives to be recorded and made available to scrutiny. Research using various methods for systems validation has proliferated in recent years (Stettinger, Weissensteiner and Khastgir, 2024[277]).
Al experts have highlighted invasive surveillance and privacy infringements that undermine the ability of individuals to freely exercise their human rights and freedoms as one of the most pressing Al risks (OECD, 2024[29]). The extensive data collection required for predictive policing risks unintentional violation of rights to personal privacy and data protection. The use of Al for surveillance purposes can lead to intrusive monitoring of individuals, potentially violating privacy rights. Policymakers should seek to promote public safety while also ensuring protection of individuals through privacy and data protection regulations to prevent misuse and overreach.
In bringing together the risks of bias and privacy infringements, remote biometric identification (i.e. facial recognition) has proven particularly controversial because the systems involved may carry an inherent technological bias (e.g. discriminating by racial or ethnic origins) (OECD, 2020[278]). Al's use in public spaces may also undermine the ability of individuals to freely exercise applicable rights related to privacy, data protection and freedom of expression and assembly, according to some civil society organisations

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
262 |
(Access Now, 2022[279]; CSOs, 2021[280]), EU enforcement bodies (EDPB-EDPS, 2021[281]), and some UN Special Rapporteurs (Khan et al., 2022[282]). Several issues related to the use of facial recognition in this context are discussed in Box 5.60.

Box 5.60. Facial recognition privacy and bias concerns
As facial recognition technology has matured, it has become increasingly capable of identifying faces in a crowd, matching images from sources ranging from CCTV footage to police databases to provide real-time surveillance, and identifying criminal suspects or missing people, among other applications. The privacy concern is that public surveillance technology enables governments to gather vast amounts of information about citizens for one purpose (without their consent) that could be used for different, unauthorised and unlawful purposes.
Al tools to enhance facial recognition technology, when trained on inadequate or skewed datasets, may reduce the accuracy of identification for some groups.
Cases have also emerged of inappropriate procedures by police forces leading to the use of poor-quality input data, substantially weakening the accuracy of facial recognition software. For example, police forces in the United States have sought to match drawings of suspects, poor quality CCTV stills, computer-enhanced images and even a picture of a suspect's celebrity doppelganger to image databases. These examples underscore the importance of clear rules on precisely how the software should be used and to clarify whether a match is sufficient grounds for an arrest.
While much attention has focused on cases where the technology malfunctions (e.g. false positives) or is misused, some privacy advocates stress that general use of underlying surveillance or monitoring technology undermines the ability to freely exercise rights by diminishing the expectation of anonymity in public spaces, which is a condition for the exercise of rights such as freedom of assembly. For example, EU data protection authorities have issued opinions stating that the use of such systems in public spaces is incompatible with the right to data protection, under EU law, as scanning all people passing through these spaces interferes with their rights under EU law. Accordingly, in the EU, the EU Al Act only allows the use of "real-time” remote biometric identification systems in publicly accessible spaces for the purposes of law enforcement if such use is authorised under a member state's national law and subject to adequate safeguards. In particular, each use must receive prior authorisation from a judicial authority or an independent administrative authority, and it must be notified to the relevant national data protection authority. Other economies draw a different balance in securing the benefits of while addressing the risks related to these technologies.
Source: (OECD, 2020[255]), https://medium.com/data-science/how-ethical-is-facial-recognition-technology-8104db2cb81b, www.bbc.co.uk/news/technology-47117299, http://ainowinstitute.org/publications/after-a-year-of-tech-scandals-our-10-recommendations-for-ai, www.flawedfacedata.com, www.americaunderwatch.com, www.bbc.co.uk/news/technology-48222017, https://edri.org/our-work/remote-biometric-identification-a-technical-legal-guide, https://eur-lex.europa.eu/eli/reg/2024/1689/oj.

Many predictive Al systems are proprietary and/or rely on “black box” models, making it difficult for the public and policymakers to understand fully why some operational decisions in the field are made. This lack of transparency can undermine trust in law enforcement. Al tools extrapolate results from statistical correlations between different data sources they aggregate. When designing and using these decision-support systems, developers and investigators should reflect on the relevance of using specific socio-demographic variables in predictive models. In the case of a popular Al tool used by the French Gendarmerie, the predictive model uses 15 socio-demographic variables which, according to the developers, are strongly correlated with crime. However, there is no transparency about the nature of these

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 263
variables and no attempt to demonstrate a genuine cause-and-effect relationship (Lecorps and Tissandier, 2022[283]).
Finally, there is a risk that law enforcement agencies may become overly reliant on Al, neglecting other critical aspects of policing such as community engagement and traditional investigative methods. Evaluative studies of alternative Al tools used in predictive policing should be conducted to identify comparative strengths in terms of crime occurring in forecasted areas and number of successful police interventions (Birks, Townsley and Hart, 2023[284]). Relatedly, the use of Al in policing and disaster risk management raises ethical questions about the delegation of moral decision-making to machines. Policymakers should consider the moral implications of using Al to make potentially life-altering decisions in the context of law enforcement and disaster risk management. Ensuring that human oversight and ultimate determinations are maintained, and that Al is used to augment rather than replace human judgment is crucial.

# Implementation challenges
*   High costs of Al adoption and scaling and demonstrating results and return on investment
*   Skills gaps
*   Inflexible or outdated legal and regulatory environments
Implementing Al technologies in policing requires significant investment. Most police departments are local agencies covering a small geographic area with small populations. Functionalities built into standard workplace software and geographic information systems can support many predictive methods. However, the most expensive Al tools, software packages or computers may exceed the affordability (and perhaps needs) of local predictive policing programmes. Policymakers should analyse the relative costs to benefits and seek to ensure that resources are allocated effectively. Law enforcement personnel need proper training to effectively use and understand Al tools. Policymakers should seek to ensure that adequate training programs are in place (EUCPN, 2022[285]), which is often not the case.
Current laws may not adequately address the unique challenges posed by Al in policing. Policymakers need to develop and update legal frameworks to regulate the use of Al in law enforcement. Establishing industry standards and best practices for the development and deployment of predictive policing technologies is essential to ensure consistency and quality.

# Untapped potential and way forward
Al tools continue to offer increasing opportunities to enhance the capabilities of law enforcement and emergency management agencies by improving public safety and responsiveness. The use of these tools across a broader range of public bodies with a role in governance of critical risks is expected to continue to increase as the underlying technologies advance and training of personnel becomes more prevalent. Anecdotes on the benefits of Al tools in relevant contexts proliferate, so too have narratives about irresponsible uses. Continued empirical research is needed to strengthen the evidence base both about measurable benefits and the drawbacks of using Al in these contexts. This will help calibrate its uptake where increased effectiveness and efficiencies can be demonstrated. Or on the contrary, it will help support more stringent oversight due to adverse impacts that erroneous results may have on human lives.
The ethical, legal and societal implications of Al adoption demand careful consideration and proactive measures to ensure that these technologies are deployed in a manner that is trustworthy and respectful of individual rights and freedoms. Policymakers should engage with communities to build trust and ensure that their concerns about Al deployment are addressed. Clear communication about how Al

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

264 |
in policing and in disaster risk management — including its goals, benefits and limitations — is vital to
maintaining public confidence (Evans, 2022[286]). Addressing the challenges outlined above requires a
comprehensive and multi-stakeholder collaboration among end-user agencies, policymakers,
technologists and the communities concerned. Research that draws on such consultations may expand
the evidence of measurable benefits of Al use as well as deepen the understanding of unintended
consequences.

Governments and law enforcement agencies should strengthen their understanding of Al's
limitations in predictive policing to reduce crime. Advanced statistical models and computational
power are neither necessary nor sufficient to reduce crime. Algorithms can help predict the risk of future
events but not the events themselves. While Al can simplify the search for patterns, the tools extrapolate
from past events and are only as accurate as the underlying data used to make them. Humans are the
most important elements in the predictive policing process; they needed to find and gather pertinent data,
prepare it for analysis, review and interpret the results of these analyses to weed out incorrect conclusions,
and offer recommendations for how to proceed based on analytical findings (Perry et al., 2013[287]).

The use of Al in law enforcement is one of the most challenging application areas for the technology. It
provides potential high benefits to national security and public safety but also potential adverse impacts.
For instance, biased algorithms may lead to false positives that result in erroneous arrests and
imprisonment of innocent persons, or false negatives that result in overlooking unlawful activity (Petra
et al., 2024[288]). Such actions strengthen the need to develop consultative mechanisms aimed
garneting public support for deployment of Al tools within conditions and modalities of accepted
guardrails. Such actions introduce significant uncertainty regarding the path forward for Al in this area.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

# Al in justice administration and access to justice
| 265

Digital technologies and data have significant potential to support access to justice, as well as to support its
resilience, efficiency, effectiveness and fairness, in line with the OECD Recommendation on Access to
Justice and People-Centred Justice Systems (2023[289]). Of all the technologies driving this transformation,
Al stands out as both remarkable and novel.

So far, Al is unevenly impacting justice systems. While certain countries have embraced Al for practical
applications within their justice sectors, others are still in the early stages of integrating more basic
technological advancements, let alone Al. Al applications in this area range from automating routine
administrative tasks related to case management to offering predictive analytics and supporting legal
research. Often challenged by backlogs, lengthy procedural requirements and limited accessibility, the
justice system is set to gain immensely from Al integration. Al has great potential to improve efficiency and
responsiveness, enhance the delivery of services tailored to people's needs, support routine tasks and
expand capabilities across a variety of justice domains (Redden and O'Donovan Dix, 2020[290]; CEPEJ,
2018[291]).

Improper development or use of Al in the justice sector can result in disparate treatment between individuals
or groups. Governance frameworks and guardrails to assess risks and incidents, and remedies for those
affected by Al systems can help ensure the trustworthy use of Al in justice.

## Current state of play

### Making internal operations more efficient
Al's impact on productivity and responsiveness in the justice system can be transformative. Advanced Al
algorithms can analyse incoming cases, categorise them based on complexity or urgency, and assign them
to appropriate departments or judges (Reiling, 2020[292]). This can significantly reduce administrative
bottlenecks, help ensure more efficient use of resources and enhance effectiveness in the delivery of
justice. For instance:

*   The French Court of Cassation (2024[293]) developed an Al system that categorises and routes
    incoming appeals and petitions to the appropriate chambers based on training from past cases,
    making case management more efficient and ensuring cases the appropriate level of scrutiny.
*   In Brazil, the VICTOR Al system automates the examination of appeals to the Supreme Court by
    identifying cases with “general repercussions”, a requirement for processing appeals (Supreme
    Court of Brazil, 2024[294]). While a court clerk takes 44 minutes to evaluate whether an appeal
    meets conditions to move forward, VICTOR Al spends a couple of seconds. In addition, Brazil's
    Superior Council of Labour Justice launched Chat-JT, a generative Al tool that assists judges, court
    staff and interns by automating tasks (e.g. legal research, document analysis, the drafting of
    standardised summaries). Launched in February 2025, the platform also allows users to create
    personalised assistants tailored to specific needs within the judicial workflow. By integrating with

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

266

*   other internal systems, Chat-JT provides advanced search capabilities across internal databases,
    aiming to streamline daily operations and improve decision-making processes within the Labour
    Justice (CNJ, 2025[295]).
*   Automated transcription can help improve access to court proceedings. In Slovenia, for instance,
    automated transcription is improving access to court proceedings (Slovenia Ministry of Justice,
    2024[296]). This technology rapidly converts spoken words into written text, ensuring greater
    transparency and allowing more people to review and understand legal proceedings (CMS,
    2023[297]). In Spain, transcription services, referred to as “textualisation”, have been operating since
    2019, integrated into the HORUS judicial electronic file viewer. This combination of systems not
    only provides transcripts but also enables rapid navigation of hearing recordings. It does so by 1)
    associating each segment of the textualisation to the corresponding time frame of the recording,
    and 2) identifying the different voices featured in the recording, allowing users to track which parties
    intervene at any given moment. This is particularly important in Spain, where the recording itself
    serves as the official record of hearings.
*   Colombia's PretorlA system assists the Constitutional Court in managing the high volume of tutela
    cases, or legal actions filed to protect human rights. With over 600 000 custodianships (“tutelas”)
    received annually, PretorlA helps pre-select cases for review by detecting predefined legal criteria.
    Ensuring human oversight and explainability has been a key priority, and PretorlA was redesigned
    in 2020 to use interpretable topic modelling rather than opaque neural networks. Judges remain
    the ultimate decision-makers, maintaining human authority over case selection (OECD/CAF,
    2022[298]).
*   In Greece, Al implementation facilitates judicial processes via automated document processing
    aligned with national legal frameworks and the European Al strategy. NLP technologies analyse
    legal documents, enabling efficient case law searches and court record management.47 Other
    current initiatives integrate Al for speech-to-text conversion, document translation, and witness
    statement interpretation. Additional applications include forensic services support and judicial
    administration optimization, all maintained under human oversight to ensure human rights
    protection while improving efficiency.48

Generative Al systems are also helping to enhance efficiency in justice systems. Automated transcription
— one of the more basic forms of generative Al — can improve access to court proceedings, as is being
done in Slovenia and Spain. This technology rapidly converts spoken words into written text, ensuring
greater transparency and allowing more people to review and understand legal proceedings.

NLP and generative Al have also supported improving case management and processing of judicial
documents. In the case of Spain, by automating repetitive tasks and improving metadata extraction, Al-
enabled services have streamlined daily workflows for justice system personnel, enabling more effective
allocation of human resources and allowing staff to focus on higher-value activities such as complex legal
analysis (Box 5.61).49

### Box 5.61. Enhancing document management in Spain
Spain's Ministry of the Presidency, Justice and Parliamentary Relations has developed an in-house
suite of NLP and generative Al tools to support efficient management and processing of judicial
documents. These tools assist legal professionals in classifying, analysing, summarising and
anonymising court-related texts, while ensuring compliance with data protection standards.

The classification functionality allows documents to be sorted by jurisdiction, registry type and document
category (e.g. legal submissions, notifications), thereby improving information retrieval and
systematisation across various branches of the justice system. The suite also includes advanced

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 267

analytical features that extract and visualise named entities, key dates, monetary values and
relationships between entities. In addition, the system performs semantic similarity detection, helping
to harmonise inconsistent name variants across documents.

Summarisation capabilities are tailored to various legal document types — such as rulings and orders
— and offer four distinct modes, ranging from extractive to generative, including a "legal to plain
language" option designed to enhance accessibility.

The suite is available through three channels:

1. a secure online portal for use by Justice personnel
2. the Justice Folder, Spain's one-stop-shop for citizens where the anonymisation and
summarisation tools are also accessible
3. integration with other digital justice products.

A notable example of this integration is LexNET, Spain's electronic information exchange platform
connecting judicial bodies with legal professionals, law enforcement agencies, hospitals and other
stakeholders. Within LexNET, NLP scans documents to identify and extract named entities, which are
then used to auto-populate required form fields that previously had to be filled in manually. This
automation significantly reduces processing time from several minutes to a matter of seconds.

Future enhancements to the NLP and generative Al suite may include translation capabilities to ensure
bilingual access across Spain's official languages (Spanish, Catalan, Galician, Valencian and Basque).

Source: Information provided by officials of the Ministry of Presidency, Justice and Parliamentary Relations to the OECD.

More sophisticated generative Al systems are helping to create content and perform information analyses.
MARIA (acronym for “Al Writing Support Module") is an LLM-driven tool that supports the Brazilian
Supreme Court in summarising documents, producing first drafts of reports and conducting preliminary
assessments to identify incoming cases with judicial precedents (STF, 2024[299]). MARIA's implementation
brings important efficiency gains; the automation of repetitive tasks frees up court clerks' time for more
complex activities. Similarly, Argentina is introducing LLM to complement its current stack of Al tools to
support the judicial sector (Box 5.62).

### Box 5.62. Prometea and ChatGPT to make Argentina's judicial sector more efficient
Prometea is an Al-powered system developed in 2017 by the Public Prosecutor's Office of the
Autonomous City of Buenos Aires and the Innovation and Artificial Intelligence Laboratory (IALAB) of
the University of Buenos Aires. Designed to automate repetitive judicial tasks and expedite case
proceedings, Prometea acted as a virtual assistant, predicting case solutions based on previous rulings
and helping assemble case files. By significantly reducing processing times, it allowed judicial officials
to focus on more complex cases requiring human judgment. Between 2017 and 2020, Prometea was
instrumental in resolving 658 cases related to housing rights, labour disputes and disability rights. The
system achieved a 90% accuracy rate in its predictions, with prosecutors' decisions aligning with the
Al's recommendations in most cases. By enhancing workflow efficiency, Prometea increased
productivity by nearly 300%, enabling legal professionals to process around 490 cases per month
compared to 130 before its implementation.

Over time, the Inter-American Court of Human Rights and other legal bodies adopted Prometea.
However, its expansion to new case categories required extensive retraining and algorithmic
adjustments, leading to concerns about its scalability. In 2024, developers began phasing out Prometea
in favour of generative Al systems, including ChatGPT, for certain legal tasks. Since May 2024, the

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

268 |

Public Prosecution Service of the City of Buenos Aires has used ChatGPT to predict rulings for some
public employment cases related to salary demands. Justice employees have uploaded case
documents into ChatGPT, which analyses patterns, offers a preliminary classification from a catalogue
of templates, and drafts decisions. So far, ChatGPT has been used for 20 legal rulings, reducing the
time needed to draft a ruling from an hour to about 10 minutes.

Source: (OECD/CAF, 2022[298]), https://restofworld.org/2024/buenos-aires-courts-adopt-chatgpt-draft-rulings.

The time courts take to provide or decline protection measures for people in vulnerable situations, such as
domestic violence, can have severe consequences for victims. Swift judicial responses are essential to
ensure the safety and well-being of individuals facing immediate threats. Prolonged waiting periods for
protective orders can leave victims vulnerable to further abuse. Some countries have implemented
solutions using a mix of methods, including generative Al, to help provide timely judicial responses and,
when applicable, issue protective measures50 to uphold victims' rights (Box 5.63).

### Box 5.63. Redesigning justice services with Al for effective protection measures in Peru
Peru's Amauta Pro system, developed in-house by the Superior Court of Justice of Lima Norte, has
been piloted with domestic violence cases. It uses an Al system and standardised templates of judicial
decisions to perform various tasks essential for the determination of the resolution to provide or decline
protection measures. The automated tasks are:

*   Conversion and categorisation: The system converts machine-readable files to text, categorises
    each page based on content and verifies the validity of file codes. This categorisation helps in
    organising and managing case files more efficiently.
*   Case matching: Amauta Pro searches for open proceedings involving the same parties or
    related facts. If matches are found, the system prepares draft resolutions, streamlining the
    process of case consolidation.
*   Data extraction and cleaning: For cases without matches, the Al system extracts data from
    police reports and other relevant documents, cleans the text and identifies key information.
*   Drafting resolutions: The system drafts resolutions based on extracted and analysed data,
    which judges can review and finalise. This reduces the time required to draft resolutions.

The project aims to improve access to justice for victims of violence by providing timely and effective
protection measures. The system reduces the time taken to draft a resolution from 3 hours to 40
seconds. The project has garnered support from the highest levels of the Peruvian judiciary, including
the President of the Judiciary, underscoring the project's importance and the confidence placed in its
ability to transform the delivery of justice services in Peru. With over 800 court ruling proposals
generated during its pilot phase, Amauta Pro enables judges to focus more of their time and resources
on the critical aspects of decision-making rather than on time-consuming administrative tasks.

Source: (Government of Peru, 2023[300]).

Al algorithms can also be trained to identify and categorise data, including text containing personal
information (e.g. name, address) from court documents and transcripts. This can be used to protect
sensitive information and maintain privacy, critical aspects of handling justice cases. A number of country
practices demonstrate the application of Al in this area (Box 5.64).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 269

# Box 5.64. Al-powered anonymisation of court decisions

## Spain: Automated anonymisation tool for legal documents
Spain's Ministry of the Presidency, Justice and Parliamentary Relations offers a robust anonymisation
tool as part of its NLP and generative Al suite. The tool removes personally identifiable information from
documents through three modes — automatic, initials-based and fully customisable — enabling the
creation of shareable, GDPR-compliant documents and datasets. In addition to choosing the mode of
anonymisation, users can specify the types of information they wish to anonymise. This includes data
related to individuals (e.g. names), legal entities, addresses, identity documents (e.g. ID or passport
numbers), as well as email addresses and social media profiles.

## Croatia: Automated anonymisation of judicial decisions
As of January 2025, Croatia has operationalised ANON, an Al-powered tool designed to automate the
anonymisation and publication of court decisions. Integrated with the national eSpis case management
system, ANON automatically anonymises first-instance judgments and proposes indexing for
publication on the publicly accessible portal, Search Engine for Decisions of the Courts of the Republic
of Croatia (Tražilica odluka sudova Republike Hrvatske). For higher-instance courts, the system
facilitates anonymisation, with final verification conducted by authorised court personnel. This initiative,
supported by the National Recovery and Resilience Plan 2021-2026, aims to enhance judicial
transparency, improve access to legal information and ensure compliance with personal data protection
standards.

## Austria: A combination of approaches to court decision anonymisation
Austria's Federal Ministry of Justice (BMJ) is implementing a comprehensive project to automate the
anonymisation of court decisions. The project's primary goals are to improve efficiency, reduce manual
effort in the anonymisation process, and enable wider publication and access to anonymised court
decisions. This initiative uses a combination of Al approaches, including search-based methods using
register data and regular expressions, NLP for named entity recognition, and custom ML algorithms to
continuously refine the quality of results based on feedback.

## France: Al-driven anonymisation for open data release
The French Court of Cassation's Al-powered anonymisation engine is a key component in its efforts to
increase transparency and accessibility of legal information. This system is designed to automatically
identify and protect personal data within court decisions, preparing them for public release as part of an
open data initiative.

## Greece: Al-enabled summarisation and anonymisation
The Ministry of Justice in Greece is using Al to translate summarize and anonymize documents.
Furthermore, the Ministry is introducing an Al assistant for providing instructions to citizens and lawyers
regarding electronic and non-electronic services of the Greek Justice System.

Note: Register data are structured databases or official registries that contain names, case numbers or other identifying information. Regular
expressions are pattern-matching rules used in text processing. They help detect and redact specific patterns, such as names, dates or
addresses, based on predefined formats.
Source: (Spain Ministry of Justice, 2022[301]; Austria Federal Ministry of Justice, 2021[302]; Sommer, 2021[303]), Croatian Ministry of Justice
officials, https://ministryofjustice.gr/?p=13929, https://ministryofjustice.gr/?p=15317.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

270 |

# Improving delivery of justice services
In OECD countries, Al is being deployed to support the delivery of and access to legal and judicial services
by facilitating initial consultations through chatbots and virtual assistants. These Al systems can provide
preliminary legal advice in accessible language, triage cases based on urgency and relevance, and guide
users through court proceedings, as done in Portugal (Box 5.65).

# Box 5.65. Portugal's Al-powered chatbot to provide practical information
Portugal's Ministry of Justice has implemented a Practical Guide to Justice (GPJ), an Al-powered
chatbot that provides the public with easy access to justice-related information. The GPJ is trained to
respond to various formulations of questions in an accessible manner. It provides answers based on
information from the Digital Justice Platform, offering people practical guidance on justice-related
matters. The chatbot is designed to speed up interactions between people and the justice system,
helping them find the information they need more efficiently. The GPJ provides user-friendly, plain
language responses to people's inquiries. It helps bridge the information gap between the complex legal
system and the general public, making justice-related information more accessible to all.
Source: (Government of Portugal, 2024[304]).

Victim support services also stand to benefit from Al-driven innovations. These services, which often
involve providing timely information, legal support and resources to victims of crime, can be augmented
through the integration of Al technologies. Al-powered chatbots, for instance, can offer personalised
support, providing victims with immediate access to information on their rights, available resources and
steps to take following a crime (see example in Box 5.66).

# Box 5.66. Chatbot supports child victims with tailored legal information
The i-ACCESS My Rights project implemented in Greece, Bulgaria and Romania provides age-
appropriate and child-friendly legal information to children aged 13-18, particularly those who have been
victims of abuse or crime. Offering general legal information and guidance on available support
services, the i-ACCESS chatbot is designed to empower young victims by informing them of their rights
within legal proceedings and directing them to relevant support networks and authorities. What sets this
project apart is its strong emphasis on child participation in the development process through co-design
sessions and Child Advisory Boards in each country. To ensure that the Al tool is truly responsive to
the needs and preferences of its young users, children with lived experiences in the justice system
actively contributed to the chatbot's design and functionality.
Source: https://justicewithchildren.org/en/i-access-my-rights.

# Enabling predictions for a more proactive justice system
Al can enhance the justice system's proactivity by enabling predictive analytics. This predictive approach
allows justice systems to shift from a reactive to a proactive approach, focusing on prevention and informed
decision-making. Two usual applications of Al in justice administration and access to justice are predictive
policing – where Al analyses historical data to identify patterns and forecast potential events (see section
on "Al in law enforcement and disaster risk management") – and risk assessment tools – where Al is used

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 271
to evaluate the likelihood of individuals becoming victims or re-engaging in similar criminal conduct in the
future, supporting decisions on bail, sentencing and parole.

Some countries have been advancing in the implementation predictive policing and risk assessment tools,
especially in the context of domestic violence and community violence prevention, with some promising
implementations. Spain and the United States operate an extensive victim risk assessment system in the
area of domestic violence (Box 5.67). Some other relevant examples on predictive policing are provided in
this chapter's section on "Al in law enforcement and disaster risk management".

# Box 5.67. Risk assessment system for domestic violence in Spain
Spain's Comprehensive Monitoring System for Gender-Based Violence Cases (VioGén) is a risk
assessment tool designed to enhance victim protection and prevent domestic violence escalations. It
aims to strengthen the country's capacity to respond to violence against women and girls using
evidence-based assessments. Since its introduction in 2007, VioGén has processed over 670 000
cases, facilitating a coordinated response across the judiciary, national and local police forces. The
system operates through a structured risk assessment process, starting when a victim reports abuse or
when police intervene in a domestic incident. Officers complete a detailed questionnaire, assessing
factors such as the aggressor's history, the severity of prior violence and victim vulnerabilities. The
algorithm then assigns a risk level — low, medium, high or very high — determining the necessary
protective measures, such as police check-ins or emergency alarms. Cases deemed "of special
relevance," based on risk levels, can be flagged for prosecutors and judges. Regular follow-up
assessments adjust risk classifications, ensuring responses remain appropriate over time.
Source: (Government of Spain, 2007[305]; Algorithm Watch, 2020[306]).

These tools help identify patterns in victimisation and anticipate and address potential issues before they
escalate. Yet they also require careful implementation to mitigate biases and uphold ethical standards
within the justice system. In Spain, while evidence suggests that the VioGén risk assessment tool
(Box 5.67) strengthens victim protection, concerns — regarding algorithmic “black box”, risks of potential
misclassification and limited literacy on the use of digital tools and approaches sensitive to women and
girls — underscore the importance of appropriate training for users, and of transparency and oversight
mechanisms. VioGén's algorithm seems to remain largely opaque; its exact formula is undisclosed, raising
questions about accountability and fairness. Reports also indicate that in 95% of cases, officers adhere to
VioGén's risk classification without modification, despite having the discretion to override it (Algorithm
Watch, 2020[306]).

Another example, in the United States, is the Correctional Offender Management Profiling for Alternative
Sanctions (COMPAS), a proprietary risk assessment tool that evaluates the likelihood of a defendant
reoffending. Used in several U.S. jurisdictions, COMPAS was designed to support courts in making
informed decisions regarding bail, sentencing and parole by predicting general and violent recidivism risks
(Equivant, 2025[307]). The system analyses data from a comprehensive questionnaire that covers factors
such as criminal history, substance abuse, social connections and personal demographics. This
information is processed through a proprietary algorithm to classify individuals as having a low, medium or
high risk of reoffending. These risk scores assist legal professionals tailor interventions and supervision
levels to each offender's assessed risk.

While COMPAS has brought efficient gains — in processing time and standardisation across jurisdictions
— the system was thrust into the spotlight due to its 68% accuracy level (De Miguel Beriain, 2018[308];
Grgić-Hlača et al., 2018[309]). As in the case of VioGén, the limited algorithmic transparency of COMPAS
also contributed to ethical questions over whether it was a trustworthy system to take fundamental

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

272 |
decisions such as defendants' freedom. Some jurisdictions have since sought more transparent
alternatives — for example, the Public Safety Assessment (PSA), a non-proprietary statistical risk
assessment method (APPR, 2025[310]) — while others continue using tools like COMPAS under closer
scrutiny.

Al has enormous potential to improve proactiveness in justice systems (see "Untapped potential and way
forward" below). Yet, there is still a long way before reaping the benefits of Al predictive systems. This
includes expanding training to justice professionals on the use of Al tools, greater algorithmic transparency,
and human oversight (see "Managing risks and challenges" below).

# Monitoring judicial performance and enhancing accountability
Al has proven effective in various scenarios to enhance the transparency and accountability of government
activities (OECD, 2022[152]). Al applications for external and internal oversight in the justice sector focus on
performance monitoring of judicial systems and enhancing accountability. Al systems can provide insights
into court performance, identify potential inconsistencies in decision-making and support policy evaluation.
These systems should be accompanied by pre-existing governance mechanisms on checks and balances
(e.g. administrative independence and autonomous judicial review) to ensure the judiciary's autonomy. Al-
driven court performance monitoring could risk undue interference if there are no protections in place.
Checks and balances (such as independent oversight bodies, administrative independence and
autonomous judicial review) help prevent Al tools from being used to influence case outcomes or unfairly
evaluate judges. Al can highlight patterns in judicial decisions, but without independent governance
mechanisms, these insights could be potentially misused (e.g. penalising judges for unpopular rulings
instead of focusing on systemic improvements).

While less common than other applications, these oversight activities represent an important area with
potential for Al development in justice systems. The RAFA 2030 project implemented by the Brazilian
Supreme Court (STF) stands out as an innovative example of Al use for oversight (Box 5.68).

# Box 5.68. Harnessing Al oversight in Brazil's Supreme Court
The RAFA 2030 project implemented by the Brazilian Supreme Court (STF) uses ML and deep learning
(DL) to classify data by category, by processes that are on the STF's plenary agenda, by origin of the
process, by class, by completed or ongoing processes, and by Sustainable Development Goals (SDGs)
2030. RAFA 2030 not only supports internal performance evaluation but also facilitates external
oversight by providing a standardised framework for assessing the implementation of the SDGs agenda
in the context of Supreme Court decisions. Automated classification of cases with SDGs provides a
clear overview of how the court's decision aligns with the 2030 Agenda.

In addition, by aligning court cases with global sustainability objectives, RAFA 2030 enables the
comparison of the STF's performance with other international higher courts. The system has already
supported the classification of 3 315 court cases, demonstrating its potential to enhance transparency
and align judicial activities with broader societal goals.
Source: https://portal.stf.jus.br/hotsites/agenda-2030.

In Israel, the Israeli Ministry of Justice has implemented an Al-driven initiative within the Public Defender's
Office to support oversight in Office, to enhance the quality of legal representation and strengthen
supervisory mechanisms. The project integrates ML, NLP and optical character recognition (OCR)
technologies to streamline the review and management of criminal case files. This initiative supports the

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 273
oversight of defence quality by enabling automated analysis of legal documents, improving consistency
checks and identifying potential issues in case handling.51

# Evidence of impact
Pioneering initiatives like those discussed above have made legal information more accessible, breaking
barriers that have long kept many people from fully engaging with the justice system. These Al-driven tools
help address the needs of many people — such as identifying the most suitable justice services for their
individual situation — promote a more informed citizenry and pave the way for more effective and efficient
justice systems.

One of Al's most significant impacts has been its ability to accelerate various legal processes. By reducing
the time needed for document review and categorisation, Al allows more cases to be handled in less time.
The French Court of Cassation's aforementioned Al solution for pre-directing appeals has, for example,
obtained results on the supplementary briefs from 2020, showing that 87% are of good pre-direction (Court
of Cassation of France, 2024[293]). As a case improving judicial responsiveness, Peru's Amauta Pro Al
system (Box 5.63) has transformed the speed at which courts can respond to victims of violence, reducing
the time needed to draft resolutions for protection measures from three hours to 40 seconds. It is also
fundamentally enhancing the judicial system's overall responsiveness in addressing cases of violence
against women and family members, contributing to effective access to justice.

While results and impact data exist for some specific use cases, as discussed in the examples above,
governments have not yet extensively collected or documented results and impacts on many others.
Despite growing interest in Al applications across justice systems, countries have not established
systematic mechanisms to collect and analyse data on their impact. Existing evidence remains
fragmented, often limited to pilot studies or sector-specific evaluations, with few comprehensive
assessments at either the organisational or national level (Queen Mary University of London; Centre for
European Policy Studies, 2021[311]). This evidence gap at organisational and national levels means
reformers are not learning from experience. Potentially effective Al innovations might be overlooked or,
conversely, unproven tools scaled up inappropriately.

While some jurisdictions report efficiency gains from Al-assisted case management or automated legal
research, there is little empirical data on whether these tools improve the delivery of people-centred justice
or enhance decision-making accuracy. Without structured monitoring, governments risk deploying Al
solutions without clear evidence of their benefits or unintended consequences, limiting their ability to make
informed policy decisions. The lack of evidence of impact reflects a broader systemic issue: justice systems
have often encountered challenges in collecting and effectively using data (World Justice Project, 2021[312])
Historically, justice systems have relied heavily on paper-based processes (Byrom, Piccinin-Barbieri and
Wells, 2024[313]) (see "Managing risks and challenges" below).

# Managing risks and challenges
## Associated risks
*   Inadequate or skewed data in Al systems
*   Lack of transparency and explainability
*   Inaccuracy, falsehoods, and unreliability
*   Over-reliance on Al and resistance to government use of Al

If Al systems rely upon inadequate or skewed data, it could lead to inaccurate or adverse outcomes for
some individuals or groups. With regard to justice administration and access to justice, this could result in,

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

274 |
for instance, inaccurate risk assessments (e.g. for likelihood of recidivism) that could result in lead to adverse impacts for some individuals.

The lack of transparency of Al systems used for justice administration was identified as another concern in the review of use cases. Taking the examples mentioned in “Enabling predictions for a more proactive justice system”, while were designed to enhance efficiency and decision-making, Al systems such as VioGén and COMPAS often operate as black boxes, with their underlying methodologies, weighting of factors and potential biases shielded from public scrutiny. The proprietary nature of certain Al systems or lack of external audits prevents defendants from understanding or challenging the risk scores that influence decisions, raising concerns about due process and fairness in judicial decisions. While lack of algorithmic transparency is not an uncommon issue, it has a very sensitive dimension in the administration and access to justice as it can be detrimental to human rights and fundamental freedoms and reinforce systemic inequalities in societies. Lack of algorithmic transparency has important impacts on explainability of judicial decisions. When Al systems are not transparent, it becomes challenging to understand the rationale of decisions. This opacity can result in difficulties in challenging and ensuring fairness of decisions, leading to distrust on the use of the tools and ultimately on justice systems.

The reliance on Al, and potential concerns regarding over-reliance on Al, for accountability introduces new layers of complexity that require robust oversight mechanisms. Not all judges are convinced of using Al systems in the justice systems and have concerns on their applications. For example, 27% of respondents to a UNESCO survey among judicial operators expressed concerns about the Al chatbot's output quality, highlighting issues such as inaccuracy, falsehoods, and unreliability. Governments can mitigate these risks by implementing strong policy and regulatory frameworks. Spain, for instance, established a framework for the responsible and ethical use of Al in justice, recognising Al's potential to support, but not substitute jurisdictional decision-making (Box 5.69). Greece's Permanent Scientific Committee of the Ministry of Justice, with the aim of examining the impacts of the introduction of Al in the judicial system, has drawn up guidelines that must be followed by the competent bodies of the Courts and Prosecutor's Offices. 52

# Box 5.69. Spain: National Policy on the Use of Al in the Administration of Justice
In June 2024, Spain's Technological Committee for the Electronic Judicial Administration (CTEAJE) approved the National Policy on the Use of Artificial Intelligence in the Administration of Justice. This policy establishes a foundational framework for the responsible, lawful, and ethical use of Al within judicial settings. Grounded in the provisions of the Spain's Justice Digital Efficiency Act (Royal Decree-Law 6/2023), which regulates the use of Al in the justice sector, the policy seeks to balance technological innovation with judicial integrity. It recognises Al's potential to support, but not substitute, jurisdictional decision-making.

The policy applies to any Al system that handles judicial data, from the initial filing of a case to its final resolution. It draws a clear line between systems that could affect judicial independence and those intended purely for administrative purposes. The guidelines are binding for all personnel operating within the justice system, including external collaborators in both the public and private sectors who have access to judicial data. The policy was agreed upon by key institutional stakeholders of Spain's Justice system: the General Council of the Judiciary (CGPJ), the Office of the Attorney General, all regional administrations with competence over the Justice Administration, and the Ministry of the Presidency, Justice and Parliamentary Relations.

In addition to these principles, the policy provides operational guidance, outlining acceptable uses of Al — such as internal document summarisation and automation of non-sensitive administrative tasks — while explicitly prohibiting others. Prohibited uses include automated decision-making without human

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 275
oversight and the generation of binding legal content based on protected data. The policy also requires clear labelling of Al-generated outputs and affirms national sovereignty over the data and algorithms deployed.

Oversight responsibilities are clearly defined in the policy. When Al tools have an impact on judicial functions, the CGPJ is responsible for conducting algorithmic audits to safeguard judicial independence and ensure transparency. For tools used in non-judicial contexts, oversight is assigned to CTEAJE or the relevant administrative authority. Additional mechanisms include the maintenance of FAT (Fairness, Accuracy, and Transparency) registers for Al systems and sustained inter-institutional collaboration to promote ethical innovation throughout Spain's judicial ecosystem.

Source: (Spain Ministry of Justice, 2024[314]); Information provided by officials of the Ministry of Presidency, Justice and Parliamentary Relations to the OECD.

In addition to algorithmic transparency, countries should consider implementing effective human oversight in the use of Al tools in their justice systems, including Al systems with clear decision-making processes allowing stakeholders to understand capabilities and limitations and interpret outcomes, conduct ongoing tracking of Al performance, and allow human intervention and control (OECD, 2024[91]). Ethical guidelines, such as the 2018 European Ethical Charter on Al in Judicial Systems, was a first step in this regard, outlining principles to ensure that Al development in judicial systems adheres to fundamental rights as conceptualised under EU law (CEPEJ, 2018[291]). Continuous monitoring and improvement should be built into an operational framework, allowing for regular audits of Al performance and outcomes. Additionally, operational plans should account for the evolving nature of law and help ensure that Al systems can be updated to reflect changes in legislation or precedent.

## Implementation challenges
*   Lack of high-quality data and the ability to share it
*   Skills gaps
*   Lack of actionable frameworks and guidance on Al usage

Historically, justice systems were predominantly paper based and, until recently, there was limited attempt to implement sound data governance in justice systems (Byrom, Piccinin-Barbieri and Wells, 2024[313]). This legacy is still very present today. For example, according to the OECD OURdata Index, countries perform relatively better in making statistics and geospatial data available, whereas weaker performance include data related to justice (OECD, 2023[315]). In addition, where data are collected, they are often held and stored in formats that are not easily accessible (e.g. in narrative format, PDF or paper files), or recorded inconsistently across agencies (Byrom, Piccinin-Barbieri and Wells, 2024[313]). The justice system deals with vast amounts of complex, nuanced data, including case law, statutes and individual case details. Ensuring this justice data is accurate, comprehensive and free from historical biases is paramount. This implies improving the quality and representativeness of data used to train Al systems, the robustness of systems housing this data, and the ability to handle sensitive information securely (Byrom, Piccinin-Barbieri and Wells, 2024[313]). Moreover, the technical infrastructure should be capable of processing this data efficiently while maintaining the highest standards of security and privacy.

Operational suitability focuses on integrating Al seamlessly into existing processes and workflows while enhancing digital competencies. This encompasses providing training to legal professionals, including judges, to effectively use Al tools and interpret Al-assisted insights, and adapting processes that need to be optimised to incorporate Al-driven solutions. Some countries have taking steps in this regard as Al tools are launched (CNJ, 2025[295]).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
276
The use of Al raises questions of regulatory compliance, which is particularly important in the justice system due to the high stakes involved in judicial decisions and the fundamental or constitutional rights at play. The EU AI Act exemplifies the evolving regulatory landscape, classifying Al systems in law enforcement and administration of justice as high-risk. This means that in the EU, strict obligations must be complied with before such systems can be put on the EU market, including the requirement to undergo a third-party assessment. While broad rules are increasingly being developed, there is often a lack of actionable guidance in how Al can be used in a trustworthy way in a domain as sensitive as justice administration. The United Kingdom and Colombia have sought to put in place such guidance (Box 5.70 and Box 5.71).

# Box 5.70. Judicial guidance on Al in the United Kingdom
The UK Al Judicial Guidance provides direction for judicial office holders on the use of Al in courts and tribunals, outlining associated risks and measures to manage them. It ensures that any Al use aligns with judicial obligations, particularly the integrity of justice. The guidance applies to all judicial office holders under the authority of the Lady Chief Justice and Senior President of Tribunals, as well as their clerks and support staff.

The guidance includes key considerations, such as confidentiality, accountability, bias and security. It sets out principles for using Al tools, specifying tasks where Al may assist, such as text summarisation and administrative activities, while advising caution in areas like legal research and analysis. It also highlights the risks of misinformation and the use of Al-generated content in judicial proceedings. In addition to key directions, the document also includes some examples to illustrate potential uses and risks of Generative Al in courts and tribunals.

Developed by a cross-jurisdictional judicial group following consultation with all judicial office holders, the guidance represents an initial step in supporting the judiciary's engagement with Al. Future initiatives include publishing a FAQ document to address questions submitted by the judiciary, with ongoing reviews to adapt to technological advancements.

Source: (United Kingdom, 2023[316])

# Box 5.71. Colombia's directive on Al rules and guidelines for the judiciary
In December 2024, the Superior Council of the Judiciary in Colombia issued Agreement PCSJA24-12243, establishing guidelines for the respectful, responsible, safe, and ethical use of Al within the Judicial Branch. This directive aims to enhance access, transparency, and efficiency in judicial administration by integrating Al into document management, administrative tasks, and judicial support activities. The document outlines three components for implementation: the need for comprehensive training programmes; the implementation of initiatives and sharing of use cases; and the development of guidelines on the use of Al systems in the judiciary.

The directive was preceded by the use of ChatGPT in a ruling concerning an autistic child's exemption from medical fees. In January 2023, a judge in Cartagena incorporated Al-generated responses into his decision to expedite the drafting process. This action sparked significant debate regarding the reliability and ethics of Al in legal judgments. In response, the Superior Council of the Judiciary issued the Agreement PCSJA24-12243, emphasising the need for clear guidelines to ensure Al tools are used

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
| 277
appropriately. The incident underscores the urgent need of building digital literacy within the judiciary on Al's capabilities and limitations to prevent over-reliance on technology and to maintain human oversight in judicial decision-making. Since the Agreement PCSJA24-12243, several actions and initiatives have been implemented, including surveys to assess the use of Al by court personnel, training programmes with legal professionals introducing Al-assisted tools for court operations, and partnerships with universities and international organisations on workshops and training programmes.

Source: (Colombia, 2024[317]; Colombia, 2024[317]; UNESCO, 2025[318]).

# Untapped potential and way forward
People and legal professionals can use Al applications for services such as legal advice, access to information or document preparation. Well-designed justice systems that incorporate efficiency, transparency and user-friendliness are more likely to be accessible and responsive to the needs of the public. Al's advanced algorithms and ML techniques can help to ensure that judicial processes are more consistent, transparent and free from human biases, and can help courts to monitor efficiency and resources. Al can improve accountability by flagging inconsistencies and potential biases in real time. Systems can be programmed to monitor for and alert stakeholders to unusual patterns that might indicate bias or misconduct. For example, if data reveals that certain demographic groups are being disproportionately targeted or receiving harsher sentences, these discrepancies can be promptly identified and addressed. Such real-time monitoring and alerts can prompt immediate reviews and corrective actions, enhancing the overall fairness and integrity of the justice system.

The Al systems should be accompanied by pre-existing governance mechanisms on checks and balances (e.g. administrative independence and autonomous judicial review) to ensure the autonomy of the judiciary. Such governance mechanisms align with the vision set forth in the Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law (2024[319]), which stresses the importance of preserving judicial independence and access to justice when implementing Al systems.

Trust is perhaps the most crucial aspect in the justice system; decisions can profoundly impact individuals' lives and societal trust. This aspect encompasses transparency, explainability, fairness and accountability, equality of treatment, ethical concerns and privacy and justice gaps that should be carefully addressed. The potential for Al systems to perpetuate or amplify existing societal disparities and justice gaps should be carefully addressed. Al systems should be designed to avoid perpetuating or exacerbating existing biases in the justice system, particularly regarding race, sex or socioeconomic status.

Algorithmic transparency is essential not only for ethical reasons but also to meet legal requirements of due process. The explainability of Al-driven decisions is crucial for maintaining public trust and allowing for meaningful appeals. Ethical considerations should extend to all stakeholders, including defendants, victims, legal professionals and society at large.

Al's transformative potential in justice requires a human-centred approach that both promotes digital transformation and protects human rights. Effective governance involves collaboration among policymakers, legal professionals and technologists to align Al applications with the principles of fairness, equity and procedural integrity. Continuous impact assessments, stakeholder engagement and mechanisms for redress enhance both legitimacy and effectiveness. This underscores the importance of designing Al systems as tools that support judicial decision-making and justice administration and reinforce the capacity to deliver people-centred justice.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025
***
278 |
In this context, it remains critical to establish robust governance frameworks, and continuous monitoring mechanisms to ensure the trustworthy and equitable use of Al in justice systems. To support the governance of Al in justice and ensure its responsible use, the OECD AI Principles (Table 2.2), the OECD Framework for Trustworthy Al in Government (Figure 4.6) and the OECD Common Reporting Framework for Al Incidents (2025[320]) can serve as good starting points. The OECD Al Principles advocate for inclusive growth, sustainable development and well-being, emphasising the importance of human-centred values and fairness. They call for Al systems to be transparent, with their decisions understandable by those affected by them. The Framework for Trustworthy Al in Government can be a useful tool to support the responsible use of Al in the justice sector. The OECD Methodology for Monitoring Al Incidents can support the justice sector monitor Al incidents, ensuring these systems are accountable, trustworthy and beneficial, while mitigating potential risks associated with their deployment.

# References
Abrell, J., M. Kosch and S. Rausch (2022), "How effective is carbon pricing?—A machine learning approach to policy evaluation", Journal of Environmental Economics and Management, Vol. 112, p. 102589, https://doi.org/10.1016/j.jeem.2021.102589.
[134]

Access Now (2022), Ban Biometric Surveillance, https://www.accessnow.org/campaign/ban-biometric-surveillance/.
[279]

ACE (2025), Government administrative data sources for evaluation in Australia, https://evaluation.treasury.gov.au/sites/evaluation.treasury.gov.au/files/2025-01/government-administrative-data-sources-for-evaluation-in-australia.pdf.
[136]

Agencia Nacional de Contratación Pública –Colombia Compra Eficiente (2024), VISUALIZACIONES COMPRA PÚBLICA, https://www.colombiacompra.gov.co/content/visualizaciones-compra-publica.
[79]

AI.GOV.UK (2024), i.Al Consultation Analyser, https://ai.gov.uk/consultations/.
[164]

Aldemir, C. and T. Uçma Uysal (2025), “Artificial Intelligence for Financial Accountability and Governance in the Public Sector: Strategic Opportunities and Challenges", Administrative Sciences, Vol. 15/2, p. 58, https://doi.org/10.3390/admsci15020058.
[223]

Algorithm Watch (2020), Automating Society Report, https://automatingsociety.algorithmwatch.org/report2020/spain/spain-story/.
[306]

Alon-Barkat, S. and M. Busuioc (2022), “Human-Al Interactions in Public Sector Decision Making: "Automation Bias" and "Selective Adherence" to Algorithmic Advice", Journal of Public Administration Research and Theory, Vol. 33/1, pp. 153-169, https://doi.org/10.1093/jopart/muac007.
[130]

Alowais, S. et al. (2023), "Revolutionizing healthcare: the role of artificial intelligence in clinical practice", BMC Medical Education, Vol. 23/1, https://doi.org/10.1186/s12909-023-04698-z.
[216]

Amos, J. (2020), "Bushfires: Australian satellite would be 'tuned' to eucalypt vegetation", https://www.bbc.com/news/science-environment-51727231 (accessed on 4 March 2025).
[270]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 279
---
Andersson, P., K. Arbin and C. Rosenqvist (2025), “Assessing the value of artificial intelligence
(Al) in governmental public procurement”, Journal of Public Procurement, Vol. 25/1, pp. 120-
139, https://doi.org/10.1108/jopp-05-2024-0057.
[83]

Androutsopoulou, A. et al. (2019), “Transforming the communication between citizens and
government through Al-guided chatbots.", Government information quarterly, Vol. 36/2,
pp. 358-367, https://doi.org/10.1016/j.giq.2018.10.001.
[169]

Ansari, B., M. Barati and E. Martin (2022), “Enhancing the usability and usefulness of open
government data: A comprehensive review of the state of open government data visualization
research", Government Information Quarterly, Vol. 39/1, p. 101657,
https://doi.org/10.1016/j.giq.2021.101657.
[78]

Anshari, M. et al. (2024), “Public service delivery, artificial intelligence and the sustainable
development goals: trends, evidence and complexities”, Journal of Science and Technology
Policy Management, Vol. 16/1, pp. 163-181, https://doi.org/10.1108/jstpm-07-2023-0123.
[193]

Aoki, N. (2020), “An experimental study of public trust in Al chatbots in the public sector",
Government Information Quarterly, Vol. 37/4, p. 101490,
https://doi.org/10.1016/j.giq.2020.101490.
[251]

Aoki, N., M. Tay and M. Yarime (2024), “Trustworthy public sector Al: research progress and
future agendas”, in Research Handbook on Public Management and Artificial Intelligence,
Edward Elgar Publishing, https://doi.org/10.4337/9781802207347.00026.
[252]

APA (2023), Worries about artificial intelligence, surveillance at work may be connected to poor
mental health, https://www.apa.org/news/press/releases/2023/09/artificial-intelligence-poor-
mental-health.
[55]

APPR (2025), About the Public Safety Assessment, https://advancingpretrial.org/psa/about/.
[310]

Arana-Catania, M. et al. (2021), "Citizen participation and machine learning for a better
democracy", Digital Government: Research and Practice, Vol. 2/3, pp. 1-22,
https://doi.org/10.1145/3452118.
[159]

Araszkiewicz, M. and V. Rodríguez-Doncel (2019), Legal Knowledge and Information Systems:
JURIX 2019: The Thirty-second Annual Conference, https://ebooks.iospress.nl/volume/legal-
knowledge-and-information-systems-jurix-2019-the-thirty-second-annual-conference.
[149]

Ash, E., S. Galletta and T. Giommoni (2020), "A Machine Learning Approach to Analyzing
Corruption in Local Public Finances", SSRN Electronic Journal,
https://doi.org/10.2139/ssrn.3589545.
[101]

Attard, J. et al. (2015), “A systematic review of open government data initiatives", Government
Information Quarterly, Vol. 32/4, pp. 399-418, https://doi.org/10.1016/j.giq.2015.07.006.
[77]

Australian Government (2020), Department of Veterans' Affairs Annual Report 2019-20,
https://www.transparency.gov.au/publications/veterans-s-affairs/department-of-veterans-
affairs/department-of-veterans-affairs-annual-report-2019-20.
[10]

Austria Federal Ministry of Justice (2021), Anonymization of court decisions in Austria: Webinar
on the use ofAl in the justice field, https://commission.europa.eu/system/files/2021-
04/anonymisation webinar 29032021 austria.pdf (accessed on 19 February 2025).
[302]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
280 |
---
Babšek, M. et al. (2025), “Artificial Intelligence Adoption in Public Administration: An Overview of
Top-Cited Articles and Practical Applications”, Al, Vol. 6/3, p. 44,
https://doi.org/10.3390/ai6030044.
[198]

Bailey, K. (2023), The Ethics of Al in Finance: How to Detect and Prevent Bias,
https://corporatefinanceinstitute.com/resources/data-science/ai-ethics-in-finance-detect-
prevent-bias/ (accessed on 10 April 2025).
[19]

Bastani, H. et al. (2021), “Efficient and targeted COVID-19 border testing via reinforcement
learning", Nature, Vol. 599/7883, pp. 108-113, https://doi.org/10.1038/s41586-021-04014-z.
[217]

Bénassy-Quéré, A. (2022), Ex ante, ex post: tuning the two pillars of policy evaluation,
https://www.tresor.economie.gouv.fr/Articles/2022/02/25/ex-ante-ex-post-tuning-the-two-
pillars-of-policy-evaluation.
[111]

Bennett Institute (2024), Public Health gets personal: The case for an Al-driven personalised
prevention platform, https://www.bennettinstitute.cam.ac.uk/wp-content/uploads/2024/03/The-
case-for-an-Al-driven-personalised-prevention-platform.pdf.
[243]

Berditchevskaia, A. and P. Baeck (2020), The Future of Minds and Machines: How artificial
intelligence can enhance collective intelligence.
[165]

BEREC (2023), Report on the impact of Artificial Intelligence (AI) solutions in the
telecommunications sector on regulation, https://www.berec.europa.eu/en/document-
categories/berec/reports/berec-report-on-the-impact-of-artificial-intelligence-ai-solutions-in-
the-telecommunications-sector-on-regulation.
[35]

Berman, A., K. de Fine Licht and V. Carlsson (2024), “Trustworthy Al in the public sector: An
empirical analysis of a Swedish labor market decision-support system”, Technology in
Society, Vol. 76, p. 102471, https://doi.org/10.1016/j.techsoc.2024.102471.
[200]

Berryhill, J. et al. (2019), “Hello, World: Artificial intelligence and its use in the public sector”,
OECD Working Papers on Public Governance, No. 36, OECD Publishing, Paris,
https://doi.org/10.1787/726fd39d-en.
[191]

Better Evaluation Knowledge (2022), Rapid Evaluation,
https://www.betterevaluation.org/methods-approaches/approaches/rapid-evaluation.
[135]

Birhane, A. et al. (2022), “The Values Encoded in Machine Learning Research", 2022 ACM
Conference on Fairness, Accountability, and Transparency,
https://doi.org/10.1145/3531146.3533083.
[227]

Birks, D., Μ. Τownsley and T. Hart (2023), Predictive policing in an Australian context: assessing
viability and utility, Australian Institute of Criminology, https://doi.org/10.52922/ti78870.
[284]

Blaizot, A. et al. (2022), “Using artificial intelligence methods for systematic review in health
sciences: A systematic review”, Research Synthesis Methods, Vol. 13/3, pp. 353-362,
https://doi.org/10.1002/jrsm.1553.
[114]

Blanc, F. (2018), From Chasing Violations to Managing Risks Origins, challenges and evolutions
in regulatory inspections,
https://www.elgaronline.com/monobook/9781788112482/9781788112482.xml (accessed on
28 May 2024).
[43]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 281
---
Blanchet, M. and M. Coueffe (2020), Improved GDP nowcasting using large datasets, Ministère
de l'Économie et des Finances, Direction générale du Trésor,
https://www.tresor.economie.gouv.fr/Articles/2020/04/09/tresor-economics-no-254-improved-
gdp-nowcasting-using-large-datasets.
[7]

Bloomberg Philanthropies (2023), State of Cities: Generative Al in Local Governments,
https://cityaiconnect.jhu.edu/pdfs/Final-Gen-Al-In-Cities-Report_10.18.2023.pdf.
[226]

Bohni Nielsen, S., F. Mazzeo Rinaldi and G. Petersson (2024), Artificial Intelligence and
Evaluation, Routledge, New York, https://doi.org/10.4324/9781003512493.
[118]

Boström, H. et al. (2020), Explaining Multivariate Time Series Forecasts: An Application to
Predicting the Swedish GDP, https://ceur-ws.org/Vol-2796/xi-ml-2020_bostrom.pdf.
[17]

Bright, J. et al. (2025), “Generative Al is already widespread in the public sector: evidence from a
survey of UK public sector professionals", Digital Government: Research and Practice,
Vol. 6/1, pp. 1-13, https://doi.org/10.1145/3700140.
[189]

Bright, J. et al. (2019), “Data Science for Local Government”, SSRN Electronic Journal,
https://doi.org/10.2139/ssrn.3370217.
[328]

Brioscú, A. et al. (2024), “A new dawn for public employment services: Service delivery in the
age of artificial intelligence”, OECD Artificial Intelligence Papers, No. 19, OECD Publishing,
Paris, https://doi.org/10.1787/5dc3eb8e-en.
[214]

Broecke, S. (2023), “Artificial intelligence and labour market matching", OECD Social,
Employment and Migration Working Papers, No. 284, OECD Publishing, Paris,
https://doi.org/10.1787/2b440821-en.
[52]

Brougham, D. and J. Haar (2017), “Smart Technology, Artificial Intelligence, Robotics, and
Algorithms (STARA): Employees' perceptions of our future workplace”, Journal of
Management &amp; Organization, Vol. 24/2, pp. 239-257,
https://doi.org/10.1017/jmo.2016.55.
[58]

Burger, M., A. Nitsche and J. Arlinghaus (2023), “Hybrid intelligence in procurement:
Disillusionment with Al's superiority?”, Computers in Industry, Vol. 150,
https://doi.org/10.1016/j.compind.2023.103946.
[90]

Byrom, N., M. Piccinin-Barbieri and P. Wells (2024), "Towards effective governance of justice
data", OECD Working Papers on Public Governance, No. 74, OECD Publishing, Paris,
https://doi.org/10.1787/d2950e02-en.
[313]

Campagnucci, F. et al. (2025), Artificial Intelligence for Participation, https://scope.uni-
muenster.de/wp-content/uploads/2025/01/ENG-Policy-Brief-Al_Jan2025.pdf.
[168]

Cappelli, P. and N. Rogovsky (2023), “Artificial intelligence in human resource management”,
ILO working paper, https://doi.org/10.54394/ohvv4382.
[59]

Carrasco, M. et al. (2019), The Citizen's Perspective on the Use of Al in Government,
https://www.bcg.com/en-ca/publications/2019/citizen-perspective-use-artificial-intelligence-
government-digital-benchmarking.
[187]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
282 |
---
Cary Coglianese (2024), “How to Regulate Artificial Intelligence", The Regulatory Review,
https://www.theregreview.org/2024/01/15/coglianese-how-to-regulate-artificial-intelligence/
(accessed on 28 May 2024).
[39]

СЕРЕЈ (2018), European ethical charter on the use of artificial intelligence in judicial systems
and their environment, https://rm.coe.int/ethical-charter-en-for-publication-4-december-
2018/16808f699c.
[291]

Chen, T., M. Gascó-Hernandez and M. Esteve (2023), “The Adoption and Implementation of
Artificial Intelligence Chatbots in Public Organizations: Evidence from U.S. State
Governments”, The American Review of Public Administration, Vol. 54/3, pp. 255-270,
https://doi.org/10.1177/02750740231200522.
[207]

ChileCompra (2024), Datos Abiertos de las compras públicas de Chile, https://datos-
abiertos.chilecompra.cl/.
[80]

Cintron, D. and B. Montrosse-Moorhead (2021), "Integrating Big Data Into Evaluation: R Code
for Topic Identification and Modeling”, American Journal of Evaluation, Vol. 43/3, pp. 412-436,
https://doi.org/10.1177/10982140211031640.
[123]

CMS (2023), CMS Expert Guide to Digital Litigation in Slovenia, https://cms.law/en/int/expert-
guides/cms-expert-guide-to-digital-litigation/slovenia (accessed on June 2024).
[297]

CNJ (2025), Labor Court launches artificial intelligence to assist professionals at the institution,
https://www.cnj.jus.br/justica-do-trabalho-lanca-inteligencia-artificial-para-auxiliar-
profissionais-da-instituicao/.
[295]

Cockx, B., M. Lechner and J. Bollens (2023), “Priority to unemployed immigrants? A causal
machine learning evaluation of training in Belgium", Labour Economics, Vol. 80, p. 102306,
https://doi.org/10.1016/j.labeco.2022.102306.
[204]

Collins, B. (2020), Transformational Results - Purchasing and Strategic Sourcing,
https://www2.elpasotexas.gov/municipal-clerk/agenda/04-27-20/1.1.2.pdf.
[69]

Colombia (2024), Information System of the Presidential Rapporteurship,
https://actosadministrativos.ramajudicial.gov.co/web/Acto%20Administrativo/Default.aspx?ID
=19280.
[317]

Cortés-Cediel, M. (2023), “Trends and challenges of e-government chatbots: Advances in
exploring open government data and citizen participation content.”, Government Information
Quarterly, Vol. 40/4, p. 101877, https://doi.org/10.1016/j.giq.2023.101877.
[171]

Council of Europe (2024), Framework Convention on Artificial Intelligence and Human Rights,
Democracy and the Rule of Law, https://www.coe.int/en/web/artificial-intelligence/the-
framework-convention-on-artificial-intelligence.
[319]

Court of Cassation of France (2024), The Court of Cassation facing digital technology and
artificial intelligence, https://www.vie-publique.fr/parole-dexpert/278415-la-cour-de-cassation-
face-au-numerique-et-lintelligence-artificielle.
[293]

Crisanto, J. et al. (2024), Regulating Al in the financial sector: recent developments and main
challenges, https://www.bis.org/fsi/publ/insights63.pdf.
[18]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
283
---
CSOs (2021), An EU Artificial Intelligence Act for Fundamental Rights: A Civil Society Statement, [280]
https://www.accessnow.org/wp-content/uploads/2021/11/joint-statement-EU-AIA.pdf.

da Rosa, I. (2023), Repository of existing projects on transparency in public procurement,
Publications Office of the European Union,
https://ted.europa.eu/documents/d/ted/final_analysis-report-on-the-inventory-of-contract-
registers_-isabel-da-rosa.
[86]

de Blasio, G., A. D'Ignazio and M. Letta (2022), “Gotham city. Predicting 'corrupted'
municipalities with machine learning", Technological Forecasting and Social Change,
Vol. 184, p. 122016, https://doi.org/10.1016/j.techfore.2022.122016.
[102]

De Miguel Beriain, I. (2018), "Does the use of risk assessments in sentences respect the right to
due process? A critical analysis of the Wisconsin v. Loomis ruling", Law, Probability and Risk,
Vol. 17/1, pp. 45-53, https://doi.org/10.1093/lpr/mgy001.
[308]

Dell'Acqua, F. et al. (2023), “Navigating the Jagged Technological Frontier: Field Experimental
Evidence of the Effects of Al on Knowledge Worker Productivity and Quality", SSRN
Electronic Journal, https://doi.org/10.2139/ssrn.4573321.
[126]

Dieterle, E., C. Dede and M. Walker (2024), “The cyclical ethical effects of using artificial
intelligence in education”, Al &amp; SOCIETY, Vol. 39/2, pp. 633-643,
https://doi.org/10.1007/s00146-022-01497-w.
[234]

DRCF (2023), Launch of the International Network for Digital Regulation Cooperation (INDRC),
https://www.drcf.org.uk/news-and-events/news/launch-of-international-network-for-digital-
regulation-cooperation-indrc.
[48]

EC (2020), Study on up-take of emerging technologies, European Commission,
https://joinup.ec.europa.eu/sites/default/files/news/2020-06/D.01.06_Final_report_v3.00.pdf.
[66]

EC JRC (2021), Selected Al cases in the public sector (JRC129301),
http://data.europa.eu/89h/7342ea15-fd4f-4184-9603-98bd87d8239a.
[218]

ECA (2024), Special report 05/2024: EU Transparency Register – provides useful but limited
information on lobbying activities, https://www.eca.europa.eu/en/publications/SR-2024-05.
[97]

ECMWF (2025), ECMWF's Al forecasts become operational,
https://www.ecmwf.int/en/about/media-centre/news/2025/ecmwfs-ai-forecasts-become-
operational (accessed on 4 March 2025).
[273]

EDPB-EDPS (2021), EDPB-EDPS Joint Opinion 5/2021 on the proposal for a Regulation of the
European Parliament and of the Council laying down harmonised rules on artificial
intelligence (Artificial Intelligence Act), https://www.edpb.europa.eu/our-work-tools/our-
documents/edpbedps-joint-opinion/edpb-edps-joint-opinion-52021-proposal_en.
[281]

Eisele, A. et al. (2024), “Exploring the potential of Claude 2 for risk of bias assessment: Using a
large language", p. 10.1101/2024.07.16.24310483.
[127]

Eisen, N. et al. (2023), Al can strengthen U.S. democracy—and weaken it,
https://www.brookings.edu/articles/ai-can-strengthen-u-s-democracy-and-weaken-it/.
[172]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# 284 |

El Morr, C. et al. (2024), “Al-based epidemic and pandemic early warning systems: A systematic [272]
scoping review", Health Informatics Journal, Vol. 30/3,
https://doi.org/10.1177/14604582241275844.

Equivant (2025), Solutions: Risk Needs Assessments, https://equivant- [307]
supervision.com/solutions/risk-needs-assessments/#COMPAS-R-P.

ERIC (2024), Electronic Registration Information Center (ERIC): Technology and, Electronic [174]
Registration Information Center, https://ericstates.org/wp-content/uploads/documents/ERIC-
Tech-Security-Brief.pdf.

EUCPN (2022), Artificial intelligence and predictive policing: risks and challenges, [285]
https://eucpn.org/document/recommendation-paper-artificial-intelligence-and-predictive-
policing-risks-and-challenges.

European Parliament (2022), Report on Artificial Intelligence in a Digital Age, [155]
https://www.europarl.europa.eu/doceo/document/A-9-2022-0088_EN.html.

Evans, N. (2022), “Policing the pandemic in Australia and New Zealand: lessons for trust and [286]
legitimacy", Journal of Criminological Research, Policy and Practice, Vol. 9/2, pp. 106-122,
https://doi.org/10.1108/jcrpp-10-2022-0050.

Faculty (2021), Automated approaches to measuring online experiences, [37]
https://www.ofcom.org.uk/__data/assets/pdf_file/0015/220425/automated-tooling-report.pdf.

Ferretti, S. (2023), “Hacking by the prompt: Innovative ways to utilize ChatGPT for evaluators”, [133]
New Directions for Evaluation, Vol. 2023/178-179, pp. 73-84,
https://doi.org/10.1002/ev.20557.

Fillet, S. (2024), Cambridge City Council analyzes input 50% faster with Go Vocal's Al assistant, [167]
https://www.govocal.com/case-studies/cambridge-city-council-analyzes-input-50-faster-with-
go-vocals-ai-assistant.

Fishkin, J. and A. al (2021), Final Report - LXS 400 - Chile Delibera, [163]
https://drive.google.com/file/d/1Vt5XaTk2MW9M_VBN2oztK2nxYZdckl89/view.

Franzen, S. et al. (2022), Advanced Content Analysis: Can Artificial Intelligence Accelerate [122]
Theory-Driven Complex Program Evaluation?, World Bank Group,
https://documents1.worldbank.org/curated/en/400031645128516191/pdf/Advanced-Content-
Analysis-Can-Artificial-Intelligence-Accelerate-Theory-Driven-Complex-Program-
Evaluation.pdf.

French Public Finances General Directorate (DGFIP) (2024), Digital Transformation of the Public [13]
Finances General Directorate (DGFIP).

French Public Finances General Directorate (DGFIP) (2024), The predictive model. [12]

Friton, P. et al. (2024), Public Procurement of Al: Current and Future Challenges, [62]
https://www.lexology.com/library/detail.aspx?g=2c131357-03ed-4965-aa19-e28a65dd9ad6
(accessed on 30 May 2024).

Garcia Rodriguez, M. et al. (2022), “Collusion detection in public procurement auctions with [71]
machine learning algorithms”, Automation in Construction, Vol. 133, p. Article 104047,
https://doi.org/10.1016/j.autcon.2021.104047.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 285

Gastaldi, L. et al. (2024), Al in Public Settings: Status and Next Steps, [64]
https://www.dt.mef.gov.it/export/sites/sitodt/modules/documenti_it/analisi_progammazione/not
e_tematiche/Nota-Tematica-n-1-February-2024.pdf.

Gatto, L. and P. Bundi (2025), The Use of Quantitative Text Analysis in Evaluations, Routledge, [120]
https://doi.org/10.4324/9781003512493-8.

Gesk, T. and M. Leyer (2022), “Artificial intelligence in public services: When and why citizens [203]
accept its usage", Government Information Quarterly, Vol. 39/3, p. 101704,
https://doi.org/10.1016/j.giq.2022.101704.

GFDRR (2018), Machine Learning for Disaster Risk Management, [267]
http://creativecommons.org/licenses/by/3.0/igo/www.worldbank.org.

Giest, S. and S. Grimmelikhuijsen (eds.) (2020), “Artificial intelligence, bureaucratic form, and [248]
discretion in public service”, Information Polity, Vol. 25/4, pp. 491-506,
https://doi.org/10.3233/ip-200223.

Glas, A. and F. Kleeman (2016), “The Impact of Industry 4.0 on Procurement and Supply [65]
Management: A Conceptual and Qualitative Analysis”, International Journal of Business and
Management Invention, Vol. 5/6, pp. 55-66, https://doi.org/10.1590/0103-6513.20180104.

GLOBO (2018), Como as robôs Alice, Sofia e Monica ajudam o TCU a caçar irregularidades em [82]
licitações, https://g1.globo.com/economia/tecnologia/noticia/como-as-robos-alice-sofia-e-
monica-ajudam-o-tcu-a-cacar-irregularidades-em-licitacoes.ghtml.

Gmyrek, P., J. Berg and D. Bescond (2023), Generative Al and Jobs: A global analysis of [57]
potential effects on job quantity and quality, ILO, https://doi.org/10.54394/FHEM8239.

GOV.UK (2019), Guidance - Understanding artificial intelligence ethics and safety, [85]
https://www.gov.uk/guidance/understanding-artificial-intelligence-ethics-and-safety.

Government of Iceland (2023), Head Start for Icelandic, https://www.government.is/diplomatic- [180]
missions/embassy-article/2023/03/14/Head-start-for-Icelandic/ (accessed on 23 May 2024).

Government of Mexico (2024), Programa Anual de Adquisiciones, Arrendamientos, Servicios y [81]
Obra Pública., https://upcp-compranet.hacienda.gob.mx/paaasopdashboard.

Government of Mexico (2023), Plataforma inteligente de apoyos del Gobierno Federal, [16]
https://www.transparenciapresupuestaria.gob.mx/es/apoyosdelgobierno (accessed on 20
April 2024).

Government of Peru (2023), Sistema con inteligencia artificial permitirá a jueces resolver solo [300]
casos de violencia severo o muy severo, https://www.gob.pe/institucion/pj/noticias/774687-
sistema-con-inteligencia-artificial-permitira-a-jueces-resolver-solo-casos-de-violencia-severo-
o-muy-severo.

Government of Portugal (2024), Guia Prático da Justiça, https://justica.gov.pt/Servicos/Guia- [304]
pratico-da-Justica.

Government of Spain (2007), VioGén, https://www.interior.gob.es/opencms/es/servicios-al- [305]
ciudadano/violencia-contra-la-mujer/sistema-viogen/.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# 286 |

Green, B. (2022), “The flaws of policies requiring human oversight of government algorithms”, [237]
Computer Law & Security Review, Vol. 45, p. 105681,
https://doi.org/10.1016/j.clsr.2022.105681.

Grgić-Hlača, N. et al. (2018), “Beyond Distributive Fairness in Algorithmic Decision Making: [309]
Feature Selection for Procedurally Fair Learning", Proceedings of the AAAI Conference on
Artificial Intelligence, Vol. 32/1, https://doi.org/10.1609/aaai.v32i1.11296.

Guida, M. et al. (2023), “The role of artificial intelligence in the procurement process: State of the [67]
art and research agenda”, Journal of Purchasing and Supply Management, Vol. 29/2,
p. Article 100823, https://doi.org/10.1016/j.pursup.2023.100823.

Guio, A. and K. Müller-Daubermann (2024), Insights and Recommendations for Policy Makers in [27]
Latin America and the Caribbean, Global Network of Internet and Society Research Centers,
https://networkofcenters.net/sites/networkofcenters.net/files/Summary%20Report%20AI%20
Governance%20Costa%20Rica%20NoC.pdf.

Hadfi, R. et al. (2021), “Argumentative Conversational Agents for Online Discussions”, Journal of [176]
Systems Science and Systems Engineering, https://doi.org/10.1007/s11518-021-5497-1.

Halpern, D. and D. Maru (2024), Global Evidence Report: A blueprint for better international [139]
collaoration on evidence, https://www.bi.team/wp-content/uploads/2024/08/ESRC-Global-
Evidence-Report-September-2024.pdf.

Handfield, R., S. Jeong and T. Choi (2019), "Emerging procurement technology: data analytics [87]
and cognitive analytics", International Journal of Physical Distribution & Logistics
Management, Vol. 49/10, https://doi.org/10.1108/IJPDLM-11-2017-0348.

Heikkila, M. (2022), Al: Decoded: A Dutch algorithm scandal serves a warning to Europe — The [92]
Al Act won't save us, https://www.politico.eu/newsletter/ai-decoded/a-dutch-algorithm-
scandal-serves-a-warning-to-europe-the-ai-act-wont-save-us-2/.

Hickok, M. (2022), Public procurement of artificial intelligence systems: new risks and future [63]
proofing., https://doi.org/10.1007/s00146-022-01572-2.

Horowitz, M. (2023), Bending the Automation Bias Curve: A Study of Human and Al-based [129]
Decision Making in National Security Contexts, https://arxiv.org/abs/2306.16507.

Hung, T. and C. Yen (2020), “On the person-based predictive policing of Al", Ethics and [260]
Information Technology, Vol. 23/3, pp. 165-176, https://doi.org/10.1007/s10676-020-09539-x.

Hutchins, B. and M. Andrejevic (2021), Olympian Surveillance: Sports Stadiums and the [257]
Normalization of Biometric Monitoring, https://ijoc.org/index.php/ijoc/article/view/16377.

IBM (2023), Government Procurement and Acquisition: Opportunities and challenges presented [88]
by artificial intelligence and machine learning, IBM Center for The Business of Government,
https://www.businessofgovernment.org/sites/default/files/Government%20Procurement%20a
nd%20Acquisition_0.pdf.

Jacob, S. (2025), "Artificial Intelligence and the Future of Evaluation: From Augmented to [125]
Automated Evaluation”, Digital Government: Research and Practice, Vol. 6/1, pp. 1-10,
https://doi.org/10.1145/3696009.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# | 287

Jarrahi, M. et al. (2023), “Artificial intelligence and knowledge management: A partnership [202]
between human and Al”, Business Horizons, Vol. 66/1, pp. 87-99,
https://doi.org/10.1016/j.bushor.2022.03.002.

Jevinger, Å. et al. (2023), “Artificial intelligence for improving public transport: a mapping study”, [221]
Public Transport, Vol. 16/1, pp. 99-158, https://doi.org/10.1007/s12469-023-00334-7.

Johnson, B., J. Coggburn and J. Llorens (2022), "Artificial Intelligence and Public Human [50]
Resource Management: Questions for Research and Practice", Public Personnel
Management, Vol. 51/4, pp. 538-562, https://doi.org/10.1177/00910260221126498.

Juneja, P. (2024), Artificial Intelligence for Electoral Management, International Institute for [173]
Democracy and Electoral Assistance, https://doi.org/10.31752/idea.2024.31.

Jung, J., M. Patnam and A. Ter-Martirosyan (2018), An Algorithmic Crystal Ball: Forecasts- [5]
based on Machine Learning, International Monetary Fund,
https://www.imf.org/en/Publications/WP/Issues/2018/11/01/An-Algorithmic-Crystal-Ball-
Forecasts-based-on-Machine-Learning-46288.

Katona, E. and M. Fazekas (2024), Hidden barriers to open competition: Using text mining to [72]
uncover corrupt restrictions to competition in public procurement,
https://www.govtransparency.eu/wp-content/uploads/2024/05/Katona-Fazekas_HU_text-
miningPP-corruption240417_GTIpublish240430final.pdf.

Kelly, S., S. Kaye and O. Oviedo-Trespalacios (2023), “What factors contribute to the [250]
acceptance of artificial intelligence? A systematic review”, Telematics and Informatics,
Vol. 77, p. 101925, https://doi.org/10.1016/j.tele.2022.101925.

Khalifa, M. and M. Albadawy (2024), “Artificial Intelligence for Clinical Prediction: Exploring Key [215]
Domains and Essential Functions”, Computer Methods and Programs in Biomedicine Update,
Vol. 5, p. 100148, https://doi.org/10.1016/j.cmpbup.2024.100148.

Khalil, H., D. Ameen and A. Zarnegar (2022), Tools to support the automation of systematic [112]
reviews: a scoping review, J Clin Epidemiology, https://doi.org/10.1016/j.jclinepi.2021.12.005.

Khan, I. et al. (2022), Mandates of the Special Rapporteur (Ref.: OL IRL 3/2022), [282]
https://spcommreports.ohchr.org/TMResultsBase/DownLoadPublicCommunicationFile?gId=2
7594.

Kim, S. et al. (2021), “Moderator Chatbot for Deliberative Discussion”, Proceedings of the ACM [177]
on Human-Computer Interaction, Vol. 5/CSCW1, pp. 1-26, https://doi.org/10.1145/3449161.

Klein, A. (2020), Reducing bias in Al-based financial services, [20]
https://www.brookings.edu/articles/reducing-bias-in-ai-based-financial-services.

Kleinberg, J. et al. (2017), “Human Decisions and Machine Predictions*", The Quarterly Journal [326]
of Economics, https://doi.org/10.1093/qje/qjx032.

Köbis, N., C. Starke and I. Rahwan (2022), “The promise and perils of using artificial intelligence [103]
to fight corruption”, Nature Machine Intelligence, Vol. 4/5, pp. 418-424,
https://doi.org/10.1038/s42256-022-00489-1.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

# 288 |

Köbis, N., C. Starke and I. Rahwan (2021), Artificial Intelligence as an Anti-Corruption Tool (AI- [95]
ACT) -- Potentials and Pitfalls for Top-down and Bottom-up Approaches,
https://arxiv.org/abs/2102.11567.

Kopponen, A. et al. (2024), “Personalised public services powered by Al: the citizen digital twin [211]
approach", in Research Handbook on Public Management and Artificial Intelligence, Edward
Elgar Publishing, https://doi.org/10.4337/9781802207347.00020.

Korea Fiscal Information Service (KFIS) (2023), Digital Transformation in Public Finance: Korean [9]
FMIS (dBrain+).

Labanava, A. et al. (2022), “Capacity Building in Government: Towards Developing a Standard [241]
for a Functional Specialist in Al for Public Services", in Communications in Computer and
Information Science, Future Data and Security Engineering. Big Data, Security and Privacy,
Smart City and Industry 4.0 Applications, Springer Nature Singapore, Singapore,
https://doi.org/10.1007/978-981-19-8069-5_34.

Lai, H. et al. (2024), “Assessing the Risk of Bias in Randomized Clinical Trials With Large [116]
Language Models”, JAMA Network Open, Vol. 7/5, p. e2412687,
https://doi.org/10.1001/jamanetworkopen.2024.12687.

Landemore, H. (2022), “Can Al bring deliberative democracy to the masses?", [156]
https://www.law.nyu.edu/sites/default/files/Helen%20Landemore%20Can%20AI%20bring%20
deliberative%20democracy%20to%20the%20masses.pdf.

Lecorps, Y. and G. Tissandier (2022), “PAVED With Good Intentions? An Evaluation of a French [283]
Police Predictive Policing System”, SSRN Electronic Journal,
https://doi.org/10.2139/ssrn.4314831.

Leeuw, F. (2003), “Reconstructing Program Theories: Methods Available and Problems to be [121]
Solved", The American Journal of Evaluation, Vol. 24/1, pp. 5-20,
https://doi.org/10.1016/s1098-2140(02)00271-0.

Leyer, M. and S. Schneider (2021), "Decision augmentation and automation with artificial [196]
intelligence: Threat or opportunity for managers?", Business Horizons, Vol. 64/5, pp. 711-724,
https://doi.org/10.1016/j.bushor.2021.02.026.

Linders, D., C. Liao and C. Wang (2018), “Proactive e-Governance: Flipping the service delivery [321]
model from pull to push in Taiwan", Government Information Quarterly, Vol. 35/4, pp. S68-
S76, https://doi.org/10.1016/j.giq.2015.08.004.

López-Iturriaga, F. and I. Sanz (2017), "Predicting Public Corruption with Neural Networks: An [73]
Analysis of Spanish Provinces", Social Indicators Research, Vol. 140/3, pp. 975-998,
https://doi.org/10.1007/s11205-017-1802-2.

Lorenz, P., K. Perset and J. Berryhill (2023), "Initial policy considerations for generative artificial [190]
intelligence", OECD Artificial Intelligence Papers, No. 1, OECD Publishing, Paris,
https://doi.org/10.1787/fae2d1e6-en.

Macnish, K., D. Wright and T. Jiya (2021), "Correction to: Predictive Policing in 2025: A [220]
Scenario", in Advanced Sciences and Technologies for Security Applications, Policing in the
Era of Al and Smart Societies, Springer International Publishing, Cham,
https://doi.org/10.1007/978-3-030-50613-1_13.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 289
Madan, R. and M. Ashok (2023), “Al adoption and diffusion in public administration: A systematic literature review and future research agenda”, Government Information Quarterly, Vol. 40/1, p. 101774, https://doi.org/10.1016/j.giq.2022.101774.
[194]

Marcucci, S. and S. Verhulst (2025), Reimagining the Policy Cycle in the Age of Artificial Intelligence, Elsevier BV, https://doi.org/10.2139/ssrn.5137557.
[128]

Margetts, H. (2011), “The Internet and Transparency”, The Political Quarterly, Vol. 82/4, pp. 518- 521, https://doi.org/10.1111/j.1467-923x.2011.02253.x.
[185]

Margetts, H. and C. Dorobantu (2019), “Rethink government with Al”, Nature, Vol. 568/7751, pp. 163-165, https://doi.org/10.1038/d41586-019-01099-5.
[322]

Martin, P. (2023), Policy modelling with Rules as Code (RaC), https://salsa.digital/insights/policy-modelling-with-rules-as-code-rac.
[33]

McKendrick, K. (2019), Artificial Intelligence Prediction and Counterterrorism, https://www.chathamhouse.org/sites/default/files/2019-08-07-AICounterterrorism.pdf.
[261]

Medaglia, R., J. Gil-Garcia and T. Pardo (2021), "Artificial Intelligence in Government: Taking Stock and Moving Forward", Social Science Computer Review, Vol. 41/1, pp. 123-140, https://doi.org/10.1177/08944393211034087.
[238]

Medaglia, R., P. Mikalef and L. Tangi (2025), Competences and governance practices for artificial intelligence in the public sector, European Commission: Joint Research Centre, https://doi.org/10.2760/7895569.
[239]

Milanez, A., A. Lemmens and C. Ruggiu (2025), “Algorithmic management in the workplace: New evidence from an OECD employer survey”, OECD Artificial Intelligence Papers, No. 31, OECD Publishing, Paris, https://doi.org/10.1787/287c13c4-en.
[53]

Miller, S. (2020), “Causal Forest estimation of heterogeneous and time-varying environmental policy effects", journal of environmental Economics and Management, Vol. 103, https://doi.org/10.1016/j.jeem.2020.102337.
[124]

Miller, S. and L. Keiser (2020), “Representative Bureaucracy and Attitudes Toward Automated Decision Making”, Journal of Public Administration Research and Theory, Vol. 31/1, pp. 150-165, https://doi.org/10.1093/jopart/muaa019.
[195]

Minozzi, S. et al. (2020), The revised Cochrane risk of bias tool for randomized trials (RoB 2) showed low interrater reliability and challenges in its application, Journal of Clinical Epidemiology, https://doi.org/10.1016/j.jclinepi.2020.06.015.
[115]

MITRE (2023), Searching for Solutions: MITRE Tool Simplifies Freedom of Information Act Requests, https://www.mitre.org/news-insights/impact-story/mitre-tool-simplifies-freedom-information-act-requests.
[148]

Mohun, J. and A. Roberts (2020), “Cracking the code: Rulemaking for humans and machines”, OECD Working Papers on Public Governance, No. 42, OECD Publishing, Paris, https://doi.org/10.1787/3afe6ba5-en.
[4]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

290 |
Mpofu, F. (2023), “The application of Artificial Intelligence in external auditing and its implications on audit quality? A review of the ongoing debates", International Journal of Research in Business and Social Science (2147-4478), Vol. 12/9, pp. 496-512, https://doi.org/10.20525/ijrbs.v12i9.2737.
[104]

Næss, T. et al. (2025), Text Mining and Machine Learning in a Performance Audit of Police Handling of Cybercrime in Norway, Routledge, https://doi.org/10.4324/9781003512493.
[119]

National Documentation Center (EKT) (2025),, https://www.didaktorika.gr/eadd/.
[150]

NCDIT (2024), New Chatbot Helps Answer IT Procurement Questions, https://it.nc.gov/blog/2024/04/04/new-chatbot-helps-answer-it-procurement-questions (accessed on 19 February 2024).
[70]

Nelson, D., Y. He and G. Moore (2024), “Trends and applications in wildfire burned area mapping: Remote sensing data, cloud geoprocessing platforms, and emerging algorithms", Geomatica, Vol. 76/1, p. 100008, https://doi.org/10.1016/j.geomat.2024.100008.
[269]

Nesta (2024), Innovation Policy Simulation for the Smart Economy, https://www.nesta.org.uk/feature/smarter-policy-through-simulation/innovation-policy-simulation-for-the-smart-economy/.
[32]

Netherlands Ministry of the Interior and Kingdom Relations (2019), NL Digital Data Agenda Government, https://www.nldigitalgovernment.nl/wp-content/uploads/sites/11/2019/04/data-agenda-government.pdf.
[138]

Nikiforova, A. et al. (2023), PPPS’2023-Proactive and Personalised Public Services: Searching for Meaningful Human Control in Algorithmic Government, https://ceur-ws.org/Vol-3449/paper27.pdf.
[230]

Odell, C. (2024), Why we need to explore the use of Al in evidence synthesis: Reflections from the Global Evidence Summit 2024, https://researchforevidence.fhi360.org/need-explore-use-ai-evidence-synthesis-reflections-global-evidence-summit-2024.
[117]

Odilla, F. (2023), "Bots against corruption: Exploring the benefits and limitations of Al-based anti-corruption technology", Crime, Law and Social Change, Vol. 80/4, pp. 353-396, https://doi.org/10.1007/s10611-023-10091-0.
[99]

OECD (2025), "Al and the future of social protection in OECD countries", OECD Artificial Intelligence Papers, No. 42, OECD Publishing, Paris, https://doi.org/10.1787/7b245f7e-en.
[212]

OECD (2025), How Innovation Ecosystems Foster Citizen Participation Using Emerging Technologies in Portugal, Spain and the Netherlands, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/2cb37a30-en.
[192]

OECD (2025), Implementation Toolkit for the OECD Recommendation on Public Policy Evaluation, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/77faa4fe-en.
[107]

OECD (2025), OECD Regulatory Policy Outlook 2025, OECD Publishing, Paris, https://doi.org/10.1787/56b60e39-en.
[31]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 291
OECD (2025), Prevention of Stalking Crimes Powered by Smart CCTV Video Analysis Technology, https://oecd-opsi.org/innovations/prevention-of-stalking-crimes-powered-by-smart-cctv-video-analysis-technology/ (accessed on 12 March 2025).
[266]

OECD (2025), “Tackling civic participation challenges with emerging technologies: Beyond the hype", OECD Public Governance Policy Papers, No. 72, OECD Publishing, Paris, https://doi.org/10.1787/ec2ca9a2-en.
[183]

OECD (2025), “Towards a common reporting framework for Al incidents”, OECD Artificial Intelligence Papers, No. 34, OECD Publishing, Paris, https://doi.org/10.1787/f326d4ac-en.
[320]

OECD (2024), “2023 OECD Digital Government Index: Results and key findings", OECD Public Governance Policy Papers, No. 44, OECD Publishing, Paris, https://doi.org/10.1787/1a89ed5e-en.
[188]

OECD (2024), Al in Health: Huge potential, huge risks, https://www.oecd.org/health/Al-in-health-huge-potential-huge-risks.pdf.
[244]

OECD (2024), Anti-Corruption and Integrity Outlook 2024, OECD Publishing, Paris, https://doi.org/10.1787/968587cd-en.
[93]

OECD (2024), “Assessing potential future artificial intelligence risks, benefits and policy imperatives", OECD Artificial Intelligence Papers, No. 27, OECD Publishing, Paris, https://doi.org/10.1787/3f4e3dfb-en.
[29]

OECD (2024), Enabling Digital Innovation in Government: The OECD GovTech Policy Framework, OECD Digital Government Studies, OECD Publishing, Paris, https://doi.org/10.1787/a51eb9b2-en.
[146]

OECD (2024), Facts not Fakes: Tackling Disinformation, Strengthening Information Integrity, OECD Publishing, Paris, https://doi.org/10.1787/d909ff7a-en.
[24]

OECD (2024), “Financial Management Information Systems in OECD countries”, OECD Papers on Budgeting, No. 2024/02, OECD Publishing, Paris, https://doi.org/10.1787/ce8367cd-en.
[21]

OECD (2024), “Fixing frictions: 'sludge audits' around the world: How governments are using behavioural science to reduce psychological burdens in public services”, OECD Public Governance Policy Papers, No. 48, OECD Publishing, Paris, https://doi.org/10.1787/5e9bb35c-en.
[253]

OECD (2024), Framework for the Anticipatory Governance of Emerging Technologies, https://doi.org/10.1787/0248ead5-en.
[144]

OECD (2024), Global Trends in Government Innovation 2024: Fostering Human-Centred Public Services, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/c1bc19c3-en.
[201]

OECD (2024), “Governing with Artificial Intelligence: Are governments ready?”, OECD Artificial Intelligence Papers, No. 20, OECD Publishing, Paris, https://doi.org/10.1787/26324bc2-en.
[60]

OECD (2024), Modernising Access to Social Protection: Strategies, Technologies and Data Advances in OECD Countries, OECD Publishing, Paris, https://doi.org/10.1787/af31746d-en.
[210]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

292 |
OECD (2024), OECD Digital Economy Outlook 2024 (Volume 1): Embracing the Technology Frontier, OECD Publishing, Paris, https://doi.org/10.1787/a1689dc5-en.
[259]

OECD (2024), OECD Survey on Drivers of Trust in Public Institutions – 2024 Results: Building Trust in a Complex Policy Environment, OECD Publishing, Paris, https://doi.org/10.1787/9a20554b-en.
[46]

OECD (2024), Public procurement, https://www.oecd.org/en/topics/public-procurement.html.
[61]

OECD (2024), Recommendation of the Council on Artificial Intelligence, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449 (accessed on 2 June 2024).
[91]

OECD (2024), Reinforcing democracy initiative, https://www.oecd.org/en/about/programmes/reinforcing-democracy-initiative.
[142]

OECD (2024), Shaping smart cities of all sizes, OECD Publishing, https://oe.cd/cities-2024-roundtable.
[224]

OECD (2024), Strengthening Oversight of the Court of Auditors for Effective Public Procurement in Portugal: Digital Transformation and Data-driven Risk Assessments, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/35aeab1e-en.
[75]

OECD (2023), 2023 OECD Open, Useful and Re-usable data (OURdata) Index: Results and key findings, OECD Publishing, https://doi.org/10.1787/a37f51c3-en.
[315]

OECD (2023), “Al language models: Technological, socio-economic and policy considerations", OECD Digital Economy Papers, No. 352, OECD Publishing, Paris, https://doi.org/10.1787/13d38f92-en.
[182]

OECD (2023), "Emerging privacy-enhancing technologies: Current regulatory and policy approaches", OECD Digital Economy Papers, No. 351, OECD Publishing, Paris, https://doi.org/10.1787/bf121be4-en.
[231]

OECD (2023), Engaging citizens in innovation policy: Why, when and how?, OECD Publishing, https://doi.org/10.1787/ba068fa6-en.
[141]

OECD (2023), Global Trends in Government Innovation 2023, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/0655b570-en.
[2]

OECD (2023), Government at a Glance 2023, OECD Publishing, Paris, https://doi.org/10.1787/3d5c5d31-en.
[34]

OECD (2023), OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market, OECD Publishing, Paris, https://doi.org/10.1787/08785bba-en.
[54]

OECD (2023), Open Government for Stronger Democracies: A Global Assessment, OECD Publishing, https://doi.org/10.1787/5478db5b-en.
[151]

OECD (2023), Public Employment and Management 2023: Towards a Flexible Public Service, OECD Publishing, Paris, https://doi.org/10.1787/5b378e11-en.
[51]

OECD (2023), Recommendation of the Council on Access to Justice and People-Centred Justice Systems, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0498.
[289]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

***

| 293
OECD (2023), Smart City Data Governance: Challenges and the Way Forward, OECD Urban Studies, OECD Publishing, Paris, https://doi.org/10.1787/e57ce301-en.
[225]

OECD (2022), “2022 OECD Financial Management and Reporting Survey", https://data-explorer.oecd.org (accessed on 22 April 2024).
[23]

OECD (2022), Building Trust to Reinforce Democracy: Main Findings from the 2021 OECD Survey on Drivers of Trust in Public Institutions, Building Trust in Public Institutions, OECD Publishing, Paris, https://doi.org/10.1787/b407f99c-en.
[143]

OECD (2022), Exploring Innovation in Law Enforcement: Opportunities and critical considerations, OECD Publishing, https://oecd-opsi.org/blog/exploring-innovation-in-law-enforcement/.
[256]

OECD (2022), OECD Guidelines for Citizen Participation Processes, OECD Publishing, https://doi.org/10.1787/f765caf6-en.
[184]

OECD (2022), Supporting Health Innovation with Fair Information Practice Principles, https://www.oecd.org/content/dam/oecd/en/topics/policy-sub-issues/digital-health-systems/oecd-israel-health-data-governance-workshop-report.pdf.
[246]

OECD (2022), Tax Administration 2022: Comparative Information on OECD and other Advanced and Emerging Economies, OECD Publishing, Paris, https://doi.org/10.1787/1e797131-en.
[1]

OECD (2022), The Protection and Promotion of Civic Space: Strengthening Alignment with International Standards and Guidance, OECD Publishing, https://doi.org/10.1787/d234e975-en.
[152]

OECD (2021), Countering Public Grant Fraud in Spain: Machine Learning for Assessing Risks and Targeting Control Activities, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/0ea22484-en.
[96]

OECD (2021), Data-Driven, Information-Enabled Regulatory Delivery, OECD Publishing, Paris, https://doi.org/10.1787/8f99ec8c-en.
[25]

OECD (2021), Evaluation Guidelines for Representative Deliberative Processes, OECD Publishing, https://doi.org/10.1787/10ccbfcb-en.
[175]

OECD (2021), OECD Regulatory Policy Outlook 2021, OECD Publishing, Paris, https://doi.org/10.1787/38b0fdb1-en.
[28]

OECD (2021), Public Employment and Management 2021: The Future of the Public Service, OECD Publishing, Paris, https://doi.org/10.1787/938f0d65-en.
[49]

OECD (2021), Recommendation of the Council for Agile Regulatory Governance to Harness Innovation, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0464.
[329]

OECD (2021), Recommendation of the Council on Enhancing Access to and Sharing of Data, OECD Publishing, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0463.
[47]

OECD (2020), Artificial Intelligence & Responsible Business Conduct, https://mneguidelines.oecd.org/RBC-and-artificial-intelligence.pdf.
[254]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

294 |
OECD (2020), Improving Governance with Policy Evaluation: Lessons From Country Experiences, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/89b1577d-en.
[108]
OECD (2020), Innovative Citizen Participation and New Democratic Institutions: Catching the Deliberative Wave, OECD Publishing, https://doi.org/10.1787/339306da-en.
[161]
OECD (2020), Public Provider versus Big Brother, OECD Publishing, https://trends.oecd-opsi.org/trend-reports/public-provider-versus-big-brother/.
[255]
OECD (2020), Shaping the Future of Regulators: The Impact of Emerging Technologies on Economic Regulators, The Governance of Regulators, OECD Publishing, Paris, https://doi.org/10.1787/db481aa3-en.
[36]
OECD (2020), Tax Administration 3.0: The Digital Transformation of Tax Administration, OECD Publishing, Paris, https://doi.org/10.1787/ca274cc5-en.
[3]
OECD (2020), “Tracking and tracing COVID: Protecting privacy and data while using apps and biometrics", OECD Policy Responses to Coronavirus (COVID-19), OECD Publishing, Paris, https://doi.org/10.1787/8f394636-en.
[278]
OECD (2018), OECD Regulatory Enforcement and Inspections Toolkit, OECD Publishing, Paris, https://doi.org/10.1787/9789264303959-en.
[42]
OECD (2017), Recommendation of the Council on Health Data Governance, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0433.
[245]
OECD (2017), Recommendation of the Council on Open Government, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0438.
[140]
OECD (2015), Recommendation of the Council on Public Procurement, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0411 (accessed on 2 June 2024).
[74]
OECD (2014), Regulatory Enforcement and Inspections, OECD Best Practice Principles for Regulatory Policy, OECD Publishing, Paris, https://doi.org/10.1787/9789264208117-en.
[41]
OECD OPSI (2019), Kol Zchut, https://oecd-opsi.org/innovations/kol-zchut/.
[153]
OECD/CAF (2022), The Strategic and Responsible Use of Artificial Intelligence in the Public Sector of Latin America and the Caribbean, OECD Public Governance Reviews, OECD Publishing, Paris, https://doi.org/10.1787/1f334543-en.
[298]
OECD/EU (2024), Reforming Regulatory Inspections in Italy at Regional and National Level 21IT12 (Final Report), https://reform-support.ec.europa.eu/document/download/e2ad74a6-9bf9-4eef-8ffc-a8f2aaee3ccd_cs?filename=05nov2024%20Final%20Report%2021IT12%20Reforming%20inspections%20in%20ltaly.pdf.
[40]
OECD/UNESCO (2024), G7 Toolkit for Artificial Intelligence in the Public Sector, OECD Publishing, Paris, https://doi.org/10.1787/421c1244-en.
[131]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 295
Ojo, A., S. Mellouli and F. Ahmadi Zeleti (2019), “A Realist Perspective on Al-era Public Management*", Proceedings of the 20th Annual International Conference on Digital Government Research, https://doi.org/10.1145/3325112.3325261.
[327]
Ovadya, A. (2023), “Bridging Systems: Open Problems for Countering Destructive Divisiveness across Ranking, Recommenders, and Governance", Arxiv, https://arxiv.org/abs/2301.09976.
[158]
Palkeet (2024), RPA/Al in Financial Management.
[14]
Pawlowski, C. and H. Scholta (2023), “A taxonomy for proactive public services", Government Information Quarterly, Vol. 40/1, p. 101780, https://doi.org/10.1016/j.giq.2022.101780.
[222]
Peixoto, T., O. Canuto and L. Jordan (2024), Al and the Future of Government: Unexpected Effects and Critical Challenges, https://www.policycenter.ma/publications/ai-and-future-government-unexpected-effects-and-critical-challenges.
[178]
Perry, A. and N. Lee (2019), Al is coming to schools, and if we're not careful, so will its biases, https://www.brookings.edu/articles/ai-is-coming-to-schools-and-if-were-not-careful-so-will-its-biases/.
[233]
Perry, W. et al. (2013), Predictive Policing: The Role of Crime Forecasting in Law Enforcement Operations, RAND Corporation, Santa Monica, CA, https://doi.org/10.7249/RR233.
[287]
PetaBencana.id (2021), As Jakarta floods again, humanitarian chatbots on social media support community-led disaster response, https://info.petabencana.id/2021/02/22/as-jakarta-floods-again-humanitarian-chatbots-on-social-media-support-community-led-disaster-response/ (accessed on 4 March 2025).
[276]
Petersson, G. et al. (2017), Cyber Society, Big Data, and Evaluation, Routledge, https://www.routledge.com/Cyber-Society-Big-Data-and-Evaluation/Petersson-Breul/p/book/9781138483033?srsltid=AfmBOooqz5iNGr7Tpm5k4aiNFcJc0RAx_yZwMW42X6AiuvNZIs0Q3bi_.
[109]
Petra, B. et al. (2024), Strategies to Counter Artificial Intelligence in Law Enforcement: Cross-Country Comparison of Citizens in Greece, Italy and Spain, https://arxiv.org/abs/2405.19970.
[288]
Policy Lab Digital, Work & Society within the German Federal Ministry of Labour and Social Affairs (2024), Guidelines for the Use of Al in the Administrative Work of Employment and Social Protection Services, https://www.denkfabrik-bmas.de/fileadmin/Downloads/Publikationen/Guidelines_for_the_use_of_ai_in_the_administrative_work_of_employment_and_social_protection_services.pdf.
[213]
Productivity Committee (2024), Making the Most of the Al Opportunity: Data Availability and Use, https://www.pc.gov.au/research/completed/making-the-most-of-the-ai-opportunity/ai-paper3-data.pdf.
[45]
Queen Mary University of London; Centre for European Policy Studies (2021), Criminal Justice, Fundamental Rights and the Rule of Law in the Digital Age, https://cdn.ceps.eu/wp-content/uploads/2021/05/Criminal-Justice-Fundamental-Rights-and-the-Rule-of-law-in-the-Digital-Age.pdf.
[311]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
296 |
Ramires Hernández, P., D. Valle-Cruz and R. Mendoza Méndez (2022), “Review on the Application of Artificial Intelligence-Based Chatbots in Public Administration”, in Handbook of Research on Applied Artificial Intelligence and Robotics for Government Processes, Advances in Computational Intelligence and Robotics, IGI Global, https://doi.org/10.4018/978-1-6684-5624-8.ch007.
[206]
Rane, N., S. Choudhary and J. Rane (2024), “Artificial intelligence for enhancing resilience”, Journal of Applied Artificial Intelligence, Vol. 5/2, pp. 1-33, https://doi.org/10.48185/jaai.v5i2.1053.
[249]
Redden, J. et al. (2022), Automating Public Services: Learning from Cancelled Systems, Carnegie UK, https://carnegieuk.org/publication/automating-public-services-learning-from-cancelled-systems/.
[229]
Redden, J. and M. O'Donovan Dix (2020), Artificial intelligence in the criminal justice system: Demystifying artificial intelligence, its applications, and potential risks, https://www.ojp.gov/ncjrs/virtual-library/abstracts/artificial-intelligence-criminal-justice-system-demystifying.
[290]
Reiling, D. (2020), Courts and artificial intelligence, https://doi.org/10.36745/ijca.343.
[292]
Richardson, A., T. van Florenstein Mulder and T. Vehbi (2019), Nowcasting GDP using machine learning algorithms: A real-time assessment, https://www.rbnz.govt.nz/-/media/c0bb0238351244c986e33550b36bd2d4.ashx.
[6]
Rinaldi, F., G. Giuffrida and T. Negrete (2017), Real-Time Monitoring and Evaluation—Emerging News as Predictive Process Using Big Data-Based Approach, Routledge.
[110]
Rivero del Paso, L. et al. (2023), Digital Solutions Guidelines for Public Financial Management, https://www.imf.org/en/Publications/TNM/Issues/2023/10/06/Digital-Solutions-Guidelines-for-Public-Financial-Management-537781.
[22]
Romberg, J. and T. Escher (2024), “Making Sense of Citizens' Input through Artificial Intelligence: A Review of Methods for Computational Text Analysis to Support the Evaluation of Contributions in Public Participatio", Digital Government: Research and Practice, pp. 1-30, https://doi.org/10.1145/3603254.
[179]
Salazar, A., J. Pérez and J. Gallego (2024), “VigIA: prioritizing public procurement oversight with machine learning models and risk indices”, Data &amp; Policy, Vol. 6, https://doi.org/10.1017/dap.2024.83.
[100]
Santiso, C. (2022), “Govtech against corruption: What are the integrity dividends of government digitalization?", Data & Policy, Vol. 4, https://doi.org/10.1017/dap.2022.31.
[76]
Schneider, B. and N. Sanders (2023), Al could shore up democracy - here's one way, https://theconversation.com/ai-could-shore-up-democracy-heres-one-way-207278 (accessed on 23 May 2024).
[166]
SDAIA (2024), SDAIA Showcases National Smart C Platform and National Algorithms for Smart Cities at Barcelona Expo, https://sdaia.gov.sa/en/MediaCenter/News/Pages/NewsDetails.aspx?NewsID=228.
[205]
Seto, J. (2018), Using Al and IoT for disaster management, https://azure.microsoft.com/en-us/blog/using-ai-and-iot-for-disaster-management/ (accessed on 3 March 2025).
[271]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 297
Shark, A. (2025), What the Rising Costs of Al Means for Government, https://statetechmagazine.com/article/2025/01/what-rising-costs-ai-means-government.
[236]
Shark, A. (2024), Artificial Intelligence: The Impact on Public Procurement - Opportunity & Risk, https://www.nigp.org/blog/ai-and-public-procurement.
[84]
Slovenia Ministry of Justice (2024), Information request to Maja Velic, advisor of the Ministry of Justice of Slovenia.
[296]
Soman, D. (2024), What Works, What Doesn't (and When): Case Studies in Applied Behavioral Science, https://utppublishing.com/doi/book/10.3138/9781487548735.
[228]
Sommer, J. (2021), La Cour de cassation à l'épreuve du numérique et de l'intelligence artificielle, https://www.vie-publique.fr/parole-dexpert/278415-la-cour-de-cassation-face-au-numerique-et-lintelligence-artificielle (accessed on 19 February 2025).
[303]
Song, C. and J. Lee (2015), "Citizens' Use of Social Media in Government, Perceived Transparency, and Trust in Government”, Public Performance &amp; Management Review, Vol. 39/2, pp. 430-453, https://doi.org/10.1080/15309576.2015.1108798.
[186]
Spain Ministry of Justice (2024), Política de uso de la IA en la Administración de Justicia, https://www.administraciondejusticia.gob.es/w/aprobada-la-politica-de-uso-de-la-ia-en-la-administracion-de-justicia.
[314]
Spain Ministry of Justice (2022), Digital transformation within the adminisitration of justice, https://www.mjusticia.gob.es/es/JusticiaEspana/ProyectosTransformacionJusticia/Documents/202209%20Digital%20Transformation%20[ENG].pdf (accessed on 19 February 2025).
[301]
Statistics Denmark (2025), Microdata schemes in Statistics Denmark, https://www.dst.dk/en/TilSalg/Forskningsservice/Dataadgang/Projektoprettelse.
[137]
Stettinger, G., P. Weissensteiner and S. Khastgir (2024), “Trustworthiness Assurance Assessment for High-Risk Al-Based Systems”, IEEE Access, Vol. 12, pp. 22718-22745, https://doi.org/10.1109/access.2024.3364387.
[277]
STF (2024), STF lança MARIA, ferramenta de inteligência artificial que dará mais agilidade aos serviços do Tribunal, https://noticias.stf.jus.br/postsnoticias/stf-lanca-maria-ferramenta-de-inteligencia-artificial-que-dara-mais-agilidade-aos-servicos-do-tribunal/.
[299]
Straub, V. et al. (2024), Al for bureaucratic productivity: Measuring the potential of Al to help automate 143 million UK government transactions, https://www.turing.ac.uk/sites/default/files/2024-03/ai_for_bureaucratic_productivity.pdf.
[199]
Sumner, J. et al. (2023), “Developing an Artificial Intelligence-Driven Nudge Intervention to Improve Medication Adherence: A Human-Centred Design Approach", Journal of Medical Systems, Vol. 48/1, https://doi.org/10.1007/s10916-023-02024-0.
[242]
Sunass (2024), Use of big data and Al in water regulation: Experience from Sunass, Peru, https://cdn.www.gob.pe/uploads/document/file/6872996/5943561-presentacion-en-la-red-de-reguladores-economicos-o-network-economic-regulators-ner.pdf.
[38]
Sun, T. and R. Medaglia (2019), “Mapping the challenges of Artificial Intelligence in the public sector: Evidence from public healthcare", Government Information Quarterly, Vol. 36/2, pp. 368-383, https://doi.org/10.1016/j.giq.2018.09.008.
[197]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
298 |
Supreme Court of Brazil (2024), Information request to Victor Durigan, advisor to the Supreme Court.
[294]
Taşdöken, Ö. (2024), “Use of Artificial Intelligence and Audit Analytics in Internal Audit Processes in the Public Sector”, EDPACS, Vol. 69/9, pp. 1-15, https://doi.org/10.1080/07366981.2024.2376790.
[94]
TBI (2024), The Economic Case for Reimagining the State, Tony Blair Institute for Global Change, https://institute.global/insights/economic-prosperity/the-economic-case-for-reimagining-the-state.
[219]
Tejwani, R. et al. (2020), Migratable Al: Effect of identity and information migration on users perception of conversational Al agents, https://ieeexplore.ieee.org/document/9223436.
[209]
Tenorio, J. and W. Perez (2023), GDP nowcasting with Machine Learning and Unstructured Data to Peru, https://perueconomics.org/wp-content/uploads/2023/11/WP-197.pdf.
[8]
The Alan Turing Institute (2023), Al Skills for Business Competency Framework, https://www.turing.ac.uk/skills/collaborate/ai-skills-business-framework.
[132]
The Computational Democracy Project (2024), The Computational Democracy Project, https://compdemocracy.org/.
[162]
The World Bank (2023), OUTPUT 14 - Report on the proposed tool for screening of legislation, https://documents1.worldbank.org/curated/en/099011924055735846/pdf/P169141129e0ad0f618892137a09a4eb9f9.pdf.
[68]
Thiebes, S., S. Lins and A. Sunyaev (2020), “Trustworthy artificial intelligence”, Electronic Markets, Vol. 31/2, pp. 447-464, https://doi.org/10.1007/s12525-020-00441-4.
[235]
Thomas, J. et al. (2024), Responsible Alin Evidence Synthesis (RAISE): guidance and recommendations, https://osf.io/fwaud/.
[113]
Tilon, S. et al. (2020), “Post-Disaster Building Damage Detection from Earth Observation Imagery Using Unsupervised and Transferable Anomaly Detecting Generative Adversarial Networks", Remote Sensing, Vol. 12/24, p. 4193, https://doi.org/10.3390/rs12244193.
[268]
Trajkovski, G. (2024), "Bridging the public administration-Al divide: A skills perspective", Public Administration and Development, Vol. 44/5, pp. 412-426, https://doi.org/10.1002/pad.2061.
[240]
Tribune News Service (2023), State Legislature Adopts Resolution on Al ... Drafted by Al, https://insider.govtech.com/california/news/state-legislature-adopts-resolution-on-ai-drafted-by-ai.
[26]
Tsai, L. et al. (2024), "Generative Al for Pro-Democracy Platforms”, An MIT Exploration of Generative Al, https://doi.org/10.21428/e4baedd9.5aaf489a.
[160]
U4 (2025), Unlocking Al's potential in anti-corruption: Hype vs. reality, https://www.u4.no/blog/unlocking-ai-s-potential-in-anti-corruption-hype-vs-reality.
[106]
UC Berkeley (2021), Positive Al Economic Futures, World Economic Forum, https://www.weforum.org/reports/positive-ai-economic-futures.
[56]
GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

| 299

Ugale, G. and C. Hall (2024), “Generative Al for anti-corruption and integrity in government: Taking stock of promise, perils and practice", OECD Artificial Intelligence Papers, No. 12, OECD Publishing, Paris, https://doi.org/10.1787/657a185a-en.
[89]

UK Government Office for Science (2023), Future Risks of Frontier Al, https://assets.publishing.service.gov.uk/media/653bc393d10f3500139a6ac5/future-risks-of-frontier-ai-annex-a.pdf.
[145]

UK National Audit Office (2023), Report on Accounts - Department for Work & Pensions, https://www.nao.org.uk/wp-content/uploads/2023/07/dwp-report-on-accounts-2022-23.pdf.
[98]

UNESCO (2025), Artificial Intelligence and the Rule of Law, https://www.unesco.org/en/artificial-intelligence/rule-law.
[318]

UNESCO (2019), Artificial Intelligence in Education: Challenges and Opportunities for Sustainable Development, https://repositorio.minedu.gob.pe/bitstream/handle/20.500.12799/6533/Artificial%20intelligenc
e%20in%20education%20challenges%20and%20opportunities%20for%20sustainable%20de
velopment.pdf.
[232]

United Kingdom (2023), Artificial Intelligence (AI) – Judicial Guidance, https://www.judiciary.uk/guidance-and-resources/artificial-intelligence-ai-judicial-guidance/.
[316]

University of Turku (2023), TurkuNLP, https://turkunlp.org/ (accessed on 23 May 2024).
[181]

UNU Institute for Environment and Human Security (2024), 5 Ways Al Can Strengthen Early Warning Systems, https://unu.edu/ehs/series/5-ways-ai-can-strengthen-early-warning-systems (accessed on 4 March 2025).
[274]

US DHS (2024), DHS Launches First-of-its-Kind Initiative to Hire 50 Artificial Intelligence Experts in 2024, https://www.dhs.gov/archive/news/2024/02/06/dhs-launches-first-its-kind-initiative-hire-50-artificial-intelligence-experts-2024.
[264]

US DHS (2024), United States Customs and Border Protection – Al Use Cases, https://www.dhs.gov/ai/use-case-inventory/cbp#deployed (accessed on 3 March 2025).
[263]

US FOIA (2023), FOIA Reference Model White Paper, FOIA.gov, https://www.foia.gov/chief-foia-officers-council/foia-reference-model-white-paper-april-19-2023.
[147]

US GAO (2024), Facial Recognition Technology: Federal Law Enforcement Agency Efforts Related to Civil Rights and Training, United States Government Accountability Office, https://www.gao.gov/products/gao-24-107372.
[258]

Valderrama, M., M. Hermosilla and R. Garrido (2023), State of the Evidence: Algorithmic Transparency, https://www.opengovpartnership.org/documents/state-of-the-evidence-algorithmic-transparency/.
[44]

van Baal, S. (2024), “Testing behaviour change with an artificial intelligence chatbot in a randomized controlled study.”, Journal Public Health, Vol. 45, pp. 506-522, https://doi.org/10.1057/s41271-024-00500-6.
[208]

van Noordt, C. and G. Misuraca (2019), "New Wine in Old Bottles: Chatbots in Government", in Lecture Notes in Computer Science, Electronic Participation, Springer International Publishing, Cham, https://doi.org/10.1007/978-3-030-27397-2_5.
[170]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
300 |

van Noordt, C. and L. Tangi (2023), “The dynamics of Al capability and its influence on public value creation of Al within public administration", Government Information Quarterly, Vol. 40/4, p. 101860, https://doi.org/10.1016/j.giq.2023.101860.
[15]

Vogl, T. et al. (2019), “Algorithmic Bureaucracy”, Proceedings of the 20th Annual International Conference on Digital Government Research, https://doi.org/10.1145/3325112.3325240.
[247]

Walprecht, S. and C. Lewerenz (2024), Facilitating Regulatory Impact Assessments: The Benefits of Machine Learning in Legislation, https://www.destatis.de/EN/About-Us/Events/Machine-Learning/Slides/s2_walprecht.pdf.
[30]

Wastupranata, L., S. Kong and L. Wang (2024), “Deep Learning for Abnormal Human Behavior Detection in Surveillance Videos—A Survey”, Electronics, Vol. 13/13, p. 2579, https://doi.org/10.3390/electronics13132579.
[262]

Welker, Y. (2023), Generative Al holds great potential for those with disabilities - but it needs policy to shape it, https://www.weforum.org/agenda/2023/11/generative-ai-holds-potential-disabilities/ (accessed on 24 May 2024).
[154]

Weyl, E., A. Tang and C. Plurality (2022), Augmented Deliberation, https://www.plurality.net/v/chapters/5-4/eng.
[157]

Wisesa, A. (2023), "Inovasi artificial intelligence sebagai financial advisor kementerian keuangan", Swatantra, Vol. XX, pp. 1-8, https://jurnal.umj.ac.id/index.php/SWATANTRA/article/viewFile/15611/8230.
[11]

World Justice Project (2021), Grasping the Justice Gap: Opportunities and Challenges for People-Centered Justice Data, https://worldjusticeproject.org/news/grasping-justice-gap-opportunities-and-challenges-people-centered-justice-data.
[312]

Xavier, O. et al. (2022), "Tax evasion identification using open data and artificial intelligence", Revista de Administração Pública, Vol. 56/3, pp. 426-440, https://doi.org/10.1590/0034-761220210256x.
[323]

Yao, M. (ed.) (2025), “Tailoring generative Al chatbots for multiethnic communities in disaster preparedness communication: extending the CASA paradigm", Journal of Computer-Mediated Communication, Vol. 30/1, https://doi.org/10.1093/jcmc/zmae022.
[275]

Zhang, G., H. Atasoy and M. Vasarhelyi (2022), “Continuous monitoring with machine learning and interactive data visualization: An application to a healthcare payroll process", International Journal of Accounting Information Systems, Vol. 46, p. 100570, https://doi.org/10.1016/j.accinf.2022.100570.
[324]

Zilka, M., H. Sargeant and A. Weller (2022), “Transparency, Governance and Regulation of Algorithmic Tools Deployed in the Criminal Justice System: a UK Case Study”, Proceedings of the 2022 AAAI/ACM Conference on Al, Ethics, and Society, https://doi.org/10.1145/3514094.3534200.
[325]

Zinnbauer, D. (2025), Un-Plateauing Corruption Research? Perhaps less necessary, but more exciting than one might think, Elsevier BV, https://doi.org/10.2139/ssrn.5094531.
[105]

Ziyadin, S. et al. (eds.) (2020), “Experience of Artificial Intelligence Implementation in Japan", E3S Web of Conferences, Vol. 159, p. 04035, https://doi.org/10.1051/e3sconf/202015904035.
[265]

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 301

# Notes

1 https://www.aade.gr/sites/default/files/2024-12/dt_.11.12.24.pdf.

2 https://www.tovima.gr/2023/05/29/finance/aade-pos-i-texniti-noimosyni-apokalyptei-tis-adilotes-pisines.

3 https://www.aade.gr/sites/default/files/2024-12.

4 https://www.oecd.org/en/data/datasets/inventory-of-tax-technology-initiatives.html

5 https://www.mononews.gr/oikonomia/aade-sta-skaria-chatbox-gia-tis-forologikes-diloseis.

6 Rules as Code (RaC) is the practice of translating legal rules and regulations into machine-readable formats (Mohun and Roberts, 2020[4]). This approach enables automated compliance checking and enforcement, and supports decision-making based on predefined legal frameworks. When applying Al in tax administration, RaC can help ensure that Al supported decision making is transparent, consistent across cases, and legally compliant. RaC can thereby help increasing public trust and accountability in Al application.

7 Macrofiscal forecasting is the process of predicting key economic and government finance indicators, including GDP growth, inflation, tax revenues, public spending, and debt levels. These forecasts help governments plan budgets, set fiscal policy, and manage public finances over multi-year periods.

8 https://ask.u.ae/en.

9 Based on OECD discussions and working party meetings with PFM officials.

10 The OECD (2021[329]) Recommendation for Agile Regulatory Governance aims to help governments develop and implement agile and resilient regulatory approaches and facilitate institutional co-operation in response to and to stimulate innovation. It highlights the need to adjust regulatory management tools, and enable greater experimentation to foster continuous learning and adaptation.

11 The 22nd meeting of the OECD Network of Economic Regulators held in Paris in April 2024.

12 https://www.oecd.org/en/networks/network-of-economic-regulators.html.

13 Unless otherwise cited, details have been sourced from OECD engagement and work with national regulators.

14 Information provided by the Government of Israel to the OECD.

15 Internal Meeting of the Network of Economic Regulators (2024).

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
302 |

16 https://www.singaporetech.edu.sg/news/impressai-revolutionises-talent-acquisition-government-agencies.

17 See https://www.mynewsdesk.com/tengai-interview-robot/pressreleases/swedish-muncipality-first-in-the-world-to-use-social-interview-robot-tengai-in-recruitment-2878357.

18 https://hbr.org/2022/11/how-walmart-automated-supplier-negotiations.

19 https://autogenai.com.

20 https://sievo.com.

21 https://www.docusign.com.

22 See also the section in this chapter on the use of "Al in public procurement”.

23 Interview with the Dutch Court of Audit.

24 Information provided by ECA officials.

25 See https://www.oecd.org/en/about/projects/tech-connect-for-integrity.html.

26 https://kudos.dfo.no.

27 https://opendata.dc.gov/pages/compass.

28 https://opencouncil.gr.

29 https://www.mapletestimony.org.

30 https://ai.gov.uk/consultations.

31 https://www.govocal.com.

32 https://panoramic.make.org/customer/cese/event/convention-citoyenne-sur-la-fin-de-vie.

33 See https://oe.cd/immersive-brief for an OECD briefing document on immersive technologies.

34 The key opportunities for public communication identified in this paragraph are the results of interviews conducted by the OECD in 2023-2024 with members of the OECD Public Communication Network.

35 https://oecd-opsi.org/innovations/use-of-robotic-process-automation-in-forensic-routines/

36 https://oecd-opsi.org/innovations/streamlined-benefits-for-a-more-equal-society/

37 See https://cms.hacienda.cl/cmod_cl/assets/documento/descargar/3a29739655166/1712674476.

38 See https://ai.gov.uk/projects/caddy.

39 https://www.tech.gov.sg/gtpc-product-1.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---
| 303

40 https://oecd-opsi.org/innovations/no-show-prediction-at-outpatient-clinic.

41 Proactive public services are services that a public organisation “pushes” toward its counterparts based on their "needs, circumstance, personal preferences, life events and location" (Linders, Liao and Wang, 2018[321]).

42 Use cases for Al have centred around high-stakes, data-rich areas including safety and security (e.g. risk detection, prediction and simulation (Margetts and Dorobantu, 2019[322]; Xavier et al., 2022[323]; Zhang, Atasoy and Vasarhelyi, 2022[324]), facial-recognition in policing (Zilka, Sargeant and Weller, 2022[325]), recidivism prediction in criminal justice (Kleinberg et al., 2017[326]), process automation (Ojo, Mellouli and Ahmadi Zeleti, 2019[327]) and forecasting future needs in services (Bright et al., 2019[328]).

43 See https://www.oecd.org/en/topics/privacy-enhancing-technologies.html.

44 https://u.ae/en/about-the-uae/digital-uae/digital-technology/artificial-intelligence/rules-as-code.

45 First, public services can be divided into general (generally provided, e.g. traffic lights) and specific (individually requested and specifically directed).

46 See https://www.youtube.com/watch?v=JzLhcQijsz4, https://epiteliki.civilprotection.gov.gr/sites/default/files/2024-01/%CE%94%CE%B9%CE%B1%CE%BA%CE%AE%CF%81%CF%85%CE%BE%CE%B7_%CE%A0%CF%85%CF%81%CE%B1%CE%BD%CE%AF%CF%87%CE%BD%CE%B5%CF%85%CF%83%CE%B7_24PROC014095623_03.01.2024.pdf and https://civilprotection.gov.gr/en/deltia-tupou/b-kikilias-i-tehniti-noimosyni-stin-ypiresia-tis-asfaleias-ton-politon (in Greek).

47 https://www.ktpae.gr/erga/anavathmisi-kai-epektasi-upodomon-tpe-tomea-dikaiosinis.

48 Information provided by Government of Greece officials.

49 Information provided by officials of the Ministry of Presidency, Justice and Parliamentary Relations to the OECD.

50 Protective measures refer to actions or legal mechanisms put in place to safeguard the rights, safety, or interests of individuals or groups, often in the context of vulnerable parties or during legal proceedings.

51 Information provided by Government of Israel officials to the OECD.

52 https://ministryofjustice.gr/?page_id=7483.

GOVERNING WITH ARTIFICIAL INTELLIGENCE © OECD 2025

---

# Governing with Artificial Intelligence
The State of Play and Way Forward in Core Government Functions

Artificial intelligence (AI) is one of the most transformative forces of the 21st century, becoming an integral part of digital government worldwide. Governments' use of AI can facilitate automated and tailored internal processes and public services; foster better decision making and forecasting; improve fraud detection; and improve public servants' job quality and learning — with tangible impacts. This report explores 200 real-world examples of how governments are using AI across 11 core functions — from delivering public services and administering justice to fighting corruption, managing finances, and reforming the civil service. It highlights the unique opportunities and risks AI presents in government, delves into the challenges governments face when adopting these technologies, and offers insights into the enablers, safeguards, and engagement strategies needed to ensure AI is used in a trustworthy and effective way.

PRINT ISBN 978-92-64-81828-6
PDF ISBN 978-92-64-68405-8

9789264818286